Current working directory: /home/v-zhijunjia/CodecGen
Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (numpy 1.24.0 (/home/v-zhijunjia/.local/lib/python3.10/site-packages), Requirement.parse('numpy!=1.19.3,<1.24; sys_platform == "linux"'), {'azureml-dataset-runtime'}).
2024-04-02 06:22:59 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
/home/v-zhijunjia/miniconda3/envs/valle-4-23/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MiniBatchKMeans from version 0.24.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
only_antoregressive is True
add_prenet is False
self.ar_text_prenet : Identity()
add_prenet：False
self.encoder_layers:6
self.decoder_layers：6
only_antoregressive is True
add_prenet is False
self.ar_text_prenet : None
add_prenet：False
[]
  0%|          | 0/1232 [00:00<?, ?it/s]processing 0th semantic_sys file
0
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE IS UNDER SAIL BUT SHE IS COUNT TIMASCHEFF'S YACHT HE WAS RIGHT
2024-04-02 06:23:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28240-0003.json
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([222.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 275, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28240-0003
generate
  0%|          | 1/1232 [00:00<17:59,  1.14it/s]processing 1th semantic_sys file
1
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SERVADAC TOOK IT FOR GRANTED THAT THE DOBRYNA WAS ENDEAVORING TO PUT IN
2024-04-02 06:23:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28240-0007.json
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 253, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28240-0007
generate
  0%|          | 2/1232 [00:01<13:11,  1.55it/s]processing 2th semantic_sys file
2
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT WAS ON THE LAST DAY OF JANUARY THAT THE REPAIRS OF THE SCHOONER WERE COMPLETED
2024-04-02 06:23:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28240-0022.json
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([273.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 302, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28240-0022
generate
  0%|          | 3/1232 [00:01<10:55,  1.88it/s]processing 3th semantic_sys file
3
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FAST AS HIS LEGS COULD CARRY HIM SERVADAC HAD MADE HIS WAY TO THE TOP OF THE CLIFF
2024-04-02 06:23:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28240-0000.json
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 218, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28240-0000
generate
  0%|          | 4/1232 [00:02<09:16,  2.21it/s]processing 4th semantic_sys file
4
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NEVER MIND NOW INTERPOSED THE CAPTAIN WE WILL TALK OF THAT BY AND BY
2024-04-02 06:23:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28240-0012.json
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([317.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 351, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28240-0012
generate
  0%|          | 5/1232 [00:02<09:09,  2.23it/s]processing 5th semantic_sys file
5
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IF THE COUNT WERE ON BOARD A STRANGE FATALITY WAS BRINGING HIM TO THE PRESENCE OF HIS RIVAL
2024-04-02 06:23:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28240-0004.json
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 271, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28240-0004
generate
  0%|          | 6/1232 [00:02<08:37,  2.37it/s]processing 6th semantic_sys file
6
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TO ALL THESE INQUIRIES THE COUNT RESPONDED IN THE AFFIRMATIVE
2024-04-02 06:23:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28240-0016.json
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 217, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28240-0016
generate
  1%|          | 7/1232 [00:03<07:55,  2.57it/s]processing 7th semantic_sys file
7
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE RECKONED THEREFORE NOT ONLY UPON ASCERTAINING THE EXTENT OF THE LATE CATASTROPHE BUT UPON LEARNING ITS CAUSE
2024-04-02 06:23:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28240-0005.json
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([253.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([284.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 314, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28240-0005
generate
  1%|          | 8/1232 [00:03<08:01,  2.54it/s]processing 8th semantic_sys file
8
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SOME MYSTERIOUS FORCE SEEMED TO HAVE BROUGHT ABOUT A CONVULSION OF THE ELEMENTS
2024-04-02 06:23:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([52], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28240-0017.json
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 264, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28240-0017
generate
  1%|          | 9/1232 [00:03<07:42,  2.65it/s]processing 9th semantic_sys file
9
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MY YACHT IS AT YOUR SERVICE SIR EVEN SHOULD YOU REQUIRE TO MAKE A TOUR ROUND THE WORLD
2024-04-02 06:23:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28240-0019.json
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 234, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28240-0019
generate
  1%|          | 10/1232 [00:04<07:26,  2.74it/s]processing 10th semantic_sys file
10
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I LEFT YOU ON A CONTINENT AND HERE I HAVE THE HONOR OF FINDING YOU ON AN ISLAND
2024-04-02 06:23:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([57], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28240-0011.json
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([264.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([313.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([366.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([421.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([477.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([534.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 592, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28240-0011
generate
  1%|          | 11/1232 [00:04<08:50,  2.30it/s]processing 11th semantic_sys file
11
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: EXCLAIMED SERVADAC KEEPING HIS EYE UNMOVED AT HIS TELESCOPE
2024-04-02 06:23:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28240-0002.json
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 234, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28240-0002
generate
  1%|          | 12/1232 [00:05<08:14,  2.47it/s]processing 12th semantic_sys file
12
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DOUBTS NOW AROSE AND SOME DISCUSSION FOLLOWED WHETHER OR NOT IT WAS DESIRABLE FOR BEN ZOOF TO ACCOMPANY HIS MASTER
2024-04-02 06:23:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28240-0024.json
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([292.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([335.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([380.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([426.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 472, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28240-0024
generate
  1%|          | 13/1232 [00:05<09:16,  2.19it/s]processing 13th semantic_sys file
13
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FOR SOME MOMENTS HE SEEMED PERFECTLY STUPEFIED THEN RECOVERING HIMSELF HE BEGAN TO OVERWHELM THE COUNT WITH A TORRENT OF QUESTIONS
2024-04-02 06:23:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28240-0015.json
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([251.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([293.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([337.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([382.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([428.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 474, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28240-0015
generate
  1%|          | 14/1232 [00:06<09:30,  2.13it/s]processing 14th semantic_sys file
14
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE EARTH HAS UNDOUBTEDLY ENTERED UPON A NEW ORBIT BUT SHE IS NOT INCURRING ANY PROBABLE RISK OF BEING PRECIPITATED ONTO THE SUN
2024-04-02 06:23:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28241-0008.json
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([304.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([349.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([396.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([443.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 491, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28241-0008
generate
  1%|          | 15/1232 [00:06<09:55,  2.04it/s]processing 15th semantic_sys file
15
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND WHAT DEMONSTRATION DO YOU OFFER ASKED SERVADAC EAGERLY THAT IT WILL NOT HAPPEN
2024-04-02 06:23:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28241-0009.json
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([258.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 286, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28241-0009
generate
  1%|▏         | 16/1232 [00:07<09:13,  2.20it/s]processing 16th semantic_sys file
16
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WOULD NOT THE LOFTIEST EMINENCES OF THE CITY AT LEAST BE VISIBLE
2024-04-02 06:23:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28241-0013.json
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 208, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28241-0013
generate
  1%|▏         | 17/1232 [00:07<08:28,  2.39it/s]processing 17th semantic_sys file
17
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE LOG AND THE COMPASS THEREFORE WERE ABLE TO BE CALLED UPON TO DO THE WORK OF THE SEXTANT WHICH HAD BECOME UTTERLY USELESS
2024-04-02 06:23:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([25], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28241-0006.json
top_k_know_token:70
known_token_update:False
T:585
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:585
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:585
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:585
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:585
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:585
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:585
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:585
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:585
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:585
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:585
T - mask_len:tensor([310.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:585
T - mask_len:tensor([362.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:585
T - mask_len:tensor([416.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:585
T - mask_len:tensor([471.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:585
T - mask_len:tensor([528.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 585, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28241-0006
generate
  1%|▏         | 18/1232 [00:08<09:31,  2.13it/s]processing 18th semantic_sys file
18
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FOR A FEW MILES SHE FOLLOWED THE LINE HITHERTO PRESUMABLY OCCUPIED BY THE COAST OF ALGERIA BUT NO LAND APPEARED TO THE SOUTH
2024-04-02 06:23:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28241-0005.json
top_k_know_token:70
known_token_update:False
T:527
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:527
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:527
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:527
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:527
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:527
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:527
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:527
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:527
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:527
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:527
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:527
T - mask_len:tensor([326.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:527
T - mask_len:tensor([375.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:527
T - mask_len:tensor([425.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:527
T - mask_len:tensor([476.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 527, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28241-0005
generate
  2%|▏         | 19/1232 [00:08<10:02,  2.01it/s]processing 19th semantic_sys file
19
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IS IT NOT IMPOSSIBLE HE MURMURED ALOUD THAT ANY CITY SHOULD DISAPPEAR SO COMPLETELY
2024-04-02 06:23:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28241-0012.json
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([258.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 285, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28241-0012
generate
  2%|▏         | 20/1232 [00:09<09:14,  2.19it/s]processing 20th semantic_sys file
20
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU MUST SEE LIEUTENANT I SHOULD THINK THAT WE ARE NOT SO NEAR THE COAST OF ALGERIA AS YOU IMAGINED
2024-04-02 06:23:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28241-0016.json
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([258.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 285, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28241-0016
generate
  2%|▏         | 21/1232 [00:09<08:40,  2.33it/s]processing 21th semantic_sys file
21
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NOTHING WAS TO BE DONE BUT TO PUT ABOUT AND RETURN IN DISAPPOINTMENT TOWARDS THE NORTH
2024-04-02 06:23:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28241-0019.json
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([261.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 289, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28241-0019
generate
  2%|▏         | 22/1232 [00:09<08:16,  2.44it/s]processing 22th semantic_sys file
22
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HER SEA GOING QUALITIES WERE EXCELLENT AND WOULD HAVE AMPLY SUFFICED FOR A CIRCUMNAVIGATION OF THE GLOBE
2024-04-02 06:23:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28241-0000.json
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([273.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([305.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 338, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28241-0000
generate
  2%|▏         | 23/1232 [00:10<08:39,  2.33it/s]processing 23th semantic_sys file
23
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: LENGTH OF SERVICE FOURTEEN YEARS THREE MONTHS AND FIVE DAYS
2024-04-02 06:23:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28233-0000.json
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 207, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28233-0000
generate
  2%|▏         | 24/1232 [00:10<07:59,  2.52it/s]processing 24th semantic_sys file
24
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE SEEMED BORN TO PLEASE WITHOUT BEING CONSCIOUS OF THE POWER HE POSSESSED
2024-04-02 06:23:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28233-0001.json
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([222.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([324.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 359, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28233-0001
generate
  2%|▏         | 25/1232 [00:11<08:08,  2.47it/s]processing 25th semantic_sys file
25
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ONCE IN ACTION HE WAS LEADING A DETACHMENT OF INFANTRY THROUGH AN INTRENCHMENT
2024-04-02 06:23:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28233-0004.json
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 210, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28233-0004
generate
  2%|▏         | 26/1232 [00:11<07:38,  2.63it/s]processing 26th semantic_sys file
26
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT MUST BE OWNED AND NO ONE WAS MORE READY TO CONFESS IT THAN HIMSELF THAT HIS LITERARY ATTAINMENTS WERE BY NO MEANS OF A HIGH ORDER
2024-04-02 06:23:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28233-0002.json
top_k_know_token:70
known_token_update:False
T:642
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:642
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:642
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:642
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:642
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:642
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:642
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:642
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:642
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:642
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:642
T - mask_len:tensor([340.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:642
T - mask_len:tensor([397.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:642
T - mask_len:tensor([456.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:642
T - mask_len:tensor([517.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:642
T - mask_len:tensor([580.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 642, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28233-0002
generate
  2%|▏         | 27/1232 [00:11<09:12,  2.18it/s]processing 27th semantic_sys file
27
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NO CATHEDRAL NOT EVEN BURGOS ITSELF COULD VIE WITH THE CHURCH AT MONTMARTRE
2024-04-02 06:23:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28233-0006.json
top_k_know_token:70
known_token_update:False
T:198
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:198
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:198
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:198
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:198
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:198
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:198
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:198
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:198
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:198
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:198
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:198
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:198
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:198
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:198
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 198, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5105-28233-0006
generate
  2%|▏         | 28/1232 [00:12<09:14,  2.17it/s]processing 28th semantic_sys file
28
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YES BUT THE MERIDIAN OF THE PALAIS ROYAL IS THE MOST EXACT
2024-04-02 06:23:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3729-6852-0026.json
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 230, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3729-6852-0026
generate
  2%|▏         | 29/1232 [00:12<08:25,  2.38it/s]processing 29th semantic_sys file
29
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MY REMARK PLEASES HIM BUT I SOON PROVE TO HIM THAT IT IS NOT THE RIGHT WAY TO SPEAK HOWEVER PERFECT MAY HAVE BEEN THE LANGUAGE OF THAT ANCIENT WRITER
2024-04-02 06:23:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3729-6852-0023.json
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([333.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([383.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([434.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([487.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 539, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3729-6852-0023
generate
  2%|▏         | 30/1232 [00:13<09:14,  2.17it/s]processing 30th semantic_sys file
30
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I SEE A CROWD IN ONE CORNER OF THE GARDEN EVERYBODY STANDING STILL AND LOOKING UP
2024-04-02 06:23:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3729-6852-0024.json
top_k_know_token:70
known_token_update:False
T:281
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:281
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:281
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:281
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:281
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:281
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:281
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:281
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:281
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:281
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:281
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:281
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:281
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:281
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:281
T - mask_len:tensor([254.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 281, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3729-6852-0024
generate
  3%|▎         | 31/1232 [00:13<08:40,  2.31it/s]processing 31th semantic_sys file
31
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I ADDRESS HIM IN ITALIAN AND HE ANSWERS VERY WITTILY BUT HIS WAY OF SPEAKING MAKES ME SMILE AND I TELL HIM WHY
2024-04-02 06:23:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([25], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3729-6852-0022.json
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([300.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([345.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([391.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([438.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 485, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3729-6852-0022
generate
  3%|▎         | 32/1232 [00:14<09:04,  2.20it/s]processing 32th semantic_sys file
32
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MADAME QUINSON BESIDES CAN ANSWER YOUR ENQUIRIES
2024-04-02 06:23:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3729-6852-0016.json
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 149, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3729-6852-0016
generate
  3%|▎         | 33/1232 [00:14<08:47,  2.27it/s]processing 33th semantic_sys file
33
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I SIT DOWN AT A SMALL TABLE A WAITER COMES IMMEDIATELY TO ENQUIRE MY WISHES
2024-04-02 06:23:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3729-6852-0018.json
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 225, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3729-6852-0018
generate
  3%|▎         | 34/1232 [00:14<08:10,  2.44it/s]processing 34th semantic_sys file
34
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ALL THESE HONEST PERSONS ARE WAITING THEIR TURN TO GET THEIR SNUFF BOXES FILLED
2024-04-02 06:23:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3729-6852-0028.json
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 194, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3729-6852-0028
generate
  3%|▎         | 35/1232 [00:15<07:40,  2.60it/s]processing 35th semantic_sys file
35
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HERE GO AND GET ME CHANGE FOR A LOUIS I HAVE IT SIR
2024-04-02 06:23:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3729-6852-0014.json
top_k_know_token:70
known_token_update:False
T:205
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:205
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:205
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:205
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:205
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:205
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:205
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:205
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:205
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:205
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:205
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:205
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:205
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:205
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:205
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 205, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3729-6852-0014
generate
  3%|▎         | 36/1232 [00:15<07:17,  2.73it/s]processing 36th semantic_sys file
36
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I HAD A NAME I BELIEVE IN MY YOUNG DAYS BUT I HAVE FORGOTTEN IT SINCE I HAVE BEEN IN SERVICE
2024-04-02 06:23:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3729-6852-0011.json
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([271.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 300, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3729-6852-0011
generate
  3%|▎         | 37/1232 [00:15<07:28,  2.66it/s]processing 37th semantic_sys file
37
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WILL MAKE YOU TRANSLATE THEM INTO FRENCH AND YOU NEED NOT BE AFRAID OF MY FINDING YOU INSATIABLE
2024-04-02 06:23:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3729-6852-0044.json
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([261.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 289, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3729-6852-0044
generate
  3%|▎         | 38/1232 [00:16<07:25,  2.68it/s]processing 38th semantic_sys file
38
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHEN THE KING COMES TO PARIS EVERYBODY CALLS OUT VIVE LE ROI
2024-04-02 06:23:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3729-6852-0036.json
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 182, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3729-6852-0036
generate
  3%|▎         | 39/1232 [00:16<07:49,  2.54it/s]processing 39th semantic_sys file
39
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT IS SOLD EVERYWHERE BUT FOR THE LAST THREE WEEKS NOBODY WILL USE ANY SNUFF BUT THAT SOLD AT THE CIVET CAT
2024-04-02 06:23:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3729-6852-0029.json
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([276.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([317.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([359.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([403.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 446, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3729-6852-0029
generate
  3%|▎         | 40/1232 [00:17<08:20,  2.38it/s]processing 40th semantic_sys file
40
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE HIMSELF RECITED THE SAME PASSAGE IN FRENCH AND POLITELY POINTED OUT THE PARTS IN WHICH HE THOUGHT THAT I HAD IMPROVED ON THE ORIGINAL
2024-04-02 06:23:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3729-6852-0039.json
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([325.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([368.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([413.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 457, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3729-6852-0039
generate
  3%|▎         | 41/1232 [00:17<08:44,  2.27it/s]processing 41th semantic_sys file
41
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT HOW DID SHE MANAGE TO RENDER IT SO FASHIONABLE
2024-04-02 06:23:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3729-6852-0031.json
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 214, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3729-6852-0031
generate
  3%|▎         | 42/1232 [00:18<08:01,  2.47it/s]processing 42th semantic_sys file
42
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN ORDER TO PLEASE HER I SPOKE TO HER OF THE ABBE CONTI AND I HAD OCCASION TO QUOTE TWO LINES OF THAT PROFOUND WRITER
2024-04-02 06:23:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3729-6852-0002.json
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([253.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 280, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3729-6852-0002
generate
  3%|▎         | 43/1232 [00:18<07:46,  2.55it/s]processing 43th semantic_sys file
43
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE INTRODUCED ME TO ALL HER GUESTS AND GAVE ME SOME PARTICULARS RESPECTING EVERY ONE OF THEM
2024-04-02 06:23:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([28], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3729-6852-0037.json
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 304, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3729-6852-0037
generate
  4%|▎         | 44/1232 [00:18<08:37,  2.30it/s]processing 44th semantic_sys file
44
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I RESIDE IN THE MARAIS RUE DE DOUZE PORTES
2024-04-02 06:23:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3729-6852-0043.json
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 143, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3729-6852-0043
generate
  4%|▎         | 45/1232 [00:19<07:41,  2.57it/s]processing 45th semantic_sys file
45
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHAT SIR I SAID TO HIM AM I FORTUNATE ENOUGH TO SEE YOU
2024-04-02 06:23:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3729-6852-0038.json
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 168, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3729-6852-0038
generate
  4%|▎         | 46/1232 [00:19<07:05,  2.79it/s]processing 46th semantic_sys file
46
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE RAFT WAS HEAVED UP ON A WATERY MOUNTAIN AND PITCHED DOWN AGAIN AT A DISTANCE OF TWENTY FATHOMS
2024-04-02 06:23:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123286-0023.json
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 301, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123286-0023
generate
  4%|▍         | 47/1232 [00:19<07:18,  2.70it/s]processing 47th semantic_sys file
47
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FLIGHT WAS OUT OF THE QUESTION NOW THE REPTILES ROSE THEY WHEELED AROUND OUR LITTLE RAFT WITH A RAPIDITY GREATER THAN THAT OF EXPRESS TRAINS
2024-04-02 06:23:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123286-0025.json
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([313.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 346, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123286-0025
generate
  4%|▍         | 48/1232 [00:20<07:38,  2.58it/s]processing 48th semantic_sys file
48
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SUDDENLY THE ICHTHYOSAURUS AND THE PLESIOSAURUS DISAPPEAR BELOW LEAVING A WHIRLPOOL EDDYING IN THE WATER
2024-04-02 06:23:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123286-0030.json
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([259.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([290.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 321, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123286-0030
generate
  4%|▍         | 49/1232 [00:20<07:51,  2.51it/s]processing 49th semantic_sys file
49
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ALL MY DANGER AND SUFFERINGS WERE NEEDED TO STRIKE A SPARK OF HUMAN FEELING OUT OF HIM BUT NOW THAT I AM WELL HIS NATURE HAS RESUMED ITS SWAY
2024-04-02 06:23:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123286-0002.json
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([241.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([314.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([352.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 390, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123286-0002
generate
  4%|▍         | 50/1232 [00:21<08:13,  2.39it/s]processing 50th semantic_sys file
50
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE ARE LOSING TIME AND THE FACT IS I HAVE NOT COME ALL THIS WAY TO TAKE A LITTLE SAIL UPON A POND ON A RAFT
2024-04-02 06:23:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123286-0006.json
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([261.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([304.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([397.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([444.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 492, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123286-0006
generate
  4%|▍         | 51/1232 [00:21<08:55,  2.21it/s]processing 51th semantic_sys file
51
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NOTHING NEW WEATHER UNCHANGED THE WIND FRESHENS
2024-04-02 06:23:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123286-0011.json
top_k_know_token:70
known_token_update:False
T:154
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:154
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:154
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:154
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:154
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:154
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:154
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:154
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:154
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:154
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:154
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:154
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:154
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:154
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:154
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 154, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123286-0011
generate
  4%|▍         | 52/1232 [00:22<07:55,  2.48it/s]processing 52th semantic_sys file
52
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I CAN DISTINGUISH THE EYE OF THE ICHTHYOSAURUS GLOWING LIKE A RED HOT COAL AND AS LARGE AS A MAN'S HEAD
2024-04-02 06:23:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123286-0027.json
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([299.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 331, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123286-0027
generate
  4%|▍         | 53/1232 [00:22<07:58,  2.46it/s]processing 53th semantic_sys file
53
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU SEEM ANXIOUS MY UNCLE I SAID SEEING HIM CONTINUALLY WITH HIS GLASS TO HIS EYE ANXIOUS
2024-04-02 06:23:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123286-0003.json
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 233, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123286-0003
generate
  4%|▍         | 54/1232 [00:22<07:30,  2.62it/s]processing 54th semantic_sys file
54
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THESE THOUGHTS AGITATED ME ALL DAY AND MY IMAGINATION SCARCELY CALMED DOWN AFTER SEVERAL HOURS SLEEP
2024-04-02 06:23:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 55th semantic_sys file
55
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE SHADOW OF THE RAFT WAS CLEARLY OUTLINED UPON THE SURFACE OF THE WAVES
2024-04-02 06:23:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123286-0013.json
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 239, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123286-0013
generate
  5%|▍         | 56/1232 [00:23<05:35,  3.51it/s]processing 56th semantic_sys file
56
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THOSE HUGE CREATURES ATTACKED EACH OTHER WITH THE GREATEST ANIMOSITY
2024-04-02 06:23:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123286-0029.json
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 232, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123286-0029
generate
  5%|▍         | 57/1232 [00:23<05:47,  3.38it/s]processing 57th semantic_sys file
57
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SATURDAY AUGUST FIFTEENTH THE SEA UNBROKEN ALL ROUND NO LAND IN SIGHT
2024-04-02 06:23:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊ'
processing 58th semantic_sys file
58
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I AM NOT COMPLAINING THAT THE RATE IS SLOW BUT THAT THE SEA IS SO WIDE
2024-04-02 06:23:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123286-0005.json
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 262, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123286-0005
generate
  5%|▍         | 59/1232 [00:23<04:48,  4.07it/s]processing 59th semantic_sys file
59
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TWO MONSTERS ONLY WERE CREATING ALL THIS COMMOTION AND BEFORE MY EYES ARE TWO REPTILES OF THE PRIMITIVE WORLD
2024-04-02 06:23:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123286-0026.json
top_k_know_token:70
known_token_update:False
T:576
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:576
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:576
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:576
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:576
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:576
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:576
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:576
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:576
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:576
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:576
T - mask_len:tensor([305.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:576
T - mask_len:tensor([356.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:576
T - mask_len:tensor([409.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:576
T - mask_len:tensor([464.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:576
T - mask_len:tensor([520.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 576, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123286-0026
generate
  5%|▍         | 60/1232 [00:24<06:16,  3.11it/s]processing 60th semantic_sys file
60
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE CALLED THIS SEA A POND AND OUR LONG VOYAGE TAKING A LITTLE SAIL
2024-04-02 06:23:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123286-0007.json
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 234, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123286-0007
generate
  5%|▍         | 61/1232 [00:24<06:20,  3.08it/s]processing 61th semantic_sys file
61
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ITS JAW IS ENORMOUS AND ACCORDING TO NATURALISTS IT IS ARMED WITH NO LESS THAN ONE HUNDRED AND EIGHTY TWO TEETH
2024-04-02 06:23:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123286-0028.json
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([264.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([299.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([335.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 371, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123286-0028
generate
  5%|▌         | 62/1232 [00:25<06:52,  2.84it/s]processing 62th semantic_sys file
62
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I TAKE THIS AS MY ANSWER AND I LEAVE THE PROFESSOR TO BITE HIS LIPS WITH IMPATIENCE
2024-04-02 06:23:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123286-0009.json
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 255, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123286-0009
generate
  5%|▌         | 63/1232 [00:25<07:28,  2.61it/s]processing 63th semantic_sys file
63
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT MUST BE AS WIDE AS THE MEDITERRANEAN OR THE ATLANTIC AND WHY NOT
2024-04-02 06:23:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123286-0015.json
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 254, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123286-0015
generate
  5%|▌         | 64/1232 [00:26<07:13,  2.69it/s]processing 64th semantic_sys file
64
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I SAW AT THE HAMBURG MUSEUM THE SKELETON OF ONE OF THESE CREATURES THIRTY FEET IN LENGTH
2024-04-02 06:23:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123286-0018.json
top_k_know_token:70
known_token_update:False
T:534
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:534
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:534
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:534
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:534
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:534
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:534
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:534
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:534
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:534
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:534
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:534
T - mask_len:tensor([330.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:534
T - mask_len:tensor([379.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:534
T - mask_len:tensor([430.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:534
T - mask_len:tensor([482.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 534, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123286-0018
generate
  5%|▌         | 65/1232 [00:26<08:17,  2.35it/s]processing 65th semantic_sys file
65
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AS FOR THE ICHTHYOSAURUS HAS HE RETURNED TO HIS SUBMARINE CAVERN
2024-04-02 06:23:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123286-0031.json
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 274, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123286-0031
generate
  5%|▌         | 66/1232 [00:26<07:59,  2.43it/s]processing 66th semantic_sys file
66
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE ATMOSPHERE IS CHARGED WITH VAPOURS PERVADED WITH THE ELECTRICITY GENERATED BY THE EVAPORATION OF SALINE WATERS
2024-04-02 06:23:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123288-0002.json
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([335.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([375.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 415, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123288-0002
generate
  5%|▌         | 67/1232 [00:27<08:16,  2.35it/s]processing 67th semantic_sys file
67
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I REFER TO THE THERMOMETER IT INDICATES THE FIGURE IS OBLITERATED
2024-04-02 06:23:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123288-0016.json
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([319.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([358.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 396, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123288-0016
generate
  6%|▌         | 68/1232 [00:27<08:38,  2.24it/s]processing 68th semantic_sys file
68
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE'S A HEAVY STORM COMING ON I CRIED POINTING TOWARDS THE HORIZON
2024-04-02 06:23:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([54], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123288-0008.json
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 181, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123288-0008
generate
  6%|▌         | 69/1232 [00:28<07:51,  2.47it/s]processing 69th semantic_sys file
69
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE WEATHER IF WE MAY USE THAT TERM WILL CHANGE BEFORE LONG
2024-04-02 06:23:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123288-0001.json
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 194, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123288-0001
generate
  6%|▌         | 70/1232 [00:28<07:19,  2.65it/s]processing 70th semantic_sys file
70
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ON THE MAST ALREADY I SEE THE LIGHT PLAY OF A LAMBENT SAINT ELMO'S FIRE THE OUTSTRETCHED SAIL CATCHES NOT A BREATH OF WIND AND HANGS LIKE A SHEET OF LEAD
2024-04-02 06:23:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123288-0010.json
top_k_know_token:70
known_token_update:False
T:535
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:535
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:535
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:535
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:535
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:535
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:535
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:535
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:535
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:535
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:535
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:535
T - mask_len:tensor([331.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:535
T - mask_len:tensor([380.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:535
T - mask_len:tensor([431.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:535
T - mask_len:tensor([483.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 535, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123288-0010
generate
  6%|▌         | 71/1232 [00:29<08:20,  2.32it/s]processing 71th semantic_sys file
71
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE ATMOSPHERE IS EVIDENTLY CHARGED AND SURCHARGED WITH ELECTRICITY
2024-04-02 06:23:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123288-0006.json
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 235, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123288-0006
generate
  6%|▌         | 72/1232 [00:29<07:46,  2.49it/s]processing 72th semantic_sys file
72
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT IF WE HAVE NOW CEASED TO ADVANCE WHY DO WE YET LEAVE THAT SAIL LOOSE WHICH AT THE FIRST SHOCK OF THE TEMPEST MAY CAPSIZE US IN A MOMENT
2024-04-02 06:23:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123288-0011.json
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([278.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([319.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([362.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([405.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 449, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123288-0011
generate
  6%|▌         | 73/1232 [00:30<09:08,  2.11it/s]processing 73th semantic_sys file
73
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A SUFFOCATING SMELL OF NITROGEN FILLS THE AIR IT ENTERS THE THROAT IT FILLS THE LUNGS
2024-04-02 06:23:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123288-0027.json
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 266, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123288-0027
generate
  6%|▌         | 74/1232 [00:30<08:29,  2.27it/s]processing 74th semantic_sys file
74
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE ELECTRIC LIGHT CAN SCARCELY PENETRATE THROUGH THE DENSE CURTAIN WHICH HAS DROPPED OVER THE THEATRE ON WHICH THE BATTLE OF THE ELEMENTS IS ABOUT TO BE WAGED
2024-04-02 06:23:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123288-0003.json
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([276.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([318.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([360.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([404.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 447, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123288-0003
generate
  6%|▌         | 75/1232 [00:30<08:42,  2.21it/s]processing 75th semantic_sys file
75
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IS THE ATMOSPHERIC CONDITION HAVING ONCE REACHED THIS DENSITY TO BECOME FINAL
2024-04-02 06:23:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123288-0017.json
top_k_know_token:70
known_token_update:False
T:268
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:268
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:268
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:268
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:268
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:268
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:268
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:268
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:268
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:268
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:268
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:268
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:268
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:268
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:268
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 268, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123288-0017
generate
  6%|▌         | 76/1232 [00:31<08:11,  2.35it/s]processing 76th semantic_sys file
76
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE AIR IS HEAVY THE SEA IS CALM
2024-04-02 06:23:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123288-0004.json
top_k_know_token:70
known_token_update:False
T:146
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:146
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:146
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:146
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:146
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:146
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:146
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:146
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:146
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:146
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:146
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:146
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:146
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:146
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:146
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 146, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123288-0004
generate
  6%|▋         | 77/1232 [00:31<07:21,  2.61it/s]processing 77th semantic_sys file
77
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I SHALL BE PUNISHED FOR IT NOW I SUPPOSE BY BEING DROWNED IN MY OWN TEARS
2024-04-02 06:23:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123440-0016.json
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 252, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123440-0016
generate
  6%|▋         | 78/1232 [00:31<07:06,  2.71it/s]processing 78th semantic_sys file
78
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HOW CHEERFULLY HE SEEMS TO GRIN HOW NEATLY SPREAD HIS CLAWS AND WELCOME LITTLE FISHES IN WITH GENTLY SMILING JAWS
2024-04-02 06:23:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123440-0010.json
top_k_know_token:70
known_token_update:False
T:739
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:739
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:739
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:739
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:739
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:739
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:739
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:739
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:739
T - mask_len:tensor([271.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:739
T - mask_len:tensor([329.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:739
T - mask_len:tensor([391.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:739
T - mask_len:tensor([457.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:739
T - mask_len:tensor([525.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:739
T - mask_len:tensor([595.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:739
T - mask_len:tensor([667.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 739, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123440-0010
generate
  6%|▋         | 79/1232 [00:32<09:27,  2.03it/s]processing 79th semantic_sys file
79
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT'LL BE NO USE THEIR PUTTING THEIR HEADS DOWN AND SAYING COME UP AGAIN DEAR
2024-04-02 06:23:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([25], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123440-0012.json
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 206, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123440-0012
generate
  6%|▋         | 80/1232 [00:32<08:28,  2.26it/s]processing 80th semantic_sys file
80
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NO I'VE MADE UP MY MIND ABOUT IT IF I'M MABEL I'LL STAY DOWN HERE
2024-04-02 06:23:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([28], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123440-0011.json
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 251, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123440-0011
generate
  7%|▋         | 81/1232 [00:33<07:52,  2.44it/s]processing 81th semantic_sys file
81
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE WON'T TALK ABOUT HER ANY MORE IF YOU'D RATHER NOT WE INDEED
2024-04-02 06:23:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123440-0020.json
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 210, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123440-0020
generate
  7%|▋         | 82/1232 [00:33<07:21,  2.60it/s]processing 82th semantic_sys file
82
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: CRIED ALICE AGAIN FOR THIS TIME THE MOUSE WAS BRISTLING ALL OVER AND SHE FELT CERTAIN IT MUST BE REALLY OFFENDED
2024-04-02 06:23:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123440-0019.json
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([247.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([284.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([322.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([360.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 399, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123440-0019
generate
  7%|▋         | 83/1232 [00:34<07:48,  2.45it/s]processing 83th semantic_sys file
83
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WISH I HADN'T CRIED SO MUCH SAID ALICE AS SHE SWAM ABOUT TRYING TO FIND HER WAY OUT
2024-04-02 06:23:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_260-123440-0015.json
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 210, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_260-123440-0015
generate
  7%|▋         | 84/1232 [00:34<09:34,  2.00it/s]processing 84th semantic_sys file
84
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ANOTHER PREACHER AFTER REPROACHING HIM TO HIS FACE WITH HIS MISGOVERNMENT ORDERED THIS PSALM TO BE SUNG
2024-04-02 06:23:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8224-274384-0005.json
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 253, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8224-274384-0005
generate
  7%|▋         | 85/1232 [00:35<08:38,  2.21it/s]processing 85th semantic_sys file
85
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HAVE MERCY LORD ON ME I PRAY FOR MEN WOULD ME DEVOUR
2024-04-02 06:23:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 86th semantic_sys file
86
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE PARLIAMENT AND THE SCOTS LAID THEIR PROPOSALS BEFORE THE KING
2024-04-02 06:23:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8224-274384-0009.json
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 214, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8224-274384-0009
generate
  7%|▋         | 87/1232 [00:35<06:06,  3.13it/s]processing 87th semantic_sys file
87
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HIS DEATH IN THIS CONJUNCTURE WAS A PUBLIC MISFORTUNE
2024-04-02 06:23:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8224-274384-0013.json
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 172, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8224-274384-0013
generate
  7%|▋         | 88/1232 [00:35<06:01,  3.16it/s]processing 88th semantic_sys file
88
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE KING STOOD UP AND CALLED FOR THAT PSALM WHICH BEGINS WITH THESE WORDS
2024-04-02 06:23:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8224-274384-0006.json
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 178, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8224-274384-0006
generate
  7%|▋         | 89/1232 [00:36<05:59,  3.18it/s]processing 89th semantic_sys file
89
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE PASSED THROUGH HENLEY SAINT ALBANS AND CAME SO NEAR TO LONDON AS HARROW ON THE HILL
2024-04-02 06:23:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8224-274384-0000.json
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 265, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8224-274384-0000
generate
  7%|▋         | 90/1232 [00:36<06:06,  3.12it/s]processing 90th semantic_sys file
90
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY INFORMED THE ENGLISH PARLIAMENT OF THIS UNEXPECTED INCIDENT AND ASSURED THEM THAT THEY HAD ENTERED INTO NO PRIVATE TREATY WITH THE KING
2024-04-02 06:23:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([26], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8224-274384-0002.json
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([266.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([347.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([388.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 430, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8224-274384-0002
generate
  7%|▋         | 91/1232 [00:37<07:32,  2.52it/s]processing 91th semantic_sys file
91
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I BELIEVE IN THE TRAINING OF PEOPLE TO THEIR HIGHEST CAPACITY THE ENGLISHMAN HERE HEARTILY SECONDED HIM
2024-04-02 06:23:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1836-0008.json
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 252, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1836-0008
generate
  7%|▋         | 92/1232 [00:37<07:13,  2.63it/s]processing 92th semantic_sys file
92
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE WAS THEREFORE MOST AGREEABLY SURPRISED TO HEAR MISTER CRESSWELL EXPRESS HIMSELF SO CORDIALLY AS APPROVING OF NEGRO EDUCATION
2024-04-02 06:23:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1836-0006.json
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([320.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([359.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 397, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1836-0006
generate
  8%|▊         | 93/1232 [00:37<07:34,  2.51it/s]processing 93th semantic_sys file
93
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT CRESSWELL ADDED SIGNIFICANTLY CAPACITY DIFFERS ENORMOUSLY BETWEEN RACES
2024-04-02 06:23:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1836-0009.json
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 309, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1836-0009
generate
  8%|▊         | 94/1232 [00:38<07:34,  2.50it/s]processing 94th semantic_sys file
94
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE HON CHARLES SMITH MISS SARAH'S BROTHER WAS WALKING SWIFTLY UPTOWN FROM MISTER EASTERLY'S WALL STREET OFFICE AND HIS FACE WAS PALE
2024-04-02 06:23:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1836-0000.json
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([271.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([316.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([363.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([412.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([461.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 511, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1836-0000
generate
  8%|▊         | 95/1232 [00:38<08:53,  2.13it/s]processing 95th semantic_sys file
95
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AT LAST THE COTTON COMBINE WAS TO ALL APPEARANCES AN ASSURED FACT AND HE WAS SLATED FOR THE SENATE
2024-04-02 06:23:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1836-0001.json
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 290, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1836-0001
generate
  8%|▊         | 96/1232 [00:39<08:18,  2.28it/s]processing 96th semantic_sys file
96
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: POSITIVELY HEROIC ADDED CRESSWELL AVOIDING HIS SISTER'S EYES
2024-04-02 06:23:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1836-0011.json
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 269, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1836-0011
generate
  8%|▊         | 97/1232 [00:39<07:51,  2.41it/s]processing 97th semantic_sys file
97
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FORTUNATELY SAID MISTER VANDERPOOL NORTHERNERS AND SOUTHERNERS ARE ARRIVING AT A BETTER MUTUAL UNDERSTANDING ON MOST OF THESE MATTERS
2024-04-02 06:23:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1836-0014.json
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([343.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 380, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1836-0014
generate
  8%|▊         | 98/1232 [00:40<07:57,  2.37it/s]processing 98th semantic_sys file
98
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE WAS NOT HERSELF A NOTABLY INTELLIGENT WOMAN SHE GREATLY ADMIRED INTELLIGENCE OR WHATEVER LOOKED TO HER LIKE INTELLIGENCE IN OTHERS
2024-04-02 06:23:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1836-0003.json
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([300.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([336.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 372, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1836-0003
generate
  8%|▊         | 99/1232 [00:40<08:01,  2.35it/s]processing 99th semantic_sys file
99
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MARY TAYLOR HOWEVER RELATED THE TALE OF ZORA TO MISSUS GREY'S PRIVATE EAR LATER
2024-04-02 06:23:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1836-0013.json
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 293, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1836-0013
generate
  8%|▊         | 100/1232 [00:40<07:41,  2.45it/s]processing 100th semantic_sys file
100
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE GLIMMERING SEA OF DELICATE LEAVES WHISPERED AND MURMURED BEFORE HER STRETCHING AWAY TO THE NORTHWARD
2024-04-02 06:23:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1826-0016.json
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([309.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([346.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 383, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1826-0016
generate
  8%|▊         | 101/1232 [00:41<07:51,  2.40it/s]processing 101th semantic_sys file
101
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SO FOR THE HUNDREDTH TIME SHE WAS THINKING TODAY AS SHE WALKED ALONE UP THE LANE BACK OF THE BARN AND THEN SLOWLY DOWN THROUGH THE BOTTOMS
2024-04-02 06:23:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1826-0013.json
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([325.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([368.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([413.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 457, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1826-0013
generate
  8%|▊         | 102/1232 [00:41<08:18,  2.27it/s]processing 102th semantic_sys file
102
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: GOOBERS DON'T GROW ON THE TOPS OF VINES BUT UNDERGROUND ON THE ROOTS LIKE YAMS IS THAT SO
2024-04-02 06:23:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1826-0023.json
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 261, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1826-0023
generate
  8%|▊         | 103/1232 [00:42<07:50,  2.40it/s]processing 103th semantic_sys file
103
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT JOHN THERE'S NO SOCIETY JUST ELEMENTARY WORK
2024-04-02 06:23:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1826-0005.json
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 185, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1826-0005
generate
  8%|▊         | 104/1232 [00:42<07:14,  2.60it/s]processing 104th semantic_sys file
104
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FIND SOME CRESSWELLS THERE BIG PLANTATIONS RATED AT TWO HUNDRED AND FIFTY THOUSAND DOLLARS
2024-04-02 06:23:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1826-0007.json
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([268.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([300.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 332, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1826-0007
generate
  9%|▊         | 105/1232 [00:42<07:22,  2.54it/s]processing 105th semantic_sys file
105
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: JOHN TAYLOR WHO HAD SUPPORTED HER THROUGH COLLEGE WAS INTERESTED IN COTTON
2024-04-02 06:23:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1826-0002.json
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 181, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1826-0002
generate
  9%|▊         | 106/1232 [00:43<07:43,  2.43it/s]processing 106th semantic_sys file
106
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE GOLDEN FLEECE IT'S THE SILVER FLEECE HE HARKENED
2024-04-02 06:23:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1826-0024.json
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 164, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1826-0024
generate
  9%|▊         | 107/1232 [00:43<07:00,  2.67it/s]processing 107th semantic_sys file
107
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HERE SHE WAS TEACHING DIRTY CHILDREN AND THE SMELL OF CONFUSED ODORS AND BODILY PERSPIRATION WAS TO HER AT TIMES UNBEARABLE
2024-04-02 06:23:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1826-0011.json
top_k_know_token:70
known_token_update:False
T:540
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:540
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:540
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:540
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:540
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:540
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:540
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:540
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:540
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:540
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:540
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:540
T - mask_len:tensor([334.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:540
T - mask_len:tensor([384.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:540
T - mask_len:tensor([435.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:540
T - mask_len:tensor([488.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 540, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1826-0011
generate
  9%|▉         | 108/1232 [00:44<08:01,  2.33it/s]processing 108th semantic_sys file
108
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU OUGHT TO KNOW JOHN IF I TEACH NEGROES I'LL SCARCELY SEE MUCH OF PEOPLE IN MY OWN CLASS
2024-04-02 06:23:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:23:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1826-0009.json
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 325, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1826-0009
generate
  9%|▉         | 109/1232 [00:44<07:53,  2.37it/s]processing 109th semantic_sys file
109
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MISS TAYLOR DID NOT KNOW MUCH ABOUT COTTON BUT AT LEAST ONE MORE REMARK SEEMED CALLED FOR
2024-04-02 06:24:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1826-0020.json
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:286
T - mask_len:tensor([258.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 286, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1826-0020
generate
  9%|▉         | 110/1232 [00:44<07:33,  2.47it/s]processing 110th semantic_sys file
110
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HER REGARD SHIFTED TO THE GREEN STALKS AND LEAVES AGAIN AND SHE STARTED TO MOVE AWAY
2024-04-02 06:24:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1826-0018.json
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([251.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([288.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([326.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([366.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 405, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1826-0018
generate
  9%|▉         | 111/1232 [00:45<08:21,  2.23it/s]processing 111th semantic_sys file
111
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN THE DEBATE BETWEEN THE SENIOR SOCIETIES HER DEFENCE OF THE FIFTEENTH AMENDMENT HAD BEEN NOT ONLY A NOTABLE BIT OF REASONING BUT DELIVERED WITH REAL ENTHUSIASM
2024-04-02 06:24:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1826-0000.json
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([338.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([384.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([430.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 476, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1826-0000
generate
  9%|▉         | 112/1232 [00:45<08:37,  2.17it/s]processing 112th semantic_sys file
112
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE WANTED A GLANCE OF THE NEW BOOKS AND PERIODICALS AND TALK OF GREAT PHILANTHROPIES AND REFORMS
2024-04-02 06:24:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1826-0012.json
top_k_know_token:70
known_token_update:False
T:311
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:311
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:311
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:311
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:311
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:311
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:311
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:311
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:311
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:311
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:311
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:311
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:311
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:311
T - mask_len:tensor([251.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:311
T - mask_len:tensor([281.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 311, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1826-0012
generate
  9%|▉         | 113/1232 [00:46<08:16,  2.25it/s]processing 113th semantic_sys file
113
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I SUPPOSE THOUGH IT'S TOO EARLY FOR THEM THEN CAME THE EXPLOSION
2024-04-02 06:24:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([19], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1826-0022.json
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 167, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1826-0022
generate
  9%|▉         | 114/1232 [00:46<07:24,  2.52it/s]processing 114th semantic_sys file
114
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: COTTON IS A WONDERFUL THING IS IT NOT BOYS SHE SAID RATHER PRIMLY
2024-04-02 06:24:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1826-0019.json
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 200, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1826-0019
generate
  9%|▉         | 115/1232 [00:46<06:56,  2.68it/s]processing 115th semantic_sys file
115
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE MIGHT BE A BIT OF POETRY HERE AND THERE BUT MOST OF THIS PLACE WAS SUCH DESPERATE PROSE
2024-04-02 06:24:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1826-0017.json
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 316, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1826-0017
generate
  9%|▉         | 116/1232 [00:47<07:06,  2.62it/s]processing 116th semantic_sys file
116
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE DARTED THROUGH THE TREES AND PAUSED A TALL MAN STRONGLY BUT SLIMLY MADE
2024-04-02 06:24:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1837-0029.json
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 226, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1837-0029
generate
  9%|▉         | 117/1232 [00:47<06:54,  2.69it/s]processing 117th semantic_sys file
117
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ON SHE HURRIED UNTIL SWEEPING DOWN TO THE LAGOON AND THE ISLAND LO THE COTTON LAY BEFORE HER
2024-04-02 06:24:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1837-0027.json
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 328, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1837-0027
generate
 10%|▉         | 118/1232 [00:48<07:06,  2.61it/s]processing 118th semantic_sys file
118
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEN OF A SUDDEN AT MIDDAY THE SUN SHOT OUT HOT AND STILL NO BREATH OF AIR STIRRED THE SKY WAS LIKE BLUE STEEL THE EARTH STEAMED
2024-04-02 06:24:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1837-0007.json
top_k_know_token:70
known_token_update:False
T:717
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:717
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:717
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:717
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:717
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:717
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:717
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:717
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:717
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:717
T - mask_len:tensor([319.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:717
T - mask_len:tensor([380.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:717
T - mask_len:tensor([443.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:717
T - mask_len:tensor([509.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:717
T - mask_len:tensor([578.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:717
T - mask_len:tensor([647.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 717, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1837-0007
generate
 10%|▉         | 119/1232 [00:48<09:01,  2.06it/s]processing 119th semantic_sys file
119
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE SAT DOWN WEAK BEWILDERED AND ONE THOUGHT WAS UPPERMOST ZORA
2024-04-02 06:24:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1837-0019.json
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 218, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1837-0019
generate
 10%|▉         | 120/1232 [00:49<08:11,  2.26it/s]processing 120th semantic_sys file
120
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FOR A WHILE SHE LAY IN HER CHAIR IN HAPPY DREAMY PLEASURE AT SUN AND BIRD AND TREE
2024-04-02 06:24:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1837-0024.json
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([259.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 287, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1837-0024
generate
 10%|▉         | 121/1232 [00:49<07:49,  2.37it/s]processing 121th semantic_sys file
121
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE SQUARES OF COTTON SHARP EDGED HEAVY WERE JUST ABOUT TO BURST TO BOLLS
2024-04-02 06:24:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1837-0015.json
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 250, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1837-0015
generate
 10%|▉         | 122/1232 [00:49<07:31,  2.46it/s]processing 122th semantic_sys file
122
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE REVELATION OF HIS LOVE LIGHTED AND BRIGHTENED SLOWLY TILL IT FLAMED LIKE A SUNRISE OVER HIM AND LEFT HIM IN BURNING WONDER
2024-04-02 06:24:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1837-0003.json
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([313.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 346, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1837-0003
generate
 10%|▉         | 123/1232 [00:50<07:34,  2.44it/s]processing 123th semantic_sys file
123
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE PANTED TO KNOW IF SHE TOO KNEW OR KNEW AND CARED NOT OR CARED AND KNEW NOT
2024-04-02 06:24:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1837-0004.json
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([316.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([354.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 392, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1837-0004
generate
 10%|█         | 124/1232 [00:50<07:45,  2.38it/s]processing 124th semantic_sys file
124
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE ROSE WITH A FLEETING GLANCE GATHERED THE SHAWL ROUND HER THEN GLIDING FORWARD WAVERING TREMULOUS SLIPPED ACROSS THE ROAD AND INTO THE SWAMP
2024-04-02 06:24:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1837-0025.json
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([316.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([358.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([401.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 444, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1837-0025
generate
 10%|█         | 125/1232 [00:51<08:04,  2.29it/s]processing 125th semantic_sys file
125
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT WAS THE FIRST GREAT SORROW OF HIS LIFE IT WAS NOT SO MUCH THE LOSS OF THE COTTON ITSELF BUT THE FANTASY THE HOPES THE DREAMS BUILT AROUND IT
2024-04-02 06:24:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1837-0001.json
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([318.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([361.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([405.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 448, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1837-0001
generate
 10%|█         | 126/1232 [00:51<08:15,  2.23it/s]processing 126th semantic_sys file
126
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE HAD BEEN BORN WITHIN ITS BORDERS WITHIN ITS BORDERS SHE HAD LIVED AND GROWN AND WITHIN ITS BORDERS SHE HAD MET HER LOVE
2024-04-02 06:24:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1837-0026.json
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([280.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([318.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([356.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 394, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1837-0026
generate
 10%|█         | 127/1232 [00:52<08:13,  2.24it/s]processing 127th semantic_sys file
127
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE SPLASHED AND STAMPED ALONG FARTHER AND FARTHER ONWARD UNTIL HE NEARED THE RAMPART OF THE CLEARING AND PUT FOOT UPON THE TREE BRIDGE
2024-04-02 06:24:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1837-0012.json
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([328.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([368.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 407, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1837-0012
generate
 10%|█         | 128/1232 [00:52<08:11,  2.25it/s]processing 128th semantic_sys file
128
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FOR ONE LONG MOMENT HE PAUSED STUPID AGAPE WITH UTTER AMAZEMENT THEN LEANED DIZZILY AGAINST A TREE
2024-04-02 06:24:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1995-1837-0016.json
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 328, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1995-1837-0016
generate
 10%|█         | 129/1232 [00:53<07:57,  2.31it/s]processing 129th semantic_sys file
129
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AS A MATTER OF FACT HE COULD NOT SAID SOAMES FOR I ENTERED BY THE SIDE DOOR
2024-04-02 06:24:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0026.json
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 167, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0026
generate
 11%|█         | 130/1232 [00:53<07:23,  2.49it/s]processing 130th semantic_sys file
130
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HOW LONG WOULD IT TAKE HIM TO DO THAT USING EVERY POSSIBLE CONTRACTION A QUARTER OF AN HOUR NOT LESS
2024-04-02 06:24:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 131th semantic_sys file
131
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE WAS STILL SUFFERING FROM THIS SUDDEN DISTURBANCE OF THE QUIET ROUTINE OF HIS LIFE
2024-04-02 06:24:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0045.json
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 213, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0045
generate
 11%|█         | 132/1232 [00:53<05:20,  3.44it/s]processing 132th semantic_sys file
132
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHAT COULD HE DO HE CAUGHT UP EVERYTHING WHICH WOULD BETRAY HIM AND HE RUSHED INTO YOUR BEDROOM TO CONCEAL HIMSELF
2024-04-02 06:24:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0037.json
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([338.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([384.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([430.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 476, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0037
generate
 11%|█         | 133/1232 [00:54<06:47,  2.69it/s]processing 133th semantic_sys file
133
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AS HOLMES DREW THE CURTAIN I WAS AWARE FROM SOME LITTLE RIGIDITY AND ALERTNESS OF HIS ATTITUDE THAT HE WAS PREPARED FOR AN EMERGENCY
2024-04-02 06:24:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([52], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0034.json
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([305.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([346.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([387.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 429, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0034
generate
 11%|█         | 134/1232 [00:54<07:14,  2.52it/s]processing 134th semantic_sys file
134
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HOLMES TURNED AWAY AND STOOPED SUDDENLY TO THE FLOOR HALLOA WHAT'S THIS
2024-04-02 06:24:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([53], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0035.json
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 224, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0035
generate
 11%|█         | 135/1232 [00:55<07:19,  2.50it/s]processing 135th semantic_sys file
135
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WATSON I HAVE ALWAYS DONE YOU AN INJUSTICE THERE ARE OTHERS
2024-04-02 06:24:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0032.json
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 163, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0032
generate
 11%|█         | 136/1232 [00:55<06:43,  2.72it/s]processing 136th semantic_sys file
136
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WAS HOPING THAT IF THE PAPER ON WHICH HE WROTE WAS THIN SOME TRACE OF IT MIGHT COME THROUGH UPON THIS POLISHED SURFACE NO I SEE NOTHING
2024-04-02 06:24:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([26], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0033.json
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([222.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([324.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 359, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0033
generate
 11%|█         | 137/1232 [00:55<06:59,  2.61it/s]processing 137th semantic_sys file
137
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE ALTERNATIVE WAS THAT SOMEONE PASSING HAD OBSERVED THE KEY IN THE DOOR HAD KNOWN THAT I WAS OUT AND HAD ENTERED TO LOOK AT THE PAPERS
2024-04-02 06:24:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0009.json
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([320.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 354, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0009
generate
 11%|█         | 138/1232 [00:56<07:11,  2.54it/s]processing 138th semantic_sys file
138
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WAS IN SUCH A HURRY TO COME TO YOU YOU LEFT YOUR DOOR OPEN
2024-04-02 06:24:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0016.json
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 191, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0016
generate
 11%|█▏        | 139/1232 [00:56<07:31,  2.42it/s]processing 139th semantic_sys file
139
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ABOVE ALL THINGS I DESIRE TO SETTLE THE MATTER QUIETLY AND DISCREETLY
2024-04-02 06:24:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0013.json
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 241, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0013
generate
 11%|█▏        | 140/1232 [00:57<07:05,  2.56it/s]processing 140th semantic_sys file
140
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WILL ENDEAVOUR IN MY STATEMENT TO AVOID SUCH TERMS AS WOULD SERVE TO LIMIT THE EVENTS TO ANY PARTICULAR PLACE OR GIVE A CLUE AS TO THE PEOPLE CONCERNED
2024-04-02 06:24:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0000.json
top_k_know_token:70
known_token_update:False
T:624
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:624
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:624
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:624
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:624
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:624
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:624
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:624
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:624
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:624
T - mask_len:tensor([278.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:624
T - mask_len:tensor([330.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:624
T - mask_len:tensor([386.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:624
T - mask_len:tensor([443.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:624
T - mask_len:tensor([503.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:624
T - mask_len:tensor([563.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 624, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0000
generate
 11%|█▏        | 141/1232 [00:57<08:23,  2.16it/s]processing 141th semantic_sys file
141
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I GAVE HIM A LITTLE BRANDY AND LEFT HIM COLLAPSED IN A CHAIR WHILE I MADE A MOST CAREFUL EXAMINATION OF THE ROOM
2024-04-02 06:24:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0010.json
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 313, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0010
generate
 12%|█▏        | 142/1232 [00:58<08:04,  2.25it/s]processing 142th semantic_sys file
142
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU HAVEN'T SEEN ANY OF THEM NO SIR
2024-04-02 06:24:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0053.json
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 122, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0053
generate
 12%|█▏        | 143/1232 [00:58<07:07,  2.55it/s]processing 143th semantic_sys file
143
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HOLMES HELD OUT A SMALL CHIP WITH THE LETTERS N N AND A SPACE OF CLEAR WOOD AFTER THEM YOU SEE
2024-04-02 06:24:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0031.json
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([222.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([324.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 359, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0031
generate
 12%|█▏        | 144/1232 [00:58<07:16,  2.49it/s]processing 144th semantic_sys file
144
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NOT ONLY THIS BUT ON THE TABLE I FOUND A SMALL BALL OF BLACK DOUGH OR CLAY WITH SPECKS OF SOMETHING WHICH LOOKS LIKE SAWDUST IN IT
2024-04-02 06:24:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0012.json
top_k_know_token:70
known_token_update:False
T:697
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:697
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:697
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:697
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:697
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:697
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:697
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:697
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:697
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:697
T - mask_len:tensor([310.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:697
T - mask_len:tensor([369.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:697
T - mask_len:tensor([431.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:697
T - mask_len:tensor([495.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:697
T - mask_len:tensor([562.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:697
T - mask_len:tensor([629.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 697, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0012
generate
 12%|█▏        | 145/1232 [00:59<08:45,  2.07it/s]processing 145th semantic_sys file
145
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MY SCHOLAR HAS BEEN LEFT VERY POOR BUT HE IS HARD WORKING AND INDUSTRIOUS HE WILL DO WELL
2024-04-02 06:24:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0042.json
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 296, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0042
generate
 12%|█▏        | 146/1232 [00:59<08:08,  2.22it/s]processing 146th semantic_sys file
146
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MY FRIEND'S TEMPER HAD NOT IMPROVED SINCE HE HAD BEEN DEPRIVED OF THE CONGENIAL SURROUNDINGS OF BAKER STREET
2024-04-02 06:24:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0002.json
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([266.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 294, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0002
generate
 12%|█▏        | 147/1232 [01:00<07:42,  2.35it/s]processing 147th semantic_sys file
147
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I HAD TO READ IT OVER CAREFULLY AS THE TEXT MUST BE ABSOLUTELY CORRECT
2024-04-02 06:24:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0004.json
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([323.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 358, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0004
generate
 12%|█▏        | 148/1232 [01:00<07:41,  2.35it/s]processing 148th semantic_sys file
148
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE PROOF WAS IN THREE LONG SLIPS I HAD LEFT THEM ALL TOGETHER
2024-04-02 06:24:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0008.json
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 188, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0008
generate
 12%|█▏        | 149/1232 [01:00<07:04,  2.55it/s]processing 149th semantic_sys file
149
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I UNDERSTAND YOU TO SAY THAT THERE ARE THREE STUDENTS WHO USE THIS STAIR AND ARE IN THE HABIT OF PASSING YOUR DOOR YES THERE ARE
2024-04-02 06:24:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([56], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0038.json
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 313, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0038
generate
 12%|█▏        | 150/1232 [01:01<07:06,  2.54it/s]processing 150th semantic_sys file
150
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEN HE APPROACHED IT AND STANDING ON TIPTOE WITH HIS NECK CRANED HE LOOKED INTO THE ROOM
2024-04-02 06:24:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([54], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0020.json
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 235, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0020
generate
 12%|█▏        | 151/1232 [01:01<06:49,  2.64it/s]processing 151th semantic_sys file
151
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE MOMENT I LOOKED AT MY TABLE I WAS AWARE THAT SOMEONE HAD RUMMAGED AMONG MY PAPERS
2024-04-02 06:24:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([26], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0007.json
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([290.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([325.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 360, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0007
generate
 12%|█▏        | 152/1232 [01:02<07:09,  2.51it/s]processing 152th semantic_sys file
152
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WITHOUT HIS SCRAPBOOKS HIS CHEMICALS AND HIS HOMELY UNTIDINESS HE WAS AN UNCOMFORTABLE MAN
2024-04-02 06:24:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0003.json
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 313, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0003
generate
 12%|█▏        | 153/1232 [01:02<07:13,  2.49it/s]processing 153th semantic_sys file
153
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I DARE NOT GO SO FAR AS THAT BUT OF THE THREE HE IS PERHAPS THE LEAST UNLIKELY
2024-04-02 06:24:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0044.json
top_k_know_token:70
known_token_update:False
T:343
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:343
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:343
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:343
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:343
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:343
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:343
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:343
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:343
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:343
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:343
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:343
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:343
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:343
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:343
T - mask_len:tensor([310.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 343, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0044
generate
 12%|█▎        | 154/1232 [01:03<07:58,  2.25it/s]processing 154th semantic_sys file
154
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DID ANYONE KNOW THAT THESE PROOFS WOULD BE THERE NO ONE SAVE THE PRINTER
2024-04-02 06:24:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([56], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0015.json
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 181, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0015
generate
 13%|█▎        | 155/1232 [01:03<09:09,  1.96it/s]processing 155th semantic_sys file
155
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU LEFT HIM IN A CHAIR YOU SAY WHICH CHAIR BY THE WINDOW THERE
2024-04-02 06:24:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([61], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141083-0024.json
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:172
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 172, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141083-0024
generate
 13%|█▎        | 156/1232 [01:04<08:01,  2.24it/s]processing 156th semantic_sys file
156
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HIS TROUBLED BLUE EYES GLANCED AT EACH OF US AND FINALLY RESTED WITH AN EXPRESSION OF BLANK DISMAY UPON BANNISTER IN THE FARTHER CORNER
2024-04-02 06:24:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0029.json
top_k_know_token:70
known_token_update:False
T:401
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:401
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:401
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:401
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:401
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:401
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:401
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:401
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:401
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:401
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:401
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:401
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:401
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:401
T - mask_len:tensor([323.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:401
T - mask_len:tensor([362.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 401, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0029
generate
 13%|█▎        | 157/1232 [01:04<07:59,  2.24it/s]processing 157th semantic_sys file
157
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHEN WE WERE OUT IN THE DARKNESS OF THE QUADRANGLE WE AGAIN LOOKED UP AT THE WINDOWS
2024-04-02 06:24:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0011.json
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 291, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0011
generate
 13%|█▎        | 158/1232 [01:04<07:33,  2.37it/s]processing 158th semantic_sys file
158
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A SUDDEN IMPULSE CAME OVER HIM TO ENTER AND SEE IF THEY WERE INDEED THE PROOFS
2024-04-02 06:24:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([57], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0042.json
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 251, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0042
generate
 13%|█▎        | 159/1232 [01:05<07:46,  2.30it/s]processing 159th semantic_sys file
159
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FOR A MOMENT GILCHRIST WITH UPRAISED HAND TRIED TO CONTROL HIS WRITHING FEATURES
2024-04-02 06:24:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0032.json
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:230
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 230, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0032
generate
 13%|█▎        | 160/1232 [01:05<07:10,  2.49it/s]processing 160th semantic_sys file
160
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT WILL BE CLEAR TO YOU FROM WHAT I HAVE SAID THAT ONLY YOU COULD HAVE LET THIS YOUNG MAN OUT SINCE YOU WERE LEFT IN THE ROOM AND MUST HAVE LOCKED THE DOOR WHEN YOU WENT OUT
2024-04-02 06:24:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([58], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0048.json
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([253.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([308.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([366.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([427.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([491.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([557.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([624.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 691, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0048
generate
 13%|█▎        | 161/1232 [01:06<08:36,  2.07it/s]processing 161th semantic_sys file
161
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WELL WELL DON'T TROUBLE TO ANSWER LISTEN AND SEE THAT I DO YOU NO INJUSTICE
2024-04-02 06:24:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([57], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0034.json
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([261.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([293.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 324, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0034
generate
 13%|█▎        | 162/1232 [01:06<08:14,  2.17it/s]processing 162th semantic_sys file
162
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WILL TAKE THE BLACK CLAY WITH ME ALSO THE PENCIL CUTTINGS GOOD BYE
2024-04-02 06:24:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0010.json
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 210, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0010
generate
 13%|█▎        | 163/1232 [01:07<07:27,  2.39it/s]processing 163th semantic_sys file
163
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NO HARM WOULD HAVE BEEN DONE HAD IT NOT BEEN THAT AS HE PASSED YOUR DOOR HE PERCEIVED THE KEY WHICH HAD BEEN LEFT BY THE CARELESSNESS OF YOUR SERVANT
2024-04-02 06:24:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([54], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0041.json
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([290.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([345.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([402.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([463.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([524.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([588.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 651, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0041
generate
 13%|█▎        | 164/1232 [01:07<08:39,  2.06it/s]processing 164th semantic_sys file
164
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN A FEW HOURS THE EXAMINATION WOULD COMMENCE AND HE WAS STILL IN THE DILEMMA BETWEEN MAKING THE FACTS PUBLIC AND ALLOWING THE CULPRIT TO COMPETE FOR THE VALUABLE SCHOLARSHIP
2024-04-02 06:24:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 165th semantic_sys file
165
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE COULD HARDLY STAND STILL SO GREAT WAS HIS MENTAL AGITATION AND HE RAN TOWARDS HOLMES WITH TWO EAGER HANDS OUTSTRETCHED THANK HEAVEN THAT YOU HAVE COME
2024-04-02 06:24:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 166th semantic_sys file
166
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT IS POSSIBLE THAT I MAY BE IN A POSITION THEN TO INDICATE SOME COURSE OF ACTION
2024-04-02 06:24:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0009.json
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([300.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([336.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 372, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0009
generate
 14%|█▎        | 167/1232 [01:08<05:18,  3.35it/s]processing 167th semantic_sys file
167
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I CANNOT ALLOW THE EXAMINATION TO BE HELD IF ONE OF THE PAPERS HAS BEEN TAMPERED WITH THE SITUATION MUST BE FACED
2024-04-02 06:24:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0008.json
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([359.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([407.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([456.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 505, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0008
generate
 14%|█▎        | 168/1232 [01:08<06:12,  2.86it/s]processing 168th semantic_sys file
168
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ON THE PALM WERE THREE LITTLE PYRAMIDS OF BLACK DOUGHY CLAY
2024-04-02 06:24:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0021.json
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 219, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0021
generate
 14%|█▎        | 169/1232 [01:09<06:05,  2.91it/s]processing 169th semantic_sys file
169
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE WANT TO KNOW MISTER GILCHRIST HOW YOU AN HONOURABLE MAN EVER CAME TO COMMIT SUCH AN ACTION AS THAT OF YESTERDAY
2024-04-02 06:24:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0031.json
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([305.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([341.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 378, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0031
generate
 14%|█▍        | 170/1232 [01:09<06:30,  2.72it/s]processing 170th semantic_sys file
170
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT WAS THE INDIAN WHOSE DARK SILHOUETTE APPEARED SUDDENLY UPON HIS BLIND
2024-04-02 06:24:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0000.json
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 261, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0000
generate
 14%|█▍        | 171/1232 [01:09<06:22,  2.77it/s]processing 171th semantic_sys file
171
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NO NAMES PLEASE SAID HOLMES AS WE KNOCKED AT GILCHRIST'S DOOR
2024-04-02 06:24:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0003.json
top_k_know_token:70
known_token_update:False
T:318
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:318
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:318
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:318
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:318
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:318
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:318
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:318
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:318
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:318
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:318
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:318
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:318
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:318
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:318
T - mask_len:tensor([287.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 318, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0003
generate
 14%|█▍        | 172/1232 [01:10<06:35,  2.68it/s]processing 172th semantic_sys file
172
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I HAVE A LETTER HERE MISTER SOAMES WHICH I WROTE TO YOU EARLY THIS MORNING IN THE MIDDLE OF A RESTLESS NIGHT
2024-04-02 06:24:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0047.json
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([302.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 334, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0047
generate
 14%|█▍        | 173/1232 [01:10<06:46,  2.61it/s]processing 173th semantic_sys file
173
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MY FRIEND DID NOT APPEAR TO BE DEPRESSED BY HIS FAILURE BUT SHRUGGED HIS SHOULDERS IN HALF HUMOROUS RESIGNATION
2024-04-02 06:24:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0016.json
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([308.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([345.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 382, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0016
generate
 14%|█▍        | 174/1232 [01:11<07:02,  2.50it/s]processing 174th semantic_sys file
174
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: COME COME SAID HOLMES KINDLY IT IS HUMAN TO ERR AND AT LEAST NO ONE CAN ACCUSE YOU OF BEING A CALLOUS CRIMINAL
2024-04-02 06:24:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0033.json
top_k_know_token:70
known_token_update:False
T:451
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:451
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:451
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:451
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:451
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:451
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:451
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:451
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:451
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:451
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:451
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:451
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:451
T - mask_len:tensor([321.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:451
T - mask_len:tensor([364.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:451
T - mask_len:tensor([407.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 451, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0033
generate
 14%|█▍        | 175/1232 [01:11<07:26,  2.36it/s]processing 175th semantic_sys file
175
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OF COURSE HE DID NOT REALIZE THAT IT WAS I WHO WAS KNOCKING BUT NONE THE LESS HIS CONDUCT WAS VERY UNCOURTEOUS AND INDEED UNDER THE CIRCUMSTANCES RATHER SUSPICIOUS
2024-04-02 06:24:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([54], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0004.json
top_k_know_token:70
known_token_update:False
T:671
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:671
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:671
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:671
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:671
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:671
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:671
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:671
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:671
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:671
T - mask_len:tensor([299.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:671
T - mask_len:tensor([355.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:671
T - mask_len:tensor([415.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:671
T - mask_len:tensor([477.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:671
T - mask_len:tensor([541.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:671
T - mask_len:tensor([606.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 671, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0004
generate
 14%|█▍        | 176/1232 [01:12<08:38,  2.04it/s]processing 176th semantic_sys file
176
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IF THIS MATTER IS NOT TO BECOME PUBLIC WE MUST GIVE OURSELVES CERTAIN POWERS AND RESOLVE OURSELVES INTO A SMALL PRIVATE COURT MARTIAL
2024-04-02 06:24:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 177th semantic_sys file
177
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT WAS SIMPLE ENOUGH SIR IF YOU ONLY HAD KNOWN BUT WITH ALL YOUR CLEVERNESS IT WAS IMPOSSIBLE THAT YOU COULD KNOW
2024-04-02 06:24:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([52], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0049.json
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 304, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0049
generate
 14%|█▍        | 178/1232 [01:12<06:20,  2.77it/s]processing 178th semantic_sys file
178
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS SET OF ROOMS IS QUITE THE OLDEST IN THE COLLEGE AND IT IS NOT UNUSUAL FOR VISITORS TO GO OVER THEM
2024-04-02 06:24:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0002.json
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([268.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 297, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0002
generate
 15%|█▍        | 179/1232 [01:12<06:22,  2.75it/s]processing 179th semantic_sys file
179
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE RETURNED CARRYING HIS JUMPING SHOES WHICH ARE PROVIDED AS YOU ARE AWARE WITH SEVERAL SHARP SPIKES
2024-04-02 06:24:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([52], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0040.json
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([276.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([309.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 342, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0040
generate
 15%|█▍        | 180/1232 [01:13<06:36,  2.65it/s]processing 180th semantic_sys file
180
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I ENTERED AND I TOOK YOU INTO MY CONFIDENCE AS TO THE SUGGESTIONS OF THE SIDE TABLE
2024-04-02 06:24:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([60], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1580-141084-0039.json
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 243, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1580-141084-0039
generate
 15%|█▍        | 181/1232 [01:13<06:24,  2.73it/s]processing 181th semantic_sys file
181
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AS TO HIS AGE AND ALSO THE NAME OF HIS MASTER JACOB'S STATEMENT VARIED SOMEWHAT FROM THE ADVERTISEMENT
2024-04-02 06:24:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-287645-0013.json
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 309, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-287645-0013
generate
 15%|█▍        | 182/1232 [01:14<06:56,  2.52it/s]processing 182th semantic_sys file
182
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS WAS WHAT DID THE MISCHIEF SO FAR AS THE RUNNING AWAY WAS CONCERNED
2024-04-02 06:24:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-287645-0000.json
top_k_know_token:70
known_token_update:False
T:157
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:157
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:157
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:157
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:157
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:157
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:157
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:157
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:157
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:157
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:157
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:157
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:157
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:157
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:157
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 157, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-287645-0000
generate
 15%|█▍        | 183/1232 [01:14<06:22,  2.74it/s]processing 183th semantic_sys file
183
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE WORKED ME VERY HARD HE WANTED TO BE BEATING ME ALL THE TIME
2024-04-02 06:24:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-287645-0010.json
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 173, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-287645-0010
generate
 15%|█▍        | 184/1232 [01:14<06:04,  2.88it/s]processing 184th semantic_sys file
184
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE WAS A LARGE HOMELY WOMAN THEY WERE COMMON WHITE PEOPLE WITH NO REPUTATION IN THE COMMUNITY
2024-04-02 06:24:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-287645-0011.json
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 257, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-287645-0011
generate
 15%|█▌        | 185/1232 [01:15<06:01,  2.89it/s]processing 185th semantic_sys file
185
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SUBSTANTIALLY THIS WAS JACOB'S UNVARNISHED DESCRIPTION OF HIS MASTER AND MISTRESS
2024-04-02 06:24:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-287645-0012.json
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 213, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-287645-0012
generate
 15%|█▌        | 186/1232 [01:15<05:59,  2.91it/s]processing 186th semantic_sys file
186
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE DOCTOR WHO ATTENDED THE INJURED CREATURE IN THIS CASE WAS SIMPLY TOLD THAT SHE SLIPPED AND FELL DOWN STAIRS AS SHE WAS COMING DOWN
2024-04-02 06:24:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-287645-0006.json
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([335.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([376.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 416, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-287645-0006
generate
 15%|█▌        | 187/1232 [01:15<06:36,  2.64it/s]processing 187th semantic_sys file
187
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: JOHN WESLEY COMBASH JACOB TAYLOR AND THOMAS EDWARD SKINNER
2024-04-02 06:24:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-287645-0004.json
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 263, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-287645-0004
generate
 15%|█▌        | 188/1232 [01:16<07:00,  2.48it/s]processing 188th semantic_sys file
188
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OF THIS PARTY EDWARD A BOY OF SEVENTEEN CALLED FORTH MUCH SYMPATHY HE TOO WAS CLAIMED BY HOLLAN
2024-04-02 06:24:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-287645-0003.json
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([253.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([384.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([431.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 477, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-287645-0003
generate
 15%|█▌        | 189/1232 [01:16<07:29,  2.32it/s]processing 189th semantic_sys file
189
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU SEE MY FRIEND IT'S AN ISSUE OF THE MONSTER THE NOTORIOUS NARWHALE
2024-04-02 06:24:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0023.json
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 210, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0023
generate
 15%|█▌        | 190/1232 [01:17<06:54,  2.51it/s]processing 190th semantic_sys file
190
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OUR BAGGAGE WAS IMMEDIATELY CARRIED TO THE DECK OF THE FRIGATE I RUSHED ABOARD
2024-04-02 06:24:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0029.json
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 236, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0029
generate
 16%|█▌        | 191/1232 [01:17<06:33,  2.64it/s]processing 191th semantic_sys file
191
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NEVER DID HE OBJECT TO BUCKLING UP HIS SUITCASE FOR ANY COUNTRY WHATEVER CHINA OR THE CONGO NO MATTER HOW FAR OFF IT WAS
2024-04-02 06:24:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0010.json
top_k_know_token:70
known_token_update:False
T:462
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:462
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:462
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:462
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:462
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:462
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:462
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:462
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:462
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:462
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:462
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:462
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:462
T - mask_len:tensor([328.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:462
T - mask_len:tensor([372.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:462
T - mask_len:tensor([417.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 462, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0010
generate
 16%|█▌        | 192/1232 [01:18<07:06,  2.44it/s]processing 192th semantic_sys file
192
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I OPENED A LINE OF CREDIT SUFFICIENT TO COVER THE BABIRUSA AND CONSEIL AT MY HEELS I JUMPED INTO A CARRIAGE
2024-04-02 06:24:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0028.json
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([313.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 346, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0028
generate
 16%|█▌        | 193/1232 [01:18<07:56,  2.18it/s]processing 193th semantic_sys file
193
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: PLEASE FORGIVE ME FOR THIS UNDERHANDED WAY OF ADMITTING I HAD TURNED FORTY
2024-04-02 06:24:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0012.json
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 178, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0012
generate
 16%|█▌        | 194/1232 [01:18<07:09,  2.42it/s]processing 194th semantic_sys file
194
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THREE SECONDS BEFORE THE ARRIVAL OF J B HOBSON'S LETTER I NO MORE DREAMED OF CHASING THE UNICORN THAN OF TRYING FOR THE NORTHWEST PASSAGE
2024-04-02 06:24:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0001.json
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([258.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([336.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([377.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 417, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0001
generate
 16%|█▌        | 195/1232 [01:19<07:21,  2.35it/s]processing 195th semantic_sys file
195
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE WAS A FANATIC ON FORMALITY AND HE ONLY ADDRESSED ME IN THE THIRD PERSON TO THE POINT WHERE IT GOT TIRESOME
2024-04-02 06:24:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0013.json
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([291.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 322, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0013
generate
 16%|█▌        | 196/1232 [01:19<07:15,  2.38it/s]processing 196th semantic_sys file
196
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FROM RUBBING SHOULDERS WITH SCIENTISTS IN OUR LITTLE UNIVERSE BY THE BOTANICAL GARDENS THE BOY HAD COME TO KNOW A THING OR TWO
2024-04-02 06:24:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0006.json
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([241.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([314.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:390
T - mask_len:tensor([352.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 390, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0006
generate
 16%|█▌        | 197/1232 [01:20<07:22,  2.34it/s]processing 197th semantic_sys file
197
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: EVEN SO I HAD JUST RETURNED FROM AN ARDUOUS JOURNEY EXHAUSTED AND BADLY NEEDING A REST
2024-04-02 06:24:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0002.json
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 293, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0002
generate
 16%|█▌        | 198/1232 [01:20<07:50,  2.20it/s]processing 198th semantic_sys file
198
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE WHARVES OF BROOKLYN AND EVERY PART OF NEW YORK BORDERING THE EAST RIVER WERE CROWDED WITH CURIOSITY SEEKERS
2024-04-02 06:24:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0036.json
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([330.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 365, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0036
generate
 16%|█▌        | 199/1232 [01:21<07:43,  2.23it/s]processing 199th semantic_sys file
199
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ANYHOW WE'LL LEAVE INSTRUCTIONS TO SHIP THE WHOLE MENAGERIE TO FRANCE
2024-04-02 06:24:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0019.json
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([274.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([307.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 340, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0019
generate
 16%|█▌        | 200/1232 [01:21<07:33,  2.28it/s]processing 200th semantic_sys file
200
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YES WE ARE CERTAINLY I REPLIED EVASIVELY BUT AFTER WE MAKE A DETOUR
2024-04-02 06:24:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0020.json
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([247.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([280.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([313.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 347, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0020
generate
 16%|█▋        | 201/1232 [01:22<07:26,  2.31it/s]processing 201th semantic_sys file
201
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I LEFT INSTRUCTIONS FOR SHIPPING MY CONTAINERS OF STUFFED ANIMALS AND DRIED PLANTS TO PARIS FRANCE
2024-04-02 06:24:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0027.json
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([291.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([326.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 361, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0027
generate
 16%|█▋        | 202/1232 [01:22<07:22,  2.33it/s]processing 202th semantic_sys file
202
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DEPARTING FROM FIVE HUNDRED THOUSAND THROATS THREE CHEERS BURST FORTH IN SUCCESSION
2024-04-02 06:24:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0037.json
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 244, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0037
generate
 16%|█▋        | 203/1232 [01:22<07:46,  2.21it/s]processing 203th semantic_sys file
203
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ONE OF THE SAILORS LED ME TO THE AFTERDECK WHERE I STOOD IN THE PRESENCE OF A SMART LOOKING OFFICER WHO EXTENDED HIS HAND TO ME
2024-04-02 06:24:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0031.json
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([273.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([305.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 338, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0031
generate
 17%|█▋        | 204/1232 [01:23<07:34,  2.26it/s]processing 204th semantic_sys file
204
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE WAS GOOD REASON TO STOP AND THINK EVEN FOR THE WORLD'S MOST EMOTIONLESS MAN
2024-04-02 06:24:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0014.json
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 261, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0014
generate
 17%|█▋        | 205/1232 [01:23<07:04,  2.42it/s]processing 205th semantic_sys file
205
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NOT ONCE DID HE COMMENT ON THE LENGTH OR THE HARDSHIPS OF A JOURNEY
2024-04-02 06:24:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0009.json
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([224.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([254.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 315, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0009
generate
 17%|█▋        | 206/1232 [01:24<07:01,  2.43it/s]processing 206th semantic_sys file
206
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WAS WELL SATISFIED WITH MY CABIN WHICH WAS LOCATED IN THE STERN AND OPENED INTO THE OFFICERS MESS
2024-04-02 06:24:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0033.json
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([320.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([359.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 397, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0033
generate
 17%|█▋        | 207/1232 [01:24<07:17,  2.35it/s]processing 207th semantic_sys file
207
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN PERSON WELCOME ABOARD PROFESSOR YOUR CABIN IS WAITING FOR YOU
2024-04-02 06:24:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0032.json
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 197, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0032
generate
 17%|█▋        | 208/1232 [01:24<06:46,  2.52it/s]processing 208th semantic_sys file
208
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WANTED NOTHING MORE THAN TO SEE MY COUNTRY AGAIN MY FRIENDS MY MODEST QUARTERS BY THE BOTANICAL GARDENS MY DEARLY BELOVED COLLECTIONS
2024-04-02 06:24:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([28], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0003.json
top_k_know_token:70
known_token_update:False
T:495
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:495
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:495
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:495
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:495
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:495
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:495
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:495
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:495
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:495
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:495
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:495
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:495
T - mask_len:tensor([352.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:495
T - mask_len:tensor([399.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:495
T - mask_len:tensor([447.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 495, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0003
generate
 17%|█▋        | 209/1232 [01:25<08:10,  2.09it/s]processing 209th semantic_sys file
209
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: CONSEIL I CALLED A THIRD TIME CONSEIL APPEARED
2024-04-02 06:24:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0015.json
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 144, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0015
generate
 17%|█▋        | 210/1232 [01:26<08:21,  2.04it/s]processing 210th semantic_sys file
210
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: PACK AS MUCH INTO MY TRUNK AS YOU CAN MY TRAVELING KIT MY SUITS SHIRTS AND SOCKS DON'T BOTHER COUNTING JUST SQUEEZE IT ALL IN AND HURRY
2024-04-02 06:24:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294828-0017.json
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([304.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 337, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294828-0017
generate
 17%|█▋        | 211/1232 [01:26<07:58,  2.13it/s]processing 211th semantic_sys file
211
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE NAUTILUS NEARLY PERISHES IN THE ANTARCTIC AND NEMO SINKS INTO A GROWING DEPRESSION
2024-04-02 06:24:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294825-0012.json
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 255, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294825-0012
generate
 17%|█▋        | 212/1232 [01:26<07:19,  2.32it/s]processing 212th semantic_sys file
212
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OTHER SUBTLETIES OCCUR INSIDE EACH EPISODE THE TEXTURES SPARKLING WITH WIT INFORMATION AND INSIGHT
2024-04-02 06:24:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294825-0005.json
top_k_know_token:70
known_token_update:False
T:428
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:428
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:428
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:428
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:428
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:428
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:428
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:428
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:428
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:428
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:428
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:428
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:428
T - mask_len:tensor([304.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:428
T - mask_len:tensor([345.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:428
T - mask_len:tensor([387.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 428, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294825-0005
generate
 17%|█▋        | 213/1232 [01:27<07:59,  2.12it/s]processing 213th semantic_sys file
213
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NEMO BUILDS A FABULOUS FUTURISTIC SUBMARINE THE NAUTILUS THEN CONDUCTS AN UNDERWATER CAMPAIGN OF VENGEANCE AGAINST HIS IMPERIALIST OPPRESSOR
2024-04-02 06:24:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294825-0003.json
top_k_know_token:70
known_token_update:False
T:583
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:583
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:583
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:583
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:583
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:583
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:583
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:583
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:583
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:583
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:583
T - mask_len:tensor([309.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:583
T - mask_len:tensor([360.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:583
T - mask_len:tensor([414.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:583
T - mask_len:tensor([470.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:583
T - mask_len:tensor([526.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 583, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294825-0003
generate
 17%|█▋        | 214/1232 [01:28<08:33,  1.98it/s]processing 214th semantic_sys file
214
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND IN THIS LAST ACTION HE FALLS INTO THE CLASSIC SIN OF PRIDE
2024-04-02 06:24:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294825-0010.json
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 177, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294825-0010
generate
 17%|█▋        | 215/1232 [01:28<07:45,  2.19it/s]processing 215th semantic_sys file
215
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS REALITY BEGINS TO EXPLAIN THE DARK POWER AND OTHERWORLDLY FASCINATION OF TWENTY THOUSAND LEAGUES UNDER THE SEAS
2024-04-02 06:24:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294825-0001.json
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 387, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294825-0001
generate
 18%|█▊        | 216/1232 [01:28<07:40,  2.21it/s]processing 216th semantic_sys file
216
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MILLIGRAM ROUGHLY ONE TWENTY EIGHT THOUSAND OF AN OUNCE
2024-04-02 06:24:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8463-294825-0016.json
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:206
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 206, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8463-294825-0016
generate
 18%|█▊        | 217/1232 [01:29<06:57,  2.43it/s]processing 217th semantic_sys file
217
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS KNOWLEDGE IS MEMORY IN ONE SENSE THOUGH IN ANOTHER IT IS NOT
2024-04-02 06:24:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8230-279154-0039.json
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 193, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8230-279154-0039
generate
 18%|█▊        | 218/1232 [01:29<07:04,  2.39it/s]processing 218th semantic_sys file
218
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN THIS CASE AS IN MOST OTHERS WHAT MAY BE TAKEN AS CERTAIN IN ADVANCE IS RATHER VAGUE
2024-04-02 06:24:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8230-279154-0023.json
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 326, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8230-279154-0023
generate
 18%|█▊        | 219/1232 [01:29<07:02,  2.39it/s]processing 219th semantic_sys file
219
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I COME NOW TO THE OTHER CHARACTERISTIC WHICH MEMORY IMAGES MUST HAVE IN ORDER TO ACCOUNT FOR OUR KNOWLEDGE OF THE PAST
2024-04-02 06:24:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8230-279154-0014.json
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([298.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([343.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([388.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([435.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 482, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8230-279154-0014
generate
 18%|█▊        | 220/1232 [01:30<07:29,  2.25it/s]processing 220th semantic_sys file
220
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE FIRST OF OUR VAGUE BUT INDUBITABLE DATA IS THAT THERE IS KNOWLEDGE OF THE PAST
2024-04-02 06:24:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8230-279154-0024.json
top_k_know_token:70
known_token_update:False
T:212
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:212
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:212
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:212
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:212
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:212
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:212
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:212
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:212
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:212
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:212
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:212
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:212
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:212
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:212
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 212, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8230-279154-0024
generate
 18%|█▊        | 221/1232 [01:30<06:56,  2.43it/s]processing 221th semantic_sys file
221
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE ANALYSIS OF KNOWLEDGE WILL OCCUPY US UNTIL THE END OF THE THIRTEENTH LECTURE AND IS THE MOST DIFFICULT PART OF OUR WHOLE ENTERPRISE
2024-04-02 06:24:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8230-279154-0000.json
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([288.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([331.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([375.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([420.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 465, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8230-279154-0000
generate
 18%|█▊        | 222/1232 [01:31<07:22,  2.28it/s]processing 222th semantic_sys file
222
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SOME POINTS MAY BE TAKEN AS FIXED AND SUCH AS ANY THEORY OF MEMORY MUST ARRIVE AT
2024-04-02 06:24:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8230-279154-0022.json
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 313, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8230-279154-0022
generate
 18%|█▊        | 223/1232 [01:31<07:38,  2.20it/s]processing 223th semantic_sys file
223
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THUS NO KNOWLEDGE AS TO THE PAST IS TO BE DERIVED FROM THE FEELING OF FAMILIARITY ALONE
2024-04-02 06:24:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8230-279154-0035.json
top_k_know_token:70
known_token_update:False
T:344
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:344
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:344
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:344
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:344
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:344
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:344
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:344
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:344
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:344
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:344
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:344
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:344
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:344
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:344
T - mask_len:tensor([311.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 344, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8230-279154-0035
generate
 18%|█▊        | 224/1232 [01:32<07:29,  2.24it/s]processing 224th semantic_sys file
224
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IF WE HAD RETAINED THE SUBJECT OR ACT IN KNOWLEDGE THE WHOLE PROBLEM OF MEMORY WOULD HAVE BEEN COMPARATIVELY SIMPLE
2024-04-02 06:24:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8230-279154-0020.json
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([313.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 346, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8230-279154-0020
generate
 18%|█▊        | 225/1232 [01:32<07:20,  2.29it/s]processing 225th semantic_sys file
225
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS DISTINCTION IS VITAL TO THE UNDERSTANDING OF MEMORY BUT IT IS NOT SO EASY TO CARRY OUT IN PRACTICE AS IT IS TO DRAW IN THEORY
2024-04-02 06:24:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8230-279154-0026.json
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([305.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([346.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([387.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 429, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8230-279154-0026
generate
 18%|█▊        | 226/1232 [01:33<07:30,  2.23it/s]processing 226th semantic_sys file
226
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ALL THAT I AM DOING IS TO USE ITS LOGICAL TENABILITY AS A HELP IN THE ANALYSIS OF WHAT OCCURS WHEN WE REMEMBER
2024-04-02 06:24:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8230-279154-0005.json
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([290.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:360
T - mask_len:tensor([325.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 360, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8230-279154-0005
generate
 18%|█▊        | 227/1232 [01:33<07:22,  2.27it/s]processing 227th semantic_sys file
227
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY MUST HAVE SOME CHARACTERISTIC WHICH MAKES US REGARD THEM AS REFERRING TO MORE OR LESS REMOTE PORTIONS OF THE PAST
2024-04-02 06:24:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8230-279154-0015.json
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([268.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([300.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 332, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8230-279154-0015
generate
 19%|█▊        | 228/1232 [01:34<07:32,  2.22it/s]processing 228th semantic_sys file
228
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SOME IMAGES LIKE SOME SENSATIONS FEEL VERY FAMILIAR WHILE OTHERS FEEL STRANGE
2024-04-02 06:24:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8230-279154-0011.json
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 272, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8230-279154-0011
generate
 19%|█▊        | 229/1232 [01:34<07:05,  2.36it/s]processing 229th semantic_sys file
229
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SEMON'S TWO BOOKS MENTIONED IN AN EARLIER LECTURE DO NOT TOUCH KNOWLEDGE MEMORY AT ALL CLOSELY
2024-04-02 06:24:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8230-279154-0030.json
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 316, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8230-279154-0030
generate
 19%|█▊        | 230/1232 [01:34<06:59,  2.39it/s]processing 230th semantic_sys file
230
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE MAY BE A SPECIFIC FEELING WHICH COULD BE CALLED THE FEELING OF PASTNESS ESPECIALLY WHERE IMMEDIATE MEMORY IS CONCERNED
2024-04-02 06:24:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8230-279154-0017.json
top_k_know_token:70
known_token_update:False
T:384
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:384
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:384
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:384
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:384
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:384
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:384
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:384
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:384
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:384
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:384
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:384
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:384
T - mask_len:tensor([273.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:384
T - mask_len:tensor([310.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:384
T - mask_len:tensor([347.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 384, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8230-279154-0017
generate
 19%|█▉        | 231/1232 [01:35<07:05,  2.35it/s]processing 231th semantic_sys file
231
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE FACT THAT A MAN CAN RECITE A POEM DOES NOT SHOW THAT HE REMEMBERS ANY PREVIOUS OCCASION ON WHICH HE HAS RECITED OR READ IT
2024-04-02 06:24:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8230-279154-0029.json
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([347.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([389.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 431, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8230-279154-0029
generate
 19%|█▉        | 232/1232 [01:35<07:20,  2.27it/s]processing 232th semantic_sys file
232
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE BEHAVIOURIST WHO ATTEMPTS TO MAKE PSYCHOLOGY A RECORD OF BEHAVIOUR HAS TO TRUST HIS MEMORY IN MAKING THE RECORD
2024-04-02 06:24:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8230-279154-0006.json
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([254.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([340.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([386.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([433.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 479, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8230-279154-0006
generate
 19%|█▉        | 233/1232 [01:36<07:53,  2.11it/s]processing 233th semantic_sys file
233
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: REMEMBERING HAS TO BE A PRESENT OCCURRENCE IN SOME WAY RESEMBLING OR RELATED TO WHAT IS REMEMBERED
2024-04-02 06:24:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8230-279154-0021.json
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 313, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8230-279154-0021
generate
 19%|█▉        | 234/1232 [01:36<08:01,  2.07it/s]processing 234th semantic_sys file
234
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NO THANK YOU I'LL JUST LOOK AT THE WHELPS AND LEAVE A MESSAGE ABOUT THEM WITH YOUR SHEPHERD
2024-04-02 06:24:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2094-142345-0051.json
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 271, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2094-142345-0051
generate
 19%|█▉        | 235/1232 [01:37<07:49,  2.12it/s]processing 235th semantic_sys file
235
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU'RE A RARE UN FOR SITTING DOWN TO YOUR WORK A LITTLE WHILE AFTER IT'S TIME TO PUT BY
2024-04-02 06:24:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2094-142345-0023.json
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([276.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([317.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([359.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([403.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 446, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2094-142345-0023
generate
 19%|█▉        | 236/1232 [01:37<08:10,  2.03it/s]processing 236th semantic_sys file
236
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SEVERAL CLOTHES HORSES A PILLION A SPINNING WHEEL AND AN OLD BOX WIDE OPEN AND STUFFED FULL OF COLOURED RAGS
2024-04-02 06:24:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2094-142345-0005.json
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([314.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([361.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([409.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([459.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 508, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2094-142345-0005
generate
 19%|█▉        | 237/1232 [01:38<09:16,  1.79it/s]processing 237th semantic_sys file
237
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NAY DEAR AUNT YOU NEVER HEARD ME SAY THAT ALL PEOPLE ARE CALLED TO FORSAKE THEIR WORK AND THEIR FAMILIES
2024-04-02 06:24:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2094-142345-0036.json
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([335.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([376.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 416, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2094-142345-0036
generate
 19%|█▉        | 238/1232 [01:38<09:01,  1.84it/s]processing 238th semantic_sys file
238
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I'VE STRONG ASSURANCE THAT NO EVIL WILL HAPPEN TO YOU AND MY UNCLE AND THE CHILDREN FROM ANYTHING I'VE DONE
2024-04-02 06:24:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2094-142345-0039.json
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([276.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 305, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2094-142345-0039
generate
 19%|█▉        | 239/1232 [01:39<08:16,  2.00it/s]processing 239th semantic_sys file
239
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BY THE BY I'VE NEVER SEEN YOUR DAIRY I MUST SEE YOUR DAIRY MISSUS POYSER
2024-04-02 06:24:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2094-142345-0058.json
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([273.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 302, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2094-142345-0058
generate
 19%|█▉        | 240/1232 [01:39<07:46,  2.13it/s]processing 240th semantic_sys file
240
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND THERE'S LINEN IN THE HOUSE AS I COULD WELL SPARE YOU FOR I'VE GOT LOTS O SHEETING AND TABLE CLOTHING AND TOWELLING AS ISN'T MADE UP
2024-04-02 06:24:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2094-142345-0034.json
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([247.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([284.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([322.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:399
T - mask_len:tensor([360.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 399, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2094-142345-0034
generate
 20%|█▉        | 241/1232 [01:40<07:39,  2.16it/s]processing 241th semantic_sys file
241
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OH SIR SAID MISSUS POYSER RATHER ALARMED YOU WOULDN'T LIKE IT AT ALL
2024-04-02 06:24:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2094-142345-0054.json
top_k_know_token:70
known_token_update:False
T:220
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:220
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:220
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:220
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:220
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:220
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:220
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:220
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:220
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:220
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:220
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:220
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:220
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:220
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:220
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 220, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2094-142345-0054
generate
 20%|█▉        | 242/1232 [01:40<07:21,  2.24it/s]processing 242th semantic_sys file
242
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MUNNY I TOULD IKE TO DO INTO DE BARN TO TOMMY TO SEE DE WHITTAWD
2024-04-02 06:24:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([24], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2094-142345-0027.json
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 259, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2094-142345-0027
generate
 20%|█▉        | 243/1232 [01:40<06:50,  2.41it/s]processing 243th semantic_sys file
243
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NO NO NO TOTTY UD GET HER FEET WET SAID MISSUS POYSER CARRYING AWAY HER IRON
2024-04-02 06:24:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2094-142345-0028.json
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([309.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([351.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([393.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 435, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2094-142345-0028
generate
 20%|█▉        | 244/1232 [01:41<07:07,  2.31it/s]processing 244th semantic_sys file
244
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT THE WINDOWS ARE PATCHED WITH WOODEN PANES AND THE DOOR I THINK IS LIKE THE GATE IT IS NEVER OPENED
2024-04-02 06:24:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2094-142345-0001.json
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 274, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2094-142345-0001
generate
 20%|█▉        | 245/1232 [01:41<06:45,  2.43it/s]processing 245th semantic_sys file
245
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SAID CAPTAIN DONNITHORNE SEATING HIMSELF WHERE HE COULD SEE ALONG THE SHORT PASSAGE TO THE OPEN DAIRY DOOR
2024-04-02 06:24:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2094-142345-0048.json
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([273.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([314.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([356.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([399.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 442, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2094-142345-0048
generate
 20%|█▉        | 246/1232 [01:42<07:04,  2.32it/s]processing 246th semantic_sys file
246
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DID EVER ANYBODY SEE THE LIKE SCREAMED MISSUS POYSER RUNNING TOWARDS THE TABLE WHEN HER EYE HAD FALLEN ON THE BLUE STREAM
2024-04-02 06:24:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2094-142345-0029.json
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([301.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([337.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 373, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2094-142345-0029
generate
 20%|██        | 247/1232 [01:42<07:50,  2.09it/s]processing 247th semantic_sys file
247
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NO SIR HE ISN'T HE'S GONE TO ROSSETER TO SEE MISTER WEST THE FACTOR ABOUT THE WOOL
2024-04-02 06:24:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2094-142345-0049.json
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 307, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2094-142345-0049
generate
 20%|██        | 248/1232 [01:43<07:43,  2.12it/s]processing 248th semantic_sys file
248
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I MUST COME ANOTHER DAY AND SEE YOUR HUSBAND I WANT TO HAVE A CONSULTATION WITH HIM ABOUT HORSES
2024-04-02 06:24:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2094-142345-0052.json
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([274.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 303, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2094-142345-0052
generate
 20%|██        | 249/1232 [01:43<07:27,  2.20it/s]processing 249th semantic_sys file
249
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MUNNY MY IRON'S TWITE TOLD PEASE PUT IT DOWN TO WARM
2024-04-02 06:24:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2094-142345-0024.json
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 178, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2094-142345-0024
generate
 20%|██        | 250/1232 [01:44<06:48,  2.40it/s]processing 250th semantic_sys file
250
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT THERE'S FATHER THE BARN SIR IF HE'D BE OF ANY USE
2024-04-02 06:24:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:24:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2094-142345-0050.json
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 167, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2094-142345-0050
generate
 20%|██        | 251/1232 [01:44<06:15,  2.61it/s]processing 251th semantic_sys file
251
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BY THIS TIME THE TWO GENTLEMEN HAD REACHED THE PALINGS AND HAD GOT DOWN FROM THEIR HORSES IT WAS PLAIN THEY MEANT TO COME IN
2024-04-02 06:25:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2094-142345-0043.json
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([258.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([293.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([328.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 363, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2094-142345-0043
generate
 20%|██        | 252/1232 [01:44<06:37,  2.47it/s]processing 252th semantic_sys file
252
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT'S THE WAY WITH YOU THAT'S THE ROAD YOU'D ALL LIKE TO GO HEADLONGS TO RUIN
2024-04-02 06:25:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2094-142345-0021.json
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 199, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2094-142345-0021
generate
 21%|██        | 253/1232 [01:45<06:53,  2.37it/s]processing 253th semantic_sys file
253
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT WAS THAT ALL HER REWARD ONE OF THE LADIES ASKED
2024-04-02 06:25:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-127105-0036.json
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:173
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 173, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-127105-0036
generate
 21%|██        | 254/1232 [01:45<06:19,  2.58it/s]processing 254th semantic_sys file
254
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE WAS A UNANIMOUS GROAN AT THIS AND MUCH REPROACH AFTER WHICH IN HIS PREOCCUPIED WAY HE EXPLAINED
2024-04-02 06:25:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([52], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-127105-0003.json
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([342.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 379, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-127105-0003
generate
 21%|██        | 255/1232 [01:46<06:34,  2.48it/s]processing 255th semantic_sys file
255
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE AWKWARD THING WAS THAT THEY HAD PRACTICALLY NO OTHER RELATIONS AND THAT HIS OWN AFFAIRS TOOK UP ALL HIS TIME
2024-04-02 06:25:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-127105-0028.json
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([259.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([290.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 321, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-127105-0028
generate
 21%|██        | 256/1232 [01:46<06:38,  2.45it/s]processing 256th semantic_sys file
256
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I COULD WRITE TO MY MAN AND ENCLOSE THE KEY HE COULD SEND DOWN THE PACKET AS HE FINDS IT
2024-04-02 06:25:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-127105-0005.json
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 265, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-127105-0005
generate
 21%|██        | 257/1232 [01:46<06:27,  2.52it/s]processing 257th semantic_sys file
257
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT SOUNDED DULL IT SOUNDED STRANGE AND ALL THE MORE SO BECAUSE OF HIS MAIN CONDITION WHICH WAS
2024-04-02 06:25:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-127105-0034.json
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([259.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([297.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([337.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([378.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 418, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-127105-0034
generate
 21%|██        | 258/1232 [01:47<06:48,  2.39it/s]processing 258th semantic_sys file
258
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE WERE PLENTY OF PEOPLE TO HELP BUT OF COURSE THE YOUNG LADY WHO SHOULD GO DOWN AS GOVERNESS WOULD BE IN SUPREME AUTHORITY
2024-04-02 06:25:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-127105-0029.json
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([299.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([380.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 421, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-127105-0029
generate
 21%|██        | 259/1232 [01:47<07:17,  2.23it/s]processing 259th semantic_sys file
259
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE FIRST OF THESE TOUCHES CONVEYED THAT THE WRITTEN STATEMENT TOOK UP THE TALE AT A POINT AFTER IT HAD IN A MANNER BEGUN
2024-04-02 06:25:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-127105-0026.json
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([264.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([304.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([344.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([386.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 427, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-127105-0026
generate
 21%|██        | 260/1232 [01:48<07:45,  2.09it/s]processing 260th semantic_sys file
260
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU'LL EASILY JUDGE WHY WHEN YOU HEAR BECAUSE THE THING HAD BEEN SUCH A SCARE HE CONTINUED TO FIX ME
2024-04-02 06:25:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-127105-0013.json
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([301.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([342.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([383.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 424, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-127105-0013
generate
 21%|██        | 261/1232 [01:48<08:07,  1.99it/s]processing 261th semantic_sys file
261
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE WAS THE MOST AGREEABLE WOMAN I'VE EVER KNOWN IN HER POSITION SHE WOULD HAVE BEEN WORTHY OF ANY WHATEVER
2024-04-02 06:25:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([58], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-127105-0011.json
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 387, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-127105-0011
generate
 21%|██▏       | 262/1232 [01:49<09:49,  1.65it/s]processing 262th semantic_sys file
262
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT WASN'T SIMPLY THAT SHE SAID SO BUT THAT I KNEW SHE HADN'T I WAS SURE I COULD SEE
2024-04-02 06:25:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-127105-0012.json
top_k_know_token:70
known_token_update:False
T:664
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:664
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:664
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:664
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:664
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:664
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:664
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:664
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:664
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:664
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:664
T - mask_len:tensor([351.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:664
T - mask_len:tensor([410.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:664
T - mask_len:tensor([472.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:664
T - mask_len:tensor([535.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:664
T - mask_len:tensor([599.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 664, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-127105-0012
generate
 21%|██▏       | 263/1232 [01:50<12:24,  1.30it/s]processing 263th semantic_sys file
263
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT WAS THIS OBSERVATION THAT DREW FROM DOUGLAS NOT IMMEDIATELY BUT LATER IN THE EVENING A REPLY THAT HAD THE INTERESTING CONSEQUENCE TO WHICH I CALL ATTENTION
2024-04-02 06:25:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-127105-0000.json
top_k_know_token:70
known_token_update:False
T:601
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:601
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:601
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:601
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:601
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:601
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:601
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:601
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:601
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:601
T - mask_len:tensor([268.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:601
T - mask_len:tensor([318.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:601
T - mask_len:tensor([372.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:601
T - mask_len:tensor([427.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:601
T - mask_len:tensor([484.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:601
T - mask_len:tensor([543.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 601, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-127105-0000
generate
 21%|██▏       | 264/1232 [01:51<13:06,  1.23it/s]processing 264th semantic_sys file
264
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WELL IF I DON'T KNOW WHO SHE WAS IN LOVE WITH I KNOW WHO HE WAS
2024-04-02 06:25:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-127105-0022.json
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([266.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([347.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([388.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 430, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-127105-0022
generate
 22%|██▏       | 265/1232 [01:52<13:30,  1.19it/s]processing 265th semantic_sys file
265
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE OTHERS RESENTED POSTPONEMENT BUT IT WAS JUST HIS SCRUPLES THAT CHARMED ME
2024-04-02 06:25:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-127105-0006.json
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 236, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-127105-0006
generate
 22%|██▏       | 266/1232 [01:53<12:34,  1.28it/s]processing 266th semantic_sys file
266
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SOMEONE ELSE TOLD A STORY NOT PARTICULARLY EFFECTIVE WHICH I SAW HE WAS NOT FOLLOWING
2024-04-02 06:25:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-127105-0001.json
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 242, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-127105-0001
generate
 22%|██▏       | 267/1232 [01:54<12:02,  1.34it/s]processing 267th semantic_sys file
267
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TO THIS HIS ANSWER WAS PROMPT OH THANK GOD NO AND IS THE RECORD YOURS
2024-04-02 06:25:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-127105-0007.json
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 247, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-127105-0007
generate
 22%|██▏       | 268/1232 [01:54<11:37,  1.38it/s]processing 268th semantic_sys file
268
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: CRIED ONE OF THE WOMEN HE TOOK NO NOTICE OF HER HE LOOKED AT ME BUT AS IF INSTEAD OF ME HE SAW WHAT HE SPOKE OF
2024-04-02 06:25:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-127105-0002.json
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([309.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([346.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 383, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-127105-0002
generate
 22%|██▏       | 269/1232 [01:55<12:26,  1.29it/s]processing 269th semantic_sys file
269
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HOUSECLEANING A DOMESTIC UPHEAVAL THAT MAKES IT EASY FOR THE GOVERNMENT TO ENLIST ALL THE SOLDIERS IT NEEDS
2024-04-02 06:25:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-121726-0010.json
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([323.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 358, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-121726-0010
generate
 22%|██▏       | 270/1232 [01:56<12:26,  1.29it/s]processing 270th semantic_sys file
270
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ANGOR PAIN PAINFUL TO HEAR
2024-04-02 06:25:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([19], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-121726-0002.json
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 98, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-121726-0002
generate
 22%|██▏       | 271/1232 [01:56<11:29,  1.39it/s]processing 271th semantic_sys file
271
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HARANGUE THE TIRESOME PRODUCT OF A TIRELESS TONGUE
2024-04-02 06:25:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([27], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-121726-0001.json
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 163, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-121726-0001
generate
 22%|██▏       | 272/1232 [01:57<10:50,  1.48it/s]processing 272th semantic_sys file
272
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HOSE MAN'S EXCUSE FOR WETTING THE WALK
2024-04-02 06:25:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([19], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-121726-0008.json
top_k_know_token:70
known_token_update:False
T:113
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:113
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:113
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:113
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:113
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:113
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:113
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:113
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:113
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:113
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:113
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:113
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:113
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:113
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:113
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 113, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-121726-0008
generate
 22%|██▏       | 273/1232 [01:58<10:16,  1.56it/s]processing 273th semantic_sys file
273
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HUSBAND THE NEXT THING TO A WIFE
2024-04-02 06:25:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-121726-0011.json
top_k_know_token:70
known_token_update:False
T:84
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:84
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:84
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:84
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:84
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:84
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:84
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:84
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:84
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:84
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:84
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:84
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:84
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:84
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:84
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 84, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-121726-0011
generate
 22%|██▏       | 274/1232 [01:58<10:46,  1.48it/s]processing 274th semantic_sys file
274
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HORSE SENSE A DEGREE OF WISDOM THAT KEEPS ONE FROM BETTING ON THE RACES
2024-04-02 06:25:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-121726-0007.json
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 249, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-121726-0007
generate
 22%|██▏       | 275/1232 [01:59<10:42,  1.49it/s]processing 275th semantic_sys file
275
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HEAVEN A GOOD PLACE TO BE RAISED TO
2024-04-02 06:25:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-121726-0004.json
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 125, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-121726-0004
generate
 22%|██▏       | 276/1232 [02:00<10:26,  1.53it/s]processing 276th semantic_sys file
276
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HOTEL A PLACE WHERE A GUEST OFTEN GIVES UP GOOD DOLLARS FOR POOR QUARTERS
2024-04-02 06:25:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-121726-0009.json
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 186, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-121726-0009
generate
 22%|██▏       | 277/1232 [02:00<09:30,  1.67it/s]processing 277th semantic_sys file
277
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HUSSY WOMAN AND BOND TIE
2024-04-02 06:25:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-121726-0012.json
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 103, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-121726-0012
generate
 23%|██▎       | 278/1232 [02:01<09:28,  1.68it/s]processing 278th semantic_sys file
278
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ALSO A POPULAR CONTRIVANCE WHEREBY LOVE MAKING MAY BE SUSPENDED BUT NOT STOPPED DURING THE PICNIC SEASON
2024-04-02 06:25:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([16], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-121726-0000.json
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([298.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([333.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 369, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-121726-0000
generate
 23%|██▎       | 279/1232 [02:02<10:32,  1.51it/s]processing 279th semantic_sys file
279
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HAY FEVER A HEART TROUBLE CAUSED BY FALLING IN LOVE WITH A GRASS WIDOW
2024-04-02 06:25:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([17], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_121-121726-0003.json
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 253, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_121-121726-0003
generate
 23%|██▎       | 280/1232 [02:02<11:20,  1.40it/s]processing 280th semantic_sys file
280
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN THE EVENINGS I CONFESS I DO THINK BUT I NEVER TROUBLE ANY ONE ELSE WITH MY THOUGHTS
2024-04-02 06:25:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0022.json
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 237, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0022
generate
 23%|██▎       | 281/1232 [02:03<11:16,  1.41it/s]processing 281th semantic_sys file
281
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I AM NOT GOOD ENOUGH FOR YOU AND YOU MUST BE KEPT FROM THE CONTAMINATION OF TOO INTIMATE SOCIETY
2024-04-02 06:25:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0045.json
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([258.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 285, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0045
generate
 23%|██▎       | 282/1232 [02:04<11:18,  1.40it/s]processing 282th semantic_sys file
282
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE MORE SHE IS ENGAGED IN HER PROPER DUTIES THE LESS LEISURE WILL SHE HAVE FOR IT EVEN AS AN ACCOMPLISHMENT AND A RECREATION
2024-04-02 06:25:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0013.json
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([258.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([336.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:417
T - mask_len:tensor([377.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 417, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0013
generate
 23%|██▎       | 283/1232 [02:05<11:50,  1.34it/s]processing 283th semantic_sys file
283
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: INDEED THERE WERE ONLY ONE OR TWO STRANGERS WHO COULD BE ADMITTED AMONG THE SISTERS WITHOUT PRODUCING THE SAME RESULT
2024-04-02 06:25:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([28], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0040.json
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([303.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 335, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0040
generate
 23%|██▎       | 284/1232 [02:05<12:28,  1.27it/s]processing 284th semantic_sys file
284
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AT TEA TIME THEY WERE SAD AND SILENT AND THE MEAL WENT AWAY UNTOUCHED BY ANY OF THE THREE
2024-04-02 06:25:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0051.json
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([291.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([326.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 361, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0051
generate
 23%|██▎       | 285/1232 [02:06<12:49,  1.23it/s]processing 285th semantic_sys file
285
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SURELY IT MUST BE BECAUSE WE ARE IN DANGER OF LOVING EACH OTHER TOO WELL OF LOSING SIGHT OF THE CREATOR IN IDOLATRY OF THE CREATURE
2024-04-02 06:25:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([27], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0003.json
top_k_know_token:70
known_token_update:False
T:1006
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:1006
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:1006
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:1006
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:1006
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:1006
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:1006
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:1006
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:1006
T - mask_len:tensor([368.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:1006
T - mask_len:tensor([448.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:1006
T - mask_len:tensor([532.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:1006
T - mask_len:tensor([622.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:1006
T - mask_len:tensor([714.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:1006
T - mask_len:tensor([810.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:1006
T - mask_len:tensor([908.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 1006, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0003
generate
 23%|██▎       | 286/1232 [02:08<18:13,  1.16s/it]processing 286th semantic_sys file
286
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OF THIS SECOND LETTER ALSO SHE SPOKE AND TOLD ME THAT IT CONTAINED AN INVITATION FOR HER TO GO AND SEE THE POET IF EVER SHE VISITED THE LAKES
2024-04-02 06:25:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0030.json
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([287.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([326.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([365.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 404, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0030
generate
 23%|██▎       | 287/1232 [02:09<17:19,  1.10s/it]processing 287th semantic_sys file
287
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I AM NOT DEPRECIATING IT WHEN I SAY THAT IN THESE TIMES IT IS NOT RARE
2024-04-02 06:25:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0010.json
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 238, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0010
generate
 23%|██▎       | 288/1232 [02:10<15:15,  1.03it/s]processing 288th semantic_sys file
288
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: KESWICK MARCH TWENTY SECOND EIGHTEEN THIRTY SEVEN DEAR MADAM
2024-04-02 06:25:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0028.json
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 226, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0028
generate
 23%|██▎       | 289/1232 [02:11<13:52,  1.13it/s]processing 289th semantic_sys file
289
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE A TORY AND CLERGYMAN'S DAUGHTER WAS ALWAYS IN A MINORITY OF ONE IN OUR HOUSE OF VIOLENT DISSENT AND RADICALISM
2024-04-02 06:25:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0005.json
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([318.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([361.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:448
T - mask_len:tensor([405.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 448, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0005
generate
 24%|██▎       | 290/1232 [02:11<13:43,  1.14it/s]processing 290th semantic_sys file
290
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TABBY HAD TENDED THEM IN THEIR CHILDHOOD THEY AND NONE OTHER SHOULD TEND HER IN HER INFIRMITY AND AGE
2024-04-02 06:25:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0050.json
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([276.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 305, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0050
generate
 24%|██▎       | 291/1232 [02:12<13:18,  1.18it/s]processing 291th semantic_sys file
291
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I KNOW THE FIRST LETTER I WROTE TO YOU WAS ALL SENSELESS TRASH FROM BEGINNING TO END BUT I AM NOT ALTOGETHER THE IDLE DREAMING BEING IT WOULD SEEM TO DENOTE
2024-04-02 06:25:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0020.json
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([347.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([389.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 431, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0020
generate
 24%|██▎       | 292/1232 [02:13<14:45,  1.06it/s]processing 292th semantic_sys file
292
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I CAREFULLY AVOID ANY APPEARANCE OF PREOCCUPATION AND ECCENTRICITY WHICH MIGHT LEAD THOSE I LIVE AMONGST TO SUSPECT THE NATURE OF MY PURSUITS
2024-04-02 06:25:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0023.json
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([266.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([347.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([388.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 430, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0023
generate
 24%|██▍       | 293/1232 [02:14<14:48,  1.06it/s]processing 293th semantic_sys file
293
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SATURDAY AFTER SATURDAY COMES ROUND AND I CAN HAVE NO HOPE OF HEARING YOUR KNOCK AT THE DOOR AND THEN BEING TOLD THAT MISS E IS COME OH DEAR
2024-04-02 06:25:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0033.json
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([316.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([358.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([401.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 444, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0033
generate
 24%|██▍       | 294/1232 [02:15<15:05,  1.04it/s]processing 294th semantic_sys file
294
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I HAD NOT VENTURED TO HOPE FOR SUCH A REPLY SO CONSIDERATE IN ITS TONE SO NOBLE IN ITS SPIRIT
2024-04-02 06:25:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0019.json
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([251.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([319.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 353, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0019
generate
 24%|██▍       | 295/1232 [02:16<13:39,  1.14it/s]processing 295th semantic_sys file
295
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: STUNG BY ANXIETY FOR THIS LITTLE SISTER SHE UPBRAIDED MISS W FOR HER FANCIED INDIFFERENCE TO ANNE'S STATE OF HEALTH
2024-04-02 06:25:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0054.json
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([247.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 273, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0054
generate
 24%|██▍       | 296/1232 [02:17<13:00,  1.20it/s]processing 296th semantic_sys file
296
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AGAIN I THANK YOU THIS INCIDENT I SUPPOSE WILL BE RENEWED NO MORE IF I LIVE TO BE AN OLD WOMAN I SHALL REMEMBER IT THIRTY YEARS HENCE AS A BRIGHT DREAM
2024-04-02 06:25:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0025.json
top_k_know_token:70
known_token_update:False
T:578
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:578
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:578
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:578
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:578
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:578
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:578
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:578
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:578
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:578
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:578
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:578
T - mask_len:tensor([357.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:578
T - mask_len:tensor([411.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:578
T - mask_len:tensor([466.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:578
T - mask_len:tensor([522.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 578, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0025
generate
 24%|██▍       | 297/1232 [02:18<14:45,  1.06it/s]processing 297th semantic_sys file
297
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOUR LETTER HAS GIVEN ME GREAT PLEASURE AND I SHOULD NOT FORGIVE MYSELF IF I DID NOT TELL YOU SO
2024-04-02 06:25:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0029.json
top_k_know_token:70
known_token_update:False
T:410
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:410
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:410
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:410
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:410
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:410
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:410
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:410
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:410
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:410
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:410
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:410
T - mask_len:tensor([254.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:410
T - mask_len:tensor([291.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:410
T - mask_len:tensor([331.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:410
T - mask_len:tensor([370.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 410, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0029
generate
 24%|██▍       | 298/1232 [02:19<14:12,  1.10it/s]processing 298th semantic_sys file
298
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HER FEEBLE HEALTH GAVE HER HER YIELDING MANNER FOR SHE COULD NEVER OPPOSE ANY ONE WITHOUT GATHERING UP ALL HER STRENGTH FOR THE STRUGGLE
2024-04-02 06:25:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0006.json
top_k_know_token:70
known_token_update:False
T:456
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:456
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:456
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:456
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:456
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:456
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:456
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:456
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:456
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:456
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:456
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:456
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:456
T - mask_len:tensor([324.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:456
T - mask_len:tensor([368.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:456
T - mask_len:tensor([412.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 456, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0006
generate
 24%|██▍       | 299/1232 [02:20<14:04,  1.11it/s]processing 299th semantic_sys file
299
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE REFUSED AT FIRST TO LISTEN TO THE CAREFUL ADVICE IT WAS REPUGNANT TO HIS LIBERAL NATURE
2024-04-02 06:25:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0048.json
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([278.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([315.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([353.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 391, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0048
generate
 24%|██▍       | 300/1232 [02:21<13:58,  1.11it/s]processing 300th semantic_sys file
300
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AFTER THIS DISAPPOINTMENT I NEVER DARE RECKON WITH CERTAINTY ON THE ENJOYMENT OF A PLEASURE AGAIN IT SEEMS AS IF SOME FATALITY STOOD BETWEEN YOU AND ME
2024-04-02 06:25:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0044.json
top_k_know_token:70
known_token_update:False
T:553
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:553
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:553
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:553
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:553
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:553
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:553
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:553
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:553
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:553
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:553
T - mask_len:tensor([293.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:553
T - mask_len:tensor([342.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:553
T - mask_len:tensor([393.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:553
T - mask_len:tensor([446.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:553
T - mask_len:tensor([499.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 553, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0044
generate
 24%|██▍       | 301/1232 [02:22<14:27,  1.07it/s]processing 301th semantic_sys file
301
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: JANUARY AND FEBRUARY OF EIGHTEEN THIRTY SEVEN HAD PASSED AWAY AND STILL THERE WAS NO REPLY FROM SOUTHEY
2024-04-02 06:25:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0009.json
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([298.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([333.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 369, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0009
generate
 25%|██▍       | 302/1232 [02:22<13:43,  1.13it/s]processing 302th semantic_sys file
302
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE SPOKE FRENCH PERFECTLY I HAVE BEEN TOLD WHEN NEED WAS BUT DELIGHTED USUALLY IN TALKING THE BROADEST YORKSHIRE
2024-04-02 06:25:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0007.json
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([302.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 375, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0007
generate
 25%|██▍       | 303/1232 [02:23<13:38,  1.14it/s]processing 303th semantic_sys file
303
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TABBY HAD LIVED WITH THEM FOR TEN OR TWELVE YEARS AND WAS AS CHARLOTTE EXPRESSED IT ONE OF THE FAMILY
2024-04-02 06:25:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0047.json
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([253.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([308.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([366.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([427.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([491.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([557.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:691
T - mask_len:tensor([624.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 691, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0047
generate
 25%|██▍       | 304/1232 [02:25<15:28,  1.00s/it]processing 304th semantic_sys file
304
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND OFTEN HAS MY MOTHER SAID WHILE ON HER LAP I LAID MY HEAD SHE FEARED FOR TIME I WAS NOT MADE BUT FOR ETERNITY
2024-04-02 06:25:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0000.json
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([278.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([319.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([362.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:449
T - mask_len:tensor([405.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 449, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0000
generate
 25%|██▍       | 305/1232 [02:25<14:54,  1.04it/s]processing 305th semantic_sys file
305
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT IT IS NOT WITH A VIEW TO DISTINCTION THAT YOU SHOULD CULTIVATE THIS TALENT IF YOU CONSULT YOUR OWN HAPPINESS
2024-04-02 06:25:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0011.json
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([308.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([345.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 382, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0011
generate
 25%|██▍       | 306/1232 [02:26<15:01,  1.03it/s]processing 306th semantic_sys file
306
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU WILL SAY THAT A WOMAN HAS NO NEED OF SUCH A CAUTION THERE CAN BE NO PERIL IN IT FOR HER
2024-04-02 06:25:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([57], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0012.json
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([302.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([343.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([384.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 425, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0012
generate
 25%|██▍       | 307/1232 [02:27<14:53,  1.04it/s]processing 307th semantic_sys file
307
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ON AUGUST TWENTY SEVENTH EIGHTEEN THIRTY SEVEN SHE WRITES
2024-04-02 06:25:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0031.json
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 208, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0031
generate
 25%|██▌       | 308/1232 [02:28<14:03,  1.10it/s]processing 308th semantic_sys file
308
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I THOUGHT IT THEREFORE MY DUTY WHEN I LEFT SCHOOL TO BECOME A GOVERNESS
2024-04-02 06:25:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0021.json
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 196, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0021
generate
 25%|██▌       | 309/1232 [02:29<12:38,  1.22it/s]processing 309th semantic_sys file
309
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WISH IT WOULD RECUR AGAIN BUT IT WILL TAKE TWO OR THREE INTERVIEWS BEFORE THE STIFFNESS THE ESTRANGEMENT OF THIS LONG SEPARATION WILL WEAR AWAY
2024-04-02 06:25:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0035.json
top_k_know_token:70
known_token_update:False
T:597
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:597
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:597
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:597
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:597
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:597
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:597
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:597
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:597
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:597
T - mask_len:tensor([266.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:597
T - mask_len:tensor([316.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:597
T - mask_len:tensor([369.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:597
T - mask_len:tensor([424.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:597
T - mask_len:tensor([481.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:597
T - mask_len:tensor([539.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 597, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0035
generate
 25%|██▌       | 310/1232 [02:30<14:42,  1.04it/s]processing 310th semantic_sys file
310
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I CANNOT DENY MYSELF THE GRATIFICATION OF INSERTING SOUTHEY'S REPLY
2024-04-02 06:25:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([52], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0027.json
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 210, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0027
generate
 25%|██▌       | 311/1232 [02:31<13:47,  1.11it/s]processing 311th semantic_sys file
311
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TO THOSE DUTIES YOU HAVE NOT YET BEEN CALLED AND WHEN YOU ARE YOU WILL BE LESS EAGER FOR CELEBRITY
2024-04-02 06:25:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3575-170457-0014.json
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([297.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 329, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3575-170457-0014
generate
 25%|██▌       | 312/1232 [02:32<13:07,  1.17it/s]processing 312th semantic_sys file
312
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FOR A FULL HOUR HE HAD PACED UP AND DOWN WAITING BUT HE COULD WAIT NO LONGER
2024-04-02 06:25:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 313th semantic_sys file
313
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE STOOD STILL IN DEFERENCE TO THEIR CALLS AND PARRIED THEIR BANTER WITH EASY WORDS
2024-04-02 06:25:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134691-0022.json
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 288, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134691-0022
generate
 25%|██▌       | 314/1232 [02:32<09:43,  1.57it/s]processing 314th semantic_sys file
314
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A MOMENT BEFORE THE GHOST OF THE ANCIENT KINGDOM OF THE DANES HAD LOOKED FORTH THROUGH THE VESTURE OF THE HAZEWRAPPED CITY
2024-04-02 06:25:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134691-0025.json
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([300.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([336.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 372, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134691-0025
generate
 26%|██▌       | 315/1232 [02:33<10:30,  1.45it/s]processing 315th semantic_sys file
315
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT WAS A PAIN TO SEE THEM AND A SWORD LIKE PAIN TO SEE THE SIGNS OF ADOLESCENCE THAT MADE REPELLENT THEIR PITIABLE NAKEDNESS
2024-04-02 06:25:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134691-0023.json
top_k_know_token:70
known_token_update:False
T:661
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:661
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:661
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:661
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:661
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:661
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:661
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:661
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:661
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:661
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:661
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:661
T - mask_len:tensor([409.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:661
T - mask_len:tensor([470.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:661
T - mask_len:tensor([533.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:661
T - mask_len:tensor([597.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 661, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134691-0023
generate
 26%|██▌       | 316/1232 [02:34<13:03,  1.17it/s]processing 316th semantic_sys file
316
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHOSE FEET ARE AS THE FEET OF HARTS AND UNDERNEATH THE EVERLASTING ARMS
2024-04-02 06:25:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134691-0005.json
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 284, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134691-0005
generate
 26%|██▌       | 317/1232 [02:35<12:25,  1.23it/s]processing 317th semantic_sys file
317
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: PRIDE AFTER SATISFACTION UPLIFTED HIM LIKE LONG SLOW WAVES
2024-04-02 06:25:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134691-0004.json
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 214, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134691-0004
generate
 26%|██▌       | 318/1232 [02:36<11:35,  1.31it/s]processing 318th semantic_sys file
318
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY WERE VOYAGING ACROSS THE DESERTS OF THE SKY A HOST OF NOMADS ON THE MARCH VOYAGING HIGH OVER IRELAND WESTWARD BOUND
2024-04-02 06:25:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134691-0016.json
top_k_know_token:70
known_token_update:False
T:699
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:699
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:699
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:699
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:699
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:699
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:699
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:699
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:699
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:699
T - mask_len:tensor([311.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:699
T - mask_len:tensor([370.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:699
T - mask_len:tensor([432.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:699
T - mask_len:tensor([497.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:699
T - mask_len:tensor([563.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:699
T - mask_len:tensor([631.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 699, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134691-0016
generate
 26%|██▌       | 319/1232 [02:37<13:23,  1.14it/s]processing 319th semantic_sys file
319
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE PHRASE AND THE DAY AND THE SCENE HARMONIZED IN A CHORD
2024-04-02 06:25:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 320th semantic_sys file
320
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE PRIDE OF THAT DIM IMAGE BROUGHT BACK TO HIS MIND THE DIGNITY OF THE OFFICE HE HAD REFUSED
2024-04-02 06:25:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 321th semantic_sys file
321
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE RETREAT WILL BEGIN ON WEDNESDAY AFTERNOON IN HONOUR OF SAINT FRANCIS XAVIER WHOSE FEAST DAY IS SATURDAY
2024-04-02 06:25:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134686-0028.json
top_k_know_token:70
known_token_update:False
T:494
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:494
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:494
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:494
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:494
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:494
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:494
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:494
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:494
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:494
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:494
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:494
T - mask_len:tensor([305.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:494
T - mask_len:tensor([351.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:494
T - mask_len:tensor([398.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:494
T - mask_len:tensor([446.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 494, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134686-0028
generate
 26%|██▌       | 322/1232 [02:38<08:46,  1.73it/s]processing 322th semantic_sys file
322
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE RECTOR DID NOT ASK FOR A CATECHISM TO HEAR THE LESSON FROM
2024-04-02 06:25:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134686-0026.json
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([224.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 248, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134686-0026
generate
 26%|██▌       | 323/1232 [02:39<09:06,  1.66it/s]processing 323th semantic_sys file
323
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN THE SILENCE THEIR DARK FIRE KINDLED THE DUSK INTO A TAWNY GLOW
2024-04-02 06:25:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134686-0037.json
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 209, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134686-0037
generate
 26%|██▋       | 324/1232 [02:39<09:12,  1.64it/s]processing 324th semantic_sys file
324
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IF EVER HE WAS IMPELLED TO CAST SIN FROM HIM AND TO REPENT THE IMPULSE THAT MOVED HIM WAS THE WISH TO BE HER KNIGHT
2024-04-02 06:25:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134686-0013.json
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([311.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([363.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([418.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([474.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([531.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 588, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134686-0013
generate
 26%|██▋       | 325/1232 [02:40<11:05,  1.36it/s]processing 325th semantic_sys file
325
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD NIGHT HUSBAND
2024-04-02 06:25:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134686-0004.json
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([222.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 312, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134686-0004
generate
 26%|██▋       | 326/1232 [02:41<11:11,  1.35it/s]processing 326th semantic_sys file
326
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A COLD LUCID INDIFFERENCE REIGNED IN HIS SOUL
2024-04-02 06:25:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134686-0007.json
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 186, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134686-0007
generate
 27%|██▋       | 327/1232 [02:42<10:46,  1.40it/s]processing 327th semantic_sys file
327
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE CHAOS IN WHICH HIS ARDOUR EXTINGUISHED ITSELF WAS A COLD INDIFFERENT KNOWLEDGE OF HIMSELF
2024-04-02 06:25:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134686-0008.json
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([292.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 323, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134686-0008
generate
 27%|██▋       | 328/1232 [02:43<11:00,  1.37it/s]processing 328th semantic_sys file
328
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ON FRIDAY CONFESSION WILL BE HEARD ALL THE AFTERNOON AFTER BEADS
2024-04-02 06:25:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134686-0029.json
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 174, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134686-0029
generate
 27%|██▋       | 329/1232 [02:43<10:30,  1.43it/s]processing 329th semantic_sys file
329
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE MUSIC CAME NEARER AND HE RECALLED THE WORDS THE WORDS OF SHELLEY'S FRAGMENT UPON THE MOON WANDERING COMPANIONLESS PALE FOR WEARINESS
2024-04-02 06:25:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:25:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134686-0005.json
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([261.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([305.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([397.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([445.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 493, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134686-0005
generate
 27%|██▋       | 330/1232 [02:44<12:10,  1.23it/s]processing 330th semantic_sys file
330
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE RECTOR PAUSED AND THEN SHAKING HIS CLASPED HANDS BEFORE HIM WENT ON
2024-04-02 06:26:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134686-0034.json
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 189, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134686-0034
generate
 27%|██▋       | 331/1232 [02:45<12:08,  1.24it/s]processing 331th semantic_sys file
331
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: STEPHEN'S HEART BEGAN SLOWLY TO FOLD AND FADE WITH FEAR LIKE A WITHERING FLOWER
2024-04-02 06:26:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134686-0031.json
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 247, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134686-0031
generate
 27%|██▋       | 332/1232 [02:46<11:51,  1.27it/s]processing 332th semantic_sys file
332
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT THE DUSK DEEPENING IN THE SCHOOLROOM COVERED OVER HIS THOUGHTS THE BELL RANG
2024-04-02 06:26:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134686-0015.json
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 272, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134686-0015
generate
 27%|██▋       | 333/1232 [02:47<11:30,  1.30it/s]processing 333th semantic_sys file
333
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: STEPHEN LEANING BACK AND DRAWING IDLY ON HIS SCRIBBLER LISTENED TO THE TALK ABOUT HIM WHICH HERON CHECKED FROM TIME TO TIME BY SAYING
2024-04-02 06:26:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134686-0017.json
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([280.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([322.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([365.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([409.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 453, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134686-0017
generate
 27%|██▋       | 334/1232 [02:48<12:35,  1.19it/s]processing 334th semantic_sys file
334
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IF A LAYMAN IN GIVING BAPTISM POUR THE WATER BEFORE SAYING THE WORDS IS THE CHILD BAPTIZED
2024-04-02 06:26:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134686-0021.json
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 232, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134686-0021
generate
 27%|██▋       | 335/1232 [02:48<11:57,  1.25it/s]processing 335th semantic_sys file
335
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A GENTLE KICK FROM THE TALL BOY IN THE BENCH BEHIND URGED STEPHEN TO ASK A DIFFICULT QUESTION
2024-04-02 06:26:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134686-0025.json
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 242, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134686-0025
generate
 27%|██▋       | 336/1232 [02:49<11:57,  1.25it/s]processing 336th semantic_sys file
336
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS
2024-04-02 06:26:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134686-0002.json
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 309, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134686-0002
generate
 27%|██▋       | 337/1232 [02:50<11:52,  1.26it/s]processing 337th semantic_sys file
337
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE IS CALLED AS YOU KNOW THE APOSTLE OF THE INDIES
2024-04-02 06:26:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134686-0032.json
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 201, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134686-0032
generate
 27%|██▋       | 338/1232 [02:50<11:01,  1.35it/s]processing 338th semantic_sys file
338
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WELL NOW ENNIS I DECLARE YOU HAVE A HEAD AND SO HAS MY STICK
2024-04-02 06:26:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1089-134686-0010.json
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 271, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1089-134686-0010
generate
 28%|██▊       | 339/1232 [02:51<11:20,  1.31it/s]processing 339th semantic_sys file
339
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEN SHE GAVE ROSALIE BACK HER MAGIC RING THANKING THE KIND WITCH FOR ALL SHE HAD DONE FOR THEM
2024-04-02 06:26:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284449-0008.json
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 255, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284449-0008
generate
 28%|██▊       | 340/1232 [02:52<10:48,  1.38it/s]processing 340th semantic_sys file
340
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT EVENING TROT GAVE A GRAND BALL IN THE PALACE TO WHICH THE MOST IMPORTANT OF THE PINKIES AND THE BLUESKINS WERE INVITED
2024-04-02 06:26:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284449-0019.json
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([323.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 358, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284449-0019
generate
 28%|██▊       | 341/1232 [02:53<11:18,  1.31it/s]processing 341th semantic_sys file
341
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NOW THEN LET'S ENTER THE CITY AN ENJOY THE GRAND FEAST THAT'S BEING COOKED I'M NEARLY STARVED MYSELF FOR THIS CONQUERIN KINGDOMS IS HARD WORK
2024-04-02 06:26:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284449-0007.json
top_k_know_token:70
known_token_update:False
T:506
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:506
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:506
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:506
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:506
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:506
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:506
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:506
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:506
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:506
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:506
T - mask_len:tensor([268.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:506
T - mask_len:tensor([313.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:506
T - mask_len:tensor([360.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:506
T - mask_len:tensor([408.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:506
T - mask_len:tensor([457.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 506, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284449-0007
generate
 28%|██▊       | 342/1232 [02:54<12:28,  1.19it/s]processing 342th semantic_sys file
342
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SCUSE ME SAID TROT I NEGLECTED TO TELL YOU THAT YOU'RE NOT THE BOOLOOROO ANY MORE
2024-04-02 06:26:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284449-0013.json
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([247.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 273, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284449-0013
generate
 28%|██▊       | 343/1232 [02:55<12:14,  1.21it/s]processing 343th semantic_sys file
343
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I'LL GLADLY DO THAT PROMISED THE NEW BOOLOOROO AND I'LL FEED THE HONORABLE GOAT ALL THE SHAVINGS AND LEATHER AND TIN CANS HE CAN EAT BESIDES THE GRASS
2024-04-02 06:26:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284449-0012.json
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([300.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([402.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([456.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([511.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 566, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284449-0012
generate
 28%|██▊       | 344/1232 [02:56<13:48,  1.07it/s]processing 344th semantic_sys file
344
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AS A PRIVATE CITIZEN I SHALL BE A MODEL OF DEPORTMENT BECAUSE IT WOULD BE DANGEROUS TO BE OTHERWISE
2024-04-02 06:26:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284449-0016.json
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:288
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 288, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284449-0016
generate
 28%|██▊       | 345/1232 [02:57<16:57,  1.15s/it]processing 345th semantic_sys file
345
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I'LL NOT BE WICKED ANY MORE SIGHED THE OLD BOOLOOROO I'LL REFORM
2024-04-02 06:26:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284449-0015.json
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([258.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 285, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284449-0015
generate
 28%|██▊       | 346/1232 [02:58<15:16,  1.03s/it]processing 346th semantic_sys file
346
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE COMBINED BANDS OF BOTH THE COUNTRIES PLAYED THE MUSIC AND A FINE SUPPER WAS SERVED
2024-04-02 06:26:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284449-0020.json
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 265, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284449-0020
generate
 28%|██▊       | 347/1232 [02:59<15:19,  1.04s/it]processing 347th semantic_sys file
347
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SO GHIP GHISIZZLE ORDERED THE CAPTAIN TO TAKE A FILE OF SOLDIERS AND ESCORT THE RAVING BEAUTIES TO THEIR NEW HOME
2024-04-02 06:26:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284449-0018.json
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([253.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([284.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 314, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284449-0018
generate
 28%|██▊       | 348/1232 [03:00<14:58,  1.02s/it]processing 348th semantic_sys file
348
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHEN THE BLUESKINS SAW GHIP GHISIZZLE THEY RAISED ANOTHER GREAT SHOUT FOR HE WAS THE FAVORITE OF THE SOLDIERS AND VERY POPULAR WITH ALL THE PEOPLE
2024-04-02 06:26:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284449-0003.json
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 387, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284449-0003
generate
 28%|██▊       | 349/1232 [03:01<13:58,  1.05it/s]processing 349th semantic_sys file
349
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEN THEY ALL MARCHED OUT A LITTLE WAY INTO THE FIELDS AND FOUND THAT THE ARMY OF PINKIES HAD ALREADY FORMED AND WAS ADVANCING STEADILY TOWARD THEM
2024-04-02 06:26:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284449-0001.json
top_k_know_token:70
known_token_update:False
T:663
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:663
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:663
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:663
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:663
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:663
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:663
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:663
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:663
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:663
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:663
T - mask_len:tensor([351.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:663
T - mask_len:tensor([410.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:663
T - mask_len:tensor([471.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:663
T - mask_len:tensor([534.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:663
T - mask_len:tensor([599.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 663, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284449-0001
generate
 28%|██▊       | 350/1232 [03:02<14:51,  1.01s/it]processing 350th semantic_sys file
350
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE ROOM OF THE GREAT KNIFE WAS HIGH AND BIG AND AROUND IT RAN ROWS OF BENCHES FOR THE SPECTATORS TO SIT UPON
2024-04-02 06:26:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([53], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284447-0005.json
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 301, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284447-0005
generate
 28%|██▊       | 351/1232 [03:03<14:38,  1.00it/s]processing 351th semantic_sys file
351
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WOULDN'T MIND A CUP O COFFEE MYSELF SAID CAP'N BILL I'VE HAD CONSID'BLE EXERCISE THIS MORNIN AND I'M ALL READY FOR BREAKFAS
2024-04-02 06:26:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284447-0002.json
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([320.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([359.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 397, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284447-0002
generate
 29%|██▊       | 352/1232 [03:04<13:56,  1.05it/s]processing 352th semantic_sys file
352
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: RICH JEWELS OF BLUE STONES GLITTERED UPON THEIR PERSONS AND THE ROYAL LADIES WERE FULLY AS GORGEOUS AS THEY WERE HAUGHTY AND OVERBEARING
2024-04-02 06:26:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284447-0008.json
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([278.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([315.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([353.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 391, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284447-0008
generate
 29%|██▊       | 353/1232 [03:05<13:23,  1.09it/s]processing 353th semantic_sys file
353
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE GOAT'S WARLIKE SPIRIT WAS ROUSED BY THIS SUCCESSFUL ATTACK
2024-04-02 06:26:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284447-0020.json
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 195, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284447-0020
generate
 29%|██▊       | 354/1232 [03:05<12:03,  1.21it/s]processing 354th semantic_sys file
354
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEREFORE HER MAJESTY PAID NO ATTENTION TO ANYONE AND NO ONE PAID ANY ATTENTION TO HER
2024-04-02 06:26:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284447-0007.json
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([288.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 319, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284447-0007
generate
 29%|██▉       | 355/1232 [03:06<11:52,  1.23it/s]processing 355th semantic_sys file
355
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHY YOU SAID TO FETCH THE FIRST LIVING CREATURE WE MET AND THAT WAS THIS BILLYGOAT REPLIED THE CAPTAIN PANTING HARD AS HE HELD FAST TO ONE OF THE GOAT'S HORNS
2024-04-02 06:26:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284447-0013.json
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([288.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([331.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([375.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([420.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 465, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284447-0013
generate
 29%|██▉       | 356/1232 [03:07<12:06,  1.21it/s]processing 356th semantic_sys file
356
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HOLD HIM FAST MY MEN AND AS SOON AS I'VE HAD MY COFFEE AND OATMEAL I'LL TAKE HIM TO THE ROOM OF THE GREAT KNIFE AND PATCH HIM
2024-04-02 06:26:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284447-0001.json
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([251.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([327.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([367.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 406, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284447-0001
generate
 29%|██▉       | 357/1232 [03:08<12:12,  1.19it/s]processing 357th semantic_sys file
357
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I COULDN'T SHIVER MUCH BEIN BOUND SO TIGHT BUT WHEN I'M LOOSE I MEAN TO HAVE JUS ONE GOOD SHIVER TO RELIEVE MY FEELIN'S
2024-04-02 06:26:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284447-0023.json
top_k_know_token:70
known_token_update:False
T:536
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:536
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:536
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:536
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:536
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:536
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:536
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:536
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:536
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:536
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:536
T - mask_len:tensor([284.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:536
T - mask_len:tensor([331.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:536
T - mask_len:tensor([381.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:536
T - mask_len:tensor([432.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:536
T - mask_len:tensor([484.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 536, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284447-0023
generate
 29%|██▉       | 358/1232 [03:09<13:56,  1.04it/s]processing 358th semantic_sys file
358
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AS SOON AS THEY ENTERED THE ROOM OF THE GREAT KNIFE THE BOOLOOROO GAVE A YELL OF DISAPPOINTMENT
2024-04-02 06:26:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284447-0004.json
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([224.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([254.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 315, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284447-0004
generate
 29%|██▉       | 359/1232 [03:10<13:16,  1.10it/s]processing 359th semantic_sys file
359
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT CAP'N BILL MADE NO SUCH ATTEMPT KNOWING IT WOULD BE USELESS
2024-04-02 06:26:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284447-0003.json
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([274.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([311.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([349.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 386, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284447-0003
generate
 29%|██▉       | 360/1232 [03:11<13:00,  1.12it/s]processing 360th semantic_sys file
360
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE IDEA OF PATCHING CAP'N BILL TO A GOAT WAS VASTLY AMUSING TO HIM AND THE MORE HE THOUGHT OF IT THE MORE HE ROARED WITH LAUGHTER
2024-04-02 06:26:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284447-0014.json
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([281.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([315.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 349, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284447-0014
generate
 29%|██▉       | 361/1232 [03:12<12:53,  1.13it/s]processing 361th semantic_sys file
361
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AT ONCE THE GOAT GAVE A LEAP ESCAPED FROM THE SOLDIERS AND WITH BOWED HEAD RUSHED UPON THE BOOLOOROO
2024-04-02 06:26:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284447-0018.json
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 304, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284447-0018
generate
 29%|██▉       | 362/1232 [03:13<12:28,  1.16it/s]processing 362th semantic_sys file
362
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEN HE RUSHED DOWN STAIRS INTO THE COURTYARD SHOUTING LOUDLY FOR HIS SOLDIERS AND THREATENING TO PATCH EVERYBODY IN HIS DOMINIONS IF THE SAILORMAN WAS NOT RECAPTURED
2024-04-02 06:26:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284447-0000.json
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([276.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([318.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([360.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([404.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 447, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284447-0000
generate
 29%|██▉       | 363/1232 [03:13<13:00,  1.11it/s]processing 363th semantic_sys file
363
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: COME AND GET THE BOOLOOROO SHE SAID GOING TOWARD THE BENCHES
2024-04-02 06:26:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-284447-0024.json
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 139, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-284447-0024
generate
 30%|██▉       | 364/1232 [03:14<11:38,  1.24it/s]processing 364th semantic_sys file
364
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT WAS BUT RUSTLING OF DRIPPING PLANTS IN THE DARK
2024-04-02 06:26:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([26], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-292519-0013.json
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 192, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-292519-0013
generate
 30%|██▉       | 365/1232 [03:15<10:58,  1.32it/s]processing 365th semantic_sys file
365
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OLD DANCES ARE SIMPLIFIED OF THEIR YEARNING BLEACHED BY TIME
2024-04-02 06:26:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-292519-0010.json
top_k_know_token:70
known_token_update:False
T:152
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:152
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:152
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:152
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:152
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:152
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:152
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:152
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:152
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:152
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:152
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:152
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:152
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:152
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:152
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 152, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-292519-0010
generate
 30%|██▉       | 366/1232 [03:15<10:35,  1.36it/s]processing 366th semantic_sys file
366
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THROUGH THE BLACK NIGHT RAIN HE SANG TO HER WINDOW BARS
2024-04-02 06:26:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-292519-0012.json
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 201, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-292519-0012
generate
 30%|██▉       | 367/1232 [03:16<11:18,  1.27it/s]processing 367th semantic_sys file
367
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHILE THE OLD GOLD AND THE MARBLE STAYS FOREVER GLEAMING ITS SOFT STRONG BLAZE CALM IN THE EARLY EVENING GLOW
2024-04-02 06:26:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-292519-0005.json
top_k_know_token:70
known_token_update:False
T:701
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:701
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:701
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:701
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:701
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:701
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:701
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:701
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:701
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:701
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:701
T - mask_len:tensor([371.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:701
T - mask_len:tensor([433.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:701
T - mask_len:tensor([498.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:701
T - mask_len:tensor([565.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:701
T - mask_len:tensor([633.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 701, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-292519-0005
generate
 30%|██▉       | 368/1232 [03:18<13:12,  1.09it/s]processing 368th semantic_sys file
368
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OVER THE TRACK LINED CITY STREET THE YOUNG MEN THE GRINNING MEN PASS
2024-04-02 06:26:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-292519-0008.json
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 232, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-292519-0008
generate
 30%|██▉       | 369/1232 [03:18<12:04,  1.19it/s]processing 369th semantic_sys file
369
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT IS MY HEART HUNG IN THE SKY AND NO CLOUDS EVER FLOAT BETWEEN THE GRAVE FLOWERS AND MY HEART ON HIGH
2024-04-02 06:26:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8555-292519-0007.json
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([317.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([355.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 393, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8555-292519-0007
generate
 30%|███       | 370/1232 [03:19<12:22,  1.16it/s]processing 370th semantic_sys file
370
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE SIGNED TO ME WITH A GHOSTLY SOLEMNITY TO TAKE THE VACANT PLACE ON THE LEFT OF HER FATHER
2024-04-02 06:26:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-36377-0004.json
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:358
T - mask_len:tensor([323.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 358, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-36377-0004
generate
 30%|███       | 371/1232 [03:20<12:12,  1.17it/s]processing 371th semantic_sys file
371
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE IS NOT WELL HE HAS COME OVER THE OCEAN FOR REST AND CHANGE OF SCENE
2024-04-02 06:26:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-36377-0010.json
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 194, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-36377-0010
generate
 30%|███       | 372/1232 [03:21<11:55,  1.20it/s]processing 372th semantic_sys file
372
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE ONLY CHEERFUL CONVERSATION WAS THE CONVERSATION ACROSS THE TABLE BETWEEN NAOMI AND ME
2024-04-02 06:26:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-36377-0017.json
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 262, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-36377-0017
generate
 30%|███       | 373/1232 [03:21<11:15,  1.27it/s]processing 373th semantic_sys file
373
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OUR FIRST IMPRESSIONS OF PEOPLE ARE IN NINE CASES OUT OF TEN THE RIGHT IMPRESSIONS
2024-04-02 06:26:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-36377-0015.json
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([224.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([292.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([327.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 362, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-36377-0015
generate
 30%|███       | 374/1232 [03:22<11:14,  1.27it/s]processing 374th semantic_sys file
374
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: PHILIP LEFRANK THIS IS MY OVERLOOKER MISTER JAGO SAID THE OLD MAN FORMALLY PRESENTING US
2024-04-02 06:26:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-36377-0009.json
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 269, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-36377-0009
generate
 30%|███       | 375/1232 [03:23<11:31,  1.24it/s]processing 375th semantic_sys file
375
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE SOUND OF AN IMPERATIVE AND UNCOMPROMISING BELL RECALLED ME IN DUE TIME TO THE REGIONS OF REALITY
2024-04-02 06:26:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-36377-0002.json
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([241.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 267, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-36377-0002
generate
 31%|███       | 376/1232 [03:24<11:36,  1.23it/s]processing 376th semantic_sys file
376
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN FIVE MINUTES I WAS IN A NEW WORLD AND MY MELANCHOLY ROOM WAS FULL OF THE LIVELIEST FRENCH COMPANY
2024-04-02 06:26:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-36377-0001.json
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([301.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([337.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 373, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-36377-0001
generate
 31%|███       | 377/1232 [03:25<11:33,  1.23it/s]processing 377th semantic_sys file
377
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NAOMI SHOOK HER FOREFINGER REPROACHFULLY AT THEM AS IF THE TWO STURDY YOUNG FARMERS HAD BEEN TWO CHILDREN
2024-04-02 06:26:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([52], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-36377-0024.json
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([342.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 379, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-36377-0024
generate
 31%|███       | 378/1232 [03:26<11:41,  1.22it/s]processing 378th semantic_sys file
378
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU WERE QUITE RIGHT TO SAY NO AMBROSE BEGAN NEVER SMOKE WITH JOHN JAGO HIS CIGARS WILL POISON YOU
2024-04-02 06:26:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-36377-0023.json
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([224.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([254.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 315, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-36377-0023
generate
 31%|███       | 379/1232 [03:26<11:36,  1.22it/s]processing 379th semantic_sys file
379
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A LITTLE CRACKED THAT IN THE POPULAR PHRASE WAS MY IMPRESSION OF THE STRANGER WHO NOW MADE HIS APPEARANCE IN THE SUPPER ROOM
2024-04-02 06:26:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([52], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-36377-0007.json
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([271.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([304.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 336, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-36377-0007
generate
 31%|███       | 380/1232 [03:27<11:59,  1.18it/s]processing 380th semantic_sys file
380
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY POINTEDLY DREW BACK FROM JOHN JAGO AS HE APPROACHED THE EMPTY CHAIR NEXT TO ME AND MOVED ROUND TO THE OPPOSITE SIDE OF THE TABLE
2024-04-02 06:26:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([56], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-36377-0013.json
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 387, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-36377-0013
generate
 31%|███       | 381/1232 [03:28<11:54,  1.19it/s]processing 381th semantic_sys file
381
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE DOOR OPENED AGAIN WHILE I WAS STILL STUDYING THE TWO BROTHERS WITHOUT I HONESTLY CONFESS BEING VERY FAVORABLY IMPRESSED BY EITHER OF THEM
2024-04-02 06:26:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-36377-0005.json
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([241.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([314.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([351.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 389, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-36377-0005
generate
 31%|███       | 382/1232 [03:29<12:24,  1.14it/s]processing 382th semantic_sys file
382
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A MORE DREARY AND MORE DISUNITED FAMILY PARTY I NEVER SAT AT THE TABLE WITH
2024-04-02 06:26:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-36377-0020.json
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 231, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-36377-0020
generate
 31%|███       | 383/1232 [03:30<11:47,  1.20it/s]processing 383th semantic_sys file
383
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A NEW MEMBER OF THE FAMILY CIRCLE WHO INSTANTLY ATTRACTED MY ATTENTION ENTERED THE ROOM
2024-04-02 06:26:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-36377-0006.json
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 270, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-36377-0006
generate
 31%|███       | 384/1232 [03:31<11:27,  1.23it/s]processing 384th semantic_sys file
384
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE LOOKED UP AT NAOMI DOUBTINGLY FROM HIS PLATE AND LOOKED DOWN AGAIN SLOWLY WITH A FROWN
2024-04-02 06:26:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([53], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-36377-0018.json
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([299.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 331, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-36377-0018
generate
 31%|███▏      | 385/1232 [03:31<11:24,  1.24it/s]processing 385th semantic_sys file
385
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEN I DRANK HALF OF THE HORNFUL AND SENT THE REST ACROSS THE FIRE TO THE FARMER HE TOOK IT AND SMILED SAYING
2024-04-02 06:26:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0034.json
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([278.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 345, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0034
generate
 31%|███▏      | 386/1232 [03:32<11:13,  1.26it/s]processing 386th semantic_sys file
386
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SO I WILL GIVE OUT THIS LAW THAT MY MEN SHALL NEVER LEAVE YOU ALONE
2024-04-02 06:26:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0036.json
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 239, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0036
generate
 31%|███▏      | 387/1232 [03:33<10:29,  1.34it/s]processing 387th semantic_sys file
387
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHAT OF THE FARM OLAF NOT YET I ANSWERED VIKING IS BETTER FOR SUMMER
2024-04-02 06:26:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0022.json
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 237, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0022
generate
 31%|███▏      | 388/1232 [03:34<10:46,  1.31it/s]processing 388th semantic_sys file
388
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I MADE HER FOR ONLY TWENTY OARS BECAUSE I THOUGHT FEW MEN WOULD FOLLOW ME FOR I WAS YOUNG FIFTEEN YEARS OLD
2024-04-02 06:26:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0006.json
top_k_know_token:70
known_token_update:False
T:558
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:558
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:558
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:558
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:558
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:558
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:558
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:558
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:558
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:558
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:558
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:558
T - mask_len:tensor([345.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:558
T - mask_len:tensor([397.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:558
T - mask_len:tensor([450.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:558
T - mask_len:tensor([504.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 558, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0006
generate
 32%|███▏      | 389/1232 [03:35<12:18,  1.14it/s]processing 389th semantic_sys file
389
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SO NO TALES GOT OUT TO THE NEIGHBORS BESIDES IT WAS A LONELY PLACE AND BY GOOD LUCK NO ONE CAME THAT WAY
2024-04-02 06:26:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([53], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0042.json
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([360.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([428.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([499.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([574.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([651.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([729.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 808, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0042
generate
 32%|███▏      | 390/1232 [03:36<15:11,  1.08s/it]processing 390th semantic_sys file
390
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HERE IS A RING FOR SIF THE FRIENDLY AND HERE IS A BRACELET A SWORD WOULD NOT BE ASHAMED TO HANG AT YOUR SIDE
2024-04-02 06:26:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0052.json
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([271.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([307.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([344.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 381, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0052
generate
 32%|███▏      | 391/1232 [03:37<14:02,  1.00s/it]processing 391th semantic_sys file
391
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SO I LIVED AND NOW AM YOUR TOOTH THRALL WELL IT IS THE LUCK OF WAR
2024-04-02 06:26:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0068.json
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([297.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 329, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0068
generate
 32%|███▏      | 392/1232 [03:38<13:30,  1.04it/s]processing 392th semantic_sys file
392
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I STOOD WITH MY BACK TO THE WALL FOR I WANTED NO SWORD REACHING OUT OF THE DARK FOR ME
2024-04-02 06:26:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0024.json
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 189, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0024
generate
 32%|███▏      | 393/1232 [03:39<12:12,  1.15it/s]processing 393th semantic_sys file
393
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEN I WILL GET ME A FARM AND WILL WINTER IN THAT LAND NOW WHO WILL FOLLOW ME
2024-04-02 06:26:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0012.json
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([280.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 310, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0012
generate
 32%|███▏      | 394/1232 [03:39<11:40,  1.20it/s]processing 394th semantic_sys file
394
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND WITH IT I LEAVE YOU A NAME SIF THE FRIENDLY I SHALL HOPE TO DRINK WITH YOU SOMETIME IN VALHALLA
2024-04-02 06:26:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0051.json
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 317, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0051
generate
 32%|███▏      | 395/1232 [03:40<11:54,  1.17it/s]processing 395th semantic_sys file
395
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AT THE PROW I CARVED THE HEAD WITH OPEN MOUTH AND FORKED TONGUE THRUST OUT
2024-04-02 06:26:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0007.json
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 181, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0007
generate
 32%|███▏      | 396/1232 [03:41<11:15,  1.24it/s]processing 396th semantic_sys file
396
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHAT IS YOUR COUNTRY OLAF HAVE YOU ALWAYS BEEN A THRALL THE THRALL'S EYES FLASHED
2024-04-02 06:26:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0001.json
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 290, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0001
generate
 32%|███▏      | 397/1232 [03:42<10:48,  1.29it/s]processing 397th semantic_sys file
397
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU WOULD NOT EAT WITH US YOU CANNOT SAY NO TO HALF OF MY ALE I DRINK THIS TO YOUR HEALTH
2024-04-02 06:26:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0033.json
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([273.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([314.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([356.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([399.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 442, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0033
generate
 32%|███▏      | 398/1232 [03:42<11:02,  1.26it/s]processing 398th semantic_sys file
398
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT IS THE BEST WAY TO DECIDE FOR THE SPEAR WILL ALWAYS POINT SOMEWHERE AND ONE THING IS AS GOOD AS ANOTHER
2024-04-02 06:26:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0054.json
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 317, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0054
generate
 32%|███▏      | 399/1232 [03:43<11:03,  1.26it/s]processing 399th semantic_sys file
399
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE SHALL NOT LEAVE YOU DAY OR NIGHT WHETHER YOU ARE WORKING OR PLAYING OR SLEEPING
2024-04-02 06:26:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:26:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([53], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0038.json
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 263, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0038
generate
 32%|███▏      | 400/1232 [03:44<10:27,  1.33it/s]processing 400th semantic_sys file
400
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OH IT IS BETTER TO LIVE ON THE SEA AND LET OTHER MEN RAISE YOUR CROPS AND COOK YOUR MEALS
2024-04-02 06:27:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0019.json
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([274.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([307.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 340, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0019
generate
 33%|███▎      | 401/1232 [03:45<10:37,  1.30it/s]processing 401th semantic_sys file
401
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY SET UP A CRANE OVER THE FIRE AND HUNG THE POT UPON IT AND WE SAT AND WATCHED IT BOIL WHILE WE JOKED AT LAST THE SUPPER BEGAN
2024-04-02 06:27:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0031.json
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([329.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([373.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([418.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 463, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0031
generate
 33%|███▎      | 402/1232 [03:46<10:56,  1.26it/s]processing 402th semantic_sys file
402
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YES AND WITH ALL YOUR FINGERS IT TOOK YOU A YEAR TO CATCH ME THE KING FROWNED MORE ANGRILY
2024-04-02 06:27:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0059.json
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([301.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([345.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([392.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([439.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 486, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0059
generate
 33%|███▎      | 403/1232 [03:46<11:21,  1.22it/s]processing 403th semantic_sys file
403
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SOFT HEART HE SAID GENTLY TO HER THEN TO THORKEL WELL LET HIM GO THORKEL
2024-04-02 06:27:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0065.json
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 186, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0065
generate
 33%|███▎      | 404/1232 [03:47<10:34,  1.30it/s]processing 404th semantic_sys file
404
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AS OUR BOAT FLASHED DOWN THE ROLLERS INTO THE WATER I MADE THIS SONG AND SANG IT
2024-04-02 06:27:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0015.json
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([299.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([380.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 421, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0015
generate
 33%|███▎      | 405/1232 [03:48<10:54,  1.26it/s]processing 405th semantic_sys file
405
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I AM STIFF WITH LONG SITTING HE SAID I ITCH FOR A FIGHT I TURNED TO THE FARMER
2024-04-02 06:27:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0044.json
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 325, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0044
generate
 33%|███▎      | 406/1232 [03:49<10:54,  1.26it/s]processing 406th semantic_sys file
406
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE FARMER SAT GLOOMILY ON THE BENCH AND WOULD NOT EAT AND YOU CANNOT WONDER FOR HE SAW US PUTTING POTFULS OF HIS GOOD BEEF AND BASKET LOADS OF BREAD INTO OUR BIG MOUTHS
2024-04-02 06:27:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0032.json
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([310.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([356.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([404.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([452.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 501, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0032
generate
 33%|███▎      | 407/1232 [03:50<12:41,  1.08it/s]processing 407th semantic_sys file
407
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT YOUNG SHARP TONGUE NOW THAT WE HAVE CAUGHT YOU WE WILL PUT YOU INTO A TRAP THAT YOU CANNOT GET OUT OF
2024-04-02 06:27:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5142-33396-0067.json
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([222.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 275, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5142-33396-0067
generate
 33%|███▎      | 408/1232 [03:51<11:48,  1.16it/s]processing 408th semantic_sys file
408
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEN THEY STARTED ON AGAIN AND TWO HOURS LATER CAME IN SIGHT OF THE HOUSE OF DOCTOR PIPT
2024-04-02 06:27:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 409th semantic_sys file
409
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I AM MY DEAR AND ALL STRANGERS ARE WELCOME TO MY HOME
2024-04-02 06:27:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0011.json
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 197, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0011
generate
 33%|███▎      | 410/1232 [03:51<08:15,  1.66it/s]processing 410th semantic_sys file
410
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: UNC KNOCKED AT THE DOOR OF THE HOUSE AND A CHUBBY PLEASANT FACED WOMAN DRESSED ALL IN BLUE OPENED IT AND GREETED THE VISITORS WITH A SMILE
2024-04-02 06:27:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0010.json
top_k_know_token:70
known_token_update:False
T:470
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:470
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:470
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:470
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:470
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:470
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:470
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:470
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:470
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:470
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:470
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:470
T - mask_len:tensor([291.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:470
T - mask_len:tensor([334.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:470
T - mask_len:tensor([379.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:470
T - mask_len:tensor([424.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 470, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0010
generate
 33%|███▎      | 411/1232 [03:52<09:28,  1.44it/s]processing 411th semantic_sys file
411
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AT THE EMERALD CITY WHERE OUR PRINCESS OZMA LIVES GREEN IS THE POPULAR COLOR
2024-04-02 06:27:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0031.json
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 263, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0031
generate
 33%|███▎      | 412/1232 [03:53<09:27,  1.45it/s]processing 412th semantic_sys file
412
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NO ONE WOULD DISTURB THEIR LITTLE HOUSE EVEN IF ANYONE CAME SO FAR INTO THE THICK FOREST WHILE THEY WERE GONE
2024-04-02 06:27:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0005.json
top_k_know_token:70
known_token_update:False
T:777
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:777
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:777
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:777
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:777
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:777
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:777
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:777
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:777
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:777
T - mask_len:tensor([346.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:777
T - mask_len:tensor([411.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:777
T - mask_len:tensor([480.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:777
T - mask_len:tensor([552.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:777
T - mask_len:tensor([626.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:777
T - mask_len:tensor([701.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 777, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0005
generate
 34%|███▎      | 413/1232 [03:54<12:05,  1.13it/s]processing 413th semantic_sys file
413
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT IS ONE REASON YOU ARE OJO THE UNLUCKY SAID THE WOMAN IN A SYMPATHETIC TONE
2024-04-02 06:27:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0024.json
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 239, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0024
generate
 34%|███▎      | 414/1232 [03:55<11:21,  1.20it/s]processing 414th semantic_sys file
414
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU SEE I'VE LIVED ALL MY LIFE WITH UNC NUNKIE THE SILENT ONE AND THERE WAS NO ONE TO TELL ME ANYTHING
2024-04-02 06:27:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0023.json
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 295, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0023
generate
 34%|███▎      | 415/1232 [03:56<11:21,  1.20it/s]processing 415th semantic_sys file
415
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE KNEW IT WOULD TAKE THEM TO THE HOUSE OF THE CROOKED MAGICIAN WHOM HE HAD NEVER SEEN BUT WHO WAS THEIR NEAREST NEIGHBOR
2024-04-02 06:27:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0007.json
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([261.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([332.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 367, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0007
generate
 34%|███▍      | 416/1232 [03:57<11:21,  1.20it/s]processing 416th semantic_sys file
416
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WILL SHOW YOU WHAT A GOOD JOB I DID AND SHE WENT TO A TALL CUPBOARD AND THREW OPEN THE DOORS
2024-04-02 06:27:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0032.json
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 316, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0032
generate
 34%|███▍      | 417/1232 [03:58<11:11,  1.21it/s]processing 417th semantic_sys file
417
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE ARE TRAVELING REPLIED OJO AND WE STOPPED AT YOUR HOUSE JUST TO REST AND REFRESH OURSELVES
2024-04-02 06:27:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 418th semantic_sys file
418
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE HAVE COME FROM A FAR LONELIER PLACE THAN THIS A LONELIER PLACE
2024-04-02 06:27:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 419th semantic_sys file
419
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FOR A LONG TIME HE HAD WISHED TO EXPLORE THE BEAUTIFUL LAND OF OZ IN WHICH THEY LIVED
2024-04-02 06:27:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0003.json
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 240, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0003
generate
 34%|███▍      | 420/1232 [03:58<06:45,  2.00it/s]processing 420th semantic_sys file
420
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE FIRST LOT WE TESTED ON OUR GLASS CAT WHICH NOT ONLY BEGAN TO LIVE BUT HAS LIVED EVER SINCE
2024-04-02 06:27:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0020.json
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([261.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 289, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0020
generate
 34%|███▍      | 421/1232 [03:59<07:34,  1.78it/s]processing 421th semantic_sys file
421
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A BED QUILT MADE OF PATCHES OF DIFFERENT KINDS AND COLORS OF CLOTH ALL NEATLY SEWED TOGETHER
2024-04-02 06:27:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0028.json
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 290, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0028
generate
 34%|███▍      | 422/1232 [04:00<08:32,  1.58it/s]processing 422th semantic_sys file
422
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I THINK I MUST SHOW YOU MY PATCHWORK GIRL SAID MARGOLOTTE LAUGHING AT THE BOY'S ASTONISHMENT FOR SHE IS RATHER DIFFICULT TO EXPLAIN
2024-04-02 06:27:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0025.json
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([297.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([332.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 368, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0025
generate
 34%|███▍      | 423/1232 [04:01<09:51,  1.37it/s]processing 423th semantic_sys file
423
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I THINK THE NEXT GLASS CAT THE MAGICIAN MAKES WILL HAVE NEITHER BRAINS NOR HEART FOR THEN IT WILL NOT OBJECT TO CATCHING MICE AND MAY PROVE OF SOME USE TO US
2024-04-02 06:27:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0021.json
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([280.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([322.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([365.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([409.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 453, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0021
generate
 34%|███▍      | 424/1232 [04:02<10:31,  1.28it/s]processing 424th semantic_sys file
424
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: INSTEAD OF SHOES THE OLD MAN WORE BOOTS WITH TURNOVER TOPS AND HIS BLUE COAT HAD WIDE CUFFS OF GOLD BRAID
2024-04-02 06:27:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0002.json
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([301.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 333, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0002
generate
 34%|███▍      | 425/1232 [04:03<10:33,  1.27it/s]processing 425th semantic_sys file
425
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHEN THEY WERE OUTSIDE UNC SIMPLY LATCHED THE DOOR AND STARTED UP THE PATH
2024-04-02 06:27:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0004.json
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:209
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 209, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0004
generate
 35%|███▍      | 426/1232 [04:03<09:58,  1.35it/s]processing 426th semantic_sys file
426
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HIS HAT HAD A PEAKED CROWN AND A FLAT BRIM AND AROUND THE BRIM WAS A ROW OF TINY GOLDEN BELLS THAT TINKLED WHEN HE MOVED
2024-04-02 06:27:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0001.json
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([335.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([375.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 415, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0001
generate
 35%|███▍      | 427/1232 [04:04<10:39,  1.26it/s]processing 427th semantic_sys file
427
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AT THE FOOT OF THE MOUNTAIN THAT SEPARATED THE COUNTRY OF THE MUNCHKINS FROM THE COUNTRY OF THE GILLIKINS THE PATH DIVIDED
2024-04-02 06:27:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0006.json
top_k_know_token:70
known_token_update:False
T:934
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:934
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:934
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:934
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:934
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:934
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:934
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:934
T - mask_len:tensor([274.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:934
T - mask_len:tensor([342.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:934
T - mask_len:tensor([416.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:934
T - mask_len:tensor([494.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:934
T - mask_len:tensor([577.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:934
T - mask_len:tensor([663.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:934
T - mask_len:tensor([752.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:934
T - mask_len:tensor([843.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 934, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0006
generate
 35%|███▍      | 428/1232 [04:06<14:29,  1.08s/it]processing 428th semantic_sys file
428
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE WORE BLUE SILK STOCKINGS BLUE KNEE PANTS WITH GOLD BUCKLES A BLUE RUFFLED WAIST AND A JACKET OF BRIGHT BLUE BRAIDED WITH GOLD
2024-04-02 06:27:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0000.json
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([251.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([327.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([367.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 406, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0000
generate
 35%|███▍      | 429/1232 [04:07<13:48,  1.03s/it]processing 429th semantic_sys file
429
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT FIRST I WILL TELL YOU THAT FOR MANY YEARS I HAVE LONGED FOR A SERVANT TO HELP ME WITH THE HOUSEWORK AND TO COOK THE MEALS AND WASH THE DISHES
2024-04-02 06:27:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0026.json
top_k_know_token:70
known_token_update:False
T:743
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:743
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:743
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:743
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:743
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:743
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:743
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:743
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:743
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:743
T - mask_len:tensor([331.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:743
T - mask_len:tensor([393.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:743
T - mask_len:tensor([459.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:743
T - mask_len:tensor([528.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:743
T - mask_len:tensor([599.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:743
T - mask_len:tensor([671.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 743, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0026
generate
 35%|███▍      | 430/1232 [04:08<14:52,  1.11s/it]processing 430th semantic_sys file
430
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SOMETIMES IT IS CALLED A CRAZY QUILT BECAUSE THE PATCHES AND COLORS ARE SO MIXED UP
2024-04-02 06:27:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1180-0029.json
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:244
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 244, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1180-0029
generate
 35%|███▍      | 431/1232 [04:09<13:40,  1.02s/it]processing 431th semantic_sys file
431
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: VERY CAREFULLY THE MAGICIAN REMOVED THIS POWDER PLACING IT ALL TOGETHER IN A GOLDEN DISH WHERE HE MIXED IT WITH A GOLDEN SPOON
2024-04-02 06:27:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1181-0011.json
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([338.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([383.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([429.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 475, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1181-0011
generate
 35%|███▌      | 432/1232 [04:10<13:16,  1.00it/s]processing 432th semantic_sys file
432
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DEAR ME WHAT A CHATTERBOX YOU'RE GETTING TO BE UNC REMARKED THE MAGICIAN WHO WAS PLEASED WITH THE COMPLIMENT
2024-04-02 06:27:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1181-0020.json
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([313.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 346, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1181-0020
generate
 35%|███▌      | 433/1232 [04:11<12:30,  1.06it/s]processing 433th semantic_sys file
433
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NO ONE SAW HIM DO THIS FOR ALL WERE LOOKING AT THE POWDER OF LIFE BUT SOON THE WOMAN REMEMBERED WHAT SHE HAD BEEN DOING AND CAME BACK TO THE CUPBOARD
2024-04-02 06:27:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1181-0012.json
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([287.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([326.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([365.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 404, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1181-0012
generate
 35%|███▌      | 434/1232 [04:12<12:04,  1.10it/s]processing 434th semantic_sys file
434
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEIR CONTENTS HAD ALL BOILED AWAY LEAVING IN THE BOTTOM OF EACH KETTLE A FEW GRAINS OF FINE WHITE POWDER
2024-04-02 06:27:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1181-0010.json
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([314.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([361.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([409.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:508
T - mask_len:tensor([459.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 508, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1181-0010
generate
 35%|███▌      | 435/1232 [04:13<12:19,  1.08it/s]processing 435th semantic_sys file
435
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE SELECTED A SMALL GOLD BOTTLE WITH A PEPPER BOX TOP SO THAT THE POWDER MIGHT BE SPRINKLED ON ANY OBJECT THROUGH THE SMALL HOLES
2024-04-02 06:27:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1181-0014.json
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([284.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([327.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([371.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([415.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 460, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1181-0014
generate
 35%|███▌      | 436/1232 [04:14<12:35,  1.05it/s]processing 436th semantic_sys file
436
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE HAIR WAS OF BROWN YARN AND HUNG DOWN ON HER NECK IN SEVERAL NEAT BRAIDS
2024-04-02 06:27:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1181-0003.json
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([297.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([332.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 368, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1181-0003
generate
 35%|███▌      | 437/1232 [04:15<12:37,  1.05it/s]processing 437th semantic_sys file
437
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE RAN TO HER HUSBAND'S SIDE AT ONCE AND HELPED HIM LIFT THE FOUR KETTLES FROM THE FIRE
2024-04-02 06:27:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1181-0009.json
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 260, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1181-0009
generate
 36%|███▌      | 438/1232 [04:15<11:30,  1.15it/s]processing 438th semantic_sys file
438
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE POURED INTO THE DISH A QUANTITY FROM EACH OF THESE BOTTLES
2024-04-02 06:27:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1181-0007.json
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:242
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 242, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1181-0007
generate
 36%|███▌      | 439/1232 [04:16<11:13,  1.18it/s]processing 439th semantic_sys file
439
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I THINK THAT WILL DO SHE CONTINUED FOR THE OTHER QUALITIES ARE NOT NEEDED IN A SERVANT
2024-04-02 06:27:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1181-0008.json
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 233, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1181-0008
generate
 36%|███▌      | 440/1232 [04:17<11:36,  1.14it/s]processing 440th semantic_sys file
440
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: GOLD IS THE MOST COMMON METAL IN THE LAND OF OZ AND IS USED FOR MANY PURPOSES BECAUSE IT IS SOFT AND PLIABLE
2024-04-02 06:27:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1181-0004.json
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([305.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([341.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 378, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1181-0004
generate
 36%|███▌      | 441/1232 [04:18<11:50,  1.11it/s]processing 441th semantic_sys file
441
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MOST PEOPLE TALK TOO MUCH SO IT IS A RELIEF TO FIND ONE WHO TALKS TOO LITTLE
2024-04-02 06:27:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1181-0015.json
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 283, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1181-0015
generate
 36%|███▌      | 442/1232 [04:19<11:20,  1.16it/s]processing 442th semantic_sys file
442
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I AM NOT ALLOWED TO PERFORM MAGIC EXCEPT FOR MY OWN AMUSEMENT HE TOLD HIS VISITORS AS HE LIGHTED A PIPE WITH A CROOKED STEM AND BEGAN TO SMOKE
2024-04-02 06:27:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1284-1181-0016.json
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([301.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([337.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 373, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1284-1181-0016
generate
 36%|███▌      | 443/1232 [04:20<11:19,  1.16it/s]processing 443th semantic_sys file
443
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YET HERE ARE WE WITHIN A SHORT RANGE OF THE SCAROONS AND NOT A SIGN OF A TRAIL HAVE WE CROSSED
2024-04-02 06:27:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122612-0005.json
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([258.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 320, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122612-0005
generate
 36%|███▌      | 444/1232 [04:20<11:31,  1.14it/s]processing 444th semantic_sys file
444
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE DEWS WERE SUFFERED TO EXHALE AND THE SUN HAD DISPERSED THE MISTS AND WAS SHEDDING A STRONG AND CLEAR LIGHT IN THE FOREST WHEN THE TRAVELERS RESUMED THEIR JOURNEY
2024-04-02 06:27:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122612-0001.json
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([261.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([304.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([397.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([444.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 492, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122612-0001
generate
 36%|███▌      | 445/1232 [04:21<12:05,  1.09it/s]processing 445th semantic_sys file
445
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE WHOLE PARTY CROWDED TO THE SPOT WHERE UNCAS POINTED OUT THE IMPRESSION OF A MOCCASIN IN THE MOIST ALLUVION
2024-04-02 06:27:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([54], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122612-0015.json
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([251.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([319.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 353, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122612-0015
generate
 36%|███▌      | 446/1232 [04:22<12:05,  1.08it/s]processing 446th semantic_sys file
446
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A CIRCLE OF A FEW HUNDRED FEET IN CIRCUMFERENCE WAS DRAWN AND EACH OF THE PARTY TOOK A SEGMENT FOR HIS PORTION
2024-04-02 06:27:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122612-0013.json
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([264.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([304.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([344.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([386.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 427, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122612-0013
generate
 36%|███▋      | 447/1232 [04:23<11:42,  1.12it/s]processing 447th semantic_sys file
447
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: LET US RETRACE OUR STEPS AND EXAMINE AS WE GO WITH KEENER EYES
2024-04-02 06:27:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122612-0006.json
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 235, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122612-0006
generate
 36%|███▋      | 448/1232 [04:24<10:39,  1.23it/s]processing 448th semantic_sys file
448
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE OFTEN STOPPED TO EXAMINE THE TREES NOR DID HE CROSS A RIVULET WITHOUT ATTENTIVELY CONSIDERING THE QUANTITY THE VELOCITY AND THE COLOR OF ITS WATERS
2024-04-02 06:27:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122612-0003.json
top_k_know_token:70
known_token_update:False
T:524
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:524
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:524
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:524
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:524
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:524
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:524
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:524
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:524
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:524
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:524
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:524
T - mask_len:tensor([324.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:524
T - mask_len:tensor([372.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:524
T - mask_len:tensor([422.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:524
T - mask_len:tensor([473.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 524, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122612-0003
generate
 36%|███▋      | 449/1232 [04:25<11:18,  1.15it/s]processing 449th semantic_sys file
449
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AFTER PROCEEDING A FEW MILES THE PROGRESS OF HAWKEYE WHO LED THE ADVANCE BECAME MORE DELIBERATE AND WATCHFUL
2024-04-02 06:27:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122612-0002.json
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 325, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122612-0002
generate
 37%|███▋      | 450/1232 [04:26<11:12,  1.16it/s]processing 450th semantic_sys file
450
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DISTRUSTING HIS OWN JUDGMENT HIS APPEALS TO THE OPINION OF CHINGACHGOOK WERE FREQUENT AND EARNEST
2024-04-02 06:27:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122612-0004.json
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([268.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 297, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122612-0004
generate
 37%|███▋      | 451/1232 [04:26<10:38,  1.22it/s]processing 451th semantic_sys file
451
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: CHINGACHGOOK HAD CAUGHT THE LOOK AND MOTIONING WITH HIS HAND HE BADE HIM SPEAK
2024-04-02 06:27:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122612-0007.json
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 223, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122612-0007
generate
 37%|███▋      | 452/1232 [04:27<10:01,  1.30it/s]processing 452th semantic_sys file
452
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE EYES OF THE WHOLE PARTY FOLLOWED THE UNEXPECTED MOVEMENT AND READ THEIR SUCCESS IN THE AIR OF TRIUMPH THAT THE YOUTH ASSUMED
2024-04-02 06:27:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122612-0008.json
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([347.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([389.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 431, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122612-0008
generate
 37%|███▋      | 453/1232 [04:28<10:25,  1.25it/s]processing 453th semantic_sys file
453
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: CAN THESE THINGS BE RETURNED DAVID BREATHING MORE FREELY AS THE TRUTH BEGAN TO DAWN UPON HIM
2024-04-02 06:27:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0006.json
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 325, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0006
generate
 37%|███▋      | 454/1232 [04:29<10:30,  1.23it/s]processing 454th semantic_sys file
454
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I GREATLY MOURN THAT ONE SO WELL DISPOSED SHOULD DIE IN HIS IGNORANCE AND I HAVE SOUGHT A GOODLY HYMN CAN YOU LEAD ME TO HIM
2024-04-02 06:27:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0009.json
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([271.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([307.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([344.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 381, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0009
generate
 37%|███▋      | 455/1232 [04:30<11:36,  1.12it/s]processing 455th semantic_sys file
455
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WELL WHAT CAN'T BE DONE BY MAIN COURAGE IN WAR MUST BE DONE BY CIRCUMVENTION
2024-04-02 06:27:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0026.json
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 317, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0026
generate
 37%|███▋      | 456/1232 [04:31<11:44,  1.10it/s]processing 456th semantic_sys file
456
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HOLD SAID DAVID PERCEIVING THAT WITH THIS ASSURANCE THEY WERE ABOUT TO LEAVE HIM I AM AN UNWORTHY AND HUMBLE FOLLOWER OF ONE WHO TAUGHT NOT THE DAMNABLE PRINCIPLE OF REVENGE
2024-04-02 06:27:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0034.json
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([253.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([384.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:477
T - mask_len:tensor([431.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 477, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0034
generate
 37%|███▋      | 457/1232 [04:32<11:53,  1.09it/s]processing 457th semantic_sys file
457
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE SCOUT WHO HAD LEFT DAVID AT THE DOOR TO ASCERTAIN THEY WERE NOT OBSERVED THOUGHT IT PRUDENT TO PRESERVE HIS DISGUISE UNTIL ASSURED OF THEIR PRIVACY
2024-04-02 06:27:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0020.json
top_k_know_token:70
known_token_update:False
T:635
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:635
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:635
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:635
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:635
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:635
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:635
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:635
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:635
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:635
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:635
T - mask_len:tensor([336.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:635
T - mask_len:tensor([392.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:635
T - mask_len:tensor([451.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:635
T - mask_len:tensor([512.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:635
T - mask_len:tensor([573.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 635, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0020
generate
 37%|███▋      | 458/1232 [04:33<12:36,  1.02it/s]processing 458th semantic_sys file
458
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: UNCAS OCCUPIED A DISTANT CORNER IN A RECLINING ATTITUDE BEING RIGIDLY BOUND BOTH HANDS AND FEET BY STRONG AND PAINFUL WITHES
2024-04-02 06:27:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0019.json
top_k_know_token:70
known_token_update:False
T:464
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:464
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:464
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:464
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:464
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:464
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:464
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:464
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:464
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:464
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:464
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:464
T - mask_len:tensor([287.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:464
T - mask_len:tensor([330.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:464
T - mask_len:tensor([374.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:464
T - mask_len:tensor([419.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 464, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0019
generate
 37%|███▋      | 459/1232 [04:34<12:16,  1.05it/s]processing 459th semantic_sys file
459
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FOUR OR FIVE OF THE LATTER ONLY LINGERED ABOUT THE DOOR OF THE PRISON OF UNCAS WARY BUT CLOSE OBSERVERS OF THE MANNER OF THEIR CAPTIVE
2024-04-02 06:27:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([59], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0012.json
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([333.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([373.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 413, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0012
generate
 37%|███▋      | 460/1232 [04:35<11:48,  1.09it/s]processing 460th semantic_sys file
460
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY DREW BACK A LITTLE FROM THE ENTRANCE AND MOTIONED TO THE SUPPOSED CONJURER TO ENTER
2024-04-02 06:27:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0014.json
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([338.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([383.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:475
T - mask_len:tensor([429.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 475, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0014
generate
 37%|███▋      | 461/1232 [04:36<12:22,  1.04it/s]processing 461th semantic_sys file
461
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE MOHICAN STARTED ON HIS FEET AND SHOOK HIS SHAGGY COVERING AS THOUGH THE ANIMAL HE COUNTERFEITED WAS ABOUT TO MAKE SOME DESPERATE EFFORT
2024-04-02 06:27:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0039.json
top_k_know_token:70
known_token_update:False
T:432
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:432
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:432
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:432
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:432
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:432
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:432
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:432
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:432
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:432
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:432
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:432
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:432
T - mask_len:tensor([307.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:432
T - mask_len:tensor([348.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:432
T - mask_len:tensor([390.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 432, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0039
generate
 38%|███▊      | 462/1232 [04:37<12:07,  1.06it/s]processing 462th semantic_sys file
462
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHAT SHALL WE DO WITH THE MINGOES AT THE DOOR THEY COUNT SIX AND THIS SINGER IS AS GOOD AS NOTHING
2024-04-02 06:27:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0021.json
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 274, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0021
generate
 38%|███▊      | 463/1232 [04:37<11:17,  1.13it/s]processing 463th semantic_sys file
463
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NOTWITHSTANDING THE HIGH RESOLUTION OF HAWKEYE HE FULLY COMPREHENDED ALL THE DIFFICULTIES AND DANGER HE WAS ABOUT TO INCUR
2024-04-02 06:27:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([57], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0000.json
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([254.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([288.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([323.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 357, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0000
generate
 38%|███▊      | 464/1232 [04:38<11:14,  1.14it/s]processing 464th semantic_sys file
464
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT HAWKEYE WHO WAS TOO MUCH OCCUPIED WITH HIS OWN THOUGHTS TO NOTE THE MOVEMENT CONTINUED SPEAKING MORE TO HIMSELF THAN TO HIS COMPANION
2024-04-02 06:27:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([58], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0024.json
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([321.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([359.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 398, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0024
generate
 38%|███▊      | 465/1232 [04:39<11:21,  1.13it/s]processing 465th semantic_sys file
465
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE HAD NO OCCASION TO DELAY FOR AT THE NEXT INSTANT A BURST OF CRIES FILLED THE OUTER AIR AND RAN ALONG THE WHOLE EXTENT OF THE VILLAGE
2024-04-02 06:27:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0040.json
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([334.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([374.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 414, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0040
generate
 38%|███▊      | 466/1232 [04:40<12:02,  1.06it/s]processing 466th semantic_sys file
466
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE WAS SOMETHING IN HIS AIR AND MANNER THAT BETRAYED TO THE SCOUT THE UTTER CONFUSION OF THE STATE OF HIS MIND
2024-04-02 06:27:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([53], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0003.json
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([284.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([326.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([370.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([415.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 459, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0003
generate
 38%|███▊      | 467/1232 [04:41<12:53,  1.01s/it]processing 467th semantic_sys file
467
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: UNCAS WHO HAD ALREADY APPROACHED THE DOOR IN READINESS TO LEAD THE WAY NOW RECOILED AND PLACED HIMSELF ONCE MORE IN THE BOTTOM OF THE LODGE
2024-04-02 06:27:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0023.json
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([333.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([383.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([434.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([487.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 539, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0023
generate
 38%|███▊      | 468/1232 [04:42<12:58,  1.02s/it]processing 468th semantic_sys file
468
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE DELAWARE DOG HE SAID LEANING FORWARD AND PEERING THROUGH THE DIM LIGHT TO CATCH THE EXPRESSION OF THE OTHER'S FEATURES IS HE AFRAID
2024-04-02 06:27:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0037.json
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 387, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0037
generate
 38%|███▊      | 469/1232 [04:43<13:04,  1.03s/it]processing 469th semantic_sys file
469
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE YOUNG MAN IS IN BONDAGE AND MUCH I FEAR HIS DEATH IS DECREED
2024-04-02 06:27:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:27:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0008.json
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 203, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0008
generate
 38%|███▊      | 470/1232 [04:44<11:51,  1.07it/s]processing 470th semantic_sys file
470
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AS SOON AS THESE DISPOSITIONS WERE MADE THE SCOUT TURNED TO DAVID AND GAVE HIM HIS PARTING INSTRUCTIONS
2024-04-02 06:28:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0027.json
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([247.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 306, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0027
generate
 38%|███▊      | 471/1232 [04:45<11:21,  1.12it/s]processing 471th semantic_sys file
471
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE BEAR SHOOK HIS SHAGGY SIDES AND THEN A WELL KNOWN VOICE REPLIED
2024-04-02 06:28:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([56], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0005.json
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 234, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0005
generate
 38%|███▊      | 472/1232 [04:46<10:46,  1.18it/s]processing 472th semantic_sys file
472
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT THE BEAR INSTEAD OF OBEYING MAINTAINED THE SEAT IT HAD TAKEN AND GROWLED
2024-04-02 06:28:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0015.json
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 238, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0015
generate
 38%|███▊      | 473/1232 [04:46<09:52,  1.28it/s]processing 473th semantic_sys file
473
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IF YOU ARE NOT THEN KNOCKED ON THE HEAD YOUR BEING A NON COMPOSSER WILL PROTECT YOU AND YOU'LL THEN HAVE A GOOD REASON TO EXPECT TO DIE IN YOUR BED
2024-04-02 06:28:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0029.json
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([301.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([342.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:424
T - mask_len:tensor([383.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 424, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0029
generate
 38%|███▊      | 474/1232 [04:47<09:56,  1.27it/s]processing 474th semantic_sys file
474
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE LODGE IN WHICH UNCAS WAS CONFINED WAS IN THE VERY CENTER OF THE VILLAGE AND IN A SITUATION PERHAPS MORE DIFFICULT THAN ANY OTHER TO APPROACH OR LEAVE WITHOUT OBSERVATION
2024-04-02 06:28:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0011.json
top_k_know_token:70
known_token_update:False
T:549
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:549
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:549
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:549
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:549
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:549
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:549
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:549
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:549
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:549
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:549
T - mask_len:tensor([291.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:549
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:549
T - mask_len:tensor([390.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:549
T - mask_len:tensor([442.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:549
T - mask_len:tensor([496.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 549, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0011
generate
 39%|███▊      | 475/1232 [04:48<10:45,  1.17it/s]processing 475th semantic_sys file
475
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: UNCAS CAST HIS SKIN AND STEPPED FORTH IN HIS OWN BEAUTIFUL PROPORTIONS
2024-04-02 06:28:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([56], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0041.json
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 257, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0041
generate
 39%|███▊      | 476/1232 [04:49<10:08,  1.24it/s]processing 476th semantic_sys file
476
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT WAS SILENT AND GLOOMY BEING TENANTED SOLELY BY THE CAPTIVE AND LIGHTED BY THE DYING EMBERS OF A FIRE WHICH HAD BEEN USED FOR THE PURPOSED OF COOKERY
2024-04-02 06:28:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0018.json
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([261.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([305.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([397.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([445.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 493, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0018
generate
 39%|███▊      | 477/1232 [04:50<11:12,  1.12it/s]processing 477th semantic_sys file
477
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEN AS IF SATISFIED OF THEIR SAFETY THE SCOUT LEFT HIS POSITION AND SLOWLY ENTERED THE PLACE
2024-04-02 06:28:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0017.json
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([271.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 300, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0017
generate
 39%|███▉      | 478/1232 [04:51<11:00,  1.14it/s]processing 478th semantic_sys file
478
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SO UNCAS YOU HAD BETTER TAKE THE LEAD WHILE I WILL PUT ON THE SKIN AGAIN AND TRUST TO CUNNING FOR WANT OF SPEED
2024-04-02 06:28:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0025.json
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([319.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([358.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 396, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0025
generate
 39%|███▉      | 479/1232 [04:52<11:08,  1.13it/s]processing 479th semantic_sys file
479
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BRAVELY AND GENEROUSLY HAS HE BATTLED IN MY BEHALF AND THIS AND MORE WILL I DARE IN HIS SERVICE
2024-04-02 06:28:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0031.json
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([241.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([314.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:389
T - mask_len:tensor([351.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 389, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0031
generate
 39%|███▉      | 480/1232 [04:53<11:16,  1.11it/s]processing 480th semantic_sys file
480
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE TASK WILL NOT BE DIFFICULT RETURNED DAVID HESITATING THOUGH I GREATLY FEAR YOUR PRESENCE WOULD RATHER INCREASE THAN MITIGATE HIS UNHAPPY FORTUNES
2024-04-02 06:28:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([53], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1320-122617-0010.json
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([315.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([362.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([410.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([460.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 509, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1320-122617-0010
generate
 39%|███▉      | 481/1232 [04:54<12:02,  1.04it/s]processing 481th semantic_sys file
481
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DO NOT THEREFORE THINK THAT THE GOTHIC SCHOOL IS AN EASY ONE
2024-04-02 06:28:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([57], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1188-133604-0014.json
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 207, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1188-133604-0014
generate
 39%|███▉      | 482/1232 [04:55<11:52,  1.05it/s]processing 482th semantic_sys file
482
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY UNITE EVERY QUALITY AND SOMETIMES YOU WILL FIND ME REFERRING TO THEM AS COLORISTS SOMETIMES AS CHIAROSCURISTS
2024-04-02 06:28:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1188-133604-0001.json
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([261.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([332.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 367, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1188-133604-0001
generate
 39%|███▉      | 483/1232 [04:56<11:39,  1.07it/s]processing 483th semantic_sys file
483
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT NOW HERE IS A SUBJECT OF WHICH YOU WILL WONDER AT FIRST WHY TURNER DREW IT AT ALL
2024-04-02 06:28:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1188-133604-0038.json
top_k_know_token:70
known_token_update:False
T:516
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:516
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:516
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:516
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:516
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:516
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:516
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:516
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:516
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:516
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:516
T - mask_len:tensor([273.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:516
T - mask_len:tensor([319.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:516
T - mask_len:tensor([367.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:516
T - mask_len:tensor([416.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:516
T - mask_len:tensor([466.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 516, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1188-133604-0038
generate
 39%|███▉      | 484/1232 [04:58<18:15,  1.46s/it]processing 484th semantic_sys file
484
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN BOTH THESE HIGH MYTHICAL SUBJECTS THE SURROUNDING NATURE THOUGH SUFFERING IS STILL DIGNIFIED AND BEAUTIFUL
2024-04-02 06:28:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1188-133604-0036.json
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([254.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([292.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([331.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([371.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 411, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1188-133604-0036
generate
 39%|███▉      | 485/1232 [04:59<15:56,  1.28s/it]processing 485th semantic_sys file
485
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT HAS NO BEAUTY WHATSOEVER NO SPECIALTY OF PICTURESQUENESS AND ALL ITS LINES ARE CRAMPED AND POOR
2024-04-02 06:28:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1188-133604-0039.json
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([247.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([281.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([314.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 348, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1188-133604-0039
generate
 39%|███▉      | 486/1232 [05:00<14:07,  1.14s/it]processing 486th semantic_sys file
486
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SEE THAT YOUR LIVES BE IN NOTHING WORSE THAN A BOY'S CLIMBING FOR HIS ENTANGLED KITE
2024-04-02 06:28:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1188-133604-0043.json
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:331
T - mask_len:tensor([299.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 331, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1188-133604-0043
generate
 40%|███▉      | 487/1232 [05:01<12:40,  1.02s/it]processing 487th semantic_sys file
487
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT A STYLE IS RESTRAINED OR SEVERE DOES NOT MEAN THAT IT IS ALSO ERRONEOUS
2024-04-02 06:28:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1188-133604-0017.json
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:334
T - mask_len:tensor([302.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 334, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1188-133604-0017
generate
 40%|███▉      | 488/1232 [05:01<11:47,  1.05it/s]processing 488th semantic_sys file
488
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU KNOW I HAVE JUST BEEN TELLING YOU HOW THIS SCHOOL OF MATERIALISM AND CLAY INVOLVED ITSELF AT LAST IN CLOUD AND FIRE
2024-04-02 06:28:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1188-133604-0025.json
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([261.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:367
T - mask_len:tensor([332.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 367, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1188-133604-0025
generate
 40%|███▉      | 489/1232 [05:02<11:49,  1.05it/s]processing 489th semantic_sys file
489
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU MUST LOOK AT HIM IN THE FACE FIGHT HIM CONQUER HIM WITH WHAT SCATHE YOU MAY YOU NEED NOT THINK TO KEEP OUT OF THE WAY OF HIM
2024-04-02 06:28:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([57], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1188-133604-0022.json
top_k_know_token:70
known_token_update:False
T:961
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:961
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:961
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:961
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:961
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:961
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:961
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:961
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:961
T - mask_len:tensor([352.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:961
T - mask_len:tensor([428.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:961
T - mask_len:tensor([508.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:961
T - mask_len:tensor([594.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:961
T - mask_len:tensor([683.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:961
T - mask_len:tensor([774.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:961
T - mask_len:tensor([867.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 961, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1188-133604-0022
generate
 40%|███▉      | 490/1232 [05:04<15:06,  1.22s/it]processing 490th semantic_sys file
490
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE'S ONE AND THERE'S ANOTHER THE DUDLEY AND THE FLINT
2024-04-02 06:28:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1188-133604-0031.json
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:98
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 98, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1188-133604-0031
generate
 40%|███▉      | 491/1232 [05:05<12:36,  1.02s/it]processing 491th semantic_sys file
491
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT IS THE HEAD OF A PARROT WITH A LITTLE FLOWER IN HIS BEAK FROM A PICTURE OF CARPACCIO'S ONE OF HIS SERIES OF THE LIFE OF SAINT GEORGE
2024-04-02 06:28:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1188-133604-0005.json
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([266.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([347.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:430
T - mask_len:tensor([388.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 430, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1188-133604-0005
generate
 40%|███▉      | 492/1232 [05:06<11:51,  1.04it/s]processing 492th semantic_sys file
492
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT IN THIS VIGNETTE COPIED FROM TURNER YOU HAVE THE TWO PRINCIPLES BROUGHT OUT PERFECTLY
2024-04-02 06:28:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1188-133604-0010.json
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 252, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1188-133604-0010
generate
 40%|████      | 493/1232 [05:06<10:41,  1.15it/s]processing 493th semantic_sys file
493
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: EVERY PLANT IN THE GRASS IS SET FORMALLY GROWS PERFECTLY AND MAY BE REALIZED COMPLETELY
2024-04-02 06:28:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1188-133604-0033.json
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([253.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 280, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1188-133604-0033
generate
 40%|████      | 494/1232 [05:07<10:30,  1.17it/s]processing 494th semantic_sys file
494
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT IS ALL QUITE TRUE MISTER NEVERBEND SAID SIR FERDINANDO BROWN
2024-04-02 06:28:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([52], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0035.json
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 177, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0035
generate
 40%|████      | 495/1232 [05:08<09:49,  1.25it/s]processing 495th semantic_sys file
495
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE PECULIAR CIRCUMSTANCES OF THE COLONY ARE WITHIN YOUR EXCELLENCY'S KNOWLEDGE
2024-04-02 06:28:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0056.json
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 250, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0056
generate
 40%|████      | 496/1232 [05:09<09:47,  1.25it/s]processing 496th semantic_sys file
496
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU WILL ALLOW ME TO SUGGEST SAID HE THAT THAT IS A MATTER OF OPINION
2024-04-02 06:28:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0052.json
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 282, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0052
generate
 40%|████      | 497/1232 [05:09<09:49,  1.25it/s]processing 497th semantic_sys file
497
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I AND MY WIFE AND SON AND THE TWO CRASWELLERS AND THREE OR FOUR OTHERS AGREED TO DINE ON BOARD THE SHIP ON THE NEXT
2024-04-02 06:28:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([25], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0015.json
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([291.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([326.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 361, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0015
generate
 40%|████      | 498/1232 [05:10<09:44,  1.26it/s]processing 498th semantic_sys file
498
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SIR KENNINGTON OVAL IS A VERY FINE PLAYER SAID MY WIFE
2024-04-02 06:28:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0014.json
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 162, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0014
generate
 41%|████      | 499/1232 [05:11<09:03,  1.35it/s]processing 499th semantic_sys file
499
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE JOHN BRIGHT IS ARMED WITH A WEAPON OF GREAT POWER AGAINST WHICH IT IS IMPOSSIBLE THAT THE PEOPLE OF BRITANNULA SHOULD PREVAIL
2024-04-02 06:28:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0060.json
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([224.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([292.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:362
T - mask_len:tensor([327.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 362, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0060
generate
 41%|████      | 500/1232 [05:12<09:18,  1.31it/s]processing 500th semantic_sys file
500
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU HAVE COME TO US THREATENING US WITH ABSOLUTE DESTRUCTION
2024-04-02 06:28:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0037.json
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 239, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0037
generate
 41%|████      | 501/1232 [05:12<08:59,  1.36it/s]processing 501th semantic_sys file
501
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT YOUR POWER IS SO SUPERIOR TO ANY THAT I CAN ADVANCE AS TO MAKE US HERE FEEL THAT THERE IS NO DISGRACE IN YIELDING TO IT
2024-04-02 06:28:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0033.json
top_k_know_token:70
known_token_update:False
T:443
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:443
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:443
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:443
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:443
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:443
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:443
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:443
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:443
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:443
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:443
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:443
T - mask_len:tensor([274.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:443
T - mask_len:tensor([315.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:443
T - mask_len:tensor([357.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:443
T - mask_len:tensor([400.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 443, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0033
generate
 41%|████      | 502/1232 [05:13<09:39,  1.26it/s]processing 502th semantic_sys file
502
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: LIEUTENANT CROSSTREES IS A VERY GALLANT OFFICER
2024-04-02 06:28:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0049.json
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 156, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0049
generate
 41%|████      | 503/1232 [05:14<08:42,  1.40it/s]processing 503th semantic_sys file
503
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND THIS PLAN WAS ADOPTED TOO IN ORDER TO EXTRACT FROM ME A PROMISE THAT I WOULD DEPART IN PEACE
2024-04-02 06:28:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0070.json
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([271.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 300, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0070
generate
 41%|████      | 504/1232 [05:14<08:52,  1.37it/s]processing 504th semantic_sys file
504
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SIR I HAVE IT IN COMMAND TO INFORM YOUR EXCELLENCY THAT YOU HAVE BEEN APPOINTED GOVERNOR OF THE CROWN COLONY WHICH IS CALLED BRITANNULA
2024-04-02 06:28:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0055.json
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([299.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([380.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 421, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0055
generate
 41%|████      | 505/1232 [05:15<09:17,  1.31it/s]processing 505th semantic_sys file
505
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: JACK HAD BEEN STANDING IN THE FAR CORNER OF THE ROOM TALKING TO EVA AND WAS NOW REDUCED TO SILENCE BY HIS PRAISES
2024-04-02 06:28:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0013.json
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([251.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([327.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([367.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 406, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0013
generate
 41%|████      | 506/1232 [05:16<09:42,  1.25it/s]processing 506th semantic_sys file
506
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: JACK WOULD BECOME EVA'S HAPPY HUSBAND AND WOULD REMAIN AMIDST THE HURRIED DUTIES OF THE EAGER WORLD
2024-04-02 06:28:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0028.json
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([259.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 287, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0028
generate
 41%|████      | 507/1232 [05:17<09:17,  1.30it/s]processing 507th semantic_sys file
507
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE HAVE OUR LITTLE STRUGGLES HERE AS ELSEWHERE AND ALL THINGS CANNOT BE DONE BY ROSE WATER
2024-04-02 06:28:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0005.json
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([292.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 323, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0005
generate
 41%|████      | 508/1232 [05:18<09:15,  1.30it/s]processing 508th semantic_sys file
508
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WAS TO BE TAKEN AWAY AND CARRIED TO ENGLAND OR ELSEWHERE OR DROWNED UPON THE VOYAGE IT MATTERED NOT WHICH
2024-04-02 06:28:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0044.json
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:354
T - mask_len:tensor([320.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 354, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0044
generate
 41%|████▏     | 509/1232 [05:19<09:37,  1.25it/s]processing 509th semantic_sys file
509
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MY WIFE ON THE SPUR OF THE MOMENT MANAGED TO GIVE THE GENTLEMEN A VERY GOOD DINNER
2024-04-02 06:28:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0017.json
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([316.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 350, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0017
generate
 41%|████▏     | 510/1232 [05:19<09:40,  1.24it/s]processing 510th semantic_sys file
510
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HOW MUCH OF EVIL OF REAL ACCOMPLISHED EVIL HAD THERE NOT OCCURRED TO ME DURING THE LAST FEW DAYS
2024-04-02 06:28:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0024.json
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([274.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 303, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0024
generate
 41%|████▏     | 511/1232 [05:20<10:26,  1.15it/s]processing 511th semantic_sys file
511
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS SHE SAID WAS TRUE HOSPITALITY AND I AM NOT SURE THAT I DID NOT AGREE WITH HER
2024-04-02 06:28:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0018.json
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([301.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 333, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0018
generate
 42%|████▏     | 512/1232 [05:21<10:15,  1.17it/s]processing 512th semantic_sys file
512
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU HEAR WHAT SIR FERDINANDO BROWN HAS SAID REPLIED CAPTAIN BATTLEAX
2024-04-02 06:28:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0042.json
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 216, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0042
generate
 42%|████▏     | 513/1232 [05:22<09:38,  1.24it/s]processing 513th semantic_sys file
513
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NOT A DOUBT BUT HAD YOUR FORCE BEEN ONLY DOUBLE OR TREBLE OUR OWN I SHOULD HAVE FOUND IT MY DUTY TO STRUGGLE WITH YOU
2024-04-02 06:28:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0034.json
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([266.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([302.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([338.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 374, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0034
generate
 42%|████▏     | 514/1232 [05:23<09:36,  1.24it/s]processing 514th semantic_sys file
514
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE SAT WITH THE OFFICERS SOME LITTLE TIME AFTER DINNER AND THEN WENT ASHORE
2024-04-02 06:28:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([58], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0023.json
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 232, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0023
generate
 42%|████▏     | 515/1232 [05:23<08:45,  1.36it/s]processing 515th semantic_sys file
515
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU MAY BE QUITE SURE IT'S THERE SAID CAPTAIN BATTLEAX AND THAT I CAN SO USE IT AS TO HALF OBLITERATE YOUR TOWN WITHIN TWO MINUTES OF MY RETURN ON BOARD
2024-04-02 06:28:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0046.json
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([268.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([309.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([392.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 434, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0046
generate
 42%|████▏     | 516/1232 [05:24<09:12,  1.29it/s]processing 516th semantic_sys file
516
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NO DOUBT IN PROCESS OF TIME THE LADIES WILL FOLLOW
2024-04-02 06:28:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0009.json
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:163
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 163, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0009
generate
 42%|████▏     | 517/1232 [05:25<09:08,  1.30it/s]processing 517th semantic_sys file
517
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I CAN ASSURE YOU HE HAS NOT EVEN ALLOWED ME TO SEE THE TRIGGER SINCE I HAVE BEEN ON BOARD
2024-04-02 06:28:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0039.json
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 231, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0039
generate
 42%|████▏     | 518/1232 [05:26<08:52,  1.34it/s]processing 518th semantic_sys file
518
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT IS FOUNDED ON THE ACKNOWLEDGED WEAKNESS OF THOSE WHO SURVIVE THAT PERIOD OF LIFE AT WHICH MEN CEASE TO WORK
2024-04-02 06:28:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0058.json
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([310.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([356.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([404.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([452.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 501, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0058
generate
 42%|████▏     | 519/1232 [05:27<09:45,  1.22it/s]processing 519th semantic_sys file
519
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I REMAINED THERE ALONE FOR MANY HOURS BUT I MUST ACKNOWLEDGE THAT BEFORE I LEFT THE CHAMBERS I HAD GRADUALLY BROUGHT MYSELF TO LOOK AT THE MATTER IN ANOTHER LIGHT
2024-04-02 06:28:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 520th semantic_sys file
520
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEN THERE WERE THREE OR FOUR LEADING MEN OF THE COMMUNITY WITH THEIR WIVES WHO WERE FOR THE MOST PART THE FATHERS AND MOTHERS OF THE YOUNG LADIES
2024-04-02 06:28:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0019.json
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([290.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([389.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([442.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([495.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 548, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0019
generate
 42%|████▏     | 521/1232 [05:27<07:34,  1.56it/s]processing 521th semantic_sys file
521
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I HAVE COME TO YOUR SHORES MISTER PRESIDENT WITH THE PURPOSE OF SEEING HOW THINGS ARE PROGRESSING IN THIS DISTANT QUARTER OF THE WORLD
2024-04-02 06:28:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0004.json
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([308.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 341, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0004
generate
 42%|████▏     | 522/1232 [05:28<08:02,  1.47it/s]processing 522th semantic_sys file
522
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU HAVE RECEIVED US WITH ALL THAT COURTESY AND HOSPITALITY FOR WHICH YOUR CHARACTER IN ENGLAND STANDS SO HIGH
2024-04-02 06:28:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0031.json
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([251.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([288.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([326.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([366.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 405, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0031
generate
 42%|████▏     | 523/1232 [05:29<08:30,  1.39it/s]processing 523th semantic_sys file
523
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IF YOU WILL GIVE US YOUR PROMISE TO MEET CAPTAIN BATTLEAX HERE AT THIS TIME TO MORROW WE WILL STRETCH A POINT AND DELAY THE DEPARTURE OF THE JOHN BRIGHT FOR TWENTY FOUR HOURS
2024-04-02 06:28:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 524th semantic_sys file
524
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE CAME UPON ME A SUDDEN SHOCK WHEN I HEARD THESE WORDS WHICH EXCEEDED ANYTHING WHICH I HAD YET FELT
2024-04-02 06:28:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0041.json
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([247.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 306, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0041
generate
 43%|████▎     | 525/1232 [05:30<07:18,  1.61it/s]processing 525th semantic_sys file
525
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WERE I TO COMPLY WITH YOUR ORDERS WITHOUT EXPRESSING MY OWN OPINION I SHOULD SEEM TO HAVE DONE SO WILLINGLY HEREAFTER
2024-04-02 06:28:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0053.json
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([273.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([305.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 338, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0053
generate
 43%|████▎     | 526/1232 [05:31<08:09,  1.44it/s]processing 526th semantic_sys file
526
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEN SAID SIR FERDINANDO THERE IS NOTHING FOR IT BUT THAT HE MUST TAKE YOU WITH HIM
2024-04-02 06:28:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0040.json
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([281.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([315.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 349, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0040
generate
 43%|████▎     | 527/1232 [05:32<08:38,  1.36it/s]processing 527th semantic_sys file
527
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT IT IS SURMISED THAT YOU WILL FIND DIFFICULTIES IN THE WAY OF YOUR ENTERING AT ONCE UPON YOUR GOVERNMENT
2024-04-02 06:28:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0059.json
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([301.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([337.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 373, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0059
generate
 43%|████▎     | 528/1232 [05:33<09:02,  1.30it/s]processing 528th semantic_sys file
528
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE ARE QUITE SATISFIED NOW CAPTAIN BATTLEAX SAID MY WIFE
2024-04-02 06:28:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0006.json
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 156, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0006
generate
 43%|████▎     | 529/1232 [05:33<08:26,  1.39it/s]processing 529th semantic_sys file
529
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ON ARRIVING AT HOME AT MY OWN RESIDENCE I FOUND THAT OUR SALON WAS FILLED WITH A BRILLIANT COMPANY
2024-04-02 06:28:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0002.json
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 254, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0002
generate
 43%|████▎     | 530/1232 [05:34<08:18,  1.41it/s]processing 530th semantic_sys file
530
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I DID NOT MEAN SAID CAPTAIN BATTLEAX TO TOUCH UPON PUBLIC SUBJECTS AT SUCH A MOMENT AS THIS
2024-04-02 06:28:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_8455-210777-0011.json
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([298.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([334.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 370, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_8455-210777-0011
generate
 43%|████▎     | 531/1232 [05:35<08:51,  1.32it/s]processing 531th semantic_sys file
531
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE HAVE HEARD SOMETHING OF YOUR STORY SAID KENNETH AND ARE INTERESTED IN IT
2024-04-02 06:28:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0022.json
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 229, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0022
generate
 43%|████▎     | 532/1232 [05:36<08:56,  1.31it/s]processing 532th semantic_sys file
532
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FAIRVIEW WAS TWELVE MILES AWAY BUT BY TEN O'CLOCK THEY DREW UP AT THE COUNTY JAIL
2024-04-02 06:28:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0008.json
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([330.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 365, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0008
generate
 43%|████▎     | 533/1232 [05:36<09:19,  1.25it/s]processing 533th semantic_sys file
533
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WAS BOOKKEEPER SO IT WAS EASY TO GET A BLANK CHECK AND FORGE THE SIGNATURE
2024-04-02 06:28:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0030.json
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([259.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 287, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0030
generate
 43%|████▎     | 534/1232 [05:37<09:15,  1.26it/s]processing 534th semantic_sys file
534
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND TO THINK WE CAN SAVE ALL THAT MISERY AND DESPAIR BY THE PAYMENT OF A HUNDRED AND FIFTY DOLLARS
2024-04-02 06:28:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([52], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0053.json
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([222.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 275, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0053
generate
 43%|████▎     | 535/1232 [05:38<09:31,  1.22it/s]processing 535th semantic_sys file
535
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY LEFT HIM THEN FOR THE JAILER ARRIVED TO UNLOCK THE DOOR AND ESCORT THEM TO THE OFFICE
2024-04-02 06:28:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0036.json
top_k_know_token:70
known_token_update:False
T:640
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:640
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:640
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:640
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:640
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:640
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:640
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:640
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:640
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:640
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:640
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:640
T - mask_len:tensor([396.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:640
T - mask_len:tensor([455.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:640
T - mask_len:tensor([516.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:640
T - mask_len:tensor([578.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 640, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0036
generate
 44%|████▎     | 536/1232 [05:39<11:04,  1.05it/s]processing 536th semantic_sys file
536
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I'M GOING TO SEE MISTER MARSHALL SAID KENNETH AND DISCOVER WHAT I CAN DO TO ASSIST YOU THANK YOU SIR
2024-04-02 06:28:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0034.json
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 283, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0034
generate
 44%|████▎     | 537/1232 [05:40<10:08,  1.14it/s]processing 537th semantic_sys file
537
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT WAS A SERIOUS CRIME INDEED MISTER WATSON TOLD THEM AND TOM GATES BADE FAIR TO SERVE A LENGTHY TERM IN STATE'S PRISON AS A CONSEQUENCE OF HIS RASH ACT
2024-04-02 06:28:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0001.json
top_k_know_token:70
known_token_update:False
T:710
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:710
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:710
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:710
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:710
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:710
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:710
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:710
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:710
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:710
T - mask_len:tensor([316.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:710
T - mask_len:tensor([376.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:710
T - mask_len:tensor([439.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:710
T - mask_len:tensor([504.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:710
T - mask_len:tensor([572.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:710
T - mask_len:tensor([641.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 710, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0001
generate
 44%|████▎     | 538/1232 [05:41<11:55,  1.03s/it]processing 538th semantic_sys file
538
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A FRESH WHOLESOME LOOKING BOY WAS TOM GATES WITH STEADY GRAY EYES AN INTELLIGENT FOREHEAD BUT A SENSITIVE RATHER WEAK MOUTH
2024-04-02 06:28:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0021.json
top_k_know_token:70
known_token_update:False
T:436
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:436
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:436
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:436
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:436
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:436
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:436
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:436
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:436
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:436
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:436
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:436
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:436
T - mask_len:tensor([310.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:436
T - mask_len:tensor([351.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:436
T - mask_len:tensor([394.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 436, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0021
generate
 44%|████▍     | 539/1232 [05:43<12:05,  1.05s/it]processing 539th semantic_sys file
539
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE WAS SOFT HEARTED AND IMPETUOUS SAID BETH AND BEING IN LOVE HE DIDN'T STOP TO COUNT THE COST
2024-04-02 06:28:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0005.json
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([303.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 335, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0005
generate
 44%|████▍     | 540/1232 [05:43<11:08,  1.04it/s]processing 540th semantic_sys file
540
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEN ROGERS WOULDN'T DO ANYTHING BUT LEAD HER AROUND AND WAIT UPON HER AND THE PLACE WENT TO RACK AND RUIN
2024-04-02 06:28:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:28:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0025.json
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([276.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([318.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([360.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([404.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 447, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0025
generate
 44%|████▍     | 541/1232 [05:44<10:56,  1.05it/s]processing 541th semantic_sys file
541
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I DIDN'T STOP TO THINK WHETHER IT WAS FOOLISH OR NOT I DID IT AND I'M GLAD I DID
2024-04-02 06:29:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0023.json
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([303.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 335, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0023
generate
 44%|████▍     | 542/1232 [05:45<09:50,  1.17it/s]processing 542th semantic_sys file
542
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT WAS A DELIBERATE THEFT FROM HIS EMPLOYERS TO PROTECT A GIRL HE LOVED
2024-04-02 06:29:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0003.json
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 211, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0003
generate
 44%|████▍     | 543/1232 [05:46<09:16,  1.24it/s]processing 543th semantic_sys file
543
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OH SAY THAT'S DIFFERENT OBSERVED MARKHAM ALTERING HIS DEMEANOR
2024-04-02 06:29:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0012.json
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 169, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0012
generate
 44%|████▍     | 544/1232 [05:46<08:40,  1.32it/s]processing 544th semantic_sys file
544
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OLD WILL IS A FINE FELLOW BUT POOR AND HELPLESS SINCE MISSUS ROGERS HAD HER ACCIDENT
2024-04-02 06:29:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0024.json
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([309.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([346.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 383, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0024
generate
 44%|████▍     | 545/1232 [05:47<09:04,  1.26it/s]processing 545th semantic_sys file
545
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SIT DOWN PLEASE SAID GATES IN A CHEERFUL AND PLEASANT VOICE THERE'S A BENCH HERE
2024-04-02 06:29:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0020.json
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 238, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0020
generate
 44%|████▍     | 546/1232 [05:48<08:45,  1.30it/s]processing 546th semantic_sys file
546
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE SPOKE SIMPLY BUT PACED UP AND DOWN THE NARROW CELL IN FRONT OF THEM
2024-04-02 06:29:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0026.json
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:188
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 188, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0026
generate
 44%|████▍     | 547/1232 [05:49<08:36,  1.33it/s]processing 547th semantic_sys file
547
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT WAS BETTER FOR HIM TO THINK THE GIRL UNFEELING THAN TO KNOW THE TRUTH
2024-04-02 06:29:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0033.json
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 232, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0033
generate
 44%|████▍     | 548/1232 [05:49<08:38,  1.32it/s]processing 548th semantic_sys file
548
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IF THE PROSECUTION WERE WITHDRAWN AND THE CASE SETTLED WITH THE VICTIM OF THE FORGED CHECK THEN THE YOUNG MAN WOULD BE ALLOWED HIS FREEDOM
2024-04-02 06:29:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([52], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0006.json
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([328.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([372.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([416.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 461, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0006
generate
 45%|████▍     | 549/1232 [05:50<09:25,  1.21it/s]processing 549th semantic_sys file
549
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE UNLOCKED THE DOOR AND CALLED HERE'S VISITORS TOM
2024-04-02 06:29:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0016.json
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 158, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0016
generate
 45%|████▍     | 550/1232 [05:51<09:01,  1.26it/s]processing 550th semantic_sys file
550
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE MIGHT HAVE HAD THAT FORGED CHECK FOR THE FACE OF IT IF HE'D BEEN SHARP
2024-04-02 06:29:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0052.json
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 179, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0052
generate
 45%|████▍     | 551/1232 [05:52<08:04,  1.41it/s]processing 551th semantic_sys file
551
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I DISCOVERED AND PUT OUT A FIRE THAT WOULD HAVE DESTROYED THE WHOLE PLANT BUT MARSHALL NEVER EVEN THANKED ME
2024-04-02 06:29:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0032.json
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 250, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0032
generate
 45%|████▍     | 552/1232 [05:52<07:59,  1.42it/s]processing 552th semantic_sys file
552
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT THEY COULD NOT HAVE PROVEN A CASE AGAINST LUCY IF SHE WAS INNOCENT AND ALL THEIR THREATS OF ARRESTING HER WERE PROBABLY MERE BLUFF
2024-04-02 06:29:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([52], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0004.json
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([247.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([284.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([322.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([361.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 400, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0004
generate
 45%|████▍     | 553/1232 [05:53<08:32,  1.33it/s]processing 553th semantic_sys file
553
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I'M RUNNING FOR REPRESENTATIVE ON THE REPUBLICAN TICKET SAID KENNETH QUIETLY
2024-04-02 06:29:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0011.json
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 223, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0011
generate
 45%|████▍     | 554/1232 [05:54<08:18,  1.36it/s]processing 554th semantic_sys file
554
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AS REGARDS MY ROBBING THE COMPANY I'LL SAY THAT I SAVED THEM A HEAVY LOSS ONE DAY
2024-04-02 06:29:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0031.json
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 328, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0031
generate
 45%|████▌     | 555/1232 [05:55<11:28,  1.02s/it]processing 555th semantic_sys file
555
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE DETESTED THE GRASPING DISPOSITION THAT WOULD ENDEAVOR TO TAKE ADVANTAGE OF HIS EVIDENT DESIRE TO HELP YOUNG GATES
2024-04-02 06:29:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([52], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0049.json
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([268.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([304.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([341.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 377, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0049
generate
 45%|████▌     | 556/1232 [05:56<10:41,  1.05it/s]processing 556th semantic_sys file
556
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: GIVE ME A CHECK FOR A HUNDRED AND FIFTY AND I'LL TURN OVER TO YOU THE FORGED CHECK AND QUASH FURTHER PROCEEDINGS
2024-04-02 06:29:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0048.json
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([297.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 329, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0048
generate
 45%|████▌     | 557/1232 [05:57<10:06,  1.11it/s]processing 557th semantic_sys file
557
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SOME GIRL HAS BEEN HERE TWICE TO INTERVIEW MY MEN AND I HAVE REFUSED TO ADMIT HER
2024-04-02 06:29:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0040.json
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 272, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0040
generate
 45%|████▌     | 558/1232 [05:58<09:46,  1.15it/s]processing 558th semantic_sys file
558
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY WERE RECEIVED IN THE LITTLE OFFICE BY A MAN NAMED MARKHAM WHO WAS THE JAILER
2024-04-02 06:29:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0009.json
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 260, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0009
generate
 45%|████▌     | 559/1232 [05:58<08:41,  1.29it/s]processing 559th semantic_sys file
559
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE LOOKED UP RATHER UNGRACIOUSLY BUT MOTIONED THEM TO BE SEATED
2024-04-02 06:29:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0039.json
top_k_know_token:70
known_token_update:False
T:150
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:150
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:150
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:150
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:150
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:150
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:150
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:150
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:150
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:150
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:150
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:150
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:150
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:150
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:150
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 150, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0039
generate
 45%|████▌     | 560/1232 [05:59<08:01,  1.39it/s]processing 560th semantic_sys file
560
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MISS DE GRAF SAID KENNETH NOTICING THE BOY'S FACE CRITICALLY AS HE STOOD WHERE THE LIGHT FROM THE PASSAGE FELL UPON IT
2024-04-02 06:29:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([52], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0018.json
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([253.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 280, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0018
generate
 46%|████▌     | 561/1232 [06:00<07:51,  1.42it/s]processing 561th semantic_sys file
561
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SOMETIMES I'M THAT YEARNING FOR A SMOKE I'M NEARLY CRAZY AN I DUNNO WHICH IS WORST DYIN ONE WAY OR ANOTHER
2024-04-02 06:29:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68769-0015.json
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([264.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([299.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([335.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 371, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68769-0015
generate
 46%|████▌     | 562/1232 [06:00<08:18,  1.34it/s]processing 562th semantic_sys file
562
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE WAS DRESSED IN THE REGULATION COSTUME OF THE MAIDS AT ELMHURST A PLAIN BLACK GOWN WITH WHITE APRON AND CAP
2024-04-02 06:29:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0019.json
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([313.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([355.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([397.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 440, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0019
generate
 46%|████▌     | 563/1232 [06:01<08:45,  1.27it/s]processing 563th semantic_sys file
563
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE WEAK KNEED CONTINGENCY MUST BE STRENGTHENED AND FORTIFIED AND A COUPLE OF HUNDRED VOTES IN ONE WAY OR ANOTHER SECURED FROM THE OPPOSITION
2024-04-02 06:29:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0002.json
top_k_know_token:70
known_token_update:False
T:490
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:490
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:490
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:490
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:490
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:490
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:490
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:490
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:490
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:490
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:490
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:490
T - mask_len:tensor([303.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:490
T - mask_len:tensor([348.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:490
T - mask_len:tensor([395.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:490
T - mask_len:tensor([442.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 490, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0002
generate
 46%|████▌     | 564/1232 [06:02<09:21,  1.19it/s]processing 564th semantic_sys file
564
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE ATTENDANCE WAS UNEXPECTEDLY LARGE AND THE GIRLS WERE DELIGHTED FORESEEING GREAT SUCCESS FOR THEIR FETE
2024-04-02 06:29:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0013.json
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 301, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0013
generate
 46%|████▌     | 565/1232 [06:03<09:00,  1.23it/s]processing 565th semantic_sys file
565
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE ROSE QUICKLY TO HER FEET WITH AN IMPETUOUS GESTURE THAT MADE HER VISITOR CATCH HER BREATH
2024-04-02 06:29:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0033.json
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([331.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 366, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0033
generate
 46%|████▌     | 566/1232 [06:04<09:52,  1.12it/s]processing 566th semantic_sys file
566
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ELIZA CLOSED THE DOOR BEHIND HER WITH A DECIDED SLAM AND A KEY CLICKED IN THE LOCK
2024-04-02 06:29:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0036.json
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:289
T - mask_len:tensor([261.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 289, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0036
generate
 46%|████▌     | 567/1232 [06:05<09:27,  1.17it/s]processing 567th semantic_sys file
567
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE FAIRVIEW BAND WAS ENGAGED TO DISCOURSE AS MUCH HARMONY AS IT COULD PRODUCE AND THE RESOURCES OF THE GREAT HOUSE WERE TAXED TO ENTERTAIN THE GUESTS
2024-04-02 06:29:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0010.json
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([261.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([305.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([397.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([445.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 493, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0010
generate
 46%|████▌     | 568/1232 [06:06<09:58,  1.11it/s]processing 568th semantic_sys file
568
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HER MANNER WAS NEITHER INDEPENDENT NOR ASSERTIVE BUT RATHER ONE OF WELL BRED COMPOSURE AND CALM RELIANCE
2024-04-02 06:29:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0030.json
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 326, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0030
generate
 46%|████▌     | 569/1232 [06:07<09:42,  1.14it/s]processing 569th semantic_sys file
569
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WON'T YOU RUN INTO THE HOUSE AND SEE IF MARTHA CAN'T SPARE ONE OR TWO MORE MAIDS
2024-04-02 06:29:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0015.json
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([222.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 275, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0015
generate
 46%|████▋     | 570/1232 [06:08<09:25,  1.17it/s]processing 570th semantic_sys file
570
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HOWEVER HER FEATURES AND FORM MIGHT REPRESS ANY EVIDENCE OF NERVOUSNESS THESE HANDS TOLD A DIFFERENT STORY
2024-04-02 06:29:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0032.json
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 317, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0032
generate
 46%|████▋     | 571/1232 [06:08<09:04,  1.21it/s]processing 571th semantic_sys file
571
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY THEY EXCITE ME IN SOME WAY AND I I CAN'T BEAR THEM YOU MUST EXCUSE ME
2024-04-02 06:29:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0027.json
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 304, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0027
generate
 46%|████▋     | 572/1232 [06:09<08:50,  1.25it/s]processing 572th semantic_sys file
572
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE SAT DOWN IN A ROCKING CHAIR AND CLASPING HER HANDS IN HER LAP ROCKED SLOWLY BACK AND FORTH I'M SORRY SAID BETH
2024-04-02 06:29:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0025.json
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:333
T - mask_len:tensor([301.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 333, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0025
generate
 47%|████▋     | 573/1232 [06:10<08:50,  1.24it/s]processing 573th semantic_sys file
573
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE WAS VERY FOND OF THE YOUNG LADIES WHOM SHE HAD KNOWN WHEN AUNT JANE WAS THE MISTRESS HERE AND BETH WAS HER ESPECIAL FAVORITE
2024-04-02 06:29:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0016.json
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([343.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 380, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0016
generate
 47%|████▋     | 574/1232 [06:11<09:05,  1.21it/s]processing 574th semantic_sys file
574
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TABLES WERE SPREAD ON THE LAWN AND A DAINTY BUT SUBSTANTIAL REPAST WAS TO BE SERVED
2024-04-02 06:29:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0011.json
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([258.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 285, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0011
generate
 47%|████▋     | 575/1232 [06:12<09:08,  1.20it/s]processing 575th semantic_sys file
575
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE OUGHT TO HAVE MORE ATTENDANTS BETH SAID LOUISE APPROACHING HER COUSIN
2024-04-02 06:29:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0014.json
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 177, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0014
generate
 47%|████▋     | 576/1232 [06:12<08:29,  1.29it/s]processing 576th semantic_sys file
576
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: UNDER ORDINARY CONDITIONS REYNOLDS WAS SURE TO BE ELECTED BUT THE COMMITTEE PROPOSED TO SACRIFICE HIM IN ORDER TO ELECT HOPKINS
2024-04-02 06:29:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0004.json
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([251.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([293.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([337.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([382.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([428.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 474, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0004
generate
 47%|████▋     | 577/1232 [06:13<09:03,  1.20it/s]processing 577th semantic_sys file
577
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE ONLY THING NECESSARY WAS TO FIX SETH REYNOLDS AND THIS HOPKINS ARRANGED PERSONALLY
2024-04-02 06:29:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0005.json
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([224.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 248, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0005
generate
 47%|████▋     | 578/1232 [06:14<08:30,  1.28it/s]processing 578th semantic_sys file
578
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEN SHE GAVE A LITTLE LAUGH AND REPLIED NO MISS BETH I'M ELIZABETH PARSONS
2024-04-02 06:29:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0020.json
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 258, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0020
generate
 47%|████▋     | 579/1232 [06:15<08:05,  1.34it/s]processing 579th semantic_sys file
579
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FOR A MOMENT BETH STOOD STARING WHILE THE NEW MAID REGARDED HER WITH COMPOSURE AND A SLIGHT SMILE UPON HER BEAUTIFUL FACE
2024-04-02 06:29:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0018.json
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([335.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:415
T - mask_len:tensor([375.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 415, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0018
generate
 47%|████▋     | 580/1232 [06:15<08:40,  1.25it/s]processing 580th semantic_sys file
580
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND THIS WAS WHY KENNETH AND BETH DISCOVERED HIM CONVERSING WITH THE YOUNG WOMAN IN THE BUGGY
2024-04-02 06:29:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0006.json
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([241.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 299, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0006
generate
 47%|████▋     | 581/1232 [06:16<08:05,  1.34it/s]processing 581th semantic_sys file
581
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE DEMOCRATIC COMMITTEE FIGURED OUT A WAY TO DO THIS
2024-04-02 06:29:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0003.json
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([254.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([288.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([323.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 357, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0003
generate
 47%|████▋     | 582/1232 [06:17<08:25,  1.29it/s]processing 582th semantic_sys file
582
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THESE WOMEN WERE FLATTERED BY THE ATTENTION OF THE YOUNG LADY AND HAD PROMISED TO ASSIST IN ELECTING MISTER FORBES
2024-04-02 06:29:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0008.json
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([261.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([293.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 324, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0008
generate
 47%|████▋     | 583/1232 [06:18<08:31,  1.27it/s]processing 583th semantic_sys file
583
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FOR THE FIRST TIME THE MAID SEEMED A LITTLE CONFUSED AND HER GAZE WANDERED FROM THE FACE OF HER VISITOR
2024-04-02 06:29:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0024.json
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([278.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([315.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:391
T - mask_len:tensor([353.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 391, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0024
generate
 47%|████▋     | 584/1232 [06:19<08:51,  1.22it/s]processing 584th semantic_sys file
584
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU SPEAK LIKE AN EDUCATED PERSON SAID BETH WONDERINGLY WHERE IS YOUR HOME
2024-04-02 06:29:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0023.json
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 199, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0023
generate
 47%|████▋     | 585/1232 [06:19<08:23,  1.28it/s]processing 585th semantic_sys file
585
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BETH WAS A BEAUTIFUL GIRL THE HANDSOMEST OF THE THREE COUSINS BY FAR YET ELIZA SURPASSED HER IN NATURAL CHARM AND SEEMED WELL AWARE OF THE FACT
2024-04-02 06:29:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0029.json
top_k_know_token:70
known_token_update:False
T:408
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:408
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:408
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:408
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:408
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:408
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:408
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:408
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:408
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:408
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:408
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:408
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:408
T - mask_len:tensor([290.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:408
T - mask_len:tensor([329.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:408
T - mask_len:tensor([369.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 408, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0029
generate
 48%|████▊     | 586/1232 [06:20<08:41,  1.24it/s]processing 586th semantic_sys file
586
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WILL YOU LEAVE ME ALONE IN MY OWN ROOM OR MUST I GO AWAY TO ESCAPE YOU
2024-04-02 06:29:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6829-68771-0035.json
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 218, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6829-68771-0035
generate
 48%|████▊     | 587/1232 [06:21<08:39,  1.24it/s]processing 587th semantic_sys file
587
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND THEN YOU CAME BACK NOT CARING VERY MUCH BUT IT MADE NO DIFFERENCE
2024-04-02 06:29:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2275-0042.json
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 234, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2275-0042
generate
 48%|████▊     | 588/1232 [06:22<08:26,  1.27it/s]processing 588th semantic_sys file
588
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ALEXANDER ROSE AND SHOOK HIMSELF ANGRILY YES I KNOW I'M COWARDLY
2024-04-02 06:29:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2275-0035.json
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 215, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2275-0035
generate
 48%|████▊     | 589/1232 [06:22<08:01,  1.34it/s]processing 589th semantic_sys file
589
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BARTLEY BENT OVER AND TOOK HER IN HIS ARMS KISSING HER MOUTH AND HER WET TIRED EYES
2024-04-02 06:29:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2275-0043.json
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 296, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2275-0043
generate
 48%|████▊     | 590/1232 [06:23<08:31,  1.26it/s]processing 590th semantic_sys file
590
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHEN DID YOU COME BARTLEY AND HOW DID IT HAPPEN YOU HAVEN'T SPOKEN A WORD
2024-04-02 06:29:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2275-0008.json
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 195, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2275-0008
generate
 48%|████▊     | 591/1232 [06:24<08:11,  1.31it/s]processing 591th semantic_sys file
591
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE CLOSED HER EYES AND TOOK A DEEP BREATH AS IF TO DRAW IN AGAIN THE FRAGRANCE OF THOSE DAYS
2024-04-02 06:29:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2275-0026.json
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([224.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([261.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([300.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([340.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([381.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 422, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2275-0026
generate
 48%|████▊     | 592/1232 [06:25<08:39,  1.23it/s]processing 592th semantic_sys file
592
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HILDA WATCHED HIM FROM HER CORNER TREMBLING AND SCARCELY BREATHING DARK SHADOWS GROWING ABOUT HER EYES IT
2024-04-02 06:29:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2275-0016.json
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 274, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2275-0016
generate
 48%|████▊     | 593/1232 [06:26<08:32,  1.25it/s]processing 593th semantic_sys file
593
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE BLUSHED AND SMILED AND FUMBLED HIS CARD IN HER CONFUSION BEFORE SHE RAN UPSTAIRS
2024-04-02 06:29:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2275-0001.json
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([297.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 329, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2275-0001
generate
 48%|████▊     | 594/1232 [06:27<10:25,  1.02it/s]processing 594th semantic_sys file
594
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE SIGHT OF YOU BARTLEY TO SEE YOU LIVING AND HAPPY AND SUCCESSFUL CAN I NEVER MAKE YOU UNDERSTAND WHAT THAT MEANS TO ME
2024-04-02 06:29:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2275-0040.json
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([284.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([326.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([370.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([415.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 459, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2275-0040
generate
 48%|████▊     | 595/1232 [06:29<12:52,  1.21s/it]processing 595th semantic_sys file
595
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE LOOKED AT HIS HEAVY SHOULDERS AND BIG DETERMINED HEAD THRUST FORWARD LIKE A CATAPULT IN LEASH
2024-04-02 06:29:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2275-0012.json
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 253, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2275-0012
generate
 48%|████▊     | 596/1232 [06:30<11:18,  1.07s/it]processing 596th semantic_sys file
596
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: PLEASE TELL ME ONE THING BARTLEY AT LEAST TELL ME THAT YOU BELIEVE I THOUGHT I WAS MAKING YOU HAPPY
2024-04-02 06:29:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2275-0029.json
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 236, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2275-0029
generate
 48%|████▊     | 597/1232 [06:30<10:44,  1.02s/it]processing 597th semantic_sys file
597
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WILL ASK THE LEAST IMAGINABLE BUT I MUST HAVE SOMETHING
2024-04-02 06:29:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2275-0038.json
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 239, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2275-0038
generate
 49%|████▊     | 598/1232 [06:31<09:41,  1.09it/s]processing 598th semantic_sys file
598
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HILDA'S FACE QUIVERED BUT SHE WHISPERED YES I THINK IT MUST HAVE BEEN
2024-04-02 06:29:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([58], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2275-0021.json
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 229, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2275-0021
generate
 49%|████▊     | 599/1232 [06:32<08:55,  1.18it/s]processing 599th semantic_sys file
599
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ALEXANDER PACED UP AND DOWN THE HALLWAY BUTTONING AND UNBUTTONING HIS OVERCOAT UNTIL SHE RETURNED AND TOOK HIM UP TO HILDA'S LIVING ROOM
2024-04-02 06:29:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2275-0002.json
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([292.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([335.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([380.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([426.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 472, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2275-0002
generate
 49%|████▊     | 600/1232 [06:33<09:09,  1.15it/s]processing 600th semantic_sys file
600
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE STOP AT QUEENSTOWN THE TEDIOUS PASSAGE UP THE MERSEY WERE THINGS THAT HE NOTED DIMLY THROUGH HIS GROWING IMPATIENCE
2024-04-02 06:29:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2275-0000.json
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([251.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([327.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:406
T - mask_len:tensor([367.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 406, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2275-0000
generate
 49%|████▉     | 601/1232 [06:34<09:42,  1.08it/s]processing 601th semantic_sys file
601
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE PUSHED HIM TOWARD THE BIG CHAIR BY THE FIRE AND SAT DOWN ON A STOOL AT THE OPPOSITE SIDE OF THE HEARTH HER KNEES DRAWN UP TO HER CHIN LAUGHING LIKE A HAPPY LITTLE GIRL
2024-04-02 06:29:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([52], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2275-0007.json
top_k_know_token:70
known_token_update:False
T:562
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:562
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:562
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:562
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:562
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:562
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:562
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:562
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:562
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:562
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:562
T - mask_len:tensor([298.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:562
T - mask_len:tensor([347.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:562
T - mask_len:tensor([399.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:562
T - mask_len:tensor([453.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:562
T - mask_len:tensor([507.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 562, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2275-0007
generate
 49%|████▉     | 602/1232 [06:35<09:58,  1.05it/s]processing 602th semantic_sys file
602
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I FELT IT IN MY BONES WHEN I WOKE THIS MORNING THAT SOMETHING SPLENDID WAS GOING TO TURN UP
2024-04-02 06:29:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2275-0005.json
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 293, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2275-0005
generate
 49%|████▉     | 603/1232 [06:36<09:07,  1.15it/s]processing 603th semantic_sys file
603
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHAT I MEAN IS THAT I WANT YOU TO PROMISE NEVER TO SEE ME AGAIN NO MATTER HOW OFTEN I COME NO MATTER HOW HARD I BEG
2024-04-02 06:29:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2275-0033.json
top_k_know_token:70
known_token_update:False
T:466
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:466
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:466
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:466
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:466
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:466
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:466
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:466
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:466
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:466
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:466
T - mask_len:tensor([247.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:466
T - mask_len:tensor([288.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:466
T - mask_len:tensor([331.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:466
T - mask_len:tensor([376.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:466
T - mask_len:tensor([421.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 466, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2275-0033
generate
 49%|████▉     | 604/1232 [06:37<09:37,  1.09it/s]processing 604th semantic_sys file
604
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE WORLD IS ALL THERE JUST AS IT USED TO BE BUT I CAN'T GET AT IT ANY MORE
2024-04-02 06:29:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2275-0019.json
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([325.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([374.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([424.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([475.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 526, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2275-0019
generate
 49%|████▉     | 605/1232 [06:38<09:59,  1.05it/s]processing 605th semantic_sys file
605
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU SEE LOVING SOME ONE AS I LOVE YOU MAKES THE WHOLE WORLD DIFFERENT
2024-04-02 06:29:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2275-0041.json
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 175, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2275-0041
generate
 49%|████▉     | 606/1232 [06:38<09:00,  1.16it/s]processing 606th semantic_sys file
606
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE HAD PRECONCEIVED IDEAS ABOUT EVERYTHING AND HIS IDEA ABOUT AMERICANS WAS THAT THEY SHOULD BE ENGINEERS OR MECHANICS
2024-04-02 06:29:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2271-0001.json
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 387, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2271-0001
generate
 49%|████▉     | 607/1232 [06:39<09:00,  1.16it/s]processing 607th semantic_sys file
607
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IRENE BURGOYNE ONE OF HER FAMILY TOLD ME IN CONFIDENCE THAT THERE WAS A ROMANCE SOMEWHERE BACK IN THE BEGINNING
2024-04-02 06:29:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2271-0008.json
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([253.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:314
T - mask_len:tensor([284.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 314, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2271-0008
generate
 49%|████▉     | 608/1232 [06:40<08:44,  1.19it/s]processing 608th semantic_sys file
608
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MAINHALL VOUCHED FOR HER CONSTANCY WITH A LOFTINESS THAT MADE ALEXANDER SMILE EVEN WHILE A KIND OF RAPID EXCITEMENT WAS TINGLING THROUGH HIM
2024-04-02 06:29:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([56], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2271-0009.json
top_k_know_token:70
known_token_update:False
T:607
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:607
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:607
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:607
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:607
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:607
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:607
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:607
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:607
T - mask_len:tensor([222.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:607
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:607
T - mask_len:tensor([321.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:607
T - mask_len:tensor([375.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:607
T - mask_len:tensor([431.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:607
T - mask_len:tensor([489.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:607
T - mask_len:tensor([548.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 607, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2271-0009
generate
 49%|████▉     | 609/1232 [06:41<09:33,  1.09it/s]processing 609th semantic_sys file
609
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WESTMERE AND I WERE BACK AFTER THE FIRST ACT AND WE THOUGHT SHE SEEMED QUITE UNCERTAIN OF HERSELF
2024-04-02 06:29:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([59], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2271-0014.json
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 298, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2271-0014
generate
 50%|████▉     | 610/1232 [06:42<09:24,  1.10it/s]processing 610th semantic_sys file
610
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DO YOU KNOW I THOUGHT THE DANCE A BIT CONSCIOUS TO NIGHT FOR THE FIRST TIME
2024-04-02 06:29:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2271-0013.json
top_k_know_token:70
known_token_update:False
T:221
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:221
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:221
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:221
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:221
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:221
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:221
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:221
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:221
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:221
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:221
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:221
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:221
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:221
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:221
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 221, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2271-0013
generate
 50%|████▉     | 611/1232 [06:43<09:06,  1.14it/s]processing 611th semantic_sys file
611
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE CONSIDERED A MOMENT AND THEN SAID NO I THINK NOT THOUGH I AM GLAD YOU ASK ME
2024-04-02 06:29:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2271-0018.json
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:273
T - mask_len:tensor([247.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 273, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2271-0018
generate
 50%|████▉     | 612/1232 [06:44<08:57,  1.15it/s]processing 612th semantic_sys file
612
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OF COURSE HE REFLECTED SHE ALWAYS HAD THAT COMBINATION OF SOMETHING HOMELY AND SENSIBLE AND SOMETHING UTTERLY WILD AND DAFT
2024-04-02 06:29:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:29:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([58], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2271-0020.json
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([313.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([355.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([397.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 440, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2271-0020
generate
 50%|████▉     | 613/1232 [06:45<09:22,  1.10it/s]processing 613th semantic_sys file
613
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHEN BARTLEY ARRIVED AT BEDFORD SQUARE ON SUNDAY EVENING MARIE THE PRETTY LITTLE FRENCH GIRL MET HIM AT THE DOOR AND CONDUCTED HIM UPSTAIRS
2024-04-02 06:30:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([53], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2273-0003.json
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([287.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([325.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([364.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 403, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2273-0003
generate
 50%|████▉     | 614/1232 [06:45<09:05,  1.13it/s]processing 614th semantic_sys file
614
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HILDA WAS VERY NICE TO HIM AND HE SAT ON THE EDGE OF HIS CHAIR FLUSHED WITH HIS CONVERSATIONAL EFFORTS AND MOVING HIS CHIN ABOUT NERVOUSLY OVER HIS HIGH COLLAR
2024-04-02 06:30:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2273-0000.json
top_k_know_token:70
known_token_update:False
T:503
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:503
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:503
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:503
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:503
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:503
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:503
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:503
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:503
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:503
T - mask_len:tensor([224.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:503
T - mask_len:tensor([266.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:503
T - mask_len:tensor([311.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:503
T - mask_len:tensor([357.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:503
T - mask_len:tensor([405.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:503
T - mask_len:tensor([454.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 503, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2273-0000
generate
 50%|████▉     | 615/1232 [06:46<09:25,  1.09it/s]processing 615th semantic_sys file
615
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT WAS VERY JOLLY HE MURMURED LAZILY AS MARIE CAME IN TO TAKE AWAY THE COFFEE
2024-04-02 06:30:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2273-0025.json
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 252, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2273-0025
generate
 50%|█████     | 616/1232 [06:47<09:02,  1.14it/s]processing 616th semantic_sys file
616
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY ASKED HIM TO COME TO SEE THEM IN CHELSEA AND THEY SPOKE VERY TENDERLY OF HILDA
2024-04-02 06:30:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2273-0001.json
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([259.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 287, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2273-0001
generate
 50%|█████     | 617/1232 [06:48<08:23,  1.22it/s]processing 617th semantic_sys file
617
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT'S NOT PARTICULARLY RARE SHE SAID BUT SOME OF IT WAS MY MOTHER'S
2024-04-02 06:30:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([54], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2273-0009.json
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 295, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2273-0009
generate
 50%|█████     | 618/1232 [06:48<07:59,  1.28it/s]processing 618th semantic_sys file
618
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NONSENSE OF COURSE I CAN'T REALLY SING EXCEPT THE WAY MY MOTHER AND GRANDMOTHER DID BEFORE ME
2024-04-02 06:30:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2273-0028.json
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 250, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2273-0028
generate
 50%|█████     | 619/1232 [06:49<08:09,  1.25it/s]processing 619th semantic_sys file
619
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE STOOD A LITTLE BEHIND HER AND TRIED TO STEADY HIMSELF AS HE SAID IT'S SOFT AND MISTY SEE HOW WHITE THE STARS ARE
2024-04-02 06:30:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2273-0032.json
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([276.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([317.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([359.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:446
T - mask_len:tensor([403.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 446, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2273-0032
generate
 50%|█████     | 620/1232 [06:50<08:27,  1.21it/s]processing 620th semantic_sys file
620
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I SHOULD NEVER HAVE ASKED YOU IF MOLLY HAD BEEN HERE FOR I REMEMBER YOU DON'T LIKE ENGLISH COOKERY
2024-04-02 06:30:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2273-0004.json
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 276, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2273-0004
generate
 50%|█████     | 621/1232 [06:51<08:07,  1.25it/s]processing 621th semantic_sys file
621
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHAT SHE WANTED FROM US WAS NEITHER OUR FLOWERS NOR OUR FRANCS BUT JUST OUR YOUTH
2024-04-02 06:30:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([27], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2273-0021.json
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([258.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([293.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:363
T - mask_len:tensor([328.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 363, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2273-0021
generate
 50%|█████     | 622/1232 [06:52<08:26,  1.20it/s]processing 622th semantic_sys file
622
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I'VE MANAGED TO SAVE SOMETHING EVERY YEAR AND THAT WITH HELPING MY THREE SISTERS NOW AND THEN AND TIDING POOR COUSIN MIKE OVER BAD SEASONS
2024-04-02 06:30:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2273-0008.json
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([264.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([304.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([344.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([386.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 427, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2273-0008
generate
 51%|█████     | 623/1232 [06:53<08:39,  1.17it/s]processing 623th semantic_sys file
623
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HER HAIR IS STILL LIKE FLAX AND HER BLUE EYES ARE JUST LIKE A BABY'S AND SHE HAS THE SAME THREE FRECKLES ON HER LITTLE NOSE AND TALKS ABOUT GOING BACK TO HER BAINS DE MER
2024-04-02 06:30:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2273-0016.json
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([290.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([345.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([402.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([463.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([524.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:651
T - mask_len:tensor([588.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 651, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2273-0016
generate
 51%|█████     | 624/1232 [06:54<09:29,  1.07it/s]processing 624th semantic_sys file
624
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY WERE BOTH REMEMBERING WHAT THE WOMAN HAD SAID WHEN SHE TOOK THE MONEY GOD GIVE YOU A HAPPY LOVE
2024-04-02 06:30:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2273-0022.json
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 269, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2273-0022
generate
 51%|█████     | 625/1232 [06:55<09:08,  1.11it/s]processing 625th semantic_sys file
625
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BARTLEY LEANED OVER HER SHOULDER WITHOUT TOUCHING HER AND WHISPERED IN HER EAR YOU ARE GIVING ME A CHANCE YES
2024-04-02 06:30:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2273-0035.json
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([291.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 322, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2273-0035
generate
 51%|█████     | 626/1232 [06:56<08:54,  1.13it/s]processing 626th semantic_sys file
626
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE STRANGE WOMAN AND HER PASSIONATE SENTENCE THAT RANG OUT SO SHARPLY HAD FRIGHTENED THEM BOTH
2024-04-02 06:30:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([53], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2273-0023.json
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 272, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2273-0023
generate
 51%|█████     | 627/1232 [06:56<08:35,  1.17it/s]processing 627th semantic_sys file
627
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I HAVEN'T HAD A CHANCE YET TO TELL YOU WHAT A JOLLY LITTLE PLACE I THINK THIS IS
2024-04-02 06:30:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([54], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2273-0005.json
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([280.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([318.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([356.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 394, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2273-0005
generate
 51%|█████     | 628/1232 [06:57<08:32,  1.18it/s]processing 628th semantic_sys file
628
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BARTLEY STARTED WHEN HILDA RANG THE LITTLE BELL BESIDE HER DEAR ME WHY DID YOU DO THAT
2024-04-02 06:30:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([53], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2273-0024.json
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([274.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 303, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2273-0024
generate
 51%|█████     | 629/1232 [06:58<08:54,  1.13it/s]processing 629th semantic_sys file
629
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DON'T I THOUGH I'M SO SORRY TO HEAR IT HOW DID HER SON TURN OUT
2024-04-02 06:30:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4446-2273-0015.json
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([222.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 312, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4446-2273-0015
generate
 51%|█████     | 630/1232 [06:59<08:35,  1.17it/s]processing 630th semantic_sys file
630
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE SCREAMED AND SHOUTED TOO WITH A TERRIFIC VOLUME OF SOUND WHICH DOUBTLESS CAUSED THE HEARTS OF THE FUGITIVES TO QUAKE WITHIN THEM
2024-04-02 06:30:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1221-135767-0010.json
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([290.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([338.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([389.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([441.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([494.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 547, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1221-135767-0010
generate
 51%|█████     | 631/1232 [07:00<09:09,  1.09it/s]processing 631th semantic_sys file
631
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT WAS THE SCARLET LETTER IN ANOTHER FORM THE SCARLET LETTER ENDOWED WITH LIFE
2024-04-02 06:30:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1221-135767-0005.json
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([319.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([358.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 396, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1221-135767-0005
generate
 51%|█████▏    | 632/1232 [07:01<09:10,  1.09it/s]processing 632th semantic_sys file
632
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: PEARL SEEING THE ROSE BUSHES BEGAN TO CRY FOR A RED ROSE AND WOULD NOT BE PACIFIED
2024-04-02 06:30:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1221-135767-0024.json
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 257, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1221-135767-0024
generate
 51%|█████▏    | 633/1232 [07:02<08:30,  1.17it/s]processing 633th semantic_sys file
633
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YEA HIS HONOURABLE WORSHIP IS WITHIN BUT HE HATH A GODLY MINISTER OR TWO WITH HIM AND LIKEWISE A LEECH
2024-04-02 06:30:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1221-135767-0014.json
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([254.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([288.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([323.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 357, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1221-135767-0014
generate
 51%|█████▏    | 634/1232 [07:03<08:51,  1.12it/s]processing 634th semantic_sys file
634
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: PEARL SAW AND GAZED INTENTLY BUT NEVER SOUGHT TO MAKE ACQUAINTANCE
2024-04-02 06:30:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1221-135766-0014.json
top_k_know_token:70
known_token_update:False
T:180
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:180
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:180
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:180
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:180
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:180
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:180
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:180
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:180
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:180
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:180
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:180
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:180
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:180
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:180
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 180, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1221-135766-0014
generate
 52%|█████▏    | 635/1232 [07:03<08:05,  1.23it/s]processing 635th semantic_sys file
635
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS OUTWARD MUTABILITY INDICATED AND DID NOT MORE THAN FAIRLY EXPRESS THE VARIOUS PROPERTIES OF HER INNER LIFE
2024-04-02 06:30:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1221-135766-0004.json
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([331.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 366, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1221-135766-0004
generate
 52%|█████▏    | 636/1232 [07:04<08:16,  1.20it/s]processing 636th semantic_sys file
636
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION
2024-04-02 06:30:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1221-135766-0002.json
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 245, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1221-135766-0002
generate
 52%|█████▏    | 637/1232 [07:05<08:03,  1.23it/s]processing 637th semantic_sys file
637
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HESTER PRYNNE NEVERTHELESS THE LOVING MOTHER OF THIS ONE CHILD RAN LITTLE RISK OF ERRING ON THE SIDE OF UNDUE SEVERITY
2024-04-02 06:30:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_1221-135766-0007.json
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 387, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_1221-135766-0007
generate
 52%|█████▏    | 638/1232 [07:06<08:08,  1.22it/s]processing 638th semantic_sys file
638
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HER BEARING WAS GRACEFUL AND ANIMATED SHE LED HER SON BY THE HAND AND BEFORE HER WALKED TWO MAIDS WITH WAX LIGHTS AND SILVER CANDLESTICKS
2024-04-02 06:30:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5639-40744-0033.json
top_k_know_token:70
known_token_update:False
T:532
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:532
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:532
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:532
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:532
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:532
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:532
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:532
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:532
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:532
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:532
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:532
T - mask_len:tensor([329.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:532
T - mask_len:tensor([378.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:532
T - mask_len:tensor([429.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:532
T - mask_len:tensor([480.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 532, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5639-40744-0033
generate
 52%|█████▏    | 639/1232 [07:07<08:50,  1.12it/s]processing 639th semantic_sys file
639
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THUS DID THIS HUMANE AND RIGHT MINDED FATHER COMFORT HIS UNHAPPY DAUGHTER AND HER MOTHER EMBRACING HER AGAIN DID ALL SHE COULD TO SOOTHE HER FEELINGS
2024-04-02 06:30:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5639-40744-0020.json
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([299.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([380.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 421, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5639-40744-0020
generate
 52%|█████▏    | 640/1232 [07:08<08:58,  1.10it/s]processing 640th semantic_sys file
640
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AMONG OTHER THINGS ON WHICH SHE CAST HER EYES WAS A SMALL CRUCIFIX OF SOLID SILVER STANDING ON A CABINET NEAR THE WINDOW
2024-04-02 06:30:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5639-40744-0014.json
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([334.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([374.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 414, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5639-40744-0014
generate
 52%|█████▏    | 641/1232 [07:09<08:56,  1.10it/s]processing 641th semantic_sys file
641
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: RODOLFO AND HIS COMPANIONS WITH THEIR FACES MUFFLED IN THEIR CLOAKS STARED RUDELY AND INSOLENTLY AT THE MOTHER THE DAUGHTER AND THE SERVANT MAID
2024-04-02 06:30:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5639-40744-0002.json
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([315.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([362.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([410.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([460.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 509, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5639-40744-0002
generate
 52%|█████▏    | 642/1232 [07:10<09:22,  1.05it/s]processing 642th semantic_sys file
642
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: RODOLFO ARRIVED AT HIS OWN HOUSE WITHOUT ANY IMPEDIMENT AND LEOCADIA'S PARENTS REACHED THEIRS HEART BROKEN AND DESPAIRING
2024-04-02 06:30:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5639-40744-0006.json
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([276.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([309.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 342, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5639-40744-0006
generate
 52%|█████▏    | 643/1232 [07:11<09:02,  1.09it/s]processing 643th semantic_sys file
643
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE SUCCEEDED IN OPENING THE WINDOW AND THE MOONLIGHT SHONE IN SO BRIGHTLY THAT SHE COULD DISTINGUISH THE COLOUR OF SOME DAMASK HANGINGS IN THE ROOM
2024-04-02 06:30:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5639-40744-0012.json
top_k_know_token:70
known_token_update:False
T:617
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:617
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:617
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:617
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:617
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:617
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:617
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:617
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:617
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:617
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:617
T - mask_len:tensor([327.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:617
T - mask_len:tensor([381.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:617
T - mask_len:tensor([438.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:617
T - mask_len:tensor([497.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:617
T - mask_len:tensor([557.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 617, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5639-40744-0012
generate
 52%|█████▏    | 644/1232 [07:12<09:46,  1.00it/s]processing 644th semantic_sys file
644
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MEANWHILE RODOLFO HAD LEOCADIA SAFE IN HIS CUSTODY AND IN HIS OWN APARTMENT
2024-04-02 06:30:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5639-40744-0007.json
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([241.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 299, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5639-40744-0007
generate
 52%|█████▏    | 645/1232 [07:13<09:12,  1.06it/s]processing 645th semantic_sys file
645
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ON THE CONTRARY HE RESOLVED TO TELL THEM THAT REPENTING OF HIS VIOLENCE AND MOVED BY HER TEARS HE HAD ONLY CARRIED HER HALF WAY TOWARDS HIS HOUSE AND THEN LET HER GO
2024-04-02 06:30:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5639-40744-0016.json
top_k_know_token:70
known_token_update:False
T:634
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:634
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:634
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:634
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:634
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:634
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:634
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:634
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:634
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:634
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:634
T - mask_len:tensor([336.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:634
T - mask_len:tensor([392.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:634
T - mask_len:tensor([450.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:634
T - mask_len:tensor([511.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:634
T - mask_len:tensor([572.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 634, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5639-40744-0016
generate
 52%|█████▏    | 646/1232 [07:14<10:08,  1.04s/it]processing 646th semantic_sys file
646
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT IS THE ONLY AMENDS I ASK OF YOU FOR THE WRONG YOU HAVE DONE ME
2024-04-02 06:30:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5639-40744-0010.json
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([222.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 312, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5639-40744-0010
generate
 53%|█████▎    | 647/1232 [07:15<09:22,  1.04it/s]processing 647th semantic_sys file
647
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE BED SHE TOO WELL REMEMBERED WAS THERE AND ABOVE ALL THE CABINET ON WHICH HAD STOOD THE IMAGE SHE HAD TAKEN AWAY WAS STILL ON THE SAME SPOT
2024-04-02 06:30:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5639-40744-0025.json
top_k_know_token:70
known_token_update:False
T:455
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:455
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:455
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:455
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:455
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:455
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:455
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:455
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:455
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:455
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:455
T - mask_len:tensor([241.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:455
T - mask_len:tensor([281.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:455
T - mask_len:tensor([323.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:455
T - mask_len:tensor([367.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:455
T - mask_len:tensor([411.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 455, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5639-40744-0025
generate
 53%|█████▎    | 648/1232 [07:15<09:11,  1.06it/s]processing 648th semantic_sys file
648
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS TRUTH WHICH I HAVE LEARNED FROM HER LIPS IS CONFIRMED BY HIS FACE IN WHICH WE HAVE BOTH BEHELD THAT OF OUR SON
2024-04-02 06:30:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5639-40744-0029.json
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([316.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 350, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5639-40744-0029
generate
 53%|█████▎    | 649/1232 [07:16<09:04,  1.07it/s]processing 649th semantic_sys file
649
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: CHOKING WITH EMOTION LEOCADI MADE A SIGN TO HER PARENTS THAT SHE WISHED TO BE ALONE WITH THEM
2024-04-02 06:30:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5639-40744-0017.json
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 316, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5639-40744-0017
generate
 53%|█████▎    | 650/1232 [07:17<08:46,  1.11it/s]processing 650th semantic_sys file
650
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ONE DAY WHEN THE BOY WAS SENT BY HIS GRANDFATHER WITH A MESSAGE TO A RELATION HE PASSED ALONG A STREET IN WHICH THERE WAS A GREAT CONCOURSE OF HORSEMEN
2024-04-02 06:30:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5639-40744-0024.json
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([311.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([352.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([395.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 437, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5639-40744-0024
generate
 53%|█████▎    | 651/1232 [07:18<09:11,  1.05it/s]processing 651th semantic_sys file
651
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE SAW THAT THE BED WAS GILDED AND SO RICH THAT IT SEEMED THAT OF A PRINCE RATHER THAN OF A PRIVATE GENTLEMAN
2024-04-02 06:30:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5639-40744-0013.json
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 307, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5639-40744-0013
generate
 53%|█████▎    | 652/1232 [07:19<08:51,  1.09it/s]processing 652th semantic_sys file
652
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FINALLY THE ONE PARTY WENT OFF EXULTING AND THE OTHER WAS LEFT IN DESOLATION AND WOE
2024-04-02 06:30:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5639-40744-0005.json
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([247.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([284.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([322.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:400
T - mask_len:tensor([361.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 400, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5639-40744-0005
generate
 53%|█████▎    | 653/1232 [07:20<08:47,  1.10it/s]processing 653th semantic_sys file
653
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OTHERWISE PAUL SHOULD HAVE WRITTEN GRACE FROM GOD THE FATHER AND PEACE FROM OUR LORD JESUS CHRIST
2024-04-02 06:30:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([63], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0056.json
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 251, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0056
generate
 53%|█████▎    | 654/1232 [07:21<08:08,  1.18it/s]processing 654th semantic_sys file
654
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DID NOT CHRIST HIMSELF SAY I AM THE WAY AND THE TRUTH AND THE LIFE NO MAN COMETH UNTO THE FATHER BUT BY ME
2024-04-02 06:30:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0050.json
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([333.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:413
T - mask_len:tensor([373.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 413, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0050
generate
 53%|█████▎    | 655/1232 [07:22<08:10,  1.18it/s]processing 655th semantic_sys file
655
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: PAUL TAKES PRIDE IN HIS MINISTRY NOT TO HIS OWN PRAISE BUT TO THE PRAISE OF GOD
2024-04-02 06:30:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0008.json
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([222.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 312, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0008
generate
 53%|█████▎    | 656/1232 [07:22<08:05,  1.19it/s]processing 656th semantic_sys file
656
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE VICIOUS CHARACTER OF SIN IS BROUGHT OUT BY THE WORDS WHO GAVE HIMSELF FOR OUR SINS
2024-04-02 06:30:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0069.json
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 295, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0069
generate
 53%|█████▎    | 657/1232 [07:23<08:15,  1.16it/s]processing 657th semantic_sys file
657
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SO MUCH FOR THE TITLE OF THE EPISTLE NOW FOLLOWS THE GREETING OF THE APOSTLE VERSE THREE
2024-04-02 06:30:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([53], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0037.json
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 226, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0037
generate
 53%|█████▎    | 658/1232 [07:24<07:48,  1.23it/s]processing 658th semantic_sys file
658
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: GRACE INVOLVES THE REMISSION OF SINS PEACE AND A HAPPY CONSCIENCE
2024-04-02 06:30:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0041.json
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 222, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0041
generate
 53%|█████▎    | 659/1232 [07:25<07:50,  1.22it/s]processing 659th semantic_sys file
659
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY DO NOT GO WHERE THE ENEMIES OF THE GOSPEL PREDOMINATE THEY GO WHERE THE CHRISTIANS ARE
2024-04-02 06:30:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0030.json
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 262, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0030
generate
 54%|█████▎    | 660/1232 [07:25<07:18,  1.30it/s]processing 660th semantic_sys file
660
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I KNEW NOTHING OF THE DOCTRINE OF FAITH BECAUSE WE WERE TAUGHT SOPHISTRY INSTEAD OF CERTAINTY AND NOBODY UNDERSTOOD SPIRITUAL BOASTING
2024-04-02 06:30:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0019.json
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([271.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([316.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([363.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([412.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([461.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 511, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0019
generate
 54%|█████▎    | 661/1232 [07:26<07:59,  1.19it/s]processing 661th semantic_sys file
661
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SINCE CHRIST WAS GIVEN FOR OUR SINS IT STANDS TO REASON THAT THEY CANNOT BE PUT AWAY BY OUR OWN EFFORTS
2024-04-02 06:30:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([54], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0066.json
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([258.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 320, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0066
generate
 54%|█████▎    | 662/1232 [07:27<08:07,  1.17it/s]processing 662th semantic_sys file
662
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TO BESTOW PEACE AND GRACE LIES IN THE PROVINCE OF GOD WHO ALONE CAN CREATE THESE BLESSINGS THE ANGELS CANNOT
2024-04-02 06:30:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0055.json
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([302.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 375, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0055
generate
 54%|█████▍    | 663/1232 [07:28<08:06,  1.17it/s]processing 663th semantic_sys file
663
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHEREVER THE MEANS OF GRACE ARE FOUND THERE IS THE HOLY CHURCH EVEN THOUGH ANTICHRIST REIGNS THERE
2024-04-02 06:30:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0036.json
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:346
T - mask_len:tensor([313.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 346, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0036
generate
 54%|█████▍    | 664/1232 [07:29<07:58,  1.19it/s]processing 664th semantic_sys file
664
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE GREATNESS OF THE RANSOM CHRIST THE SON OF GOD INDICATES THIS
2024-04-02 06:30:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0068.json
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 217, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0068
generate
 54%|█████▍    | 665/1232 [07:30<07:55,  1.19it/s]processing 665th semantic_sys file
665
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE TERMS OF GRACE AND PEACE ARE COMMON TERMS WITH PAUL AND ARE NOW PRETTY WELL UNDERSTOOD
2024-04-02 06:30:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0039.json
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 309, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0039
generate
 54%|█████▍    | 666/1232 [07:31<08:02,  1.17it/s]processing 666th semantic_sys file
666
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: UNDERSCORE THESE WORDS FOR THEY ARE FULL OF COMFORT FOR SORE CONSCIENCES
2024-04-02 06:30:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0063.json
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 189, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0063
generate
 54%|█████▍    | 667/1232 [07:32<07:48,  1.21it/s]processing 667th semantic_sys file
667
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TO DO SO IS TO LOSE GOD ALTOGETHER BECAUSE GOD BECOMES INTOLERABLE WHEN WE SEEK TO MEASURE AND TO COMPREHEND HIS INFINITE MAJESTY
2024-04-02 06:30:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([61], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0047.json
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([315.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([362.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([410.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([460.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 509, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0047
generate
 54%|█████▍    | 668/1232 [07:33<08:21,  1.12it/s]processing 668th semantic_sys file
668
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: PAUL ANSWERS THE MAN WHO IS NAMED JESUS CHRIST AND THE SON OF GOD GAVE HIMSELF FOR OUR SINS
2024-04-02 06:30:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([54], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0065.json
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:285
T - mask_len:tensor([258.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 285, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0065
generate
 54%|█████▍    | 669/1232 [07:33<08:03,  1.16it/s]processing 669th semantic_sys file
669
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE ARE TO HEAR CHRIST WHO HAS BEEN APPOINTED BY THE FATHER AS OUR DIVINE TEACHER
2024-04-02 06:30:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([27], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0052.json
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 266, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0052
generate
 54%|█████▍    | 670/1232 [07:34<07:09,  1.31it/s]processing 670th semantic_sys file
670
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS ATTITUDE IS UNIVERSAL AND PARTICULARLY DEVELOPED IN THOSE WHO CONSIDER THEMSELVES BETTER THAN OTHERS
2024-04-02 06:30:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0074.json
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([280.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([318.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:394
T - mask_len:tensor([356.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 394, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0074
generate
 54%|█████▍    | 671/1232 [07:35<07:27,  1.25it/s]processing 671th semantic_sys file
671
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHY DO THEY NOT INVADE THE CATHOLIC PROVINCES AND PREACH THEIR DOCTRINE TO GODLESS PRINCES BISHOPS AND DOCTORS AS WE HAVE DONE BY THE HELP OF GOD
2024-04-02 06:30:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0031.json
top_k_know_token:70
known_token_update:False
T:596
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:596
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:596
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:596
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:596
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:596
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:596
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:596
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:596
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:596
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:596
T - mask_len:tensor([316.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:596
T - mask_len:tensor([368.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:596
T - mask_len:tensor([423.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:596
T - mask_len:tensor([480.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:596
T - mask_len:tensor([538.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 596, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0031
generate
 55%|█████▍    | 672/1232 [07:36<08:25,  1.11it/s]processing 672th semantic_sys file
672
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: PAUL DECLARES THAT THE FALSE APOSTLES WERE CALLED OR SENT NEITHER BY MEN NOR BY MAN
2024-04-02 06:30:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0011.json
top_k_know_token:70
known_token_update:False
T:471
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:471
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:471
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:471
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:471
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:471
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:471
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:471
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:471
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:471
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:471
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:471
T - mask_len:tensor([291.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:471
T - mask_len:tensor([335.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:471
T - mask_len:tensor([380.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:471
T - mask_len:tensor([425.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 471, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0011
generate
 55%|█████▍    | 673/1232 [07:37<08:16,  1.13it/s]processing 673th semantic_sys file
673
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AT THE SAME TIME PAUL CONFIRMS OUR CREED THAT CHRIST IS VERY GOD
2024-04-02 06:30:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0053.json
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 213, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0053
generate
 55%|█████▍    | 674/1232 [07:37<07:32,  1.23it/s]processing 674th semantic_sys file
674
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THESE PERVERTERS OF THE RIGHTEOUSNESS OF CHRIST RESIST THE FATHER AND THE SON AND THE WORKS OF THEM BOTH
2024-04-02 06:30:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0023.json
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([297.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 329, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0023
generate
 55%|█████▍    | 675/1232 [07:38<07:32,  1.23it/s]processing 675th semantic_sys file
675
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DO YOU SUPPOSE THAT GOD FOR THE SAKE OF A FEW LUTHERAN HERETICS WOULD DISOWN HIS ENTIRE CHURCH
2024-04-02 06:30:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0005.json
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:316
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 316, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0005
generate
 55%|█████▍    | 676/1232 [07:39<07:34,  1.22it/s]processing 676th semantic_sys file
676
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE MENTIONS THE APOSTLES FIRST BECAUSE THEY WERE APPOINTED DIRECTLY BY GOD
2024-04-02 06:30:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0013.json
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 213, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0013
generate
 55%|█████▍    | 677/1232 [07:40<07:05,  1.31it/s]processing 677th semantic_sys file
677
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT THE REAL SIGNIFICANCE AND COMFORT OF THE WORDS FOR OUR SINS IS LOST UPON THEM
2024-04-02 06:30:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0075.json
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:200
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 200, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0075
generate
 55%|█████▌    | 678/1232 [07:40<06:55,  1.33it/s]processing 678th semantic_sys file
678
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ON THE OTHER HAND WE ARE NOT TO REGARD THEM AS SO TERRIBLE THAT WE MUST DESPAIR
2024-04-02 06:30:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0076.json
top_k_know_token:70
known_token_update:False
T:330
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:330
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:330
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:330
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:330
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:330
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:330
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:330
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:330
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:330
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:330
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:330
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:330
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:330
T - mask_len:tensor([266.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:330
T - mask_len:tensor([298.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 330, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0076
generate
 55%|█████▌    | 679/1232 [07:41<06:56,  1.33it/s]processing 679th semantic_sys file
679
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS SENTENCE ALSO DEFINES OUR SINS AS GREAT SO GREAT IN FACT THAT THE WHOLE WORLD COULD NOT MAKE AMENDS FOR A SINGLE SIN
2024-04-02 06:30:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0067.json
top_k_know_token:70
known_token_update:False
T:517
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:517
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:517
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:517
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:517
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:517
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:517
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:517
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:517
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:517
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:517
T - mask_len:tensor([274.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:517
T - mask_len:tensor([320.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:517
T - mask_len:tensor([367.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:517
T - mask_len:tensor([417.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:517
T - mask_len:tensor([467.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 517, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0067
generate
 55%|█████▌    | 680/1232 [07:42<07:48,  1.18it/s]processing 680th semantic_sys file
680
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AGAINST THESE BOASTING FALSE APOSTLES PAUL BOLDLY DEFENDS HIS APOSTOLIC AUTHORITY AND MINISTRY
2024-04-02 06:30:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0006.json
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([259.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 287, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0006
generate
 55%|█████▌    | 681/1232 [07:43<07:21,  1.25it/s]processing 681th semantic_sys file
681
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHEN YOU ARGUE ABOUT THE NATURE OF GOD APART FROM THE QUESTION OF JUSTIFICATION YOU MAY BE AS PROFOUND AS YOU LIKE
2024-04-02 06:30:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:30:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0051.json
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([298.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([334.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 370, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0051
generate
 55%|█████▌    | 682/1232 [07:44<07:33,  1.21it/s]processing 682th semantic_sys file
682
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BY HIS RESURRECTION CHRIST WON THE VICTORY OVER LAW SIN FLESH WORLD DEVIL DEATH HELL AND EVERY EVIL
2024-04-02 06:31:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0025.json
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([284.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([318.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 352, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0025
generate
 55%|█████▌    | 683/1232 [07:45<07:58,  1.15it/s]processing 683th semantic_sys file
683
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ALTHOUGH THE BRETHREN WITH ME ARE NOT APOSTLES LIKE MYSELF YET THEY ARE ALL OF ONE MIND WITH ME THINK WRITE AND TEACH AS I DO
2024-04-02 06:31:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0029.json
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([278.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 345, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0029
generate
 56%|█████▌    | 684/1232 [07:46<07:51,  1.16it/s]processing 684th semantic_sys file
684
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: GRACE BE TO YOU AND PEACE FROM GOD THE FATHER AND FROM OUR LORD JESUS CHRIST
2024-04-02 06:31:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0038.json
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([321.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 355, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0038
generate
 56%|█████▌    | 685/1232 [07:47<07:53,  1.15it/s]processing 685th semantic_sys file
685
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE ARIANS TOOK CHRIST FOR A NOBLE AND PERFECT CREATURE SUPERIOR EVEN TO THE ANGELS BECAUSE BY HIM GOD CREATED HEAVEN AND EARTH
2024-04-02 06:31:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0057.json
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([271.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([311.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([353.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([396.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 438, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0057
generate
 56%|█████▌    | 686/1232 [07:48<08:14,  1.10it/s]processing 686th semantic_sys file
686
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NOT GOLD OR SILVER OR PASCHAL LAMBS OR AN ANGEL BUT HIMSELF WHAT FOR
2024-04-02 06:31:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0061.json
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([343.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 380, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0061
generate
 56%|█████▌    | 687/1232 [07:48<08:05,  1.12it/s]processing 687th semantic_sys file
687
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: EITHER HE CALLS MINISTERS THROUGH THE AGENCY OF MEN OR HE CALLS THEM DIRECTLY AS HE CALLED THE PROPHETS AND APOSTLES
2024-04-02 06:31:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0010.json
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([328.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:407
T - mask_len:tensor([368.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 407, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0010
generate
 56%|█████▌    | 688/1232 [07:49<08:17,  1.09it/s]processing 688th semantic_sys file
688
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE LOOK FOR THAT REWARD WHICH EYE HATH NOT SEEN NOR EAR HEARD NEITHER HATH ENTERED INTO THE HEART OF MAN
2024-04-02 06:31:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0032.json
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 295, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0032
generate
 56%|█████▌    | 689/1232 [07:50<07:52,  1.15it/s]processing 689th semantic_sys file
689
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NOT FOR A CROWN OR A KINGDOM OR OUR GOODNESS BUT FOR OUR SINS
2024-04-02 06:31:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0062.json
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 243, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0062
generate
 56%|█████▌    | 690/1232 [07:51<07:30,  1.20it/s]processing 690th semantic_sys file
690
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS PASSAGE THEN BEARS OUT THE FACT THAT ALL MEN ARE SOLD UNDER SIN
2024-04-02 06:31:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3980-0072.json
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 243, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3980-0072
generate
 56%|█████▌    | 691/1232 [07:52<07:02,  1.28it/s]processing 691th semantic_sys file
691
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT PRESENTS LIKE NO OTHER OF LUTHER'S WRITINGS THE CENTRAL THOUGHT OF CHRISTIANITY THE JUSTIFICATION OF THE SINNER FOR THE SAKE OF CHRIST'S MERITS ALONE
2024-04-02 06:31:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3979-0009.json
top_k_know_token:70
known_token_update:False
T:662
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:662
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:662
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:662
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:662
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:662
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:662
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:662
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:662
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:662
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:662
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:662
T - mask_len:tensor([409.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:662
T - mask_len:tensor([470.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:662
T - mask_len:tensor([533.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:662
T - mask_len:tensor([598.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 662, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3979-0009
generate
 56%|█████▌    | 692/1232 [07:53<08:12,  1.10it/s]processing 692th semantic_sys file
692
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE UNDERTAKING WHICH SEEMED SO ATTRACTIVE WHEN VIEWED AS A LITERARY TASK PROVED A MOST DIFFICULT ONE AND AT TIMES BECAME OPPRESSIVE
2024-04-02 06:31:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([56], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3979-0003.json
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([342.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 379, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3979-0003
generate
 56%|█████▋    | 693/1232 [07:55<11:28,  1.28s/it]processing 693th semantic_sys file
693
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE LORD WHO HAS GIVEN US POWER TO TEACH AND TO HEAR LET HIM ALSO GIVE US THE POWER TO SERVE AND TO DO LUKE TWO
2024-04-02 06:31:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3979-0011.json
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([300.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([351.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([403.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([457.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([512.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 567, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3979-0011
generate
 56%|█████▋    | 694/1232 [07:56<11:02,  1.23s/it]processing 694th semantic_sys file
694
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN OTHER WORDS THESE THREE MEN TOOK DOWN THE LECTURES WHICH LUTHER ADDRESSED TO HIS STUDENTS IN THE COURSE OF GALATIANS AND ROERER PREPARED THE MANUSCRIPT FOR THE PRINTER
2024-04-02 06:31:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([58], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3979-0008.json
top_k_know_token:70
known_token_update:False
T:614
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:614
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:614
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:614
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:614
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:614
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:614
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:614
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:614
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:614
T - mask_len:tensor([273.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:614
T - mask_len:tensor([325.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:614
T - mask_len:tensor([380.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:614
T - mask_len:tensor([436.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:614
T - mask_len:tensor([495.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:614
T - mask_len:tensor([554.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 614, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3979-0008
generate
 56%|█████▋    | 695/1232 [07:57<10:55,  1.22s/it]processing 695th semantic_sys file
695
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE WANT YOU TO HELP US PUBLISH SOME LEADING WORK OF LUTHER'S FOR THE GENERAL AMERICAN MARKET WILL YOU DO IT
2024-04-02 06:31:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3979-0000.json
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([268.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([304.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:377
T - mask_len:tensor([341.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 377, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3979-0000
generate
 56%|█████▋    | 696/1232 [07:58<10:15,  1.15s/it]processing 696th semantic_sys file
696
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A WORD SHOULD NOW BE SAID ABOUT THE ORIGIN OF LUTHER'S COMMENTARY ON GALATIANS
2024-04-02 06:31:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([52], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3979-0006.json
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 283, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3979-0006
generate
 57%|█████▋    | 697/1232 [07:59<09:12,  1.03s/it]processing 697th semantic_sys file
697
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: LET US BEGIN WITH THAT HIS COMMENTARY ON GALATIANS
2024-04-02 06:31:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2830-3979-0002.json
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 178, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2830-3979-0002
generate
 57%|█████▋    | 698/1232 [08:00<08:21,  1.06it/s]processing 698th semantic_sys file
698
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT IS SUCH A NOBLE AMBITION THAT IT IS A PITY IT HAS USUALLY SUCH A SHALLOW FOUNDATION
2024-04-02 06:31:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29093-0007.json
top_k_know_token:70
known_token_update:False
T:700
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:700
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:700
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:700
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:700
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:700
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:700
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:700
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:700
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:700
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:700
T - mask_len:tensor([371.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:700
T - mask_len:tensor([433.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:700
T - mask_len:tensor([497.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:700
T - mask_len:tensor([564.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:700
T - mask_len:tensor([632.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 700, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29093-0007
generate
 57%|█████▋    | 699/1232 [08:01<09:02,  1.02s/it]processing 699th semantic_sys file
699
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND HE WENT BACK TO HIS BOOKS AND TO HIS WAITING FOR AN OPENING LARGE ENOUGH FOR HIS DIGNIFIED ENTRANCE INTO THE LITERARY WORLD
2024-04-02 06:31:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29093-0013.json
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([324.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([363.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 402, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29093-0013
generate
 57%|█████▋    | 700/1232 [08:02<08:33,  1.04it/s]processing 700th semantic_sys file
700
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE WELL KNEW THE PERILS OF THE FRONTIER THE SAVAGE STATE OF SOCIETY THE LURKING INDIANS AND THE DANGERS OF FEVER
2024-04-02 06:31:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29093-0023.json
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([222.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([324.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 359, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29093-0023
generate
 57%|█████▋    | 701/1232 [08:03<08:22,  1.06it/s]processing 701th semantic_sys file
701
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHY IT'S IN MISSOURI SOMEWHERE ON THE FRONTIER I THINK WE'LL GET A MAP
2024-04-02 06:31:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29093-0020.json
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 227, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29093-0020
generate
 57%|█████▋    | 702/1232 [08:03<07:39,  1.15it/s]processing 702th semantic_sys file
702
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE KNEW HIS UNCLE WOULD BE GLAD TO HEAR THAT HE HAD AT LAST TURNED HIS THOUGHTS TO A PRACTICAL MATTER
2024-04-02 06:31:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29093-0022.json
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([303.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 335, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29093-0022
generate
 57%|█████▋    | 703/1232 [08:04<07:29,  1.18it/s]processing 703th semantic_sys file
703
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: PHILIP THEREFORE READ DILIGENTLY IN THE ASTOR LIBRARY PLANNED LITERARY WORKS THAT SHOULD COMPEL ATTENTION AND NURSED HIS GENIUS
2024-04-02 06:31:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29093-0009.json
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([254.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([288.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([323.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 357, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29093-0009
generate
 57%|█████▋    | 704/1232 [08:05<07:35,  1.16it/s]processing 704th semantic_sys file
704
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT PHILIP DID AFFORD IT AND HE WROTE THANKING HIS FRIENDS AND DECLINING BECAUSE HE SAID THE POLITICAL SCHEME WOULD FAIL AND OUGHT TO FAIL
2024-04-02 06:31:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([52], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29093-0012.json
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([354.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([396.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 439, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29093-0012
generate
 57%|█████▋    | 705/1232 [08:06<07:39,  1.15it/s]processing 705th semantic_sys file
705
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE TWO YOUNG MEN WHO WERE BY THIS TIME FULL OF THE ADVENTURE WENT DOWN TO THE WALL STREET OFFICE OF HENRY'S UNCLE AND HAD A TALK WITH THAT WILY OPERATOR
2024-04-02 06:31:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29093-0018.json
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([333.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([377.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([423.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 468, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29093-0018
generate
 57%|█████▋    | 706/1232 [08:07<08:12,  1.07it/s]processing 706th semantic_sys file
706
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE NIGHT WAS SPENT IN PACKING UP AND WRITING LETTERS FOR PHILIP WOULD NOT TAKE SUCH AN IMPORTANT STEP WITHOUT INFORMING HIS FRIENDS
2024-04-02 06:31:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29093-0019.json
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:387
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 387, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29093-0019
generate
 57%|█████▋    | 707/1232 [08:08<07:48,  1.12it/s]processing 707th semantic_sys file
707
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WELL I'M GOING AS AN ENGINEER YOU CAN GO AS ONE
2024-04-02 06:31:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29093-0014.json
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 147, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29093-0014
generate
 57%|█████▋    | 708/1232 [08:08<06:52,  1.27it/s]processing 708th semantic_sys file
708
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT HAS OCCUPIED MOTHER A LONG TIME TO FIND AT THE SHOPS THE EXACT SHADE FOR HER NEW BONNET
2024-04-02 06:31:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29095-0024.json
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([287.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([325.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:403
T - mask_len:tensor([364.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 403, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29095-0024
generate
 58%|█████▊    | 709/1232 [08:09<07:20,  1.19it/s]processing 709th semantic_sys file
709
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND IF I HAD A FORTUNE WOULD THEE WANT ME TO LEAD A USELESS LIFE
2024-04-02 06:31:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29095-0035.json
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 215, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29095-0035
generate
 58%|█████▊    | 710/1232 [08:10<06:37,  1.31it/s]processing 710th semantic_sys file
710
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FATHER THEE'S UNJUST TO PHILIP HE'S GOING INTO BUSINESS
2024-04-02 06:31:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29095-0030.json
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 143, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29095-0030
generate
 58%|█████▊    | 711/1232 [08:10<06:04,  1.43it/s]processing 711th semantic_sys file
711
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: RUTH WAS GLAD TO HEAR THAT PHILIP HAD MADE A PUSH INTO THE WORLD AND SHE WAS SURE THAT HIS TALENT AND COURAGE WOULD MAKE A WAY FOR HIM
2024-04-02 06:31:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29095-0038.json
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([334.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([374.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 414, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29095-0038
generate
 58%|█████▊    | 712/1232 [08:11<06:23,  1.36it/s]processing 712th semantic_sys file
712
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: RUTH SAT QUITE STILL FOR A TIME WITH FACE INTENT AND FLUSHED IT WAS OUT NOW
2024-04-02 06:31:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29095-0016.json
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([288.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 319, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29095-0016
generate
 58%|█████▊    | 713/1232 [08:12<06:49,  1.27it/s]processing 713th semantic_sys file
713
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHY SHOULD I RUST AND BE STUPID AND SIT IN INACTION BECAUSE I AM A GIRL
2024-04-02 06:31:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29095-0034.json
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([302.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([343.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([384.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 425, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29095-0034
generate
 58%|█████▊    | 714/1232 [08:13<06:51,  1.26it/s]processing 714th semantic_sys file
714
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT'S SUCH A CRUSH AT THE YEARLY MEETING AT ARCH STREET AND THEN THERE'S THE ROW OF SLEEK LOOKING YOUNG MEN WHO LINE THE CURBSTONE AND STARE AT US AS WE COME OUT
2024-04-02 06:31:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29095-0027.json
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([261.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([305.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([397.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:493
T - mask_len:tensor([445.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 493, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29095-0027
generate
 58%|█████▊    | 715/1232 [08:14<07:16,  1.18it/s]processing 715th semantic_sys file
715
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IS THEE GOING TO THE YEARLY MEETING RUTH ASKED ONE OF THE GIRLS
2024-04-02 06:31:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29095-0022.json
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 185, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29095-0022
generate
 58%|█████▊    | 716/1232 [08:14<06:32,  1.32it/s]processing 716th semantic_sys file
716
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IS THY FATHER WILLING THEE SHOULD GO AWAY TO A SCHOOL OF THE WORLD'S PEOPLE
2024-04-02 06:31:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29095-0006.json
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 147, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29095-0006
generate
 58%|█████▊    | 717/1232 [08:15<05:55,  1.45it/s]processing 717th semantic_sys file
717
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WELL MOTHER SAID THE YOUNG STUDENT LOOKING UP WITH A SHADE OF IMPATIENCE
2024-04-02 06:31:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29095-0002.json
top_k_know_token:70
known_token_update:False
T:160
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:160
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:160
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:160
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:160
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:160
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:160
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:160
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:160
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:160
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:160
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:160
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:160
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:160
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:160
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 160, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29095-0002
generate
 58%|█████▊    | 718/1232 [08:16<05:52,  1.46it/s]processing 718th semantic_sys file
718
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND BESIDES SUPPOSE THEE DOES LEARN MEDICINE
2024-04-02 06:31:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29095-0012.json
top_k_know_token:70
known_token_update:False
T:116
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:116
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:116
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:116
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:116
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:116
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:116
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:116
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:116
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:116
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:116
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:116
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:116
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:116
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:116
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 116, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29095-0012
generate
 58%|█████▊    | 719/1232 [08:16<06:02,  1.42it/s]processing 719th semantic_sys file
719
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THY WAYS GREATLY TRY ME RUTH AND ALL THY RELATIONS
2024-04-02 06:31:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29095-0005.json
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 223, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29095-0005
generate
 58%|█████▊    | 720/1232 [08:17<05:56,  1.44it/s]processing 720th semantic_sys file
720
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT PHILIP IS HONEST AND HE HAS TALENT ENOUGH IF HE WILL STOP SCRIBBLING TO MAKE HIS WAY
2024-04-02 06:31:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29095-0032.json
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([253.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 280, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29095-0032
generate
 59%|█████▊    | 721/1232 [08:18<05:52,  1.45it/s]processing 721th semantic_sys file
721
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT THAT WISE AND PLACID WOMAN UNDERSTOOD THE SWEET REBEL A GREAT DEAL BETTER THAN RUTH UNDERSTOOD HERSELF
2024-04-02 06:31:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29095-0037.json
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([313.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([355.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:440
T - mask_len:tensor([397.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 440, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29095-0037
generate
 59%|█████▊    | 722/1232 [08:19<06:38,  1.28it/s]processing 722th semantic_sys file
722
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MARGARET BOLTON ALMOST LOST FOR A MOMENT HER HABITUAL PLACIDITY
2024-04-02 06:31:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29095-0009.json
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 225, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29095-0009
generate
 59%|█████▊    | 723/1232 [08:19<06:23,  1.33it/s]processing 723th semantic_sys file
723
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HAS THEE CONSULTED THY MOTHER ABOUT A CAREER I SUPPOSE IT IS A CAREER THEE WANTS
2024-04-02 06:31:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29095-0036.json
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:237
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 237, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29095-0036
generate
 59%|█████▉    | 724/1232 [08:20<06:35,  1.29it/s]processing 724th semantic_sys file
724
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I HEARD FATHER TELL COUSIN ABNER THAT HE WAS WHIPPED SO OFTEN FOR WHISTLING WHEN HE WAS A BOY THAT HE WAS DETERMINED TO HAVE WHAT COMPENSATION HE COULD GET NOW
2024-04-02 06:31:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4970-29095-0004.json
top_k_know_token:70
known_token_update:False
T:674
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:674
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:674
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:674
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:674
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:674
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:674
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:674
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:674
T - mask_len:tensor([247.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:674
T - mask_len:tensor([300.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:674
T - mask_len:tensor([357.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:674
T - mask_len:tensor([417.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:674
T - mask_len:tensor([479.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:674
T - mask_len:tensor([543.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:674
T - mask_len:tensor([608.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 674, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4970-29095-0004
generate
 59%|█████▉    | 725/1232 [08:21<07:40,  1.10it/s]processing 725th semantic_sys file
725
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FOR SOME YEARS IT WAS NOT FOUND FEASIBLE TO OPERATE MOTORS ON ALTERNATING CURRENT CIRCUITS AND THAT REASON WAS OFTEN URGED AGAINST IT SERIOUSLY
2024-04-02 06:31:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2300-131720-0009.json
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([325.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([374.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([424.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([475.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 526, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2300-131720-0009
generate
 59%|█████▉    | 726/1232 [08:23<08:13,  1.03it/s]processing 726th semantic_sys file
726
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE WEIGHED AND REWEIGHED THE METER PLATES AND PURSUED EVERY LINE OF INVESTIGATION IMAGINABLE BUT ALL IN VAIN
2024-04-02 06:31:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2300-131720-0037.json
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([304.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([349.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([396.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:491
T - mask_len:tensor([443.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 491, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2300-131720-0037
generate
 59%|█████▉    | 727/1232 [08:24<08:19,  1.01it/s]processing 727th semantic_sys file
727
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE SEEMS NO GOOD REASON FOR BELIEVING THAT IT WILL CHANGE
2024-04-02 06:31:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2300-131720-0006.json
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 199, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2300-131720-0006
generate
 59%|█████▉    | 728/1232 [08:24<07:23,  1.14it/s]processing 728th semantic_sys file
728
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE PARIS PLANT LIKE THAT AT THE CRYSTAL PALACE WAS A TEMPORARY EXHIBIT
2024-04-02 06:31:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2300-131720-0000.json
top_k_know_token:70
known_token_update:False
T:228
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:228
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:228
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:228
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:228
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:228
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:228
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:228
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:228
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:228
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:228
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:228
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:228
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:228
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:228
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 228, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2300-131720-0000
generate
 59%|█████▉    | 729/1232 [08:25<07:11,  1.17it/s]processing 729th semantic_sys file
729
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE OBTAINED THE DESIRED SPEED AND LOAD WITH A FRICTION BRAKE ALSO REGULATOR OF SPEED BUT WAITED FOR AN INDICATOR TO VERIFY IT
2024-04-02 06:31:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2300-131720-0015.json
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([299.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([380.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 421, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2300-131720-0015
generate
 59%|█████▉    | 730/1232 [08:26<07:39,  1.09it/s]processing 730th semantic_sys file
730
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE WERE MORE INTERESTED IN THE TECHNICAL CONDITION OF THE STATION THAN IN THE COMMERCIAL PART
2024-04-02 06:31:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2300-131720-0040.json
top_k_know_token:70
known_token_update:False
T:279
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:279
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:279
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:279
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:279
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:279
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:279
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:279
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:279
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:279
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:279
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:279
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:279
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:279
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:279
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 279, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2300-131720-0040
generate
 59%|█████▉    | 731/1232 [08:27<07:45,  1.08it/s]processing 731th semantic_sys file
731
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: EVERYTHING HE HAS DONE HAS BEEN AIMED AT THE CONSERVATION OF ENERGY THE CONTRACTION OF SPACE THE INTENSIFICATION OF CULTURE
2024-04-02 06:31:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2300-131720-0008.json
top_k_know_token:70
known_token_update:False
T:645
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:645
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:645
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:645
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:645
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:645
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:645
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:645
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:645
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:645
T - mask_len:tensor([287.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:645
T - mask_len:tensor([341.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:645
T - mask_len:tensor([399.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:645
T - mask_len:tensor([458.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:645
T - mask_len:tensor([520.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:645
T - mask_len:tensor([582.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 645, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2300-131720-0008
generate
 59%|█████▉    | 732/1232 [08:28<08:27,  1.02s/it]processing 732th semantic_sys file
732
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE PRINCIPLE EMPLOYED IN THE EDISON ELECTROLYTIC METER IS THAT WHICH EXEMPLIFIES THE POWER OF ELECTRICITY TO DECOMPOSE A CHEMICAL SUBSTANCE
2024-04-02 06:31:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2300-131720-0030.json
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([271.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([316.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([363.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([412.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:511
T - mask_len:tensor([461.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 511, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2300-131720-0030
generate
 59%|█████▉    | 733/1232 [08:29<08:26,  1.02s/it]processing 733th semantic_sys file
733
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE FELT HE WAS UP AGAINST IT AND THAT PERHAPS ANOTHER KIND OF A JOB WOULD SUIT HIM BETTER
2024-04-02 06:31:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2300-131720-0038.json
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([331.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 366, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2300-131720-0038
generate
 60%|█████▉    | 734/1232 [08:30<08:00,  1.04it/s]processing 734th semantic_sys file
734
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHY IF WE ERECT A STATION AT THE FALLS IT IS A GREAT ECONOMY TO GET IT UP TO THE CITY
2024-04-02 06:31:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2300-131720-0005.json
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([297.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 329, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2300-131720-0005
generate
 60%|█████▉    | 735/1232 [08:31<07:29,  1.11it/s]processing 735th semantic_sys file
735
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: EDISON HELD THAT THE ELECTRICITY SOLD MUST BE MEASURED JUST LIKE GAS OR WATER AND HE PROCEEDED TO DEVELOP A METER
2024-04-02 06:31:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2300-131720-0027.json
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([299.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([379.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 420, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2300-131720-0027
generate
 60%|█████▉    | 736/1232 [08:32<07:22,  1.12it/s]processing 736th semantic_sys file
736
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT THE PLANT RAN AND IT WAS THE FIRST THREE WIRE STATION IN THIS COUNTRY
2024-04-02 06:31:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2300-131720-0024.json
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 199, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2300-131720-0024
generate
 60%|█████▉    | 737/1232 [08:33<06:58,  1.18it/s]processing 737th semantic_sys file
737
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE OTHERS HAVING BEEN IN OPERATION TOO SHORT A TIME TO SHOW DEFINITE RESULTS ALTHOUGH THEY ALSO WENT QUICKLY TO A DIVIDEND BASIS
2024-04-02 06:31:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2300-131720-0034.json
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([330.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([379.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([430.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([481.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 533, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2300-131720-0034
generate
 60%|█████▉    | 738/1232 [08:34<07:39,  1.07it/s]processing 738th semantic_sys file
738
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE METER CONTINUED IN GENERAL SERVICE DURING EIGHTEEN NINETY NINE AND PROBABLY UP TO THE CLOSE OF THE CENTURY
2024-04-02 06:31:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2300-131720-0036.json
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([224.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([254.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 315, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2300-131720-0036
generate
 60%|█████▉    | 739/1232 [08:34<07:22,  1.11it/s]processing 739th semantic_sys file
739
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HENCE THE EDISON ELECTROLYTIC METER IS NO LONGER USED DESPITE ITS EXCELLENT QUALITIES
2024-04-02 06:31:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2300-131720-0029.json
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([264.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 327, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2300-131720-0029
generate
 60%|██████    | 740/1232 [08:35<07:18,  1.12it/s]processing 740th semantic_sys file
740
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE HAWK SAT UPON THE BRANCH AND WATCHED HIS QUARRY SWIMMING BENEATH THE SURFACE
2024-04-02 06:31:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-88083-0014.json
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 260, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-88083-0014
generate
 60%|██████    | 741/1232 [08:36<06:54,  1.18it/s]processing 741th semantic_sys file
741
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ONCE FAIRLY A WING HOWEVER HE WHEELED AND MADE BACK HURRIEDLY FOR HIS PERCH
2024-04-02 06:31:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-88083-0005.json
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:255
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 255, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-88083-0005
generate
 60%|██████    | 742/1232 [08:37<06:40,  1.22it/s]processing 742th semantic_sys file
742
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AS HE FLEW HIS DOWN REACHING CLUTCHING TALONS WERE NOT HALF A YARD ABOVE THE FUGITIVE'S HEAD
2024-04-02 06:31:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-88083-0019.json
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 250, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-88083-0019
generate
 60%|██████    | 743/1232 [08:38<06:27,  1.26it/s]processing 743th semantic_sys file
743
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE DRAG UPON HIS BEAK AND THE LIGHT CHECK UPON HIS WINGS WERE INEXPLICABLE TO HIM AND APPALLING
2024-04-02 06:31:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-88083-0026.json
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 251, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-88083-0026
generate
 60%|██████    | 744/1232 [08:38<06:18,  1.29it/s]processing 744th semantic_sys file
744
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE HAWK ALIGHTED ON THE DEAD BRANCH AND SAT UPRIGHT MOTIONLESS AS IF SURPRISED
2024-04-02 06:31:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-88083-0012.json
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 236, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-88083-0012
generate
 60%|██████    | 745/1232 [08:39<06:14,  1.30it/s]processing 745th semantic_sys file
745
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT MIGHT HAVE SEEMED THAT A TROUT OF THIS SIZE WAS A FAIRLY SUBSTANTIAL MEAL
2024-04-02 06:31:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-88083-0006.json
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 190, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-88083-0006
generate
 61%|██████    | 746/1232 [08:40<05:58,  1.36it/s]processing 746th semantic_sys file
746
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE LAST DROP FLY AS LUCK WOULD HAVE IT CAUGHT JUST IN THE CORNER OF THE HAWK'S ANGRILY OPEN BEAK HOOKING ITSELF FIRMLY
2024-04-02 06:31:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-88083-0024.json
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([343.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 380, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-88083-0024
generate
 61%|██████    | 747/1232 [08:41<06:17,  1.28it/s]processing 747th semantic_sys file
747
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE HAD A LOT OF LINE OUT AND THE PLACE WAS NONE TOO FREE FOR A LONG CAST BUT HE WAS IMPATIENT TO DROP HIS FLIES AGAIN ON THE SPOT WHERE THE BIG FISH WAS FEEDING
2024-04-02 06:31:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-88083-0023.json
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([300.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([345.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([391.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:485
T - mask_len:tensor([438.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 485, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-88083-0023
generate
 61%|██████    | 748/1232 [08:42<06:36,  1.22it/s]processing 748th semantic_sys file
748
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE CAT GROWLED SOFTLY PICKED UP THE PRIZE IN HER JAWS AND TROTTED INTO THE BUSHES TO DEVOUR IT
2024-04-02 06:31:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊ'
processing 749th semantic_sys file
749
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HIS FEET WERE RED HIS LONG NARROW BEAK WITH ITS SAW TOOTHED EDGES AND SHARP HOOKED TIP WAS BRIGHT RED
2024-04-02 06:31:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-88083-0002.json
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([308.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 341, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-88083-0002
generate
 61%|██████    | 750/1232 [08:43<05:27,  1.47it/s]processing 750th semantic_sys file
750
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE HAWK EMBITTERED BY THE LOSS OF HIS FIRST QUARRY HAD BECOME AS DOGGED IN PURSUIT AS A WEASEL NOT TO BE SHAKEN OFF OR EVADED OR DECEIVED
2024-04-02 06:31:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-88083-0022.json
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([335.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:416
T - mask_len:tensor([376.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 416, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-88083-0022
generate
 61%|██████    | 751/1232 [08:44<06:05,  1.32it/s]processing 751th semantic_sys file
751
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT HERE HE WAS AT A TERRIBLE DISADVANTAGE AS COMPARED WITH THE OWLS HAWKS AND EAGLES HE HAD NO RENDING CLAWS
2024-04-02 06:31:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:31:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-88083-0003.json
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([319.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:396
T - mask_len:tensor([358.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 396, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-88083-0003
generate
 61%|██████    | 752/1232 [08:44<06:20,  1.26it/s]processing 752th semantic_sys file
752
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE GREAT HAWK FOLLOWED HURRIEDLY TO RETRIEVE HIS PREY FROM THE GROUND
2024-04-02 06:32:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-88083-0009.json
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:175
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 175, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-88083-0009
generate
 61%|██████    | 753/1232 [08:45<06:07,  1.30it/s]processing 753th semantic_sys file
753
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHERE THE WAVES FOR AN INSTANT SANK THEY CAME CLOSER BUT NOT QUITE WITHIN GRASPING REACH
2024-04-02 06:32:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-88083-0020.json
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 328, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-88083-0020
generate
 61%|██████    | 754/1232 [08:46<06:17,  1.27it/s]processing 754th semantic_sys file
754
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AT THE SUDDEN SHARP STING OF IT THE GREAT BIRD TURNED HIS HEAD AND NOTICED FOR THE FIRST TIME THE FISHERMAN STANDING ON THE BANK
2024-04-02 06:32:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-88083-0025.json
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([274.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([307.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 340, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-88083-0025
generate
 61%|██████▏   | 755/1232 [08:47<06:51,  1.16it/s]processing 755th semantic_sys file
755
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ALL ABOUT HIM WAS A TUMULT OF BRIGHT AND BROKEN COLOR SCATTERED IN BROAD SPLASHES
2024-04-02 06:32:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-88083-0000.json
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([258.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 320, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-88083-0000
generate
 61%|██████▏   | 756/1232 [08:48<06:51,  1.16it/s]processing 756th semantic_sys file
756
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT SUDDENLY STRAIGHT AND SWIFT AS A DIVING CORMORANT HE SHOT DOWN INTO THE TORRENT AND DISAPPEARED BENEATH THE SURFACE
2024-04-02 06:32:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-88083-0004.json
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([268.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([309.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:434
T - mask_len:tensor([392.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 434, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-88083-0004
generate
 61%|██████▏   | 757/1232 [08:49<06:56,  1.14it/s]processing 757th semantic_sys file
757
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TO BE OR NOT TO BE THAT IS THE QUESTION WHETHER TIS NOBLER
2024-04-02 06:32:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([22], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0024.json
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:162
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 162, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0024
generate
 62%|██████▏   | 758/1232 [08:49<06:28,  1.22it/s]processing 758th semantic_sys file
758
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A STAGE MEAL IS POPULAR BECAUSE IT PROVES TO THE AUDIENCE THAT THE ACTORS EVEN WHEN CALLED CHARLES HAWTREY OR OWEN NARES ARE REAL PEOPLE JUST LIKE YOU AND ME
2024-04-02 06:32:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([22], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0038.json
top_k_know_token:70
known_token_update:False
T:514
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:514
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:514
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:514
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:514
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:514
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:514
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:514
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:514
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:514
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:514
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:514
T - mask_len:tensor([318.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:514
T - mask_len:tensor([365.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:514
T - mask_len:tensor([414.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:514
T - mask_len:tensor([464.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 514, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0038
generate
 62%|██████▏   | 759/1232 [08:51<07:04,  1.11it/s]processing 759th semantic_sys file
759
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND I SHOULD BEGIN WITH A SHORT HOMILY ON SOLILOQUY
2024-04-02 06:32:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0009.json
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:208
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 208, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0009
generate
 62%|██████▏   | 760/1232 [08:51<07:02,  1.12it/s]processing 760th semantic_sys file
760
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE CROWD DRIFTS OFF LEAVING THE HERO AND HEROINE ALONE IN THE MIDDLE OF THE STAGE AND THEN YOU CAN BEGIN
2024-04-02 06:32:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0036.json
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:341
T - mask_len:tensor([308.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 341, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0036
generate
 62%|██████▏   | 761/1232 [08:52<06:55,  1.13it/s]processing 761th semantic_sys file
761
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: LEND ME YOUR EAR FOR TEN MINUTES AND YOU SHALL LEARN JUST WHAT STAGECRAFT IS
2024-04-02 06:32:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0008.json
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 274, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0008
generate
 62%|██████▏   | 762/1232 [08:53<06:40,  1.17it/s]processing 762th semantic_sys file
762
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU GAVE ME DOUBLE FIVE I WANT DOUBLE NINE HALLO IS THAT YOU HORATIO HAMLET SPEAKING
2024-04-02 06:32:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0023.json
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 274, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0023
generate
 62%|██████▏   | 763/1232 [08:54<06:27,  1.21it/s]processing 763th semantic_sys file
763
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TO BE OR NOT TO BE THAT IS THE QUESTION WHETHER TIS NOBLER IN THE MIND TO SUFFER THE SLINGS AND ARROWS WHAT NO HAMLET SPEAKING
2024-04-02 06:32:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0022.json
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([330.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([379.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([430.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:533
T - mask_len:tensor([481.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 533, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0022
generate
 62%|██████▏   | 764/1232 [08:55<07:14,  1.08it/s]processing 764th semantic_sys file
764
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT IT IS THE CIGARETTE WHICH CHIEFLY HAS BROUGHT THE MODERN DRAMA TO ITS PRESENT STATE OF PERFECTION
2024-04-02 06:32:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0044.json
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 264, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0044
generate
 62%|██████▏   | 765/1232 [08:56<07:05,  1.10it/s]processing 765th semantic_sys file
765
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT SUPPOSE YOU SAID I'M FOND OF WRITING MY PEOPLE ALWAYS SAY MY LETTERS HOME ARE GOOD ENOUGH FOR PUNCH
2024-04-02 06:32:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0005.json
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([247.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:306
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 306, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0005
generate
 62%|██████▏   | 766/1232 [08:57<07:03,  1.10it/s]processing 766th semantic_sys file
766
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND THERE YOU ARE YOU WILL OF COURSE APPRECIATE THAT THE UNFINISHED SENTENCES NOT ONLY SAVE TIME BUT ALSO MAKE THE MANOEUVRING VERY MUCH MORE NATURAL
2024-04-02 06:32:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0031.json
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([264.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([313.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([366.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([421.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([477.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:592
T - mask_len:tensor([534.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 592, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0031
generate
 62%|██████▏   | 767/1232 [08:58<07:28,  1.04it/s]processing 767th semantic_sys file
767
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND SO ON TILL YOU GET TO THE END WHEN OPHELIA MIGHT SAY AH YES OR SOMETHING NON COMMITTAL OF THAT SORT
2024-04-02 06:32:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0015.json
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([316.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([359.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([402.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 445, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0015
generate
 62%|██████▏   | 768/1232 [08:59<07:20,  1.05it/s]processing 768th semantic_sys file
768
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN NOVELS THE HERO HAS OFTEN PUSHED HIS MEALS AWAY UNTASTED BUT NO STAGE HERO WOULD DO ANYTHING SO UNNATURAL AS THIS
2024-04-02 06:32:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([52], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0042.json
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([325.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([374.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([424.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([475.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 526, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0042
generate
 62%|██████▏   | 769/1232 [09:00<07:39,  1.01it/s]processing 769th semantic_sys file
769
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS WOULD BE AN EASY WAY OF DOING IT BUT IT WOULD NOT BE THE BEST WAY FOR THE REASON THAT IT IS TOO EASY TO CALL ATTENTION TO ITSELF
2024-04-02 06:32:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0016.json
top_k_know_token:70
known_token_update:False
T:521
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:521
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:521
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:521
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:521
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:521
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:521
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:521
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:521
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:521
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:521
T - mask_len:tensor([276.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:521
T - mask_len:tensor([322.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:521
T - mask_len:tensor([370.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:521
T - mask_len:tensor([420.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:521
T - mask_len:tensor([470.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 521, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0016
generate
 62%|██████▎   | 770/1232 [09:01<07:10,  1.07it/s]processing 770th semantic_sys file
770
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN THE MODERN WELL CONSTRUCTED PLAY HE SIMPLY RINGS UP AN IMAGINARY CONFEDERATE AND TELLS HIM WHAT HE IS GOING TO DO COULD ANYTHING BE MORE NATURAL
2024-04-02 06:32:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0018.json
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([224.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([261.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([300.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([340.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:422
T - mask_len:tensor([381.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 422, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0018
generate
 63%|██████▎   | 771/1232 [09:02<07:00,  1.10it/s]processing 771th semantic_sys file
771
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN THE OLD BADLY MADE PLAY IT WAS FREQUENTLY NECESSARY FOR ONE OF THE CHARACTERS TO TAKE THE AUDIENCE INTO HIS CONFIDENCE
2024-04-02 06:32:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0017.json
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([276.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:342
T - mask_len:tensor([309.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 342, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0017
generate
 63%|██████▎   | 772/1232 [09:02<06:38,  1.16it/s]processing 772th semantic_sys file
772
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: RE ENTER BUTLER AND THREE FOOTMEN WHO REMOVE THE TEA THINGS HOSTESS TO GUEST
2024-04-02 06:32:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0041.json
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([222.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 312, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0041
generate
 63%|██████▎   | 773/1232 [09:03<06:21,  1.20it/s]processing 773th semantic_sys file
773
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN SHORT HE BECOMES A PROMINENT FIGURE IN LONDON SOCIETY AND IF HE IS NOT CAREFUL SOMEBODY WILL SAY SO
2024-04-02 06:32:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0001.json
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 307, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0001
generate
 63%|██████▎   | 774/1232 [09:04<06:29,  1.18it/s]processing 774th semantic_sys file
774
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: LORD JOHN TAKING OUT GOLD CIGARETTE CASE FROM HIS LEFT HAND UPPER WAISTCOAT POCKET
2024-04-02 06:32:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0045.json
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 243, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0045
generate
 63%|██████▎   | 775/1232 [09:05<06:34,  1.16it/s]processing 775th semantic_sys file
775
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE DUCHESS OF SOUTHBRIDGE TO LORD REGGIE OH REGGIE WHAT DID YOU SAY
2024-04-02 06:32:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([53], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0034.json
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 171, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0034
generate
 63%|██████▎   | 776/1232 [09:05<06:01,  1.26it/s]processing 776th semantic_sys file
776
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I'VE GOT A LITTLE IDEA FOR A PLAY ABOUT A MAN AND A WOMAN AND ANOTHER WOMAN AND BUT PERHAPS I'D BETTER KEEP THE PLOT A SECRET FOR THE MOMENT
2024-04-02 06:32:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0006.json
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([311.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([363.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([418.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([474.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:588
T - mask_len:tensor([531.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 588, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0006
generate
 63%|██████▎   | 777/1232 [09:07<06:37,  1.15it/s]processing 777th semantic_sys file
777
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DOUBLE NINE TWO THREE ELSINORE DOUBLE NINE YES HALLO IS THAT YOU HORATIO HAMLET SPEAKING
2024-04-02 06:32:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([25], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7176-92135-0020.json
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([325.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([368.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([413.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 457, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7176-92135-0020
generate
 63%|██████▎   | 778/1232 [09:07<06:43,  1.13it/s]processing 778th semantic_sys file
778
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FOOTNOTE SUMNER TO SHANNON MAY TWELFTH EIGHTEEN FIFTY SIX
2024-04-02 06:32:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0027.json
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 176, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0027
generate
 63%|██████▎   | 779/1232 [09:08<06:06,  1.24it/s]processing 779th semantic_sys file
779
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE SUMMONED HALF A DOZEN CITIZENS TO JOIN HIS POSSE WHO FOLLOWED OBEYED AND ASSISTED HIM
2024-04-02 06:32:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0030.json
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:366
T - mask_len:tensor([331.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 366, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0030
generate
 63%|██████▎   | 780/1232 [09:09<06:07,  1.23it/s]processing 780th semantic_sys file
780
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS WAS A FORMIDABLE ARRAY OF ADVANTAGES SLAVERY WAS PLAYING WITH LOADED DICE
2024-04-02 06:32:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0005.json
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 274, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0005
generate
 63%|██████▎   | 781/1232 [09:10<06:00,  1.25it/s]processing 781th semantic_sys file
781
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE LEADERS OF THE CONSPIRACY BECAME DISTRUSTFUL OF THEIR POWER TO CRUSH THE TOWN
2024-04-02 06:32:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0014.json
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 219, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0014
generate
 63%|██████▎   | 782/1232 [09:10<05:46,  1.30it/s]processing 782th semantic_sys file
782
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEIR DISTINCTIVE CHARACTERS HOWEVER DISPLAY ONE BROAD AND UNFAILING DIFFERENCE
2024-04-02 06:32:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0023.json
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 222, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0023
generate
 64%|██████▎   | 783/1232 [09:11<05:47,  1.29it/s]processing 783th semantic_sys file
783
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE INMATES BEING REMOVED AT THE APPOINTED HOUR A FEW CANNON BALLS WERE FIRED THROUGH THE STONE WALLS
2024-04-02 06:32:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊ'
processing 784th semantic_sys file
784
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT SUMMER'S EMIGRATION HOWEVER BEING MAINLY FROM THE FREE STATES GREATLY CHANGED THE RELATIVE STRENGTH OF THE TWO PARTIES
2024-04-02 06:32:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0002.json
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([278.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 308, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0002
generate
 64%|██████▎   | 785/1232 [09:12<04:43,  1.57it/s]processing 785th semantic_sys file
785
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE CONTINUED HIS PRETENDED SEARCH AND TO GIVE COLOR TO HIS ERRAND MADE TWO ARRESTS
2024-04-02 06:32:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0031.json
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([241.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:299
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 299, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0031
generate
 64%|██████▍   | 786/1232 [09:13<04:59,  1.49it/s]processing 786th semantic_sys file
786
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OF THE LYNCHINGS THE MOBS AND THE MURDERS IT WOULD BE IMPOSSIBLE EXCEPT IN A VERY EXTENDED WORK TO NOTE THE FREQUENT AND ATROCIOUS DETAILS
2024-04-02 06:32:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0010.json
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([273.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([314.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([356.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:442
T - mask_len:tensor([399.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 442, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0010
generate
 64%|██████▍   | 787/1232 [09:14<05:29,  1.35it/s]processing 787th semantic_sys file
787
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE MILITARY FORCE PARTLY RABBLE PARTLY ORGANIZED HAD MEANWHILE MOVED INTO THE TOWN
2024-04-02 06:32:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0035.json
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 272, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0035
generate
 64%|██████▍   | 788/1232 [09:14<05:21,  1.38it/s]processing 788th semantic_sys file
788
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: RELOCATED FOOTNOTE GOVERNOR ROBINSON BEING ON HIS WAY EAST THE STEAMBOAT ON WHICH HE WAS TRAVELING STOPPED AT LEXINGTON MISSOURI
2024-04-02 06:32:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0042.json
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([251.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([293.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([337.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([382.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:474
T - mask_len:tensor([428.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 474, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0042
generate
 64%|██████▍   | 789/1232 [09:15<05:44,  1.29it/s]processing 789th semantic_sys file
789
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: PRIVATE PERSONS WHO HAD LEASED THE FREE STATE HOTEL VAINLY BESOUGHT THE VARIOUS AUTHORITIES TO PREVENT THE DESTRUCTION OF THEIR PROPERTY
2024-04-02 06:32:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0028.json
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([308.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:382
T - mask_len:tensor([345.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 382, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0028
generate
 64%|██████▍   | 790/1232 [09:16<06:10,  1.19it/s]processing 790th semantic_sys file
790
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TEN DAYS WERE CONSUMED IN THESE NEGOTIATIONS BUT THE SPIRIT OF VENGEANCE REFUSED TO YIELD
2024-04-02 06:32:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0029.json
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([297.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 329, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0029
generate
 64%|██████▍   | 791/1232 [09:17<06:17,  1.17it/s]processing 791th semantic_sys file
791
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SEVERAL HUNDRED FREE STATE MEN PROMPTLY RESPONDED TO THE SUMMONS
2024-04-02 06:32:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0012.json
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:233
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 233, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0012
generate
 64%|██████▍   | 792/1232 [09:18<06:21,  1.15it/s]processing 792th semantic_sys file
792
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE PLANTED A COMPANY BEFORE THE HOTEL AND DEMANDED A SURRENDER OF THE ARMS BELONGING TO THE FREE STATE MILITARY COMPANIES
2024-04-02 06:32:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([27], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0036.json
top_k_know_token:70
known_token_update:False
T:497
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:497
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:497
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:497
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:497
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:497
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:497
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:497
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:497
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:497
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:497
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:497
T - mask_len:tensor([307.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:497
T - mask_len:tensor([353.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:497
T - mask_len:tensor([401.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:497
T - mask_len:tensor([449.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 497, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0036
generate
 64%|██████▍   | 793/1232 [09:19<06:44,  1.09it/s]processing 793th semantic_sys file
793
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AS HE HAD PROMISED TO PROTECT THE HOTEL THE REASSURED CITIZENS BEGAN TO LAUGH AT THEIR OWN FEARS
2024-04-02 06:32:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0033.json
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([254.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([292.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([331.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:411
T - mask_len:tensor([371.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 411, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0033
generate
 64%|██████▍   | 794/1232 [09:20<06:36,  1.11it/s]processing 794th semantic_sys file
794
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ATCHISON WHO HAD BEEN HARANGUING THE MOB PLANTED HIS TWO GUNS BEFORE THE BUILDING AND TRAINED THEM UPON IT
2024-04-02 06:32:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0038.json
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([271.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([307.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([344.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 381, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0038
generate
 65%|██████▍   | 795/1232 [09:21<06:03,  1.20it/s]processing 795th semantic_sys file
795
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEIR ASSUMED CHARACTER CHANGED WITH THEIR CHANGING OPPORTUNITIES OR NECESSITIES
2024-04-02 06:32:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0025.json
top_k_know_token:70
known_token_update:False
T:204
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:204
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:204
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:204
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:204
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:204
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:204
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:204
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:204
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:204
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:204
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:204
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:204
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:204
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:204
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 204, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0025
generate
 65%|██████▍   | 796/1232 [09:21<05:38,  1.29it/s]processing 796th semantic_sys file
796
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: CAPTAIN MARTIN SAID I SHALL GIVE YOU A PISTOL TO HELP PROTECT YOURSELF IF WORSE COMES TO WORST
2024-04-02 06:32:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0045.json
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 276, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0045
generate
 65%|██████▍   | 797/1232 [09:22<05:37,  1.29it/s]processing 797th semantic_sys file
797
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT THE AFFAIR WAS MAGNIFIED AS A CROWNING PROOF THAT THE FREE STATE MEN WERE INSURRECTIONISTS AND OUTLAWS
2024-04-02 06:32:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0021.json
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([328.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([372.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:461
T - mask_len:tensor([416.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 461, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0021
generate
 65%|██████▍   | 798/1232 [09:23<06:09,  1.17it/s]processing 798th semantic_sys file
798
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TO EMBARRASS THIS DAMAGING EXPOSURE JUDGE LECOMPTE ISSUED A WRIT AGAINST THE EX GOVERNOR ON A FRIVOLOUS CHARGE OF CONTEMPT
2024-04-02 06:32:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7729-102255-0019.json
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([287.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([326.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([365.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 404, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7729-102255-0019
generate
 65%|██████▍   | 799/1232 [09:24<06:10,  1.17it/s]processing 799th semantic_sys file
799
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE WAS SUCH A BIG BOY THAT HE WORE HIGH BOOTS AND CARRIED A JACK KNIFE
2024-04-02 06:32:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-85628-0002.json
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 256, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-85628-0002
generate
 65%|██████▍   | 800/1232 [09:25<06:19,  1.14it/s]processing 800th semantic_sys file
800
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND IT IS MADE OF MOTHER'S BEST YARN AND SHE KNITTED IT HERSELF AND EVERYBODY WANTS TO GET IT AWAY FROM ME
2024-04-02 06:32:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-85628-0018.json
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([290.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([389.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([442.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:548
T - mask_len:tensor([495.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 548, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-85628-0018
generate
 65%|██████▌   | 801/1232 [09:26<06:30,  1.10it/s]processing 801th semantic_sys file
801
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT YOU MUST NOT EAT WITH YOUR CAP ON YOUR HEAD SHE SAID AND WAS GOING TO TAKE IT OFF
2024-04-02 06:32:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-85628-0012.json
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 234, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-85628-0012
generate
 65%|██████▌   | 802/1232 [09:27<05:59,  1.20it/s]processing 802th semantic_sys file
802
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FOR LIKE AS NOT THEY MUST HAVE THOUGHT HIM A PRINCE WHEN THEY SAW HIS FINE CAP
2024-04-02 06:32:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-85628-0008.json
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 214, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-85628-0008
generate
 65%|██████▌   | 803/1232 [09:27<05:40,  1.26it/s]processing 803th semantic_sys file
803
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SEEING THAT I AM SO FINE I MAY AS WELL GO AND VISIT THE KING
2024-04-02 06:32:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-85628-0005.json
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 182, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-85628-0005
generate
 65%|██████▌   | 804/1232 [09:28<05:18,  1.35it/s]processing 804th semantic_sys file
804
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE DARTED LIKE AN ARROW THROUGH ALL THE HALLS DOWN ALL THE STAIRS AND ACROSS THE YARD
2024-04-02 06:32:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-85628-0020.json
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:350
T - mask_len:tensor([316.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 350, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-85628-0020
generate
 65%|██████▌   | 805/1232 [09:29<05:23,  1.32it/s]processing 805th semantic_sys file
805
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IF YOU DRESSED IN SILK AND GOLD FROM TOP TO TOE YOU COULD NOT LOOK ANY NICER THAN IN YOUR LITTLE RED CAP
2024-04-02 06:32:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-85628-0027.json
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 313, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-85628-0027
generate
 65%|██████▌   | 806/1232 [09:30<05:32,  1.28it/s]processing 806th semantic_sys file
806
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE STILL HELD ON TO IT WITH BOTH HANDS AS HE RUSHED INTO HIS MOTHER'S COTTAGE
2024-04-02 06:32:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-85628-0021.json
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 266, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-85628-0021
generate
 66%|██████▌   | 807/1232 [09:30<05:36,  1.26it/s]processing 807th semantic_sys file
807
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ON HUGE SILVER PLATTERS WERE PYRAMIDS OF TARTS AND CAKES AND RED WINE SPARKLED IN GLITTERING DECANTERS
2024-04-02 06:32:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-85628-0010.json
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([347.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([389.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 431, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-85628-0010
generate
 66%|██████▌   | 808/1232 [09:31<05:45,  1.23it/s]processing 808th semantic_sys file
808
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT WHEN HIS BIG BROTHER HEARD THAT HE HAD REFUSED TO GIVE HIS CAP FOR A KING'S GOLDEN CROWN HE SAID THAT ANDERS WAS A STUPID
2024-04-02 06:32:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-85628-0023.json
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([284.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([327.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([371.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:460
T - mask_len:tensor([415.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 460, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-85628-0023
generate
 66%|██████▌   | 809/1232 [09:32<06:13,  1.13it/s]processing 809th semantic_sys file
809
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT IS A VERY FINE CAP YOU HAVE HE SAID
2024-04-02 06:32:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-85628-0016.json
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:125
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 125, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-85628-0016
generate
 66%|██████▌   | 810/1232 [09:33<05:33,  1.27it/s]processing 810th semantic_sys file
810
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND ALL HIS BROTHERS AND SISTERS STOOD ROUND AND LISTENED WITH THEIR MOUTHS OPEN
2024-04-02 06:32:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([28], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-85628-0022.json
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 201, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-85628-0022
generate
 66%|██████▌   | 811/1232 [09:34<05:36,  1.25it/s]processing 811th semantic_sys file
811
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE PRINCESS SAT DOWN UNDER A BLUE CANOPY WITH BOUQUETS OF ROSES AND SHE LET ANDERS SIT IN A GOLDEN CHAIR BY HER SIDE
2024-04-02 06:32:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-85628-0011.json
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([342.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 379, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-85628-0011
generate
 66%|██████▌   | 812/1232 [09:35<05:45,  1.22it/s]processing 812th semantic_sys file
812
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AT THE FARTHER END OF THE LARGEST HALL A TABLE WAS SET WITH GOLDEN CUPS AND GOLDEN PLATES IN LONG ROWS
2024-04-02 06:32:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-85628-0009.json
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([324.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([363.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 402, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-85628-0009
generate
 66%|██████▌   | 813/1232 [09:36<05:58,  1.17it/s]processing 813th semantic_sys file
813
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: PUT THESE PLAYTHINGS ALL AWAY QUICK AND CAREFULLY AND WE WILL NOT LET THEM KNOW ANY THING ABOUT YOUR LEAVING THEM OUT
2024-04-02 06:32:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-79740-0013.json
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 291, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-79740-0013
generate
 66%|██████▌   | 814/1232 [09:36<05:37,  1.24it/s]processing 814th semantic_sys file
814
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DELLA HAD A YOUNG SISTER NAMED MARIA AND A COUSIN WHOSE NAME WAS JANE
2024-04-02 06:32:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-79740-0001.json
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 291, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-79740-0001
generate
 66%|██████▌   | 815/1232 [09:37<05:22,  1.29it/s]processing 815th semantic_sys file
815
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I EXPECT YOU HAVE BEEN A VERY GOOD GIRL ANDELLA SINCE YOU WERE HERE LAST
2024-04-02 06:32:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-79740-0006.json
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:176
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 176, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-79740-0006
generate
 66%|██████▌   | 816/1232 [09:38<05:07,  1.35it/s]processing 816th semantic_sys file
816
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NOW DELIA CONTRIVED TO OBTAIN A GREAT INFLUENCE AND ASCENDENCY OVER THE MINDS OF THE CHILDREN BY MEANS OF THESE DOLLS
2024-04-02 06:32:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-79740-0002.json
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([298.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([334.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 370, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-79740-0002
generate
 66%|██████▋   | 817/1232 [09:38<05:15,  1.31it/s]processing 817th semantic_sys file
817
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TO GIVE AN IDEA OF THESE CONVERSATIONS I WILL REPORT ONE OF THEM IN FULL
2024-04-02 06:32:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-79740-0003.json
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:335
T - mask_len:tensor([303.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 335, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-79740-0003
generate
 66%|██████▋   | 818/1232 [09:39<05:25,  1.27it/s]processing 818th semantic_sys file
818
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEN TURNING TO JANE SHE ASKED IN A SOMEWHAT ALTERED TONE HAS SHE BEEN A GOOD GIRL JANE
2024-04-02 06:32:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-79740-0007.json
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([281.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([318.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([357.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 395, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-79740-0007
generate
 66%|██████▋   | 819/1232 [09:40<05:27,  1.26it/s]processing 819th semantic_sys file
819
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU HAVE COME ANDELLA ANDELLA WAS THE NAME OF JANE'S DOLL TO MAKE ROSALIE A VISIT
2024-04-02 06:32:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-79740-0004.json
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:240
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 240, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-79740-0004
generate
 67%|██████▋   | 820/1232 [09:41<05:07,  1.34it/s]processing 820th semantic_sys file
820
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NATURE OF THE EFFECT PRODUCED BY EARLY IMPRESSIONS
2024-04-02 06:32:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-79759-0000.json
top_k_know_token:70
known_token_update:False
T:137
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:137
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:137
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:137
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:137
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:137
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:137
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:137
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:137
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:137
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:137
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:137
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:137
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:137
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:137
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 137, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-79759-0000
generate
 67%|██████▋   | 821/1232 [09:41<04:51,  1.41it/s]processing 821th semantic_sys file
821
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY ARE CHIEFLY FORMED FROM COMBINATIONS OF THE IMPRESSIONS MADE IN CHILDHOOD
2024-04-02 06:32:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-79759-0002.json
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:236
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 236, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-79759-0002
generate
 67%|██████▋   | 822/1232 [09:42<04:41,  1.46it/s]processing 822th semantic_sys file
822
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: VAST IMPORTANCE AND INFLUENCE OF THIS MENTAL FURNISHING
2024-04-02 06:32:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7021-79759-0003.json
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 249, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7021-79759-0003
generate
 67%|██████▋   | 823/1232 [09:43<04:51,  1.40it/s]processing 823th semantic_sys file
823
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ALL THE TIME HE WAS TALKING TO ME HIS ANGRY LITTLE EYES WERE FOLLOWING LAKE
2024-04-02 06:32:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([18], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32865-0017.json
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 232, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32865-0017
generate
 67%|██████▋   | 824/1232 [09:43<04:44,  1.44it/s]processing 824th semantic_sys file
824
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I'M GLAD YOU LIKE IT SAYS WYLDER CHUCKLING BENIGNANTLY ON IT OVER HIS SHOULDER
2024-04-02 06:32:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:32:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32865-0007.json
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 261, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32865-0007
generate
 67%|██████▋   | 825/1232 [09:44<04:48,  1.41it/s]processing 825th semantic_sys file
825
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHATEVER LORD CHELFORD SAID MISS BRANDON RECEIVED IT VERY GRACIOUSLY AND EVEN WITH A MOMENTARY SMILE
2024-04-02 06:33:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32865-0004.json
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([347.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([389.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 431, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32865-0004
generate
 67%|██████▋   | 826/1232 [09:45<05:14,  1.29it/s]processing 826th semantic_sys file
826
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I HAD A HORRID DREAM ABOUT HIM LAST NIGHT THAT
2024-04-02 06:33:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32865-0015.json
top_k_know_token:70
known_token_update:False
T:136
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:136
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:136
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:136
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:136
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:136
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:136
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:136
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:136
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:136
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:136
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:136
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:136
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:136
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:136
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 136, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32865-0015
generate
 67%|██████▋   | 827/1232 [09:46<04:58,  1.35it/s]processing 827th semantic_sys file
827
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I BELIEVE I HAVE A LITTLE TASTE THAT WAY THOSE ARE ALL REAL YOU KNOW THOSE JEWELS
2024-04-02 06:33:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32865-0008.json
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 223, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32865-0008
generate
 67%|██████▋   | 828/1232 [09:46<04:49,  1.39it/s]processing 828th semantic_sys file
828
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHEREUPON LAKE LAUGHED QUIETLY STILL LOOKING ON THE ACE OF HEARTS WITH HIS SLY EYES
2024-04-02 06:33:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32865-0011.json
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:304
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 304, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32865-0011
generate
 67%|██████▋   | 829/1232 [09:47<05:03,  1.33it/s]processing 829th semantic_sys file
829
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND HE PLACED IT IN THAT GENTLEMAN'S FINGERS WHO NOW TOOK HIS TURN AT THE LAMP AND CONTEMPLATED THE LITTLE PARALLELOGRAM WITH A GLEAM OF SLY AMUSEMENT
2024-04-02 06:33:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32865-0009.json
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([310.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([356.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([404.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([452.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 501, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32865-0009
generate
 67%|██████▋   | 830/1232 [09:48<05:50,  1.15it/s]processing 830th semantic_sys file
830
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WAS THINKING IT'S VERY LIKE THE ACE OF HEARTS ANSWERED THE CAPTAIN SOFTLY SMILING ON
2024-04-02 06:33:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32865-0010.json
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:295
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 295, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32865-0010
generate
 67%|██████▋   | 831/1232 [09:49<06:02,  1.11it/s]processing 831th semantic_sys file
831
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DO YOU KNOW LAKE OH I REALLY CAN'T TELL BUT HE'LL SOON TIRE OF COUNTRY LIFE
2024-04-02 06:33:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32865-0013.json
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([224.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([254.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 315, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32865-0013
generate
 68%|██████▊   | 832/1232 [09:50<05:45,  1.16it/s]processing 832th semantic_sys file
832
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE WAS A BRIGHT MOONLIGHT BROKEN BY THE SHADOWS OF OVERHANGING BOUGHS AND WITHERED LEAVES AND THE MOTTLED LIGHTS AND SHADOWS GLIDED ODDLY ACROSS HIS PALE FEATURES
2024-04-02 06:33:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32866-0013.json
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([271.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([311.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([353.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:438
T - mask_len:tensor([396.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 438, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32866-0013
generate
 68%|██████▊   | 833/1232 [09:51<05:54,  1.12it/s]processing 833th semantic_sys file
833
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A LITTLE BIT OF PLASTER TUMBLED DOWN THE CHIMNEY AND STARTLED ME CONFOUNDEDLY
2024-04-02 06:33:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32866-0030.json
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:248
T - mask_len:tensor([224.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 248, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32866-0030
generate
 68%|██████▊   | 834/1232 [09:52<05:31,  1.20it/s]processing 834th semantic_sys file
834
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A COLD BRIGHT MOON WAS SHINING WITH CLEAR SHARP LIGHTS AND SHADOWS
2024-04-02 06:33:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32866-0027.json
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 174, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32866-0027
generate
 68%|██████▊   | 835/1232 [09:52<05:05,  1.30it/s]processing 835th semantic_sys file
835
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BY THIS TIME LORD CHELFORD AND WYLDER RETURNED AND DISGUSTED RATHER WITH MYSELF I RUMINATED ON MY WANT OF GENERAL SHIP
2024-04-02 06:33:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32866-0004.json
top_k_know_token:70
known_token_update:False
T:542
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:542
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:542
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:542
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:542
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:542
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:542
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:542
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:542
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:542
T - mask_len:tensor([241.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:542
T - mask_len:tensor([287.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:542
T - mask_len:tensor([335.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:542
T - mask_len:tensor([385.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:542
T - mask_len:tensor([437.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:542
T - mask_len:tensor([489.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 542, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32866-0004
generate
 68%|██████▊   | 836/1232 [09:53<05:33,  1.19it/s]processing 836th semantic_sys file
836
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IF A FELLOW'S BEEN A LITTLE BIT WILD HE'S BEELZEBUB AT ONCE
2024-04-02 06:33:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32866-0007.json
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:256
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 256, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32866-0007
generate
 68%|██████▊   | 837/1232 [09:54<05:18,  1.24it/s]processing 837th semantic_sys file
837
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TO MY MIND THERE HAS ALWAYS BEEN SOMETHING INEXPRESSIBLY AWFUL IN FAMILY FEUDS
2024-04-02 06:33:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32866-0018.json
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:294
T - mask_len:tensor([266.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 294, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32866-0018
generate
 68%|██████▊   | 838/1232 [09:55<05:07,  1.28it/s]processing 838th semantic_sys file
838
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NOW THAT'S IMPOSSIBLE RADIE FOR I REALLY DON'T THINK I ONCE THOUGHT OF HIM ALL THIS EVENING EXCEPT JUST WHILE WE WERE TALKING
2024-04-02 06:33:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32866-0012.json
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([288.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 319, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32866-0012
generate
 68%|██████▊   | 839/1232 [09:56<05:19,  1.23it/s]processing 839th semantic_sys file
839
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE SOMBRE OLD TREES LIKE GIGANTIC HEARSE PLUMES BLACK AND AWFUL
2024-04-02 06:33:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32866-0028.json
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 193, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32866-0028
generate
 68%|██████▊   | 840/1232 [09:57<05:24,  1.21it/s]processing 840th semantic_sys file
840
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MY BED WAS UNEXCEPTIONABLY COMFORTABLE BUT IN MY THEN MOOD I COULD HAVE WISHED IT A GREAT DEAL MORE MODERN
2024-04-02 06:33:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32866-0021.json
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([333.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([377.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:468
T - mask_len:tensor([423.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 468, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32866-0021
generate
 68%|██████▊   | 841/1232 [09:58<05:48,  1.12it/s]processing 841th semantic_sys file
841
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MARK MY WORDS YOU'LL FIND HIM TOO STRONG FOR YOU AYE AND TOO DEEP
2024-04-02 06:33:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32866-0016.json
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 259, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32866-0016
generate
 68%|██████▊   | 842/1232 [09:58<05:20,  1.22it/s]processing 842th semantic_sys file
842
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I SHAN'T TROUBLE YOU ABOUT MY TRAIN OF THOUGHTS OR FANCIES BUT I BEGAN TO FEEL VERY LIKE A GENTLEMAN IN A GHOST STORY WATCHING EXPERIMENTALLY IN A HAUNTED CHAMBER
2024-04-02 06:33:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32866-0024.json
top_k_know_token:70
known_token_update:False
T:620
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:620
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:620
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:620
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:620
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:620
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:620
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:620
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:620
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:620
T - mask_len:tensor([276.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:620
T - mask_len:tensor([328.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:620
T - mask_len:tensor([383.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:620
T - mask_len:tensor([441.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:620
T - mask_len:tensor([500.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:620
T - mask_len:tensor([560.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 620, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32866-0024
generate
 68%|██████▊   | 843/1232 [09:59<05:58,  1.09it/s]processing 843th semantic_sys file
843
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I AM VERY UNEASY ABOUT IT WHATEVER IT IS I CAN'T HELP IT
2024-04-02 06:33:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32866-0017.json
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 251, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32866-0017
generate
 69%|██████▊   | 844/1232 [10:00<05:30,  1.18it/s]processing 844th semantic_sys file
844
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YES SO THEY SAID BUT THAT WOULD I THINK HAVE BEEN WORSE
2024-04-02 06:33:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32866-0006.json
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 192, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32866-0006
generate
 69%|██████▊   | 845/1232 [10:01<05:13,  1.24it/s]processing 845th semantic_sys file
845
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEIR WALK CONTINUED SILENT FOR THE GREATER PART NEITHER WAS QUITE SATISFIED WITH THE OTHER BUT RACHEL AT LAST SAID
2024-04-02 06:33:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32866-0011.json
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([253.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([287.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([322.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 356, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32866-0011
generate
 69%|██████▊   | 846/1232 [10:02<05:15,  1.23it/s]processing 846th semantic_sys file
846
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT DON'T THESE VERY WISE THINGS SOMETIMES TURN OUT VERY FOOLISHLY
2024-04-02 06:33:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32866-0002.json
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 179, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32866-0002
generate
 69%|██████▉   | 847/1232 [10:02<05:01,  1.28it/s]processing 847th semantic_sys file
847
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND HE MADE A LITTLE DIP OF HIS CANE TOWARDS BRANDON HALL OVER HIS SHOULDER
2024-04-02 06:33:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32866-0005.json
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 186, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32866-0005
generate
 69%|██████▉   | 848/1232 [10:03<04:43,  1.36it/s]processing 848th semantic_sys file
848
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DORCAS IN HER STRANGE WAY WAS MOVED
2024-04-02 06:33:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32879-0021.json
top_k_know_token:70
known_token_update:False
T:99
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:99
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:99
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:99
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:99
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:99
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:99
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:99
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:99
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:99
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:99
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:99
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:99
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:99
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:99
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 99, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32879-0021
generate
 69%|██████▉   | 849/1232 [10:04<04:23,  1.45it/s]processing 849th semantic_sys file
849
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE SPOKE WITH A SUDDEN ENERGY WHICH PARTOOK OF FEAR AND PASSION AND FLUSHED HER THIN CHEEK AND MADE HER LANGUID EYES FLASH
2024-04-02 06:33:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32879-0011.json
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:379
T - mask_len:tensor([342.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 379, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32879-0011
generate
 69%|██████▉   | 850/1232 [10:04<04:40,  1.36it/s]processing 850th semantic_sys file
850
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: RACHEL'S PALE AND SHARPENED FEATURES AND DILATED EYE STRUCK HER WITH A PAINFUL SURPRISE
2024-04-02 06:33:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32879-0007.json
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:303
T - mask_len:tensor([274.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 303, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32879-0007
generate
 69%|██████▉   | 851/1232 [10:05<04:51,  1.31it/s]processing 851th semantic_sys file
851
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS TRANSIENT SPRING AND LIGHTING UP ARE BEAUTIFUL A GLAMOUR BEGUILING OUR SENSES
2024-04-02 06:33:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32879-0005.json
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 301, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32879-0005
generate
 69%|██████▉   | 852/1232 [10:06<04:58,  1.27it/s]processing 852th semantic_sys file
852
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ILL AND TROUBLED DEAR TROUBLED IN MIND AND MISERABLY NERVOUS
2024-04-02 06:33:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32879-0009.json
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 190, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32879-0009
generate
 69%|██████▉   | 853/1232 [10:07<04:52,  1.30it/s]processing 853th semantic_sys file
853
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THANK YOU RACHEL MY COUSIN RACHEL MY ONLY FRIEND
2024-04-02 06:33:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32879-0012.json
top_k_know_token:70
known_token_update:False
T:145
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:145
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:145
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:145
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:145
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:145
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:145
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:145
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:145
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:145
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:145
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:145
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:145
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:145
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:145
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 145, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32879-0012
generate
 69%|██████▉   | 854/1232 [10:07<04:32,  1.38it/s]processing 854th semantic_sys file
854
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: POOR RACHEL HER NATURE RECOILED FROM DECEIT AND SHE TOLD AT ALL EVENTS AS MUCH OF THE TRUTH AS SHE DARED
2024-04-02 06:33:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32879-0010.json
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([316.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([359.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:445
T - mask_len:tensor([402.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 445, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32879-0010
generate
 69%|██████▉   | 855/1232 [10:08<04:57,  1.27it/s]processing 855th semantic_sys file
855
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT WAS NOT VERY MUCH PAST ELEVEN THAT MORNING WHEN THE PONY CARRIAGE FROM BRANDON DREW UP BEFORE THE LITTLE GARDEN WICKET OF REDMAN'S FARM
2024-04-02 06:33:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32879-0000.json
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([326.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([369.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([414.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 458, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32879-0000
generate
 69%|██████▉   | 856/1232 [10:09<05:31,  1.13it/s]processing 856th semantic_sys file
856
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I LIKE YOU STILL RACHEL I'M SURE I'LL ALWAYS LIKE YOU
2024-04-02 06:33:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32879-0022.json
top_k_know_token:70
known_token_update:False
T:133
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:133
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:133
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:133
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:133
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:133
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:133
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:133
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:133
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:133
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:133
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:133
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:133
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:133
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:133
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 133, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32879-0022
generate
 70%|██████▉   | 857/1232 [10:10<05:05,  1.23it/s]processing 857th semantic_sys file
857
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WOMEN CAN HIDE THEIR PAIN BETTER THAN WE MEN AND BEAR IT BETTER TOO EXCEPT WHEN SHAME DROPS FIRE INTO THE DREADFUL CHALICE
2024-04-02 06:33:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32879-0003.json
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([259.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([297.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([337.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:418
T - mask_len:tensor([378.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 418, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32879-0003
generate
 70%|██████▉   | 858/1232 [10:11<05:08,  1.21it/s]processing 858th semantic_sys file
858
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT IS AN ANTIPATHY AN ANTIPATHY I CANNOT GET OVER DEAR DORCAS YOU MAY THINK IT A MADNESS BUT DON'T BLAME ME
2024-04-02 06:33:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32879-0018.json
top_k_know_token:70
known_token_update:False
T:719
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:719
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:719
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:719
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:719
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:719
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:719
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:719
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:719
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:719
T - mask_len:tensor([320.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:719
T - mask_len:tensor([381.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:719
T - mask_len:tensor([444.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:719
T - mask_len:tensor([511.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:719
T - mask_len:tensor([579.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:719
T - mask_len:tensor([649.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 719, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32879-0018
generate
 70%|██████▉   | 859/1232 [10:12<06:06,  1.02it/s]processing 859th semantic_sys file
859
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I HAVE VERY FEW TO LOVE ME NOW AND I THOUGHT YOU MIGHT LOVE ME AS I HAVE BEGUN TO LOVE YOU
2024-04-02 06:33:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32879-0019.json
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 224, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32879-0019
generate
 70%|██████▉   | 860/1232 [10:13<05:36,  1.11it/s]processing 860th semantic_sys file
860
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND SHE THREW HER ARMS ROUND HER COUSIN'S NECK AND BRAVE RACHEL AT LAST BURST INTO TEARS
2024-04-02 06:33:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32879-0020.json
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:260
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 260, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32879-0020
generate
 70%|██████▉   | 861/1232 [10:14<05:28,  1.13it/s]processing 861th semantic_sys file
861
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YES SOMETHING EVERYTHING SAID RACHEL HURRIEDLY LOOKING FROWNINGLY AT A FLOWER WHICH SHE WAS TWIRLING IN HER FINGERS
2024-04-02 06:33:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32879-0014.json
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([310.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([356.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([404.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:501
T - mask_len:tensor([452.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 501, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32879-0014
generate
 70%|██████▉   | 862/1232 [10:15<05:42,  1.08it/s]processing 862th semantic_sys file
862
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU RESEMBLE ME RACHEL YOU ARE FEARLESS AND INFLEXIBLE AND GENEROUS
2024-04-02 06:33:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5683-32879-0023.json
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 252, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_5683-32879-0023
generate
 70%|███████   | 863/1232 [10:16<05:17,  1.16it/s]processing 863th semantic_sys file
863
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WON'T TREMBLE TO MORROW THOUGHT THE FIR TREE
2024-04-02 06:33:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0039.json
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 211, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0039
generate
 70%|███████   | 864/1232 [10:16<04:35,  1.34it/s]processing 864th semantic_sys file
864
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT IT WAS NOT THE FIR TREE THAT THEY MEANT
2024-04-02 06:33:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0068.json
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:247
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 247, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0068
generate
 70%|███████   | 865/1232 [10:17<04:34,  1.34it/s]processing 865th semantic_sys file
865
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DON'T YOU KNOW ONE ABOUT BACON AND TALLOW CANDLES CAN'T YOU TELL ANY LARDER STORIES
2024-04-02 06:33:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0061.json
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([280.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 310, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0061
generate
 70%|███████   | 866/1232 [10:18<04:47,  1.27it/s]processing 866th semantic_sys file
866
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WOULD FAIN KNOW IF I AM DESTINED FOR SO GLORIOUS A CAREER CRIED THE TREE REJOICING
2024-04-02 06:33:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0012.json
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:298
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 298, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0012
generate
 70%|███████   | 867/1232 [10:18<04:42,  1.29it/s]processing 867th semantic_sys file
867
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE WOOD FLAMED UP SPLENDIDLY UNDER THE LARGE BREWING COPPER AND IT SIGHED SO DEEPLY
2024-04-02 06:33:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([18], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0073.json
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 293, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0073
generate
 70%|███████   | 868/1232 [10:19<04:31,  1.34it/s]processing 868th semantic_sys file
868
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN AUTUMN THE WOOD CUTTERS ALWAYS CAME AND FELLED SOME OF THE LARGEST TREES
2024-04-02 06:33:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0007.json
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 277, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0007
generate
 71%|███████   | 869/1232 [10:20<04:25,  1.37it/s]processing 869th semantic_sys file
869
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE WELL KNEW THAT HE SHOULD NEVER SEE HIS DEAR OLD COMRADES THE LITTLE BUSHES AND FLOWERS AROUND HIM ANYMORE PERHAPS NOT EVEN THE BIRDS
2024-04-02 06:33:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0023.json
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([325.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([374.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([424.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:526
T - mask_len:tensor([475.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 526, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0023
generate
 71%|███████   | 870/1232 [10:21<04:50,  1.24it/s]processing 870th semantic_sys file
870
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: CRIED THE YOUNG LADIES AND THEY QUICKLY PUT OUT THE FIRE
2024-04-02 06:33:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0032.json
top_k_know_token:70
known_token_update:False
T:123
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:123
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:123
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:123
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:123
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:123
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:123
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:123
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:123
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:123
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:123
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:123
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:123
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:123
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:123
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 123, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0032
generate
 71%|███████   | 871/1232 [10:21<04:23,  1.37it/s]processing 871th semantic_sys file
871
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND THE GARDENER'S BOY CHOPPED THE TREE INTO SMALL PIECES THERE WAS A WHOLE HEAP LYING THERE
2024-04-02 06:33:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0072.json
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([253.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 280, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0072
generate
 71%|███████   | 872/1232 [10:22<04:19,  1.39it/s]processing 872th semantic_sys file
872
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IF IT ONLY WERE NOT SO DARK HERE AND SO TERRIBLY LONELY
2024-04-02 06:33:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([22], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0048.json
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:234
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 234, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0048
generate
 71%|███████   | 873/1232 [10:23<04:21,  1.37it/s]processing 873th semantic_sys file
873
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: REJOICE IN OUR PRESENCE SAID THE AIR AND THE SUNLIGHT
2024-04-02 06:33:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0018.json
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:181
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 181, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0018
generate
 71%|███████   | 874/1232 [10:24<04:42,  1.27it/s]processing 874th semantic_sys file
874
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEN GOOD BYE SAID THE RATS AND THEY WENT HOME
2024-04-02 06:33:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0063.json
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 143, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0063
generate
 71%|███████   | 875/1232 [10:24<04:21,  1.37it/s]processing 875th semantic_sys file
875
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A STORY CRIED THE CHILDREN DRAWING A LITTLE FAT MAN TOWARDS THE TREE
2024-04-02 06:33:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0034.json
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 216, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0034
generate
 71%|███████   | 876/1232 [10:25<04:11,  1.41it/s]processing 876th semantic_sys file
876
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY SNUFFED ABOUT THE FIR TREE AND RUSTLED AMONG THE BRANCHES
2024-04-02 06:33:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([28], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0050.json
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 164, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0050
generate
 71%|███████   | 877/1232 [10:26<04:00,  1.48it/s]processing 877th semantic_sys file
877
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT THE TREE DID NOT REJOICE AT ALL HE GREW AND GREW AND WAS GREEN BOTH WINTER AND SUMMER
2024-04-02 06:33:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0020.json
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 313, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0020
generate
 71%|███████▏  | 878/1232 [10:27<04:31,  1.30it/s]processing 878th semantic_sys file
878
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE GOLDEN STAR OF TINSEL WAS STILL ON THE TOP OF THE TREE AND GLITTERED IN THE SUNSHINE
2024-04-02 06:33:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0070.json
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 245, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0070
generate
 71%|███████▏  | 879/1232 [10:27<04:22,  1.34it/s]processing 879th semantic_sys file
879
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I KNOW NO SUCH PLACE SAID THE TREE
2024-04-02 06:33:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([25], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0054.json
top_k_know_token:70
known_token_update:False
T:95
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:95
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:95
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:95
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:95
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:95
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:95
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:95
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:95
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:95
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:95
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:95
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:95
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:95
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:95
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 95, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0054
generate
 71%|███████▏  | 880/1232 [10:28<04:17,  1.37it/s]processing 880th semantic_sys file
880
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND THEN HE TOLD ALL ABOUT HIS YOUTH AND THE LITTLE MICE HAD NEVER HEARD THE LIKE BEFORE AND THEY LISTENED AND SAID
2024-04-02 06:33:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([25], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0055.json
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([298.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([343.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([388.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([435.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 482, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0055
generate
 72%|███████▏  | 881/1232 [10:29<04:35,  1.27it/s]processing 881th semantic_sys file
881
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND THE WHOLE NIGHT THE TREE STOOD STILL AND IN DEEP THOUGHT
2024-04-02 06:33:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0040.json
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([264.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 292, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0040
generate
 72%|███████▏  | 882/1232 [10:30<04:20,  1.34it/s]processing 882th semantic_sys file
882
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HUMPY DUMPY FELL DOWNSTAIRS AND YET HE MARRIED THE PRINCESS
2024-04-02 06:33:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0036.json
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 164, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0036
generate
 72%|███████▏  | 883/1232 [10:30<04:08,  1.41it/s]processing 883th semantic_sys file
883
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN THE COURT YARD SOME OF THE MERRY CHILDREN WERE PLAYING WHO HAD DANCED AT CHRISTMAS ROUND THE FIR TREE AND WERE SO GLAD AT THE SIGHT OF HIM
2024-04-02 06:33:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0071.json
top_k_know_token:70
known_token_update:False
T:512
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:512
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:512
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:512
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:512
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:512
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:512
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:512
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:512
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:512
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:512
T - mask_len:tensor([271.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:512
T - mask_len:tensor([317.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:512
T - mask_len:tensor([364.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:512
T - mask_len:tensor([413.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:512
T - mask_len:tensor([462.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 512, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0071
generate
 72%|███████▏  | 884/1232 [10:31<04:39,  1.25it/s]processing 884th semantic_sys file
884
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHO IS HUMPY DUMPY ASKED THE MICE
2024-04-02 06:33:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0058.json
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:143
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 143, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0058
generate
 72%|███████▏  | 885/1232 [10:32<04:22,  1.32it/s]processing 885th semantic_sys file
885
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE DEPARTURE WAS NOT AT ALL AGREEABLE
2024-04-02 06:33:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([24], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0024.json
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 167, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0024
generate
 72%|███████▏  | 886/1232 [10:32<04:04,  1.41it/s]processing 886th semantic_sys file
886
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: REJOICE IN THY OWN FRESH YOUTH
2024-04-02 06:33:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0019.json
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 103, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0019
generate
 72%|███████▏  | 887/1232 [10:33<03:51,  1.49it/s]processing 887th semantic_sys file
887
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I AM BY NO MEANS OLD SAID THE FIR TREE
2024-04-02 06:33:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0051.json
top_k_know_token:70
known_token_update:False
T:111
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:111
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:111
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:111
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:111
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:111
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:111
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:111
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:111
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:111
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:111
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:111
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:111
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:111
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:111
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 111, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0051
generate
 72%|███████▏  | 888/1232 [10:34<03:37,  1.58it/s]processing 888th semantic_sys file
888
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HOWEVER THAT WAS OVER NOW THE TREE GONE THE STORY AT AN END
2024-04-02 06:33:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0074.json
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 182, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0074
generate
 72%|███████▏  | 889/1232 [10:34<03:53,  1.47it/s]processing 889th semantic_sys file
889
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT THIS WAS WHAT THE TREE COULD NOT BEAR TO HEAR
2024-04-02 06:33:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0003.json
top_k_know_token:70
known_token_update:False
T:140
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:140
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:140
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:140
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:140
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:140
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:140
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:140
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:140
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:140
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:140
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:140
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:140
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:140
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:140
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 140, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0003
generate
 72%|███████▏  | 890/1232 [10:35<03:49,  1.49it/s]processing 890th semantic_sys file
890
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SOMETHING BETTER SOMETHING STILL GRANDER MUST FOLLOW BUT WHAT
2024-04-02 06:33:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0017.json
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:203
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 203, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0017
generate
 72%|███████▏  | 891/1232 [10:36<03:49,  1.49it/s]processing 891th semantic_sys file
891
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WERE I IN THE WARM ROOM WITH ALL THE SPLENDOR AND MAGNIFICENCE
2024-04-02 06:33:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0015.json
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 249, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0015
generate
 72%|███████▏  | 892/1232 [10:36<03:55,  1.44it/s]processing 892th semantic_sys file
892
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND TOWARDS CHRISTMAS HE WAS ONE OF THE FIRST THAT WAS CUT DOWN
2024-04-02 06:33:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([24], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0021.json
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:169
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 169, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0021
generate
 72%|███████▏  | 893/1232 [10:37<03:48,  1.48it/s]processing 893th semantic_sys file
893
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT WAS IN A CORNER THAT HE LAY AMONG WEEDS AND NETTLES
2024-04-02 06:33:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0069.json
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 274, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0069
generate
 73%|███████▎  | 894/1232 [10:38<03:56,  1.43it/s]processing 894th semantic_sys file
894
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YES IN REALITY THOSE WERE HAPPY TIMES
2024-04-02 06:33:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([21], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0057.json
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 185, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0057
generate
 73%|███████▎  | 895/1232 [10:38<03:53,  1.44it/s]processing 895th semantic_sys file
895
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I AM NOW TALL AND MY BRANCHES SPREAD LIKE THE OTHERS THAT WERE CARRIED OFF LAST YEAR OH
2024-04-02 06:33:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([20], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0013.json
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([305.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:378
T - mask_len:tensor([341.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 378, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0013
generate
 73%|███████▎  | 896/1232 [10:39<04:12,  1.33it/s]processing 896th semantic_sys file
896
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SAID THE FIR TREE THINKING OVER WHAT HE HAD HIMSELF RELATED
2024-04-02 06:33:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0056.json
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:190
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 190, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0056
generate
 73%|███████▎  | 897/1232 [10:40<04:01,  1.39it/s]processing 897th semantic_sys file
897
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TIS NOW WINTER OUT OF DOORS THOUGHT THE TREE
2024-04-02 06:33:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([18], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0046.json
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 147, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0046
generate
 73%|███████▎  | 898/1232 [10:41<03:52,  1.44it/s]processing 898th semantic_sys file
898
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHY ONE MORNING THERE CAME A QUANTITY OF PEOPLE AND SET TO WORK IN THE LOFT
2024-04-02 06:33:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0066.json
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 217, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0066
generate
 73%|███████▎  | 899/1232 [10:41<03:50,  1.45it/s]processing 899th semantic_sys file
899
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THOUGHT THE FIR TREE AND BELIEVED IT ALL BECAUSE THE MAN WHO TOLD THE STORY WAS SO GOOD LOOKING WELL WELL
2024-04-02 06:33:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0038.json
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([264.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 327, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0038
generate
 73%|███████▎  | 900/1232 [10:42<04:06,  1.35it/s]processing 900th semantic_sys file
900
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE SERVANTS AS WELL AS THE YOUNG LADIES DECORATED IT
2024-04-02 06:33:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0027.json
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:144
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 144, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0027
generate
 73%|███████▎  | 901/1232 [10:43<03:46,  1.46it/s]processing 901th semantic_sys file
901
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OUT IN THE WOODS STOOD A NICE LITTLE FIR TREE
2024-04-02 06:33:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0000.json
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 217, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0000
generate
 73%|███████▎  | 902/1232 [10:43<03:39,  1.50it/s]processing 902th semantic_sys file
902
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE'S MANY A ONE CONSIDERABLY OLDER THAN I AM
2024-04-02 06:33:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:33:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0052.json
top_k_know_token:70
known_token_update:False
T:151
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:151
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:151
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:151
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:151
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:151
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:151
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:151
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:151
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:151
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:151
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:151
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:151
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:151
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:151
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 151, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0052
generate
 73%|███████▎  | 903/1232 [10:44<03:32,  1.55it/s]processing 903th semantic_sys file
903
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YES THEN SOMETHING BETTER SOMETHING STILL GRANDER WILL SURELY FOLLOW OR WHEREFORE SHOULD THEY THUS ORNAMENT ME
2024-04-02 06:34:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0016.json
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([276.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([318.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([360.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:447
T - mask_len:tensor([404.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 447, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0016
generate
 73%|███████▎  | 904/1232 [10:45<04:04,  1.34it/s]processing 904th semantic_sys file
904
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: PERHAPS THE OTHER TREES FROM THE FOREST WILL COME TO LOOK AT ME
2024-04-02 06:34:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([26], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_672-122797-0030.json
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 164, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_672-122797-0030
generate
 73%|███████▎  | 905/1232 [10:46<03:48,  1.43it/s]processing 905th semantic_sys file
905
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DOES YOUR MAJESTY THEN NO LONGER BELIEVE THE DISLOYAL ATTEMPT
2024-04-02 06:34:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75946-0008.json
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:264
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 264, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75946-0008
generate
 74%|███████▎  | 906/1232 [10:46<03:53,  1.40it/s]processing 906th semantic_sys file
906
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT IS NECESSARY THEREFORE THAT HE SHOULD COMPLY THE KING FROWNED
2024-04-02 06:34:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75946-0007.json
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 229, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75946-0007
generate
 74%|███████▎  | 907/1232 [10:47<04:08,  1.31it/s]processing 907th semantic_sys file
907
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE KING HAD COMPLETED HIS TOILETTE BY NINE O'CLOCK HE APPEARED IN AN OPEN CARRIAGE DECORATED WITH BRANCHES OF TREES AND FLOWERS
2024-04-02 06:34:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75946-0013.json
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([315.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([362.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([410.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:509
T - mask_len:tensor([460.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 509, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75946-0013
generate
 74%|███████▎  | 908/1232 [10:48<04:30,  1.20it/s]processing 908th semantic_sys file
908
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: GENTLEMEN TO YOUR POSTS WHEREUPON SAINT AIGNAN AND VILLEROY TOOK THEIR LEAVE
2024-04-02 06:34:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75946-0003.json
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 262, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75946-0003
generate
 74%|███████▍  | 909/1232 [10:49<04:15,  1.26it/s]processing 909th semantic_sys file
909
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE HAS GIVEN THEM WITH TOO MUCH GRACE NOT TO HAVE OTHERS STILL TO GIVE IF THEY ARE REQUIRED WHICH IS THE CASE AT THE PRESENT MOMENT
2024-04-02 06:34:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75946-0006.json
top_k_know_token:70
known_token_update:False
T:525
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:525
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:525
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:525
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:525
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:525
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:525
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:525
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:525
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:525
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:525
T - mask_len:tensor([278.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:525
T - mask_len:tensor([325.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:525
T - mask_len:tensor([373.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:525
T - mask_len:tensor([423.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:525
T - mask_len:tensor([474.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 525, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75946-0006
generate
 74%|███████▍  | 910/1232 [10:50<04:33,  1.18it/s]processing 910th semantic_sys file
910
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE NEWS CIRCULATED WITH THE RAPIDITY OF LIGHTNING DURING ITS PROGRESS IT KINDLED EVERY VARIETY OF COQUETRY DESIRE AND WILD AMBITION
2024-04-02 06:34:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75946-0012.json
top_k_know_token:70
known_token_update:False
T:496
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:496
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:496
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:496
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:496
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:496
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:496
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:496
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:496
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:496
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:496
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:496
T - mask_len:tensor([307.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:496
T - mask_len:tensor([353.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:496
T - mask_len:tensor([400.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:496
T - mask_len:tensor([448.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 496, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75946-0012
generate
 74%|███████▍  | 911/1232 [10:51<04:51,  1.10it/s]processing 911th semantic_sys file
911
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MONSIEUR WAS THE ONLY ONE WHO DID NOT UNDERSTAND ANYTHING ABOUT THE MATTER
2024-04-02 06:34:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75946-0024.json
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:261
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 261, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75946-0024
generate
 74%|███████▍  | 912/1232 [10:52<04:40,  1.14it/s]processing 912th semantic_sys file
912
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DISDAINFUL OF A SUCCESS OF WHICH MADAME SHOWED NO ACKNOWLEDGEMENT HE THOUGHT OF NOTHING BUT BOLDLY REGAINING THE MARKED PREFERENCE OF THE PRINCESS
2024-04-02 06:34:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75946-0027.json
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([309.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([351.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:435
T - mask_len:tensor([393.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 435, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75946-0027
generate
 74%|███████▍  | 913/1232 [10:53<04:48,  1.11it/s]processing 913th semantic_sys file
913
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NOT AT ALL YOU ARE ON THE CONTRARY MOST AGREEABLE TO ME
2024-04-02 06:34:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75946-0009.json
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 166, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75946-0009
generate
 74%|███████▍  | 914/1232 [10:53<04:29,  1.18it/s]processing 914th semantic_sys file
914
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: CERTAINLY SIRE BUT I MUST HAVE MONEY TO DO THAT WHAT
2024-04-02 06:34:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75946-0004.json
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:158
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 158, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75946-0004
generate
 74%|███████▍  | 915/1232 [10:54<04:15,  1.24it/s]processing 915th semantic_sys file
915
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SUDDENLY FOR THE PURPOSE OF RESTORING PEACE AND ORDER SPRING ACCOMPANIED BY HIS WHOLE COURT MADE HIS APPEARANCE
2024-04-02 06:34:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75946-0015.json
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 325, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75946-0015
generate
 74%|███████▍  | 916/1232 [10:55<04:21,  1.21it/s]processing 916th semantic_sys file
916
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FAR FROM IT SIRE YOUR MAJESTY HAVING GIVEN NO DIRECTIONS ABOUT IT THE MUSICIANS HAVE RETAINED IT
2024-04-02 06:34:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75946-0020.json
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([266.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([302.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([338.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 374, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75946-0020
generate
 74%|███████▍  | 917/1232 [10:56<04:28,  1.17it/s]processing 917th semantic_sys file
917
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE KING WHO HAD FROM THIS MOMENT BECOME IN REALITY THE PRINCIPAL DANCER IN THE QUADRILLE CAST A LOOK UPON HIS VANQUISHED RIVAL
2024-04-02 06:34:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75946-0029.json
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([253.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([340.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([385.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([432.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 478, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75946-0029
generate
 75%|███████▍  | 918/1232 [10:57<04:50,  1.08it/s]processing 918th semantic_sys file
918
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE WAS SOMETHING IN HIS CARRIAGE WHICH RESEMBLED THE BUOYANT MOVEMENTS OF AN IMMORTAL AND HE DID NOT DANCE SO MUCH AS SEEM TO SOAR ALONG
2024-04-02 06:34:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75946-0018.json
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([311.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([352.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:437
T - mask_len:tensor([395.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 437, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75946-0018
generate
 75%|███████▍  | 919/1232 [10:58<04:46,  1.09it/s]processing 919th semantic_sys file
919
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: QUICK QUICK THEN AMONG THE HIGH REED GRASS SAID MONTALAIS STOOP ATHENAIS YOU ARE SO TALL
2024-04-02 06:34:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75947-0028.json
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 326, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75947-0028
generate
 75%|███████▍  | 920/1232 [10:59<04:42,  1.11it/s]processing 920th semantic_sys file
920
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE YOUNG GIRLS HAD INDEED MADE THEMSELVES SMALL INDEED INVISIBLE
2024-04-02 06:34:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75947-0029.json
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 229, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75947-0029
generate
 75%|███████▍  | 921/1232 [10:59<04:17,  1.21it/s]processing 921th semantic_sys file
921
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YES BUT PERHAPS I FRIGHTENED HER IN WHAT WAY
2024-04-02 06:34:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75947-0032.json
top_k_know_token:70
known_token_update:False
T:187
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:187
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:187
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:187
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:187
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:187
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:187
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:187
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:187
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:187
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:187
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:187
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:187
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:187
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:187
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 187, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75947-0032
generate
 75%|███████▍  | 922/1232 [11:00<04:07,  1.25it/s]processing 922th semantic_sys file
922
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: EXQUISITE SOFT TURF OF THE WOODS THE HAPPINESS WHICH YOUR FRIENDSHIP CONFERS UPON ME
2024-04-02 06:34:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75947-0025.json
top_k_know_token:70
known_token_update:False
T:544
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:544
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:544
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:544
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:544
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:544
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:544
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:544
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:544
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:544
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:544
T - mask_len:tensor([288.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:544
T - mask_len:tensor([336.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:544
T - mask_len:tensor([387.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:544
T - mask_len:tensor([438.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:544
T - mask_len:tensor([491.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 544, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75947-0025
generate
 75%|███████▍  | 923/1232 [11:01<04:09,  1.24it/s]processing 923th semantic_sys file
923
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHEN SHE PERCEIVED THE YOUNG MAN SHE ROSE LIKE A WOMAN SURPRISED IN THE MIDST OF IDEAS SHE WAS DESIROUS OF CONCEALING FROM HERSELF
2024-04-02 06:34:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 924th semantic_sys file
924
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WELL SAID MADEMOISELLE DE TONNAY CHARENTE I ALSO THINK A GOOD DEAL BUT I TAKE CARE
2024-04-02 06:34:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75947-0026.json
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 227, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75947-0026
generate
 75%|███████▌  | 925/1232 [11:02<03:06,  1.64it/s]processing 925th semantic_sys file
925
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HOW IS IT LA VALLIERE SAID MADEMOISELLE DE TONNAY CHARENTE THAT THE VICOMTE DE BRAGELONNE SPOKE OF YOU AS LOUISE
2024-04-02 06:34:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75947-0033.json
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([329.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([373.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:463
T - mask_len:tensor([418.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 463, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75947-0033
generate
 75%|███████▌  | 926/1232 [11:03<03:37,  1.41it/s]processing 926th semantic_sys file
926
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE CANNOT BE A DOUBT HE RECEIVED YOU KINDLY FOR IN FACT YOU RETURNED WITHOUT HIS PERMISSION
2024-04-02 06:34:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75947-0015.json
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 270, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75947-0015
generate
 75%|███████▌  | 927/1232 [11:03<03:36,  1.41it/s]processing 927th semantic_sys file
927
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE ARROW PIERCED HIS HEART AND WOUNDED HIM MORTALLY
2024-04-02 06:34:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75947-0008.json
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 166, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75947-0008
generate
 75%|███████▌  | 928/1232 [11:04<03:28,  1.46it/s]processing 928th semantic_sys file
928
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: UPON THIS MADAME DEIGNED TO TURN HER EYES LANGUISHINGLY TOWARDS THE COMTE OBSERVING
2024-04-02 06:34:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75947-0001.json
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 271, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75947-0001
generate
 75%|███████▌  | 929/1232 [11:05<03:54,  1.29it/s]processing 929th semantic_sys file
929
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OH MADEMOISELLE WHY HAVE I NOT A DEVOTED SISTER OR A TRUE FRIEND SUCH AS YOURSELF
2024-04-02 06:34:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75947-0016.json
top_k_know_token:70
known_token_update:False
T:339
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:339
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:339
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:339
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:339
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:339
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:339
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:339
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:339
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:339
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:339
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:339
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:339
T - mask_len:tensor([241.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:339
T - mask_len:tensor([273.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:339
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 339, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75947-0016
generate
 75%|███████▌  | 930/1232 [11:06<04:03,  1.24it/s]processing 930th semantic_sys file
930
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE THEN ROSE HUMMING THE AIR TO WHICH SHE WAS PRESENTLY GOING TO DANCE
2024-04-02 06:34:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75947-0007.json
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:235
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 235, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75947-0007
generate
 76%|███████▌  | 931/1232 [11:08<05:16,  1.05s/it]processing 931th semantic_sys file
931
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I REMEMBER NOW AND I CONGRATULATE MYSELF DO YOU LOVE ANY ONE
2024-04-02 06:34:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75947-0013.json
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 216, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75947-0013
generate
 76%|███████▌  | 932/1232 [11:08<04:58,  1.01it/s]processing 932th semantic_sys file
932
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT IS TOO DIFFICULT REPLIED MADEMOISELLE DE TONNAY CHARENTE LAUGHING LOUDLY
2024-04-02 06:34:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75947-0023.json
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([309.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([346.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 383, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75947-0023
generate
 76%|███████▌  | 933/1232 [11:09<04:56,  1.01it/s]processing 933th semantic_sys file
933
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: LOOK YONDER DO YOU NOT SEE THE MOON SLOWLY RISING SILVERING THE TOPMOST BRANCHES OF THE CHESTNUTS AND THE OAKS
2024-04-02 06:34:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75947-0024.json
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([287.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([326.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:404
T - mask_len:tensor([365.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 404, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75947-0024
generate
 76%|███████▌  | 934/1232 [11:10<04:45,  1.04it/s]processing 934th semantic_sys file
934
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: GOOD GRACIOUS HAS THE KING ANY RIGHT TO INTERFERE IN MATTERS OF THAT KIND
2024-04-02 06:34:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75947-0035.json
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([271.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 300, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75947-0035
generate
 76%|███████▌  | 935/1232 [11:11<04:30,  1.10it/s]processing 935th semantic_sys file
935
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OH I AM SPEAKING SERIOUSLY REPLIED MONTALAIS AND MY OPINION IN THIS CASE IS QUITE AS GOOD AS THE KING'S I SUPPOSE IS IT NOT LOUISE
2024-04-02 06:34:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 936th semantic_sys file
936
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I HAVE BEEN HERE THIS QUARTER OF AN HOUR REPLIED LA VALLIERE
2024-04-02 06:34:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 937th semantic_sys file
937
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YES THE CHARACTER WHICH YOUR ROYAL HIGHNESS ASSUMED IS IN PERFECT HARMONY WITH YOUR OWN
2024-04-02 06:34:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75947-0003.json
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 265, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75947-0003
generate
 76%|███████▌  | 938/1232 [11:12<02:41,  1.82it/s]processing 938th semantic_sys file
938
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TO SAY NOTHING SAID MONTALAIS SO THAT WHEN MADEMOISELLE DE TONNAY CHARENTE THINKS ATHENAIS IS THE ONLY ONE WHO KNOWS IT
2024-04-02 06:34:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_7127-75947-0027.json
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([325.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([368.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:457
T - mask_len:tensor([413.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 457, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_7127-75947-0027
generate
 76%|███████▌  | 939/1232 [11:13<03:05,  1.58it/s]processing 939th semantic_sys file
939
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE IS NO CLASS AND NO COUNTRY THAT HAS YIELDED SO ABJECTLY BEFORE THE PRESSURE OF PHYSICAL WANT AS TO DENY THEMSELVES ALL GRATIFICATION OF THIS HIGHER OR SPIRITUAL NEED
2024-04-02 06:34:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5695-0007.json
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([300.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([402.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([456.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([511.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 566, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5695-0007
generate
 76%|███████▋  | 940/1232 [11:14<03:38,  1.34it/s]processing 940th semantic_sys file
940
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE RESULT IS A GREAT MOBILITY OF THE LABOR EMPLOYED IN PRINTING PERHAPS GREATER THAN IN ANY OTHER EQUALLY WELL DEFINED AND CONSIDERABLE BODY OF WORKMEN
2024-04-02 06:34:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5695-0015.json
top_k_know_token:70
known_token_update:False
T:550
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:550
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:550
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:550
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:550
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:550
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:550
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:550
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:550
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:550
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:550
T - mask_len:tensor([291.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:550
T - mask_len:tensor([340.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:550
T - mask_len:tensor([391.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:550
T - mask_len:tensor([443.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:550
T - mask_len:tensor([497.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 550, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5695-0015
generate
 76%|███████▋  | 941/1232 [11:15<03:57,  1.23it/s]processing 941th semantic_sys file
941
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: EACH WILL THEREFORE SERVE ABOUT EQUALLY WELL DURING THE EARLIER STAGES OF SOCIAL GROWTH
2024-04-02 06:34:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5695-0009.json
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([354.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:439
T - mask_len:tensor([396.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 439, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5695-0009
generate
 76%|███████▋  | 942/1232 [11:16<04:14,  1.14it/s]processing 942th semantic_sys file
942
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN A GENERAL WAY THOUGH NOT WHOLLY NOR CONSISTENTLY THESE TWO GROUPS COINCIDE
2024-04-02 06:34:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5695-0000.json
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([298.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:369
T - mask_len:tensor([333.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 369, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5695-0000
generate
 77%|███████▋  | 943/1232 [11:17<04:15,  1.13it/s]processing 943th semantic_sys file
943
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN THE COMMUNITIES OF THE WESTERN CULTURE THIS POINT IS AT PRESENT FOUND AMONG THE LOWER MIDDLE CLASS
2024-04-02 06:34:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5695-0003.json
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 307, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5695-0003
generate
 77%|███████▋  | 944/1232 [11:18<04:08,  1.16it/s]processing 944th semantic_sys file
944
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT IS EVIDENT THEREFORE THAT THE PRESENT TREND OF THE DEVELOPMENT IS IN THE DIRECTION OF HEIGHTENING THE UTILITY OF CONSPICUOUS CONSUMPTION AS COMPARED WITH LEISURE
2024-04-02 06:34:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([61], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5695-0011.json
top_k_know_token:70
known_token_update:False
T:590
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:590
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:590
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:590
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:590
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:590
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:590
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:590
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:590
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:590
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:590
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:590
T - mask_len:tensor([365.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:590
T - mask_len:tensor([419.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:590
T - mask_len:tensor([475.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:590
T - mask_len:tensor([533.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 590, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5695-0011
generate
 77%|███████▋  | 945/1232 [11:19<04:29,  1.07it/s]processing 945th semantic_sys file
945
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT AS WE DESCEND THE SOCIAL SCALE THE POINT IS PRESENTLY REACHED WHERE THE DUTIES OF VICARIOUS LEISURE AND CONSUMPTION DEVOLVE UPON THE WIFE ALONE
2024-04-02 06:34:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([59], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5695-0002.json
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([251.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([288.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([326.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:405
T - mask_len:tensor([366.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 405, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5695-0002
generate
 77%|███████▋  | 946/1232 [11:20<04:31,  1.05it/s]processing 946th semantic_sys file
946
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE QUESTION IS WHICH OF THE TWO METHODS WILL MOST EFFECTIVELY REACH THE PERSONS WHOSE CONVICTIONS IT IS DESIRED TO AFFECT
2024-04-02 06:34:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5695-0008.json
top_k_know_token:70
known_token_update:False
T:481
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:481
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:481
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:481
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:481
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:481
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:481
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:481
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:481
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:481
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:481
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:481
T - mask_len:tensor([297.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:481
T - mask_len:tensor([342.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:481
T - mask_len:tensor([388.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:481
T - mask_len:tensor([434.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 481, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5695-0008
generate
 77%|███████▋  | 947/1232 [11:21<04:14,  1.12it/s]processing 947th semantic_sys file
947
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: VERY MUCH OF SQUALOR AND DISCOMFORT WILL BE ENDURED BEFORE THE LAST TRINKET OR THE LAST PRETENSE OF PECUNIARY DECENCY IS PUT AWAY
2024-04-02 06:34:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([61], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5695-0006.json
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([253.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([340.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([385.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:478
T - mask_len:tensor([432.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 478, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5695-0006
generate
 77%|███████▋  | 948/1232 [11:22<04:17,  1.10it/s]processing 948th semantic_sys file
948
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: CONSUMPTION BECOMES A LARGER ELEMENT IN THE STANDARD OF LIVING IN THE CITY THAN IN THE COUNTRY
2024-04-02 06:34:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5695-0013.json
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 245, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5695-0013
generate
 77%|███████▋  | 949/1232 [11:22<03:55,  1.20it/s]processing 949th semantic_sys file
949
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE MODERN ORGANIZATION OF INDUSTRY WORKS IN THE SAME DIRECTION ALSO BY ANOTHER LINE
2024-04-02 06:34:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([54], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5695-0010.json
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:302
T - mask_len:tensor([273.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 302, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5695-0010
generate
 77%|███████▋  | 950/1232 [11:23<03:56,  1.19it/s]processing 950th semantic_sys file
950
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE CONSUMPTION OF LUXURIES IN THE TRUE SENSE IS A CONSUMPTION DIRECTED TO THE COMFORT OF THE CONSUMER HIMSELF AND IS THEREFORE A MARK OF THE MASTER
2024-04-02 06:34:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5694-0008.json
top_k_know_token:70
known_token_update:False
T:604
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:604
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:604
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:604
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:604
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:604
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:604
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:604
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:604
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:604
T - mask_len:tensor([269.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:604
T - mask_len:tensor([320.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:604
T - mask_len:tensor([373.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:604
T - mask_len:tensor([429.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:604
T - mask_len:tensor([487.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:604
T - mask_len:tensor([545.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 604, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5694-0008
generate
 77%|███████▋  | 951/1232 [11:24<04:20,  1.08it/s]processing 951th semantic_sys file
951
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS DIFFERENTIATION IS FURTHERED BY THE INHERITANCE OF WEALTH AND THE CONSEQUENT INHERITANCE OF GENTILITY
2024-04-02 06:34:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5694-0013.json
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 313, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5694-0013
generate
 77%|███████▋  | 952/1232 [11:25<04:33,  1.02it/s]processing 952th semantic_sys file
952
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE WEARING OF UNIFORMS OR LIVERIES IMPLIES A CONSIDERABLE DEGREE OF DEPENDENCE AND MAY EVEN BE SAID TO BE A MARK OF SERVITUDE REAL OR OSTENSIBLE
2024-04-02 06:34:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5694-0017.json
top_k_know_token:70
known_token_update:False
T:641
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:641
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:641
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:641
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:641
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:641
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:641
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:641
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:641
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:641
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:641
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:641
T - mask_len:tensor([396.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:641
T - mask_len:tensor([455.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:641
T - mask_len:tensor([516.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:641
T - mask_len:tensor([579.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 641, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5694-0017
generate
 77%|███████▋  | 953/1232 [11:27<04:52,  1.05s/it]processing 953th semantic_sys file
953
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE UTILITY OF CONSUMPTION AS AN EVIDENCE OF WEALTH IS TO BE CLASSED AS A DERIVATIVE GROWTH
2024-04-02 06:34:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5694-0001.json
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([274.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:340
T - mask_len:tensor([307.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 340, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5694-0001
generate
 77%|███████▋  | 954/1232 [11:27<04:42,  1.02s/it]processing 954th semantic_sys file
954
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: UNDER THE TABU CERTAIN VICTUALS AND MORE PARTICULARLY CERTAIN BEVERAGES ARE STRICTLY RESERVED FOR THE USE OF THE SUPERIOR CLASS
2024-04-02 06:34:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5694-0005.json
top_k_know_token:70
known_token_update:False
T:484
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:484
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:484
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:484
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:484
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:484
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:484
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:484
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:484
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:484
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:484
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:484
T - mask_len:tensor([299.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:484
T - mask_len:tensor([344.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:484
T - mask_len:tensor([390.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:484
T - mask_len:tensor([437.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 484, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5694-0005
generate
 78%|███████▊  | 955/1232 [11:29<04:58,  1.08s/it]processing 955th semantic_sys file
955
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN THE NATURE OF THINGS LUXURIES AND THE COMFORTS OF LIFE BELONG TO THE LEISURE CLASS
2024-04-02 06:34:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5694-0004.json
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([222.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:359
T - mask_len:tensor([324.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 359, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5694-0004
generate
 78%|███████▊  | 956/1232 [11:30<04:36,  1.00s/it]processing 956th semantic_sys file
956
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SO MANY OF THEM HOWEVER AS MAKE UP THE RETAINER AND HANGERS ON OF THE PATRON MAY BE CLASSED AS VICARIOUS CONSUMER WITHOUT QUALIFICATION
2024-04-02 06:34:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5694-0015.json
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([290.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([338.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([389.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([441.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:547
T - mask_len:tensor([494.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 547, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5694-0015
generate
 78%|███████▊  | 957/1232 [11:31<04:37,  1.01s/it]processing 957th semantic_sys file
957
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE LIVERY BECOMES OBNOXIOUS TO NEARLY ALL WHO ARE REQUIRED TO WEAR IT
2024-04-02 06:34:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5694-0022.json
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:317
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 317, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5694-0022
generate
 78%|███████▊  | 958/1232 [11:31<04:16,  1.07it/s]processing 958th semantic_sys file
958
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE WEARERS OF UNIFORMS AND LIVERIES MAY BE ROUGHLY DIVIDED INTO TWO CLASSES THE FREE AND THE SERVILE OR THE NOBLE AND THE IGNOBLE
2024-04-02 06:34:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5694-0018.json
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([288.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([331.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([375.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:465
T - mask_len:tensor([420.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 465, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5694-0018
generate
 78%|███████▊  | 959/1232 [11:32<04:10,  1.09it/s]processing 959th semantic_sys file
959
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AS USED IN THE SPEECH OF EVERYDAY LIFE THE WORD CARRIES AN UNDERTONE OF DEPRECATION
2024-04-02 06:34:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([56], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5696-0006.json
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([280.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 310, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5696-0006
generate
 78%|███████▊  | 960/1232 [11:33<04:04,  1.11it/s]processing 960th semantic_sys file
960
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT IT IS ON OTHER GROUNDS WORTH NOTING THAT THE TERM WASTE IN THE LANGUAGE OF EVERYDAY LIFE IMPLIES DEPRECATION OF WHAT IS CHARACTERIZED AS WASTEFUL
2024-04-02 06:34:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5696-0008.json
top_k_know_token:70
known_token_update:False
T:682
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:682
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:682
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:682
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:682
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:682
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:682
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:682
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:682
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:682
T - mask_len:tensor([304.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:682
T - mask_len:tensor([361.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:682
T - mask_len:tensor([422.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:682
T - mask_len:tensor([485.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:682
T - mask_len:tensor([549.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:682
T - mask_len:tensor([616.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 682, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5696-0008
generate
 78%|███████▊  | 961/1232 [11:34<04:30,  1.00it/s]processing 961th semantic_sys file
961
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN STRICT ACCURACY NOTHING SHOULD BE INCLUDED UNDER THE HEAD OF CONSPICUOUS WASTE BUT SUCH EXPENDITURE AS IS INCURRED ON THE GROUND OF AN INVIDIOUS PECUNIARY COMPARISON
2024-04-02 06:34:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([54], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5696-0009.json
top_k_know_token:70
known_token_update:False
T:669
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:669
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:669
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:669
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:669
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:669
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:669
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:669
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:669
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:669
T - mask_len:tensor([298.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:669
T - mask_len:tensor([354.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:669
T - mask_len:tensor([413.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:669
T - mask_len:tensor([475.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:669
T - mask_len:tensor([539.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:669
T - mask_len:tensor([604.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 669, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5696-0009
generate
 78%|███████▊  | 962/1232 [11:36<04:51,  1.08s/it]processing 962th semantic_sys file
962
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OTHER CIRCUMSTANCES PERMITTING THAT INSTINCT DISPOSES MEN TO LOOK WITH FAVOR UPON PRODUCTIVE EFFICIENCY AND ON WHATEVER IS OF HUMAN USE
2024-04-02 06:34:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([56], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5696-0002.json
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([299.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([380.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 421, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5696-0002
generate
 78%|███████▊  | 963/1232 [11:36<04:34,  1.02s/it]processing 963th semantic_sys file
963
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE SALIENT FEATURES OF THIS DEVELOPMENT OF DOMESTIC SERVICE HAVE ALREADY BEEN INDICATED
2024-04-02 06:34:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([56], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5696-0004.json
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([280.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 310, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5696-0004
generate
 78%|███████▊  | 964/1232 [11:37<04:12,  1.06it/s]processing 964th semantic_sys file
964
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AN ARTICLE MAY BE USEFUL AND WASTEFUL BOTH AND ITS UTILITY TO THE CONSUMER MAY BE MADE UP OF USE AND WASTE IN THE MOST VARYING PROPORTIONS
2024-04-02 06:34:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([53], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5696-0010.json
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([274.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([311.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:386
T - mask_len:tensor([349.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 386, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5696-0010
generate
 78%|███████▊  | 965/1232 [11:38<04:06,  1.08it/s]processing 965th semantic_sys file
965
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE USE OF THE WORD WASTE AS A TECHNICAL TERM THEREFORE IMPLIES NO DEPRECATION OF THE MOTIVES OR OF THE ENDS SOUGHT BY THE CONSUMER UNDER THIS CANON OF CONSPICUOUS WASTE
2024-04-02 06:34:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([57], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_3570-5696-0007.json
top_k_know_token:70
known_token_update:False
T:643
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:643
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:643
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:643
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:643
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:643
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:643
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:643
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:643
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:643
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:643
T - mask_len:tensor([340.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:643
T - mask_len:tensor([397.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:643
T - mask_len:tensor([457.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:643
T - mask_len:tensor([518.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:643
T - mask_len:tensor([580.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 643, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_3570-5696-0007
generate
 78%|███████▊  | 966/1232 [11:39<04:38,  1.05s/it]processing 966th semantic_sys file
966
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE CRIED IN HIGH DUDGEON JUST AS IF HE OWNED THE WHOLE OF THE PEPPERS AND COULD DISPOSE OF THEM ALL TO SUIT HIS FANCY
2024-04-02 06:34:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-126133-0023.json
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([300.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:372
T - mask_len:tensor([336.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 372, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-126133-0023
generate
 78%|███████▊  | 967/1232 [11:40<04:25,  1.00s/it]processing 967th semantic_sys file
967
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT POLLY COULDN'T SPEAK AND IF JASPER HADN'T CAUGHT HER JUST IN TIME SHE WOULD HAVE TUMBLED OVER BACKWARD FROM THE STOOL PHRONSIE AND ALL
2024-04-02 06:34:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-126133-0007.json
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([359.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([407.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:505
T - mask_len:tensor([456.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 505, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-126133-0007
generate
 79%|███████▊  | 968/1232 [11:41<04:37,  1.05s/it]processing 968th semantic_sys file
968
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DEAR ME EJACULATED THE OLD GENTLEMAN IN THE UTMOST AMAZEMENT AND SUCH A TIME AS I'VE HAD TO GET HER HERE TOO
2024-04-02 06:34:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-126133-0019.json
top_k_know_token:70
known_token_update:False
T:694
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:694
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:694
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:694
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:694
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:694
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:694
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:694
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:694
T - mask_len:tensor([254.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:694
T - mask_len:tensor([309.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:694
T - mask_len:tensor([367.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:694
T - mask_len:tensor([429.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:694
T - mask_len:tensor([493.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:694
T - mask_len:tensor([559.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:694
T - mask_len:tensor([626.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 694, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-126133-0019
generate
 79%|███████▊  | 969/1232 [11:43<04:57,  1.13s/it]processing 969th semantic_sys file
969
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ASKED PHRONSIE IN INTENSE INTEREST SLIPPING DOWN OUT OF POLLY'S ARMS AND CROWDING UP CLOSE TO JASPER'S SIDE
2024-04-02 06:34:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-126133-0014.json
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([259.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([290.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 321, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-126133-0014
generate
 79%|███████▊  | 970/1232 [11:44<04:34,  1.05s/it]processing 970th semantic_sys file
970
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND THE OLD GENTLEMAN WAS SO DELIGHTED WITH HIS SUCCESS THAT HE HAD TO BURST OUT INTO A SERIES OF SHORT HAPPY BITS OF LAUGHTER THAT OCCUPIED QUITE A SPACE OF TIME
2024-04-02 06:34:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:34:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-126133-0024.json
top_k_know_token:70
known_token_update:False
T:761
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:761
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:761
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:761
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:761
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:761
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:761
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:761
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:761
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:761
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:761
T - mask_len:tensor([403.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:761
T - mask_len:tensor([470.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:761
T - mask_len:tensor([541.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:761
T - mask_len:tensor([613.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:761
T - mask_len:tensor([687.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 761, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-126133-0024
generate
 79%|███████▉  | 971/1232 [11:45<04:58,  1.14s/it]processing 971th semantic_sys file
971
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE THERE HE SAID SOOTHINGLY PATTING HER BROWN FUZZY HEAD
2024-04-02 06:35:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-126133-0012.json
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 185, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-126133-0012
generate
 79%|███████▉  | 972/1232 [11:46<04:19,  1.00it/s]processing 972th semantic_sys file
972
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YES ALL ALONE BY HIMSELF ASSERTED JASPER VEHEMENTLY AND WINKING FURIOUSLY TO THE OTHERS TO STOP THEIR LAUGHING HE DID NOW TRULY PHRONSIE
2024-04-02 06:35:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-126133-0015.json
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([300.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([402.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([456.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:566
T - mask_len:tensor([511.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 566, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-126133-0015
generate
 79%|███████▉  | 973/1232 [11:47<04:25,  1.02s/it]processing 973th semantic_sys file
973
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ISN'T HE SPLENDID CRIED JASPER IN INTENSE PRIDE SWELLING UP FATHER KNEW HOW TO DO IT
2024-04-02 06:35:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-126133-0011.json
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([264.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 327, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-126133-0011
generate
 79%|███████▉  | 974/1232 [11:48<04:15,  1.01it/s]processing 974th semantic_sys file
974
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I KNOW GASPED POLLY CONTROLLING HER SOBS I WON'T ONLY I CAN'T THANK YOU
2024-04-02 06:35:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-126133-0013.json
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:215
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 215, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-126133-0013
generate
 79%|███████▉  | 975/1232 [11:48<04:00,  1.07it/s]processing 975th semantic_sys file
975
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DON'T MIND IT POLLY WHISPERED JASPER TWASN'T HER FAULT
2024-04-02 06:35:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-126133-0018.json
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:216
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 216, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-126133-0018
generate
 79%|███████▉  | 976/1232 [11:49<04:02,  1.06it/s]processing 976th semantic_sys file
976
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OH NO JASPER I MUST GO BY MY VERY OWN SELF
2024-04-02 06:35:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-126133-0016.json
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:167
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 167, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-126133-0016
generate
 79%|███████▉  | 977/1232 [11:50<03:36,  1.18it/s]processing 977th semantic_sys file
977
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AT THIS THE BUNDLE OPENED SUDDENLY AND OUT POPPED PHRONSIE
2024-04-02 06:35:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-126133-0006.json
top_k_know_token:70
known_token_update:False
T:155
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:155
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:155
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:155
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:155
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:155
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:155
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:155
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:155
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:155
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:155
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:155
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:155
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:155
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:155
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 155, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-126133-0006
generate
 79%|███████▉  | 978/1232 [11:51<03:21,  1.26it/s]processing 978th semantic_sys file
978
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE ASKED IMPULSIVELY I DIDN'T BELIEVE YOU COULD PERSUADE HER FATHER
2024-04-02 06:35:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-126133-0021.json
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 189, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-126133-0021
generate
 79%|███████▉  | 979/1232 [11:51<03:11,  1.32it/s]processing 979th semantic_sys file
979
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I DIDN'T HAVE ANY FEARS IF I WORKED IT RIGHTLY SAID THE OLD GENTLEMAN COMPLACENTLY
2024-04-02 06:35:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-126133-0022.json
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:272
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 272, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-126133-0022
generate
 80%|███████▉  | 980/1232 [11:52<03:17,  1.27it/s]processing 980th semantic_sys file
980
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SOMEHOW OF ALL THE DAYS WHEN THE HOME FEELING WAS THE STRONGEST THIS DAY IT SEEMED AS IF SHE COULD BEAR IT NO LONGER
2024-04-02 06:35:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([28], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-126133-0003.json
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([280.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([322.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([365.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:453
T - mask_len:tensor([409.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 453, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-126133-0003
generate
 80%|███████▉  | 981/1232 [11:53<03:37,  1.15it/s]processing 981th semantic_sys file
981
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE JAP YOU'VE CAUGHT IT LAUGHED PERCY WHILE THE OTHERS SCREAMED AT THE SIGHT OF JASPER'S FACE
2024-04-02 06:35:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([28], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-126133-0017.json
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 270, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-126133-0017
generate
 80%|███████▉  | 982/1232 [11:54<03:23,  1.23it/s]processing 982th semantic_sys file
982
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEN DEAR SAID MISSUS WHITNEY YOU MUST BE KINDER TO HER THAN EVER THINK WHAT IT WOULD BE FOR ONE OF YOU TO BE AWAY FROM HOME EVEN AMONG FRIENDS
2024-04-02 06:35:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-126133-0002.json
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([254.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([340.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([386.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:479
T - mask_len:tensor([433.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 479, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-126133-0002
generate
 80%|███████▉  | 983/1232 [11:55<03:30,  1.18it/s]processing 983th semantic_sys file
983
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OH YOU ARE THE DEAREST AND BEST MISTER KING I EVER SAW BUT HOW DID YOU MAKE MAMMY LET HER COME
2024-04-02 06:35:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-126133-0010.json
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:296
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 296, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-126133-0010
generate
 80%|███████▉  | 984/1232 [11:56<03:26,  1.20it/s]processing 984th semantic_sys file
984
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OH SHE'S ALWAYS AT THE PIANO SAID VAN SHE MUST BE THERE NOW SOMEWHERE AND THEN SOMEBODY LAUGHED
2024-04-02 06:35:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-126133-0005.json
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([247.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([281.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:348
T - mask_len:tensor([314.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 348, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-126133-0005
generate
 80%|███████▉  | 985/1232 [11:57<03:26,  1.19it/s]processing 985th semantic_sys file
985
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE WAS SOMETHING INDIVIDUAL ABOUT THE GREAT FARM A MOST UNUSUAL TRIMNESS AND CARE FOR DETAIL
2024-04-02 06:35:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134493-0015.json
top_k_know_token:70
known_token_update:False
T:718
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:718
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:718
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:718
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:718
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:718
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:718
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:718
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:718
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:718
T - mask_len:tensor([320.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:718
T - mask_len:tensor([380.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:718
T - mask_len:tensor([444.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:718
T - mask_len:tensor([510.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:718
T - mask_len:tensor([578.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:718
T - mask_len:tensor([648.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 718, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134493-0015
generate
 80%|████████  | 986/1232 [11:58<04:03,  1.01it/s]processing 986th semantic_sys file
986
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HOW BROWN YOU'VE GOT SINCE YOU CAME HOME I WISH I HAD AN ATHLETE TO MOW MY ORCHARD
2024-04-02 06:35:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134493-0011.json
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([251.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([319.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 353, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134493-0011
generate
 80%|████████  | 987/1232 [11:59<03:52,  1.06it/s]processing 987th semantic_sys file
987
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ANY ONE THEREABOUTS WOULD HAVE TOLD YOU THAT THIS WAS ONE OF THE RICHEST FARMS ON THE DIVIDE AND THAT THE FARMER WAS A WOMAN ALEXANDRA BERGSON
2024-04-02 06:35:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134493-0017.json
top_k_know_token:70
known_token_update:False
T:552
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:552
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:552
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:552
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:552
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:552
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:552
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:552
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:552
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:552
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:552
T - mask_len:tensor([292.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:552
T - mask_len:tensor([341.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:552
T - mask_len:tensor([392.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:552
T - mask_len:tensor([445.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:552
T - mask_len:tensor([498.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 552, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134493-0017
generate
 80%|████████  | 988/1232 [12:00<04:15,  1.05s/it]processing 988th semantic_sys file
988
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HIS WIFE NOW LIES BESIDE HIM AND THE WHITE SHAFT THAT MARKS THEIR GRAVES GLEAMS ACROSS THE WHEAT FIELDS
2024-04-02 06:35:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134493-0001.json
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 284, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134493-0001
generate
 80%|████████  | 989/1232 [12:01<03:56,  1.03it/s]processing 989th semantic_sys file
989
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT IS SIXTEEN YEARS SINCE JOHN BERGSON DIED
2024-04-02 06:35:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134493-0000.json
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 178, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134493-0000
generate
 80%|████████  | 990/1232 [12:02<03:36,  1.12it/s]processing 990th semantic_sys file
990
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE AIR AND THE EARTH ARE CURIOUSLY MATED AND INTERMINGLED AS IF THE ONE WERE THE BREATH OF THE OTHER
2024-04-02 06:35:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134493-0004.json
top_k_know_token:70
known_token_update:False
T:376
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:376
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:376
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:376
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:376
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:376
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:376
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:376
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:376
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:376
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:376
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:376
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:376
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:376
T - mask_len:tensor([303.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:376
T - mask_len:tensor([340.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 376, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134493-0004
generate
 80%|████████  | 991/1232 [12:03<04:19,  1.08s/it]processing 991th semantic_sys file
991
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: INDEED HE HAD LOOKED AWAY WITH THE PURPOSE OF NOT SEEING IT
2024-04-02 06:35:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134493-0013.json
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 189, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134493-0013
generate
 81%|████████  | 992/1232 [12:04<03:50,  1.04it/s]processing 992th semantic_sys file
992
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE IS EVEN A WHITE ROW OF BEEHIVES IN THE ORCHARD UNDER THE WALNUT TREES
2024-04-02 06:35:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134493-0018.json
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:249
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 249, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134493-0018
generate
 81%|████████  | 993/1232 [12:04<03:33,  1.12it/s]processing 993th semantic_sys file
993
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT'S NOT MUCH OF A JOB FOR AN ATHLETE HERE I'VE BEEN TO TOWN AND BACK
2024-04-02 06:35:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134493-0006.json
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 231, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134493-0006
generate
 81%|████████  | 994/1232 [12:05<03:18,  1.20it/s]processing 994th semantic_sys file
994
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OH EVER SO MUCH ONLY HE SEEMS KIND OF STAID AND SCHOOL TEACHERY
2024-04-02 06:35:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([54], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134500-0021.json
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 196, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134500-0021
generate
 81%|████████  | 995/1232 [12:06<03:05,  1.28it/s]processing 995th semantic_sys file
995
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I CAN'T PLAY WITH YOU LIKE A LITTLE BOY ANY MORE HE SAID SLOWLY THAT'S WHAT YOU MISS MARIE
2024-04-02 06:35:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134500-0036.json
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 257, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134500-0036
generate
 81%|████████  | 996/1232 [12:06<02:54,  1.35it/s]processing 996th semantic_sys file
996
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHEN SHE USED TO TELL ME ABOUT HIM I ALWAYS WONDERED WHETHER SHE WASN'T A LITTLE IN LOVE WITH HIM
2024-04-02 06:35:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134500-0022.json
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([288.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 319, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134500-0022
generate
 81%|████████  | 997/1232 [12:07<02:57,  1.32it/s]processing 997th semantic_sys file
997
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT EMIL IF I UNDERSTAND THEN ALL OUR GOOD TIMES ARE OVER WE CAN NEVER DO NICE THINGS TOGETHER ANY MORE
2024-04-02 06:35:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134500-0037.json
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([247.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([280.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([313.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 347, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134500-0037
generate
 81%|████████  | 998/1232 [12:08<02:58,  1.31it/s]processing 998th semantic_sys file
998
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND EMIL MOWED HIS WAY SLOWLY DOWN TOWARD THE CHERRY TREES
2024-04-02 06:35:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134500-0014.json
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 241, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134500-0014
generate
 81%|████████  | 999/1232 [12:09<02:49,  1.37it/s]processing 999th semantic_sys file
999
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WISH YOU WEREN'T SO RESTLESS AND DIDN'T GET SO WORKED UP OVER THINGS SHE SAID SADLY
2024-04-02 06:35:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134500-0033.json
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:239
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 239, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134500-0033
generate
 81%|████████  | 1000/1232 [12:09<02:50,  1.36it/s]processing 1000th semantic_sys file
1000
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT WON'T LAST IT WILL GO AWAY AND THINGS WILL BE JUST AS THEY USED TO
2024-04-02 06:35:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134500-0039.json
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 192, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134500-0039
generate
 81%|████████▏ | 1001/1232 [12:10<02:45,  1.40it/s]processing 1001th semantic_sys file
1001
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I'M SURE ALEXANDRA HOPES YOU WILL STAY ON HERE SHE MURMURED
2024-04-02 06:35:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134500-0028.json
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:149
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 149, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134500-0028
generate
 81%|████████▏ | 1002/1232 [12:11<02:39,  1.44it/s]processing 1002th semantic_sys file
1002
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I PRAY FOR YOU BUT THAT'S NOT THE SAME AS IF YOU PRAYED YOURSELF
2024-04-02 06:35:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([27], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134500-0040.json
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 211, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134500-0040
generate
 81%|████████▏ | 1003/1232 [12:12<02:49,  1.35it/s]processing 1003th semantic_sys file
1003
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I GET TIRED OF SEEING MEN AND HORSES GOING UP AND DOWN UP AND DOWN
2024-04-02 06:35:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134500-0032.json
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:166
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 166, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134500-0032
generate
 81%|████████▏ | 1004/1232 [12:12<02:43,  1.40it/s]processing 1004th semantic_sys file
1004
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FRANK READ ENGLISH SLOWLY AND THE MORE HE READ ABOUT THIS DIVORCE CASE THE ANGRIER HE GREW
2024-04-02 06:35:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134500-0000.json
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:210
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 210, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134500-0000
generate
 82%|████████▏ | 1005/1232 [12:13<02:38,  1.44it/s]processing 1005th semantic_sys file
1005
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: JUST SMELL THE WILD ROSES THEY ARE ALWAYS SO SPICY AFTER A RAIN
2024-04-02 06:35:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134500-0006.json
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 178, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134500-0006
generate
 82%|████████▏ | 1006/1232 [12:14<02:36,  1.44it/s]processing 1006th semantic_sys file
1006
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I LIKE TO TALK TO CARL ABOUT NEW YORK AND WHAT A FELLOW CAN DO THERE
2024-04-02 06:35:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134500-0024.json
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([222.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:275
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 275, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134500-0024
generate
 82%|████████▏ | 1007/1232 [12:14<02:50,  1.32it/s]processing 1007th semantic_sys file
1007
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I CAN'T PRAY TO HAVE THE THINGS I WANT HE SAID SLOWLY AND I WON'T PRAY NOT TO HAVE THEM NOT IF I'M DAMNED FOR IT
2024-04-02 06:35:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134500-0041.json
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([258.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:320
T - mask_len:tensor([289.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 320, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134500-0041
generate
 82%|████████▏ | 1008/1232 [12:15<02:58,  1.26it/s]processing 1008th semantic_sys file
1008
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A BRISK WIND HAD COME UP AND WAS DRIVING PUFFY WHITE CLOUDS ACROSS THE SKY
2024-04-02 06:35:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_237-134500-0002.json
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 213, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_237-134500-0002
generate
 82%|████████▏ | 1009/1232 [12:16<02:50,  1.31it/s]processing 1009th semantic_sys file
1009
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY REGAINED THEIR APARTMENT APPARENTLY WITHOUT DISTURBING THE HOUSEHOLD OF GAMEWELL
2024-04-02 06:35:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0040.json
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 218, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0040
generate
 82%|████████▏ | 1010/1232 [12:17<02:46,  1.34it/s]processing 1010th semantic_sys file
1010
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: STUTELEY WAS BY HIS SIDE IN A FLASH AND THEN THEY BOTH BEGAN FEELING ABOUT THEM TO ASCERTAIN THE SHAPE AND CHARACTER OF THIS VAULT
2024-04-02 06:35:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0028.json
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([338.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([384.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:476
T - mask_len:tensor([430.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 476, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0028
generate
 82%|████████▏ | 1011/1232 [12:18<02:58,  1.24it/s]processing 1011th semantic_sys file
1011
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WARRENTON SPOKE THUS WITH SIGNIFICANCE TO SHOW ROBIN THAT HE WAS NOT TO THINK GEOFFREY'S CLAIMS TO THE ESTATE WOULD BE PASSED BY
2024-04-02 06:35:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0035.json
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([321.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([359.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 398, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0035
generate
 82%|████████▏ | 1012/1232 [12:19<03:06,  1.18it/s]processing 1012th semantic_sys file
1012
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE HOURS PASSED WEARILY BY AND MOVEMENT COULD YET BE HEARD ABOUT THE HALL
2024-04-02 06:35:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 1013th semantic_sys file
1013
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FROM THE BLACKNESS BEHIND THE LIGHT THEY HEARD A VOICE WARRENTON'S
2024-04-02 06:35:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([60], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0029.json
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 245, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0029
generate
 82%|████████▏ | 1014/1232 [12:19<02:14,  1.62it/s]processing 1014th semantic_sys file
1014
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ROBIN CAREFULLY DESCENDED THE LADDER AND FOUND HIMSELF SOON UPON FIRM ROCKY GROUND
2024-04-02 06:35:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0027.json
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 191, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0027
generate
 82%|████████▏ | 1015/1232 [12:20<02:14,  1.62it/s]processing 1015th semantic_sys file
1015
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE IMPLORES US TO BE DISCREET AS THE GRAVE IN THIS MATTER FOR IN SOOTH HIS LIFE IS IN THE HOLLOW OF OUR HANDS
2024-04-02 06:35:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0039.json
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:325
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 325, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0039
generate
 82%|████████▏ | 1016/1232 [12:21<02:29,  1.44it/s]processing 1016th semantic_sys file
1016
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY THEN RENEWED THEIR JOURNEY AND UNDER THE BETTER LIGHT MADE A SAFE CROSSING OF THE STABLE ROOFS
2024-04-02 06:35:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0021.json
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:270
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 270, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0021
generate
 83%|████████▎ | 1017/1232 [12:22<02:34,  1.39it/s]processing 1017th semantic_sys file
1017
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HIS TONES RANG PLEASANTLY ON WARRENTON'S EARS AND FORTHWITH A GOOD FELLOWSHIP WAS HERALDED BETWEEN THEM
2024-04-02 06:35:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0037.json
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([261.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:324
T - mask_len:tensor([293.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 324, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0037
generate
 83%|████████▎ | 1018/1232 [12:23<02:50,  1.25it/s]processing 1018th semantic_sys file
1018
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FITZOOTH'S HAND RESTED AT LAST UPON THE TOP RUNG OF A LADDER AND SLOWLY THE TRUTH CAME TO HIM
2024-04-02 06:35:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0026.json
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([301.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:373
T - mask_len:tensor([337.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 373, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0026
generate
 83%|████████▎ | 1019/1232 [12:24<02:51,  1.24it/s]processing 1019th semantic_sys file
1019
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ROBIN FITZOOTH SAW THAT HIS DOUBTS OF WARRENTON HAD BEEN UNFAIR AND HE BECAME ASHAMED OF HIMSELF FOR HARBORING THEM
2024-04-02 06:35:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0036.json
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([281.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([315.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 349, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0036
generate
 83%|████████▎ | 1020/1232 [12:24<02:50,  1.25it/s]processing 1020th semantic_sys file
1020
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MOST OF ALL ROBIN THOUGHT OF HIS FATHER WHAT WOULD HE COUNSEL
2024-04-02 06:35:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0002.json
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 211, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0002
generate
 83%|████████▎ | 1021/1232 [12:25<02:40,  1.32it/s]processing 1021th semantic_sys file
1021
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AS ANY IN ENGLAND I WOULD SAY SAID GAMEWELL PROUDLY THAT IS IN HIS DAY
2024-04-02 06:35:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0011.json
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:297
T - mask_len:tensor([268.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 297, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0011
generate
 83%|████████▎ | 1022/1232 [12:26<02:36,  1.34it/s]processing 1022th semantic_sys file
1022
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WILL WHISPERED ROBIN OPENING HIS DOOR AS HE SPOKE ARE YOU READY
2024-04-02 06:35:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([54], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0020.json
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 153, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0020
generate
 83%|████████▎ | 1023/1232 [12:26<02:30,  1.39it/s]processing 1023th semantic_sys file
1023
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY MOVED THEREAFTER CAUTIOUSLY ABOUT THE HUT GROPING BEFORE AND ABOUT THEM TO FIND SOMETHING TO SHOW THAT WARRENTON HAD FULFILLED HIS MISSION
2024-04-02 06:35:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0024.json
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([302.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([359.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([420.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([482.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([547.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([613.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 679, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0024
generate
 83%|████████▎ | 1024/1232 [12:27<02:46,  1.25it/s]processing 1024th semantic_sys file
1024
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE WAS IN DEEP CONVERSE WITH THE CLERK AND ENTERED THE HALL HOLDING HIM BY THE ARM
2024-04-02 06:35:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0007.json
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:322
T - mask_len:tensor([291.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 322, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0007
generate
 83%|████████▎ | 1025/1232 [12:28<02:48,  1.23it/s]processing 1025th semantic_sys file
1025
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NAY NAY LORDING ANSWERED WARRENTON WITH A HALF LAUGH
2024-04-02 06:35:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0034.json
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:153
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 153, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0034
generate
 83%|████████▎ | 1026/1232 [12:29<02:35,  1.33it/s]processing 1026th semantic_sys file
1026
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE BEFELL AN ANXIOUS INTERVIEW MISTRESS FITZOOTH ARGUING FOR AND AGAINST THE SQUIRE'S PROJECT IN A BREATH
2024-04-02 06:35:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0001.json
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 307, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0001
generate
 83%|████████▎ | 1027/1232 [12:30<02:40,  1.27it/s]processing 1027th semantic_sys file
1027
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY WERE UPON THE VERGE OF AN OPEN TRAP IN THE FAR CORNER OF THE HUT AND STUTELEY HAD TRIPPED OVER THE EDGE OF THE REVERSED FLAP MOUTH OF THIS PIT
2024-04-02 06:35:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([26], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0025.json
top_k_know_token:70
known_token_update:False
T:504
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:504
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:504
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:504
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:504
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:504
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:504
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:504
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:504
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:504
T - mask_len:tensor([224.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:504
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:504
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:504
T - mask_len:tensor([358.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:504
T - mask_len:tensor([406.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:504
T - mask_len:tensor([455.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 504, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0025
generate
 83%|████████▎ | 1028/1232 [12:31<02:54,  1.17it/s]processing 1028th semantic_sys file
1028
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE WILL GO OUT TOGETHER TO THE BOWER THERE IS A WAY DOWN TO THE COURT FROM MY WINDOW
2024-04-02 06:35:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0016.json
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 250, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0016
generate
 84%|████████▎ | 1029/1232 [12:31<02:45,  1.23it/s]processing 1029th semantic_sys file
1029
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: CRIED HE WAVING THE LANTHORN BEFORE HIM TO MAKE SURE THAT THESE WERE NO GHOSTS IN FRONT OF HIM
2024-04-02 06:35:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0031.json
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([276.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 305, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0031
generate
 84%|████████▎ | 1030/1232 [12:32<02:52,  1.17it/s]processing 1030th semantic_sys file
1030
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WILL CRIED HE SOFTLY AND STUTELEY WHO HAD CHOSEN HIS COUCH ACROSS THE DOOR OF HIS YOUNG MASTER'S CHAMBER SPRANG UP AT ONCE IN ANSWER
2024-04-02 06:35:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0015.json
top_k_know_token:70
known_token_update:False
T:488
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:488
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:488
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:488
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:488
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:488
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:488
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:488
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:488
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:488
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:488
T - mask_len:tensor([258.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:488
T - mask_len:tensor([302.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:488
T - mask_len:tensor([347.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:488
T - mask_len:tensor([393.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:488
T - mask_len:tensor([441.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 488, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0015
generate
 84%|████████▎ | 1031/1232 [12:33<03:01,  1.10it/s]processing 1031th semantic_sys file
1031
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOUNG FITZOOTH HAD BEEN COMMANDED TO HIS MOTHER'S CHAMBER SO SOON AS HE HAD COME OUT FROM HIS CONVERSE WITH THE SQUIRE
2024-04-02 06:35:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0000.json
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:351
T - mask_len:tensor([317.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 351, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0000
generate
 84%|████████▍ | 1032/1232 [12:34<03:00,  1.11it/s]processing 1032th semantic_sys file
1032
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE WAS NO CHANCE TO ALTER HIS SLEEPING ROOM TO ONE NEARER TO GAMEWELL'S CHAMBER
2024-04-02 06:35:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70970-0013.json
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([264.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 327, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70970-0013
generate
 84%|████████▍ | 1033/1232 [12:35<03:01,  1.10it/s]processing 1033th semantic_sys file
1033
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHAT IS YOUR NAME LORDING ASKED THE LITTLE STROLLER PRESENTLY
2024-04-02 06:35:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0037.json
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 138, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0037
generate
 84%|████████▍ | 1034/1232 [12:36<02:43,  1.21it/s]processing 1034th semantic_sys file
1034
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU ARE A WORTHY LEECH WILL PRESENTLY WHISPERED ROBIN THE WINE HAS WORKED A MARVEL
2024-04-02 06:35:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0061.json
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:226
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 226, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0061
generate
 84%|████████▍ | 1035/1232 [12:37<02:48,  1.17it/s]processing 1035th semantic_sys file
1035
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SPOKE THE SQUIRE LOSING ALL PATIENCE AND IT WAS TO YOU THAT I GAVE ANOTHER PURSE IN CONSOLATION
2024-04-02 06:35:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([25], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0024.json
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([224.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([251.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 278, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0024
generate
 84%|████████▍ | 1036/1232 [12:37<02:40,  1.22it/s]processing 1036th semantic_sys file
1036
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS WAS SO SWEET A LADY SIR AND IN SOME MANNER I DO THINK SHE DIED
2024-04-02 06:35:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0005.json
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:241
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 241, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0005
generate
 84%|████████▍ | 1037/1232 [12:38<02:40,  1.21it/s]processing 1037th semantic_sys file
1037
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BEFORE THEM FLED THE STROLLER AND HIS THREE SONS CAPLESS AND TERRIFIED
2024-04-02 06:35:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0013.json
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 274, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0013
generate
 84%|████████▍ | 1038/1232 [12:39<02:35,  1.24it/s]processing 1038th semantic_sys file
1038
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE BEGAN A CONFUSED COMPLAINT AGAINST THE WIZARD WHO HAD VANISHED BEHIND THE CURTAIN ON THE LEFT
2024-04-02 06:35:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0000.json
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 293, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0000
generate
 84%|████████▍ | 1039/1232 [12:40<02:35,  1.24it/s]processing 1039th semantic_sys file
1039
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHAT IS THE TUMULT AND RIOTING CRIED OUT THE SQUIRE AUTHORITATIVELY AND HE BLEW TWICE ON A SILVER WHISTLE WHICH HUNG AT HIS BELT
2024-04-02 06:35:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0014.json
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([302.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([343.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([384.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 425, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0014
generate
 84%|████████▍ | 1040/1232 [12:41<02:41,  1.19it/s]processing 1040th semantic_sys file
1040
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE MADE AN EFFORT TO HIDE HIS CONDITION FROM THEM ALL AND ROBIN FELT HIS FINGERS TIGHTEN UPON HIS ARM
2024-04-02 06:35:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0050.json
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 293, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0050
generate
 84%|████████▍ | 1041/1232 [12:42<02:37,  1.21it/s]processing 1041th semantic_sys file
1041
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: LIKE AS NOT YOUNG MASTER THOUGH I AM AN OLD MAN
2024-04-02 06:35:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([56], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0009.json
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 161, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0009
generate
 85%|████████▍ | 1042/1232 [12:42<02:23,  1.32it/s]processing 1042th semantic_sys file
1042
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE IS MY ESQUIRE EXCELLENCY RETURNED ROBIN WITH DIGNITY
2024-04-02 06:35:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0053.json
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 222, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0053
generate
 85%|████████▍ | 1043/1232 [12:43<02:17,  1.37it/s]processing 1043th semantic_sys file
1043
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THESE ESCAPADES ARE NOT FOR OLD GAMEWELL LAD HIS DAY HAS COME TO TWILIGHT
2024-04-02 06:35:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0057.json
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 252, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0057
generate
 85%|████████▍ | 1044/1232 [12:44<02:16,  1.38it/s]processing 1044th semantic_sys file
1044
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: COME TO ME MEN HERE HERE HE RAISED HIS VOICE STILL LOUDER
2024-04-02 06:35:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:35:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0025.json
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 185, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0025
generate
 85%|████████▍ | 1045/1232 [12:44<02:13,  1.41it/s]processing 1045th semantic_sys file
1045
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT IS ENOUGH SAID GEORGE GAMEWELL SHARPLY AND HE TURNED UPON THE CROWD
2024-04-02 06:36:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([53], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0019.json
top_k_know_token:70
known_token_update:False
T:385
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:385
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:385
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:385
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:385
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:385
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:385
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:385
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:385
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:385
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:385
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:385
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:385
T - mask_len:tensor([274.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:385
T - mask_len:tensor([310.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:385
T - mask_len:tensor([348.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 385, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0019
generate
 85%|████████▍ | 1046/1232 [12:45<02:23,  1.29it/s]processing 1046th semantic_sys file
1046
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A MONTFICHET A MONTFICHET GAMEWELL TO THE RESCUE
2024-04-02 06:36:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([56], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0034.json
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([224.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:278
T - mask_len:tensor([251.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 278, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0034
generate
 85%|████████▍ | 1047/1232 [12:46<02:21,  1.31it/s]processing 1047th semantic_sys file
1047
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TAKING ADVANTAGE OF THIS THE SQUIRE'S FEW MEN REDOUBLED THEIR EFFORTS AND ENCOURAGED BY ROBIN'S AND THE LITTLE STROLLER'S CRIES FOUGHT THEIR WAY TO HIM
2024-04-02 06:36:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0035.json
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([284.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([326.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([370.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:459
T - mask_len:tensor([415.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 459, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0035
generate
 85%|████████▌ | 1048/1232 [12:47<02:30,  1.22it/s]processing 1048th semantic_sys file
1048
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I LIKE YOU WILL YOU ARE THE SECOND WILL THAT I HAVE MET AND LIKED WITHIN TWO DAYS IS THERE A SIGN IN THAT
2024-04-02 06:36:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([27], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0041.json
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:310
T - mask_len:tensor([280.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 310, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0041
generate
 85%|████████▌ | 1049/1232 [12:48<02:30,  1.22it/s]processing 1049th semantic_sys file
1049
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHAME ON YOU CITIZENS CRIED HE I BLUSH FOR MY FELLOWS OF NOTTINGHAM
2024-04-02 06:36:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([54], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0020.json
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([298.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:370
T - mask_len:tensor([334.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 370, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0020
generate
 85%|████████▌ | 1050/1232 [12:49<02:35,  1.17it/s]processing 1050th semantic_sys file
1050
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE GAVE WAY TO THE OTHERS VERY READILY AND RETREATED UNPERCEIVED BY THE SQUIRE AND MISTRESS FITZOOTH TO THE REAR OF THE TENT
2024-04-02 06:36:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0011.json
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([326.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([369.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:458
T - mask_len:tensor([414.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 458, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0011
generate
 85%|████████▌ | 1051/1232 [12:50<02:40,  1.13it/s]processing 1051th semantic_sys file
1051
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NOW BE SILENT ON YOUR LIVES HE BEGAN BUT THE CAPTURED APPRENTICE SET UP AN INSTANT SHOUT
2024-04-02 06:36:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([24], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0030.json
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([324.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:402
T - mask_len:tensor([363.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 402, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0030
generate
 85%|████████▌ | 1052/1232 [12:51<02:44,  1.09it/s]processing 1052th semantic_sys file
1052
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT I WRESTLED WITH THIS FELLOW AND DO KNOW THAT HE PLAYED UNFAIRLY IN THE SECOND BOUT
2024-04-02 06:36:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([27], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0023.json
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:290
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 290, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0023
generate
 85%|████████▌ | 1053/1232 [12:51<02:35,  1.15it/s]processing 1053th semantic_sys file
1053
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE HEAD AND CHIEF OF THE RIOT THE NOTTINGHAM APPRENTICE WITH CLENCHED FISTS THREATENED MONTFICHET
2024-04-02 06:36:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0028.json
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:293
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 293, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0028
generate
 86%|████████▌ | 1054/1232 [12:52<02:30,  1.18it/s]processing 1054th semantic_sys file
1054
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MASTER MONCEUX THE SHERIFF OF NOTTINGHAM WAS MIGHTILY PUT ABOUT WHEN TOLD OF THE RIOTING
2024-04-02 06:36:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0047.json
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([273.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:338
T - mask_len:tensor([305.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 338, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0047
generate
 86%|████████▌ | 1055/1232 [12:53<02:25,  1.22it/s]processing 1055th semantic_sys file
1055
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE WAS LIKE UNTO MY FATHER IN A WAY AND YET WAS NOT MY FATHER
2024-04-02 06:36:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0003.json
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 232, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0003
generate
 86%|████████▌ | 1056/1232 [12:54<02:15,  1.30it/s]processing 1056th semantic_sys file
1056
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FRIENDS SAID MONTFICHET FAINTLY TO THE WRESTLERS BEAR US ESCORT SO FAR AS THE SHERIFF'S HOUSE
2024-04-02 06:36:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0043.json
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:301
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 301, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0043
generate
 86%|████████▌ | 1057/1232 [12:54<02:16,  1.28it/s]processing 1057th semantic_sys file
1057
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TIS FINE FOR YOU TO TALK OLD MAN ANSWERED THE LEAN SULLEN APPRENTICE
2024-04-02 06:36:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0022.json
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:231
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 231, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0022
generate
 86%|████████▌ | 1058/1232 [12:55<02:09,  1.34it/s]processing 1058th semantic_sys file
1058
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THRUSTING OPEN THE PROPER ENTRANCE OF THE TENT ROBIN SUDDENLY RUSHED FORTH WITH HIS BURDEN WITH A GREAT SHOUT
2024-04-02 06:36:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0033.json
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([299.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:421
T - mask_len:tensor([380.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 421, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0033
generate
 86%|████████▌ | 1059/1232 [12:56<02:23,  1.20it/s]processing 1059th semantic_sys file
1059
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HAVE YOUR WILL CHILD IF THE BOY ALSO WILLS IT MONTFICHET ANSWERED FEELING TOO ILL TO OPPOSE ANYTHING VERY STRONGLY JUST THEN
2024-04-02 06:36:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([56], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0049.json
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([321.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:398
T - mask_len:tensor([359.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 398, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0049
generate
 86%|████████▌ | 1060/1232 [12:57<02:22,  1.21it/s]processing 1060th semantic_sys file
1060
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I COULD NOT SEE MY BOY INJURED EXCELLENCE FOR BUT DOING HIS DUTY AS ONE OF CUMBERLAND'S SONS
2024-04-02 06:36:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0017.json
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([241.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 267, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0017
generate
 86%|████████▌ | 1061/1232 [12:58<02:15,  1.26it/s]processing 1061th semantic_sys file
1061
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FORTHWITH ALL RAN TO THE OPENING OF THE TENT TO SEE WHAT MIGHT BE AMISS BUT MASTER WILL WHO PEEPED OUT FIRST NEEDED NO MORE THAN ONE GLANCE
2024-04-02 06:36:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0010.json
top_k_know_token:70
known_token_update:False
T:454
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:454
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:454
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:454
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:454
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:454
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:454
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:454
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:454
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:454
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:454
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:454
T - mask_len:tensor([281.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:454
T - mask_len:tensor([323.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:454
T - mask_len:tensor([366.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:454
T - mask_len:tensor([410.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 454, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0010
generate
 86%|████████▌ | 1062/1232 [12:59<02:22,  1.19it/s]processing 1062th semantic_sys file
1062
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ROBIN AND THE LITTLE TUMBLER BETWEEN THEM TRIED TO FORCE THE SQUIRE TO STAND BACK AND VERY VALIANTLY DID THESE TWO COMPORT THEMSELVES
2024-04-02 06:36:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0027.json
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([225.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([302.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([343.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:425
T - mask_len:tensor([384.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 425, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0027
generate
 86%|████████▋ | 1063/1232 [12:59<02:25,  1.16it/s]processing 1063th semantic_sys file
1063
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NAY WE REFUSED THEIR REQUEST MOST POLITELY MOST NOBLE SAID THE LITTLE STROLLER
2024-04-02 06:36:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0015.json
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 291, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0015
generate
 86%|████████▋ | 1064/1232 [13:00<02:23,  1.17it/s]processing 1064th semantic_sys file
1064
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MISTRESS FITZOOTH HAD BEEN CARRIED OFF BY THE SHERIFF'S DAUGHTER AND HER MAIDS AS SOON AS THEY HAD ENTERED THE HOUSE SO THAT ROBIN ALONE HAD THE CARE OF MONTFICHET
2024-04-02 06:36:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([61], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0054.json
top_k_know_token:70
known_token_update:False
T:452
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:452
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:452
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:452
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:452
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:452
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:452
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:452
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:452
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:452
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:452
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:452
T - mask_len:tensor([280.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:452
T - mask_len:tensor([321.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:452
T - mask_len:tensor([364.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:452
T - mask_len:tensor([408.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 452, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0054
generate
 86%|████████▋ | 1065/1232 [13:01<02:30,  1.11it/s]processing 1065th semantic_sys file
1065
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE STROLLERS TOOK THEIR PART IN IT WITH HEARTY ZEST NOW THAT THEY HAD SOME CHANCE OF BEATING OFF THEIR FOES
2024-04-02 06:36:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0026.json
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([264.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:327
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 327, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0026
generate
 87%|████████▋ | 1066/1232 [13:02<02:24,  1.15it/s]processing 1066th semantic_sys file
1066
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE FELT FOR AND FOUND THE WIZARD'S BLACK CLOTH THE SQUIRE WAS QUITE OUT OF BREATH
2024-04-02 06:36:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_61-70968-0032.json
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([222.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:312
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 312, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_61-70968-0032
generate
 87%|████████▋ | 1067/1232 [13:03<02:24,  1.15it/s]processing 1067th semantic_sys file
1067
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NOW WHEN HAS HORROR EVER EXCLUDED STUDY
2024-04-02 06:36:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0014.json
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:139
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 139, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0014
generate
 87%|████████▋ | 1068/1232 [13:04<02:13,  1.23it/s]processing 1068th semantic_sys file
1068
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE IS HARDLY ONE DAY OUT OF A HUNDRED WHICH IS WHOLLY JOYOUS AND SUNNY
2024-04-02 06:36:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0049.json
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:185
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 185, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0049
generate
 87%|████████▋ | 1069/1232 [13:04<02:04,  1.31it/s]processing 1069th semantic_sys file
1069
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TO DIMINISH THE NUMBER OF THE SHADY TO AUGMENT THE NUMBER OF THE LUMINOUS THAT IS THE OBJECT
2024-04-02 06:36:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([14], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0053.json
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 307, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0053
generate
 87%|████████▋ | 1070/1232 [13:05<02:07,  1.27it/s]processing 1070th semantic_sys file
1070
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TO TEACH READING MEANS TO LIGHT THE FIRE EVERY SYLLABLE SPELLED OUT SPARKLES
2024-04-02 06:36:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0055.json
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:252
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 252, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0055
generate
 87%|████████▋ | 1071/1232 [13:06<02:03,  1.30it/s]processing 1071th semantic_sys file
1071
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TO BURN WITHOUT CEASING TO FLY THEREIN LIES THE MARVEL OF GENIUS
2024-04-02 06:36:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0059.json
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:222
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 222, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0059
generate
 87%|████████▋ | 1072/1232 [13:07<02:00,  1.33it/s]processing 1072th semantic_sys file
1072
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE REAL HUMAN DIVISION IS THIS THE LUMINOUS AND THE SHADY
2024-04-02 06:36:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([26], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0052.json
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:177
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 177, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0052
generate
 87%|████████▋ | 1073/1232 [13:07<02:00,  1.32it/s]processing 1073th semantic_sys file
1073
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN THIS WORLD EVIDENTLY THE VESTIBULE OF ANOTHER THERE ARE NO FORTUNATE
2024-04-02 06:36:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0051.json
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 218, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0051
generate
 87%|████████▋ | 1074/1232 [13:08<01:56,  1.36it/s]processing 1074th semantic_sys file
1074
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHY SHOULD ONE NOT EXPLORE EVERYTHING AND STUDY EVERYTHING
2024-04-02 06:36:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([24], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0011.json
top_k_know_token:70
known_token_update:False
T:170
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:170
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:170
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:170
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:170
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:170
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:170
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:170
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:170
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:170
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:170
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:170
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:170
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:170
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:170
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 170, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0011
generate
 87%|████████▋ | 1075/1232 [13:09<01:55,  1.36it/s]processing 1075th semantic_sys file
1075
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE HAVE NEVER UNDERSTOOD THIS SORT OF OBJECTIONS
2024-04-02 06:36:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0005.json
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:138
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 138, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0005
generate
 87%|████████▋ | 1076/1232 [13:09<01:55,  1.35it/s]processing 1076th semantic_sys file
1076
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT IS SO MADE THAT EVERYWHERE WE FEEL THE SENSE OF PUNISHMENT
2024-04-02 06:36:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0045.json
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([271.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([304.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 336, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0045
generate
 87%|████████▋ | 1077/1232 [13:10<01:55,  1.34it/s]processing 1077th semantic_sys file
1077
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: EACH DAY HAS ITS OWN GREAT GRIEF OR ITS LITTLE CARE
2024-04-02 06:36:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0046.json
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:218
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 218, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0046
generate
 88%|████████▊ | 1078/1232 [13:11<01:49,  1.41it/s]processing 1078th semantic_sys file
1078
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE IS THE SLANG OF THE AFFECTED LADY AS WELL AS OF THE PRECIEUSES
2024-04-02 06:36:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0022.json
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:223
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 223, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0022
generate
 88%|████████▊ | 1079/1232 [13:12<01:57,  1.31it/s]processing 1079th semantic_sys file
1079
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT IS WHY WE CRY EDUCATION SCIENCE
2024-04-02 06:36:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([12], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0054.json
top_k_know_token:70
known_token_update:False
T:121
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:121
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:121
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:121
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:121
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:121
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:121
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:121
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:121
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:121
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:121
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:121
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:121
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:121
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:121
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 121, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0054
generate
 88%|████████▊ | 1080/1232 [13:12<01:48,  1.40it/s]processing 1080th semantic_sys file
1080
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TO MEET THE NEEDS OF THIS CONFLICT WRETCHEDNESS HAS INVENTED A LANGUAGE OF COMBAT WHICH IS SLANG
2024-04-02 06:36:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([20], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0025.json
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([320.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([359.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 397, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0025
generate
 88%|████████▊ | 1081/1232 [13:13<01:59,  1.26it/s]processing 1081th semantic_sys file
1081
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE IT CLOTHES ITSELF IN WORD MASKS IN METAPHOR RAGS
2024-04-02 06:36:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0037.json
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:283
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 283, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0037
generate
 88%|████████▊ | 1082/1232 [13:14<01:52,  1.34it/s]processing 1082th semantic_sys file
1082
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TRUE HISTORY BEING A MIXTURE OF ALL THINGS THE TRUE HISTORIAN MINGLES IN EVERYTHING
2024-04-02 06:36:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([27], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0035.json
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:266
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 266, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0035
generate
 88%|████████▊ | 1083/1232 [13:15<01:52,  1.32it/s]processing 1083th semantic_sys file
1083
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE HAS A SON THEFT AND A DAUGHTER HUNGER
2024-04-02 06:36:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([25], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0003.json
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:147
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 147, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0003
generate
 88%|████████▊ | 1084/1232 [13:15<01:45,  1.40it/s]processing 1084th semantic_sys file
1084
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DO WE REALLY KNOW THE MOUNTAIN WELL WHEN WE ARE NOT ACQUAINTED WITH THE CAVERN
2024-04-02 06:36:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([20], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0033.json
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:171
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 171, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0033
generate
 88%|████████▊ | 1085/1232 [13:16<01:49,  1.34it/s]processing 1085th semantic_sys file
1085
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: PEOPLE SUFFER IN THE LIGHT EXCESS BURNS
2024-04-02 06:36:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0057.json
top_k_know_token:70
known_token_update:False
T:142
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:142
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:142
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:142
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:142
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:142
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:142
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:142
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:142
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:142
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:142
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:142
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:142
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:142
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:142
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 142, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0057
generate
 88%|████████▊ | 1086/1232 [13:17<01:41,  1.44it/s]processing 1086th semantic_sys file
1086
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HOWEVER HE WHO SAYS LIGHT DOES NOT NECESSARILY SAY JOY
2024-04-02 06:36:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([16], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0056.json
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:225
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 225, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0056
generate
 88%|████████▊ | 1087/1232 [13:17<01:41,  1.43it/s]processing 1087th semantic_sys file
1087
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS WITHOUT RECKONING IN THE PAINS OF THE HEART AND SO IT GOES ON
2024-04-02 06:36:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0048.json
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:195
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 195, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0048
generate
 88%|████████▊ | 1088/1232 [13:18<01:39,  1.45it/s]processing 1088th semantic_sys file
1088
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FACTS FORM ONE OF THESE AND IDEAS THE OTHER
2024-04-02 06:36:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([26], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0036.json
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 164, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0036
generate
 88%|████████▊ | 1089/1232 [13:19<01:43,  1.38it/s]processing 1089th semantic_sys file
1089
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ALGEBRA MEDICINE BOTANY HAVE EACH THEIR SLANG
2024-04-02 06:36:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([23], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4507-16021-0024.json
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:178
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 178, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4507-16021-0024
generate
 88%|████████▊ | 1090/1232 [13:20<01:39,  1.42it/s]processing 1090th semantic_sys file
1090
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT THE MORE FORGETFULNESS HAD THEN PREVAILED THE MORE POWERFUL WAS THE FORCE OF REMEMBRANCE WHEN SHE AWOKE
2024-04-02 06:36:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-23283-0000.json
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([224.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([254.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 315, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-23283-0000
generate
 89%|████████▊ | 1091/1232 [13:21<01:50,  1.28it/s]processing 1091th semantic_sys file
1091
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MY LORD MISS MILNER'S TASTE IS NOT A DEPRAVED ONE IT IS BUT TOO REFINED
2024-04-02 06:36:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-23283-0013.json
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 258, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-23283-0013
generate
 89%|████████▊ | 1092/1232 [13:21<01:48,  1.29it/s]processing 1092th semantic_sys file
1092
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IF SHE DOES NOT KNOW HOW TO ESTIMATE HER OWN VALUE I DO
2024-04-02 06:36:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-23283-0011.json
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:186
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 186, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-23283-0011
generate
 89%|████████▊ | 1093/1232 [13:22<01:48,  1.28it/s]processing 1093th semantic_sys file
1093
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AGAIN HE SEARCHED HIS OWN THOUGHTS NOR INEFFECTUALLY AS BEFORE
2024-04-02 06:36:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-23283-0016.json
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 182, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-23283-0016
generate
 89%|████████▉ | 1094/1232 [13:23<01:48,  1.28it/s]processing 1094th semantic_sys file
1094
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHAT CAN YOU MEAN BY THAT MISS WOODLEY YOU TALK MYSTERIOUSLY
2024-04-02 06:36:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-23283-0014.json
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:258
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 258, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-23283-0014
generate
 89%|████████▉ | 1095/1232 [13:24<01:45,  1.30it/s]processing 1095th semantic_sys file
1095
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND YET YOU MUST OWN HER BEHAVIOUR HAS WARRANTED THEM HAS IT NOT BEEN IN THIS PARTICULAR INCOHERENT AND UNACCOUNTABLE
2024-04-02 06:36:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-23283-0004.json
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([262.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([297.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:368
T - mask_len:tensor([332.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 368, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-23283-0004
generate
 89%|████████▉ | 1096/1232 [13:24<01:44,  1.30it/s]processing 1096th semantic_sys file
1096
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SO THERE IS TO ME ADDED SANDFORD WITH A SARCASTIC SNEER
2024-04-02 06:36:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-23283-0003.json
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:194
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 194, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-23283-0003
generate
 89%|████████▉ | 1097/1232 [13:25<01:39,  1.35it/s]processing 1097th semantic_sys file
1097
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TO ASK ANY MORE QUESTIONS OF YOU I BELIEVE WOULD BE UNFAIR
2024-04-02 06:36:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-23283-0007.json
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:191
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 191, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-23283-0007
generate
 89%|████████▉ | 1098/1232 [13:26<01:38,  1.36it/s]processing 1098th semantic_sys file
1098
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT IN SUCH A CASE MISS MILNER'S ELECTION OF A HUSBAND SHALL NOT DIRECT MINE
2024-04-02 06:36:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-23283-0010.json
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:365
T - mask_len:tensor([330.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 365, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-23283-0010
generate
 89%|████████▉ | 1099/1232 [13:27<01:40,  1.32it/s]processing 1099th semantic_sys file
1099
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WILL MAKE NO UNJUST USE OF WHAT I KNOW HE REPLIED WITH FIRMNESS I BELIEVE YOU MY LORD
2024-04-02 06:36:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-23283-0019.json
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:282
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 282, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-23283-0019
generate
 89%|████████▉ | 1100/1232 [13:27<01:36,  1.36it/s]processing 1100th semantic_sys file
1100
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TO RELIEVE HER FROM BOTH HE LAID HIS HAND WITH FORCE UPON HIS HEART AND SAID DO YOU BELIEVE ME
2024-04-02 06:36:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-23283-0018.json
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:292
T - mask_len:tensor([264.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 292, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-23283-0018
generate
 89%|████████▉ | 1101/1232 [13:28<01:35,  1.37it/s]processing 1101th semantic_sys file
1101
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE SEEMED TO WAIT FOR HER REPLY BUT AS SHE MADE NONE HE PROCEEDED
2024-04-02 06:36:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-23283-0008.json
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 199, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-23283-0008
generate
 89%|████████▉ | 1102/1232 [13:29<01:31,  1.43it/s]processing 1102th semantic_sys file
1102
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OH MY LORD CRIED MISS WOODLEY WITH A MOST FORCIBLE ACCENT YOU ARE THE LAST PERSON ON EARTH SHE WOULD PARDON ME FOR ENTRUSTING
2024-04-02 06:36:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-23283-0009.json
top_k_know_token:70
known_token_update:False
T:523
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:523
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:523
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:523
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:523
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:523
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:523
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:523
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:523
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:523
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:523
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:523
T - mask_len:tensor([323.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:523
T - mask_len:tensor([372.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:523
T - mask_len:tensor([421.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:523
T - mask_len:tensor([472.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 523, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-23283-0009
generate
 90%|████████▉ | 1103/1232 [13:30<01:41,  1.27it/s]processing 1103th semantic_sys file
1103
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: KATHLEEN WAVED THE TORCH TO AND FRO AS SHE RECITED SOME BEAUTIFUL LINES WRITTEN FOR SOME SUCH PURPOSE AS THAT WHICH CALLED THEM TOGETHER TO NIGHT
2024-04-02 06:36:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41806-0003.json
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([347.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:431
T - mask_len:tensor([389.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 431, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41806-0003
generate
 90%|████████▉ | 1104/1232 [13:30<01:43,  1.24it/s]processing 1104th semantic_sys file
1104
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AT THAT MOMENT THE GENTLEMAN ENTERED BEARING A HUGE OBJECT CONCEALED BY A PIECE OF GREEN FELT
2024-04-02 06:36:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41806-0012.json
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:284
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 284, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41806-0012
generate
 90%|████████▉ | 1105/1232 [13:31<01:38,  1.29it/s]processing 1105th semantic_sys file
1105
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TO NIGHT THERE WAS NO NEED OF EXTRA HEAT AND THERE WERE GREAT CEREMONIES TO BE OBSERVED IN LIGHTING THE FIRES ON THE HEARTHSTONES
2024-04-02 06:36:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41806-0001.json
top_k_know_token:70
known_token_update:False
T:781
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:781
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:781
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:781
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:781
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:781
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:781
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:781
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:781
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:781
T - mask_len:tensor([348.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:781
T - mask_len:tensor([413.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:781
T - mask_len:tensor([483.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:781
T - mask_len:tensor([555.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:781
T - mask_len:tensor([629.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:781
T - mask_len:tensor([705.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 781, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41806-0001
generate
 90%|████████▉ | 1106/1232 [13:33<02:00,  1.04it/s]processing 1106th semantic_sys file
1106
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: EXCLAIMED BILL HARMON TO HIS WIFE AS THEY WENT THROUGH THE LIGHTED HALL
2024-04-02 06:36:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41806-0009.json
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 253, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41806-0009
generate
 90%|████████▉ | 1107/1232 [13:33<01:51,  1.13it/s]processing 1107th semantic_sys file
1107
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: APPROACHING THE DINING TABLE HE CAREFULLY PLACED THE ARTICLE IN THE CENTRE AND REMOVED THE CLOTH
2024-04-02 06:36:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41806-0013.json
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:313
T - mask_len:tensor([283.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 313, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41806-0013
generate
 90%|████████▉ | 1108/1232 [13:34<01:42,  1.21it/s]processing 1108th semantic_sys file
1108
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MOTHER CAREY POURED COFFEE NANCY CHOCOLATE AND THE OTHERS HELPED SERVE THE SANDWICHES AND CAKE DOUGHNUTS AND TARTS
2024-04-02 06:36:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41806-0011.json
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([251.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([319.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 353, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41806-0011
generate
 90%|█████████ | 1109/1232 [13:35<01:39,  1.24it/s]processing 1109th semantic_sys file
1109
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHEN SHE COULD NOT MAKE A RABBIT OR A BIRD LOOK REAL ON PAPER SHE SEARCHED IN HER FATHER'S BOOKS FOR PICTURES OF ITS BONES
2024-04-02 06:36:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41797-0014.json
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([299.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:420
T - mask_len:tensor([379.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 420, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41797-0014
generate
 90%|█████████ | 1110/1232 [13:36<01:40,  1.22it/s]processing 1110th semantic_sys file
1110
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YES DEAD THESE FOUR YEARS AN A GOOD JOB FOR HER TOO
2024-04-02 06:36:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41797-0000.json
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:214
T - mask_len:tensor([194.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 214, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41797-0000
generate
 90%|█████████ | 1111/1232 [13:36<01:35,  1.26it/s]processing 1111th semantic_sys file
1111
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE MAKES EFFORT AFTER EFFORT TREMBLING WITH EAGERNESS AND WHEN SHE FAILS TO REPRODUCE WHAT SHE SEES SHE WORKS HERSELF INTO A FRENZY OF GRIEF AND DISAPPOINTMENT
2024-04-02 06:36:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41797-0013.json
top_k_know_token:70
known_token_update:False
T:690
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:690
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:690
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:690
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:690
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:690
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:690
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:690
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:690
T - mask_len:tensor([253.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:690
T - mask_len:tensor([307.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:690
T - mask_len:tensor([365.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:690
T - mask_len:tensor([426.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:690
T - mask_len:tensor([490.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:690
T - mask_len:tensor([556.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:690
T - mask_len:tensor([623.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 690, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41797-0013
generate
 90%|█████████ | 1112/1232 [13:38<01:50,  1.09it/s]processing 1112th semantic_sys file
1112
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NANCY'S CURLY CHESTNUT CROP SHONE IN THE SUN AND OLIVE'S THICK BLACK PLAITS LOOKED BLACKER BY CONTRAST
2024-04-02 06:36:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41797-0020.json
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([261.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([304.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([397.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:492
T - mask_len:tensor([444.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 492, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41797-0020
generate
 90%|█████████ | 1113/1232 [13:39<01:52,  1.06it/s]processing 1113th semantic_sys file
1113
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MISTER POPHAM EXAGGERATED NOTHING BUT ON THE CONTRARY LEFT MUCH UNSAID IN HIS NARRATIVE OF THE FAMILY AT THE HOUSE OF LORDS
2024-04-02 06:36:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41797-0008.json
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([264.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([304.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([344.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:427
T - mask_len:tensor([386.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 427, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41797-0008
generate
 90%|█████████ | 1114/1232 [13:40<01:52,  1.05it/s]processing 1114th semantic_sys file
1114
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE IN THE CEDAR HOLLOW THEN LIVED OLIVE LORD AN ANGRY RESENTFUL LITTLE CREATURE WEIGHED DOWN BY A FIERCE SENSE OF INJURY
2024-04-02 06:36:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41797-0018.json
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([305.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([346.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:429
T - mask_len:tensor([387.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 429, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41797-0018
generate
 91%|█████████ | 1115/1232 [13:40<01:47,  1.09it/s]processing 1115th semantic_sys file
1115
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OLIVE'S MOURNFUL BLACK EYES MET NANCY'S SPARKLING BROWN ONES
2024-04-02 06:36:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41797-0019.json
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 250, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41797-0019
generate
 91%|█████████ | 1116/1232 [13:41<01:43,  1.12it/s]processing 1116th semantic_sys file
1116
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: GRANDFATHER WAS ALEXANDER CAREY L L D DOCTOR OF LAWS THAT IS
2024-04-02 06:36:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41797-0002.json
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:179
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 179, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41797-0002
generate
 91%|█████████ | 1117/1232 [13:42<01:35,  1.21it/s]processing 1117th semantic_sys file
1117
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE WOULDN'T SEARCH SO DON'T WORRY REPLIED CYRIL QUIETLY AND THE TWO LOOKED AT EACH OTHER AND KNEW THAT IT WAS SO
2024-04-02 06:36:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41797-0017.json
top_k_know_token:70
known_token_update:False
T:515
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:515
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:515
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:515
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:515
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:515
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:515
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:515
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:515
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:515
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:515
T - mask_len:tensor([273.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:515
T - mask_len:tensor([318.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:515
T - mask_len:tensor([366.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:515
T - mask_len:tensor([415.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:515
T - mask_len:tensor([465.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 515, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41797-0017
generate
 91%|█████████ | 1118/1232 [13:43<01:41,  1.12it/s]processing 1118th semantic_sys file
1118
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE KEEPS THE THOU SHALT NOT COMMANDMENTS FIRST RATE HEN LORD DOES
2024-04-02 06:36:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41797-0006.json
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:227
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 227, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41797-0006
generate
 91%|█████████ | 1119/1232 [13:44<01:34,  1.20it/s]processing 1119th semantic_sys file
1119
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I SWAN TO MAN HE EJACULATED IF YOU DON'T WORK HARD YOU CAN'T KEEP UP WITH THE TIMES DOCTOR OF LAWS
2024-04-02 06:36:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:36:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41797-0004.json
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([264.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([299.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:371
T - mask_len:tensor([335.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 371, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41797-0004
generate
 91%|█████████ | 1120/1232 [13:45<01:35,  1.17it/s]processing 1120th semantic_sys file
1120
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ALWAYS IRRITABLE COLD INDIFFERENT HE HAD GROWN RAPIDLY MORE SO AS YEARS WENT ON
2024-04-02 06:37:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41797-0010.json
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:276
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 276, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41797-0010
generate
 91%|█████████ | 1121/1232 [13:45<01:30,  1.22it/s]processing 1121th semantic_sys file
1121
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE GIVE UP HIS POSITION AND SHUT THE FAMILY UP IN THAT TOMB OF A HOUSE SO T HE COULD STUDY HIS BOOKS
2024-04-02 06:37:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41797-0007.json
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([253.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([287.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([322.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 356, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41797-0007
generate
 91%|█████████ | 1122/1232 [13:46<01:30,  1.22it/s]processing 1122th semantic_sys file
1122
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE'S OLDER THAN I AM BUT SO TINY AND SAD AND SHY THAT SHE SEEMS LIKE A CHILD
2024-04-02 06:37:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41797-0022.json
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 250, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41797-0022
generate
 91%|█████████ | 1123/1232 [13:47<01:24,  1.29it/s]processing 1123th semantic_sys file
1123
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: CYRIL THERE MUST BE SOME BETTER WAY OF DOING I JUST DRAW THE OUTLINE OF AN ANIMAL AND THEN I PUT HAIRS OR FEATHERS ON IT THEY HAVE NO BODIES
2024-04-02 06:37:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([28], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41797-0015.json
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([333.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([383.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([434.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([487.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 539, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41797-0015
generate
 91%|█████████ | 1124/1232 [13:48<01:33,  1.16it/s]processing 1124th semantic_sys file
1124
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHATEVER APPEALED TO HER SENSE OF BEAUTY WAS STRAIGHTWAY TRANSFERRED TO PAPER OR CANVAS
2024-04-02 06:37:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41797-0011.json
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([200.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([260.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:323
T - mask_len:tensor([292.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 323, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41797-0011
generate
 91%|█████████▏| 1125/1232 [13:49<01:30,  1.18it/s]processing 1125th semantic_sys file
1125
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE'S WONDERFUL MORE WONDERFUL THAN ANYBODY WE'VE EVER SEEN ANYWHERE AND SHE DRAWS BETTER THAN THE TEACHER IN CHARLESTOWN
2024-04-02 06:37:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4992-41797-0021.json
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([231.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([266.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([302.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:374
T - mask_len:tensor([338.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 374, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4992-41797-0021
generate
 91%|█████████▏| 1126/1232 [13:50<01:31,  1.15it/s]processing 1126th semantic_sys file
1126
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MY TONGUE REFUSED TO ARTICULATE MY POWER OF SPEECH LEFT ME
2024-04-02 06:37:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-81414-0024.json
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 197, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-81414-0024
generate
 91%|█████████▏| 1127/1232 [13:50<01:25,  1.23it/s]processing 1127th semantic_sys file
1127
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I HAD AGAIN BEEN ACTING UNDER THE INFLUENCE OF THIS MAN'S POWER
2024-04-02 06:37:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-81414-0022.json
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:232
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 232, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-81414-0022
generate
 92%|█████████▏| 1128/1232 [13:51<01:20,  1.28it/s]processing 1128th semantic_sys file
1128
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SAID ANOTHER VOICE WHICH I RECOGNIZED AS VOLTAIRE'S KAFFAR
2024-04-02 06:37:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-81414-0012.json
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:193
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 193, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-81414-0012
generate
 92%|█████████▏| 1129/1232 [13:52<01:22,  1.25it/s]processing 1129th semantic_sys file
1129
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IN THE LIGHT OF THE MOON I SAW A KNIFE RED WITH BLOOD AND MY HAND TOO WAS ALSO DISCOLOURED
2024-04-02 06:37:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-81414-0014.json
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:254
T - mask_len:tensor([230.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 254, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-81414-0014
generate
 92%|█████████▏| 1130/1232 [13:52<01:18,  1.30it/s]processing 1130th semantic_sys file
1130
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHAT THEN A HUMAN HAND LARGE AND SHAPELY APPEARED DISTINCTLY ON THE SURFACE OF THE POND
2024-04-02 06:37:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-81414-0006.json
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([211.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:262
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 262, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-81414-0006
generate
 92%|█████████▏| 1131/1232 [13:53<01:16,  1.33it/s]processing 1131th semantic_sys file
1131
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I HAD SCARCELY KNOWN WHAT I HAD BEEN SAYING OR DOING UP TO THIS TIME BUT AS HE SPOKE I LOOKED AT MY HAND
2024-04-02 06:37:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([23], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-81414-0013.json
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([360.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([428.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([499.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([574.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([651.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:808
T - mask_len:tensor([729.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 808, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-81414-0013
generate
 92%|█████████▏| 1132/1232 [13:55<01:33,  1.07it/s]processing 1132th semantic_sys file
1132
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I SAY YOU DO KNOW WHAT THIS MEANS AND YOU MUST TELL US
2024-04-02 06:37:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-81414-0020.json
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:122
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 122, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-81414-0020
generate
 92%|█████████▏| 1133/1232 [13:55<01:21,  1.22it/s]processing 1133th semantic_sys file
1133
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A FEELING OF FREEDOM AND I WAS AWAKE WHERE
2024-04-02 06:37:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-81414-0011.json
top_k_know_token:70
known_token_update:False
T:124
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:124
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:124
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:124
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:124
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:124
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:124
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:124
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:124
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:124
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:124
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:124
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:124
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:124
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:124
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 124, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-81414-0011
generate
 92%|█████████▏| 1134/1232 [13:56<01:14,  1.31it/s]processing 1134th semantic_sys file
1134
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: PERCHANCE TOO KAFFAR'S DEATH MIGHT SERVE HIM IN GOOD STEAD
2024-04-02 06:37:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-81414-0023.json
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:164
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 164, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-81414-0023
generate
 92%|█████████▏| 1135/1232 [13:56<01:07,  1.43it/s]processing 1135th semantic_sys file
1135
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE STORY OF ITS EVIL INFLUENCE CAME BACK TO ME AND IN MY BEWILDERED CONDITION I WONDERED WHETHER THERE WAS NOT SOME TRUTH IN WHAT HAD BEEN SAID
2024-04-02 06:37:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-81414-0004.json
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([284.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:352
T - mask_len:tensor([318.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 352, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-81414-0004
generate
 92%|█████████▏| 1136/1232 [13:57<01:09,  1.37it/s]processing 1136th semantic_sys file
1136
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NOTHING MORE NOT EVEN THE WRIST TO WHICH IT MIGHT BE ATTACHED
2024-04-02 06:37:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-81414-0007.json
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 265, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-81414-0007
generate
 92%|█████████▏| 1137/1232 [13:58<01:07,  1.40it/s]processing 1137th semantic_sys file
1137
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT DID NOT BECKON OR INDEED MOVE AT ALL IT WAS AS STILL AS THE HAND OF DEATH
2024-04-02 06:37:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([26], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-81414-0008.json
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([278.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 345, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-81414-0008
generate
 92%|█████████▏| 1138/1232 [13:59<01:12,  1.30it/s]processing 1138th semantic_sys file
1138
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS HAS INDEED BEEN A HARASSING DAY CONTINUED THE YOUNG MAN HIS EYES FIXED UPON HIS FRIEND
2024-04-02 06:37:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-75918-0006.json
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([253.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([287.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:356
T - mask_len:tensor([322.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 356, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-75918-0006
generate
 92%|█████████▏| 1139/1232 [14:00<01:23,  1.12it/s]processing 1139th semantic_sys file
1139
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT IN THIS FRIENDLY PRESSURE RAOUL COULD DETECT THE NERVOUS AGITATION OF A GREAT INTERNAL CONFLICT
2024-04-02 06:37:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-75918-0017.json
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([85.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:287
T - mask_len:tensor([259.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 287, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-75918-0017
generate
 93%|█████████▎| 1140/1232 [14:01<01:20,  1.15it/s]processing 1140th semantic_sys file
1140
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: CONGRATULATIONS WERE POURED IN UPON THE PRINCESS EVERYWHERE DURING HER JOURNEY
2024-04-02 06:37:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-75918-0002.json
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:269
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 269, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-75918-0002
generate
 93%|█████████▎| 1141/1232 [14:01<01:18,  1.16it/s]processing 1141th semantic_sys file
1141
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THUS IT IS THAT THE HONOR OF THREE IS SAVED OUR COUNTRY'S OUR MASTER'S AND OUR OWN
2024-04-02 06:37:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-75918-0015.json
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([243.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([317.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:393
T - mask_len:tensor([355.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 393, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-75918-0015
generate
 93%|█████████▎| 1142/1232 [14:02<01:17,  1.16it/s]processing 1142th semantic_sys file
1142
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT IS YOU WHO ARE MISTAKEN RAOUL I HAVE READ HIS DISTRESS IN HIS EYES IN HIS EVERY GESTURE AND ACTION THE WHOLE DAY
2024-04-02 06:37:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-75918-0009.json
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([255.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([298.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([343.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([388.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:482
T - mask_len:tensor([435.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 482, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-75918-0009
generate
 93%|█████████▎| 1143/1232 [14:03<01:21,  1.09it/s]processing 1143th semantic_sys file
1143
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: CAN YOU IMAGINE WHY BUCKINGHAM HAS BEEN SO VIOLENT I SUSPECT
2024-04-02 06:37:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-75918-0008.json
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:174
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 174, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-75918-0008
generate
 93%|█████████▎| 1144/1232 [14:04<01:13,  1.19it/s]processing 1144th semantic_sys file
1144
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FORGETTING ALL THEIR WEARINESS THEY SEIZED THEIR CANDLES AND SCURRIED THROUGH THE HOUSE FINDING AN OCCASIONAL PAPER TUCKED AWAY IN SOME ODD CORNER
2024-04-02 06:37:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-76324-0027.json
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([292.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([335.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([380.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:472
T - mask_len:tensor([426.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 472, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-76324-0027
generate
 93%|█████████▎| 1145/1232 [14:05<01:20,  1.08it/s]processing 1145th semantic_sys file
1145
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE'LL COME IN HERE THIS AFTERNOON WITH OLD CLOTHES ON AND HAVE A REGULAR HOUSE CLEANING
2024-04-02 06:37:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-76324-0012.json
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 251, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-76324-0012
generate
 93%|█████████▎| 1146/1232 [14:06<01:13,  1.16it/s]processing 1146th semantic_sys file
1146
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHY IT'S GOLIATH AS USUAL THEY BOTH CRIED PEERING IN
2024-04-02 06:37:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-76324-0025.json
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:161
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 161, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-76324-0025
generate
 93%|█████████▎| 1147/1232 [14:07<01:07,  1.26it/s]processing 1147th semantic_sys file
1147
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YET LITTLE AS IT WAS IT HAD ALREADY MADE A VAST DIFFERENCE IN THE ASPECT OF THE ROOM
2024-04-02 06:37:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-76324-0020.json
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:253
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 253, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-76324-0020
generate
 93%|█████████▎| 1148/1232 [14:07<01:08,  1.23it/s]processing 1148th semantic_sys file
1148
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I THOUGHT WE WERE STUMPED AGAIN WHEN I FIRST SAW THAT PICTURE BUT IT'S BEEN OF SOME USE AFTER ALL
2024-04-02 06:37:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-76324-0008.json
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:291
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 291, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-76324-0008
generate
 93%|█████████▎| 1149/1232 [14:08<01:06,  1.24it/s]processing 1149th semantic_sys file
1149
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE LURE PROVED TOO MUCH FOR HIM AND HE CAME SPORTING AFTER IT AS FRISKILY AS A YOUNG KITTEN MUCH TO CYNTHIA'S DELIGHT WHEN SHE CAUGHT SIGHT OF HIM
2024-04-02 06:37:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-76324-0016.json
top_k_know_token:70
known_token_update:False
T:726
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:726
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:726
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:726
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:726
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:726
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:726
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:726
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:726
T - mask_len:tensor([266.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:726
T - mask_len:tensor([323.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:726
T - mask_len:tensor([384.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:726
T - mask_len:tensor([449.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:726
T - mask_len:tensor([516.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:726
T - mask_len:tensor([585.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:726
T - mask_len:tensor([655.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 726, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-76324-0016
generate
 93%|█████████▎| 1150/1232 [14:10<01:23,  1.01s/it]processing 1150th semantic_sys file
1150
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SURFACE DUST AT LEAST HAD BEEN REMOVED AND THE FINE OLD FURNITURE GAVE A HINT OF ITS REAL ELEGANCE AND POLISH
2024-04-02 06:37:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-76324-0021.json
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:307
T - mask_len:tensor([277.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 307, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-76324-0021
generate
 93%|█████████▎| 1151/1232 [14:10<01:16,  1.06it/s]processing 1151th semantic_sys file
1151
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS THOUGHT HOWEVER DID NOT ENTER THE HEADS OF THE ENTHUSIASTIC PAIR
2024-04-02 06:37:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-76324-0014.json
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:201
T - mask_len:tensor([182.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 201, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-76324-0014
generate
 94%|█████████▎| 1152/1232 [14:11<01:10,  1.14it/s]processing 1152th semantic_sys file
1152
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY SAY ILLUMINATION BY CANDLE LIGHT IS THE PRETTIEST IN THE WORLD
2024-04-02 06:37:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-76324-0024.json
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:207
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 207, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-76324-0024
generate
 94%|█████████▎| 1153/1232 [14:12<01:04,  1.23it/s]processing 1153th semantic_sys file
1153
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT JOYCE HAD NOT BEEN LISTENING ALL AT ONCE SHE PUT DOWN HER CANDLE ON THE TABLE AND FACED HER COMPANION
2024-04-02 06:37:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-76324-0004.json
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([204.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:329
T - mask_len:tensor([297.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 329, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-76324-0004
generate
 94%|█████████▎| 1154/1232 [14:13<01:03,  1.22it/s]processing 1154th semantic_sys file
1154
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE POOR LITTLE THINGS CRIED CYNTHIA THINK OF THEM HAVING BEEN TURNED TO THE WALL ALL THESE YEARS
2024-04-02 06:37:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-76324-0002.json
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([154.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([278.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:345
T - mask_len:tensor([312.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 345, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-76324-0002
generate
 94%|█████████▍| 1155/1232 [14:14<01:03,  1.21it/s]processing 1155th semantic_sys file
1155
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HERS HAPPENED TO BE IN THE SAME FRAME TOO BUT SHE EVIDENTLY DIDN'T CARE ABOUT THAT
2024-04-02 06:37:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-76324-0006.json
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([188.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([286.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:355
T - mask_len:tensor([321.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 355, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-76324-0006
generate
 94%|█████████▍| 1156/1232 [14:14<01:03,  1.19it/s]processing 1156th semantic_sys file
1156
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND MY POCKET MONEY IS GETTING LOW AGAIN AND YOU HAVEN'T ANY LEFT AS USUAL
2024-04-02 06:37:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-76324-0023.json
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:199
T - mask_len:tensor([180.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 199, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-76324-0023
generate
 94%|█████████▍| 1157/1232 [14:15<00:57,  1.31it/s]processing 1157th semantic_sys file
1157
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY WORRY ME TERRIBLY AND BESIDES I'D LIKE TO SEE WHAT THIS LOVELY FURNITURE LOOKS LIKE WITHOUT SUCH QUANTITIES OF DUST ALL OVER IT GOOD SCHEME CYN
2024-04-02 06:37:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:31 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-76324-0011.json
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([252.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([300.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([351.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([403.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([457.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:567
T - mask_len:tensor([512.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 567, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-76324-0011
generate
 94%|█████████▍| 1158/1232 [14:16<01:01,  1.19it/s]processing 1158th semantic_sys file
1158
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OH LET HIM COME ALONG SHE URGED I DO LOVE TO SEE HIM ABOUT THAT OLD HOUSE
2024-04-02 06:37:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-76324-0017.json
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:211
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 211, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-76324-0017
generate
 94%|█████████▍| 1159/1232 [14:17<01:00,  1.20it/s]processing 1159th semantic_sys file
1159
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE TWIN BROTHER DID SOMETHING SHE DIDN'T LIKE AND SHE TURNED HIS PICTURE TO THE WALL
2024-04-02 06:37:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-76324-0005.json
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 257, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-76324-0005
generate
 94%|█████████▍| 1160/1232 [14:18<00:58,  1.23it/s]processing 1160th semantic_sys file
1160
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WELL I'M CONVINCED THAT THE BOARDED UP HOUSE MYSTERY HAPPENED NOT EARLIER THAN APRIL SIXTEENTH EIGHTEEN SIXTY ONE AND PROBABLY NOT MUCH LATER
2024-04-02 06:37:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-76324-0028.json
top_k_know_token:70
known_token_update:False
T:579
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:579
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:579
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:579
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:579
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:579
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:579
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:579
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:579
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:579
T - mask_len:tensor([258.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:579
T - mask_len:tensor([307.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:579
T - mask_len:tensor([358.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:579
T - mask_len:tensor([411.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:579
T - mask_len:tensor([467.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:579
T - mask_len:tensor([523.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 579, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-76324-0028
generate
 94%|█████████▍| 1161/1232 [14:19<01:02,  1.14it/s]processing 1161th semantic_sys file
1161
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT CAN'T HURT ANYTHING I'M SURE FOR WE WON'T DISTURB THINGS AT ALL
2024-04-02 06:37:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_6930-76324-0013.json
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:274
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 274, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_6930-76324-0013
generate
 94%|█████████▍| 1162/1232 [14:19<00:57,  1.22it/s]processing 1162th semantic_sys file
1162
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND SAYS THOU MOTHER OF MY CHILDREN I HAVE LOVED THEE AND I HAVE GIVEN THEE A CROWN THAT NONE CAN TAKE AWAY
2024-04-02 06:37:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([22], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-157963-0026.json
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:309
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 309, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-157963-0026
generate
 94%|█████████▍| 1163/1232 [14:20<00:57,  1.20it/s]processing 1163th semantic_sys file
1163
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DESCEND O LITTLE CLOUD AND HOVER BEFORE THE EYES OF THEL
2024-04-02 06:37:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-157963-0014.json
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 196, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-157963-0014
generate
 94%|█████████▍| 1164/1232 [14:21<00:50,  1.34it/s]processing 1164th semantic_sys file
1164
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I PASS AWAY YET I COMPLAIN AND NO ONE HEARS MY VOICE
2024-04-02 06:37:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-157963-0016.json
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:168
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 168, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-157963-0016
generate
 95%|█████████▍| 1165/1232 [14:21<00:47,  1.42it/s]processing 1165th semantic_sys file
1165
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND WHY IT SCATTERS ITS BRIGHT BEAUTY THRO THE HUMID AIR
2024-04-02 06:37:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([27], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-157963-0013.json
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([233.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([265.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:328
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 328, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-157963-0013
generate
 95%|█████████▍| 1166/1232 [14:22<00:47,  1.38it/s]processing 1166th semantic_sys file
1166
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE CLOUD THEN SHEWD HIS GOLDEN HEAD AND HIS BRIGHT FORM EMERG'D
2024-04-02 06:37:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-157963-0017.json
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 224, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-157963-0017
generate
 95%|█████████▍| 1167/1232 [14:23<00:49,  1.31it/s]processing 1167th semantic_sys file
1167
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE HELPLESS WORM AROSE AND SAT UPON THE LILLYS LEAF AND THE BRIGHT CLOUD SAILD ON TO FIND HIS PARTNER IN THE VALE
2024-04-02 06:37:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-157963-0023.json
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([279.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([316.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:392
T - mask_len:tensor([354.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 392, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-157963-0023
generate
 95%|█████████▍| 1168/1232 [14:24<00:51,  1.25it/s]processing 1168th semantic_sys file
1168
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND LAY ME DOWN IN THY COLD BED AND LEAVE MY SHINING LOT
2024-04-02 06:37:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-157963-0027.json
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([108.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([129.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([151.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:243
T - mask_len:tensor([220.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 243, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-157963-0027
generate
 95%|█████████▍| 1169/1232 [14:25<00:50,  1.25it/s]processing 1169th semantic_sys file
1169
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TILL WE ARISE LINK'D IN A GOLDEN BAND AND NEVER PART BUT WALK UNITED BEARING FOOD TO ALL OUR TENDER FLOWERS
2024-04-02 06:37:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-157963-0020.json
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([247.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([280.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([313.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 347, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-157963-0020
generate
 95%|█████████▍| 1170/1232 [14:25<00:48,  1.27it/s]processing 1170th semantic_sys file
1170
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: LIKE THE DOVES VOICE LIKE TRANSIENT DAY LIKE MUSIC IN THE AIR AH
2024-04-02 06:37:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([27], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-157963-0005.json
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:182
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 182, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-157963-0005
generate
 95%|█████████▌| 1171/1232 [14:26<00:46,  1.32it/s]processing 1171th semantic_sys file
1171
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND FEAREST THOU BECAUSE I VANISH AND AM SEEN NO MORE
2024-04-02 06:37:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([28], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-157963-0018.json
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([168.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:271
T - mask_len:tensor([245.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 271, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-157963-0018
generate
 95%|█████████▌| 1172/1232 [14:27<00:44,  1.34it/s]processing 1172th semantic_sys file
1172
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND GENTLE SLEEP THE SLEEP OF DEATH AND GENTLY HEAR THE VOICE OF HIM THAT WALKETH IN THE GARDEN IN THE EVENING TIME
2024-04-02 06:37:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-157963-0006.json
top_k_know_token:70
known_token_update:False
T:388
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:388
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:388
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:388
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:388
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:388
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:388
T - mask_len:tensor([89.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:388
T - mask_len:tensor([114.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:388
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:388
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:388
T - mask_len:tensor([206.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:388
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:388
T - mask_len:tensor([276.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:388
T - mask_len:tensor([313.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:388
T - mask_len:tensor([350.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 388, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-157963-0006
generate
 95%|█████████▌| 1173/1232 [14:28<00:48,  1.23it/s]processing 1173th semantic_sys file
1173
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OR AN EYE OF GIFTS AND GRACES SHOWRING FRUITS AND COINED GOLD
2024-04-02 06:37:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-157963-0028.json
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:277
T - mask_len:tensor([250.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 277, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-157963-0028
generate
 95%|█████████▌| 1174/1232 [14:29<00:47,  1.22it/s]processing 1174th semantic_sys file
1174
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHY SHOULD THE MISTRESS OF THE VALES OF HAR UTTER A SIGH
2024-04-02 06:37:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-157963-0009.json
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([135.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:189
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 189, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-157963-0009
generate
 95%|█████████▌| 1175/1232 [14:29<00:44,  1.28it/s]processing 1175th semantic_sys file
1175
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHY AN EAR A WHIRLPOOL FIERCE TO DRAW CREATIONS IN
2024-04-02 06:37:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-157963-0030.json
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([160.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:259
T - mask_len:tensor([234.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 259, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-157963-0030
generate
 95%|█████████▌| 1176/1232 [14:30<00:43,  1.29it/s]processing 1176th semantic_sys file
1176
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE CEASD AND SMILD IN TEARS THEN SAT DOWN IN HER SILVER SHRINE
2024-04-02 06:37:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:46 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-157963-0010.json
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([63.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([172.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:213
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 213, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-157963-0010
generate
 96%|█████████▌| 1177/1232 [14:31<00:40,  1.35it/s]processing 1177th semantic_sys file
1177
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: COME FORTH WORM AND THE SILENT VALLEY TO THY PENSIVE QUEEN
2024-04-02 06:37:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-157963-0022.json
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([254.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([288.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:357
T - mask_len:tensor([323.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 357, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-157963-0022
generate
 96%|█████████▌| 1178/1232 [14:32<00:41,  1.29it/s]processing 1178th semantic_sys file
1178
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I SEE THEY LAY HELPLESS AND NAKED WEEPING AND NONE TO ANSWER NONE TO CHERISH THEE WITH MOTHERS SMILES
2024-04-02 06:37:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-157963-0025.json
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([247.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([280.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:347
T - mask_len:tensor([313.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 347, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-157963-0025
generate
 96%|█████████▌| 1179/1232 [14:33<00:44,  1.19it/s]processing 1179th semantic_sys file
1179
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IF HE TO KEEP ONE OATH MUST LOSE ONE JOY BY HIS LIFE'S STAR FORETOLD
2024-04-02 06:37:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-31957-0012.json
top_k_know_token:70
known_token_update:False
T:246
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:246
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:246
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:246
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:246
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:246
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:246
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:246
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:246
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:246
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:246
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:246
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:246
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:246
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:246
T - mask_len:tensor([222.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 246, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-31957-0012
generate
 96%|█████████▌| 1180/1232 [14:33<00:42,  1.23it/s]processing 1180th semantic_sys file
1180
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ALAS I HAVE GRIEVED SO I AM HARD TO LOVE
2024-04-02 06:37:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-31957-0005.json
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:156
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 156, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-31957-0005
generate
 96%|█████████▌| 1181/1232 [14:34<00:39,  1.28it/s]processing 1181th semantic_sys file
1181
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I THANK ALL WHO HAVE LOVED ME IN THEIR HEARTS WITH THANKS AND LOVE FROM MINE
2024-04-02 06:37:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-31957-0020.json
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([105.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:197
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 197, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-31957-0020
generate
 96%|█████████▌| 1182/1232 [14:35<00:37,  1.33it/s]processing 1182th semantic_sys file
1182
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: COULD IT MEAN TO LAST A LOVE SET PENDULOUS BETWEEN SORROW AND SORROW
2024-04-02 06:37:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-31957-0007.json
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([68.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([84.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:229
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 229, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-31957-0007
generate
 96%|█████████▌| 1183/1232 [14:35<00:35,  1.39it/s]processing 1183th semantic_sys file
1183
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I LOVE THEE FREELY AS MEN STRIVE FOR RIGHT I LOVE THEE PURELY AS THEY TURN FROM PRAISE
2024-04-02 06:37:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-31957-0023.json
top_k_know_token:70
known_token_update:False
T:559
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:559
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:559
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:559
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:559
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:559
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:559
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:559
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:559
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:559
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:559
T - mask_len:tensor([296.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:559
T - mask_len:tensor([346.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:559
T - mask_len:tensor([397.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:559
T - mask_len:tensor([450.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:559
T - mask_len:tensor([505.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 559, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-31957-0023
generate
 96%|█████████▌| 1184/1232 [14:36<00:38,  1.24it/s]processing 1184th semantic_sys file
1184
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND THOUGH I HAVE GROWN SERENE AND STRONG SINCE THEN I THINK THAT GOD HAS WILLED A STILL RENEWABLE FEAR
2024-04-02 06:37:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([25], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-31957-0009.json
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([201.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([270.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([306.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:380
T - mask_len:tensor([343.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 380, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-31957-0009
generate
 96%|█████████▌| 1185/1232 [14:37<00:37,  1.24it/s]processing 1185th semantic_sys file
1185
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OPEN THY HEART WIDE AND FOLD WITHIN THE WET WINGS OF THY DOVE
2024-04-02 06:37:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-31957-0006.json
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([126.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([147.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([192.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:238
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 238, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-31957-0006
generate
 96%|█████████▋| 1186/1232 [14:38<00:35,  1.28it/s]processing 1186th semantic_sys file
1186
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THOU CANST WAIT THROUGH SORROW AND SICKNESS TO BRING SOULS TO TOUCH AND THINK IT SOON WHEN OTHERS CRY TOO LATE
2024-04-02 06:37:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-31957-0019.json
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([249.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([302.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([359.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([420.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([482.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([547.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:679
T - mask_len:tensor([613.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 679, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-31957-0019
generate
 96%|█████████▋| 1187/1232 [14:39<00:39,  1.15it/s]processing 1187th semantic_sys file
1187
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A RING OF AMETHYST I COULD NOT WEAR HERE PLAINER TO MY SIGHT THAN THAT FIRST KISS
2024-04-02 06:37:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-31957-0014.json
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([128.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([185.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([281.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:349
T - mask_len:tensor([315.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 349, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-31957-0014
generate
 96%|█████████▋| 1188/1232 [14:40<00:37,  1.17it/s]processing 1188th semantic_sys file
1188
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MUSSULMANS AND GIAOURS THROW KERCHIEFS AT A SMILE AND HAVE NO RUTH FOR ANY WEEPING
2024-04-02 06:37:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-31957-0017.json
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([164.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([214.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:265
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 265, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-31957-0017
generate
 97%|█████████▋| 1189/1232 [14:40<00:34,  1.26it/s]processing 1189th semantic_sys file
1189
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHEN CALLED BEFORE I TOLD HOW HASTILY I DROPPED MY FLOWERS OR BRAKE OFF FROM A GAME
2024-04-02 06:37:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-31957-0003.json
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 250, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-31957-0003
generate
 97%|█████████▋| 1190/1232 [14:41<00:33,  1.25it/s]processing 1190th semantic_sys file
1190
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SLOW TO WORLD GREETINGS QUICK WITH ITS O LIST WHEN THE ANGELS SPEAK
2024-04-02 06:37:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([20], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-31957-0013.json
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([79.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([165.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([190.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([215.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:267
T - mask_len:tensor([241.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 267, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-31957-0013
generate
 97%|█████████▋| 1191/1232 [14:42<00:31,  1.30it/s]processing 1191th semantic_sys file
1191
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I LOVE THEE WITH THE PASSION PUT TO USE IN MY OLD GRIEFS AND WITH MY CHILDHOOD'S FAITH
2024-04-02 06:37:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:58 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([25], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-31957-0024.json
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([205.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([268.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:332
T - mask_len:tensor([300.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 332, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-31957-0024
generate
 97%|█████████▋| 1192/1232 [14:43<00:33,  1.18it/s]processing 1192th semantic_sys file
1192
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: DEAREST TEACH ME SO TO POUR OUT GRATITUDE AS THOU DOST GOOD
2024-04-02 06:37:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-31957-0016.json
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([121.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:196
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 196, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-31957-0016
generate
 97%|█████████▋| 1193/1232 [14:44<00:30,  1.28it/s]processing 1193th semantic_sys file
1193
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I DID NOT WRONG MYSELF SO BUT I PLACED A WRONG ON THEE
2024-04-02 06:37:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:37:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_908-31957-0002.json
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([80.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([175.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:217
T - mask_len:tensor([196.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 217, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_908-31957-0002
generate
 97%|█████████▋| 1194/1232 [14:44<00:27,  1.36it/s]processing 1194th semantic_sys file
1194
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT THEY HAVE NOTHING TO DO WITH THE INTERPRETATION OF PLATO AND IN SPIRIT THEY ARE OPPOSED TO HIM
2024-04-02 06:38:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-960-0007.json
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([78.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([212.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:263
T - mask_len:tensor([238.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 263, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-960-0007
generate
 97%|█████████▋| 1195/1232 [14:45<00:26,  1.41it/s]processing 1195th semantic_sys file
1195
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE IDEAS ALSO REMAIN BUT THEY HAVE BECOME TYPES IN NATURE FORMS OF MEN ANIMALS BIRDS FISHES
2024-04-02 06:38:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:01 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-960-0014.json
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([162.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([189.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([217.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:305
T - mask_len:tensor([276.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 305, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-960-0014
generate
 97%|█████████▋| 1196/1232 [14:46<00:27,  1.29it/s]processing 1196th semantic_sys file
1196
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT PLATO HAS NOT THE SAME MASTERY OVER HIS INSTRUMENT WHICH HE EXHIBITS IN THE PHAEDRUS OR SYMPOSIUM
2024-04-02 06:38:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-960-0016.json
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([333.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([383.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([434.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:539
T - mask_len:tensor([487.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 539, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-960-0016
generate
 97%|█████████▋| 1197/1232 [14:47<00:29,  1.19it/s]processing 1197th semantic_sys file
1197
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: PLATO HAD NOT THE COMMAND OF HIS MATERIALS WHICH WOULD HAVE ENABLED HIM TO PRODUCE A PERFECT WORK OF ART
2024-04-02 06:38:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-960-0022.json
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([48.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([103.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([149.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:280
T - mask_len:tensor([253.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 280, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-960-0022
generate
 97%|█████████▋| 1198/1232 [14:48<00:27,  1.21it/s]processing 1198th semantic_sys file
1198
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NOTHING CAN EXCEED THE BEAUTY OR ART OF THE INTRODUCTION IN WHICH HE IS USING WORDS AFTER HIS ACCUSTOMED MANNER
2024-04-02 06:38:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-960-0017.json
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([34.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([53.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([75.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([101.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([131.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([235.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([275.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([316.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([358.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:444
T - mask_len:tensor([401.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 444, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-960-0017
generate
 97%|█████████▋| 1199/1232 [14:48<00:27,  1.18it/s]processing 1199th semantic_sys file
1199
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT IN THE REST OF THE WORK THE POWER OF LANGUAGE SEEMS TO FAIL HIM AND THE DRAMATIC FORM IS WHOLLY GIVEN UP
2024-04-02 06:38:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-960-0018.json
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([138.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([267.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([302.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:375
T - mask_len:tensor([339.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 375, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-960-0018
generate
 97%|█████████▋| 1200/1232 [14:49<00:26,  1.19it/s]processing 1200th semantic_sys file
1200
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE IS NO DANGER OF THE MODERN COMMENTATORS ON THE TIMAEUS FALLING INTO THE ABSURDITIES OF THE NEO PLATONISTS
2024-04-02 06:38:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-960-0004.json
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:251
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 251, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-960-0004
generate
 97%|█████████▋| 1201/1232 [14:50<00:26,  1.18it/s]processing 1201th semantic_sys file
1201
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE STYLE AND PLAN OF THE TIMAEUS DIFFER GREATLY FROM THAT OF ANY OTHER OF THE PLATONIC DIALOGUES
2024-04-02 06:38:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-960-0015.json
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([104.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([157.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([187.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([218.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([251.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:353
T - mask_len:tensor([319.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 353, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-960-0015
generate
 98%|█████████▊| 1202/1232 [14:51<00:25,  1.19it/s]processing 1202th semantic_sys file
1202
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE INFLUENCE WITH THE TIMAEUS HAS EXERCISED UPON POSTERITY IS DUE PARTLY TO A MISUNDERSTANDING
2024-04-02 06:38:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-960-0001.json
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([208.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([239.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([271.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:336
T - mask_len:tensor([304.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 336, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-960-0001
generate
 98%|█████████▊| 1203/1232 [14:52<00:24,  1.18it/s]processing 1203th semantic_sys file
1203
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND HENCE WE FIND THE SAME SORT OF CLUMSINESS IN THE TIMAEUS OF PLATO WHICH CHARACTERIZES THE PHILOSOPHICAL POEM OF LUCRETIUS
2024-04-02 06:38:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([30], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-960-0020.json
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([176.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([244.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([281.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([318.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:395
T - mask_len:tensor([357.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 395, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-960-0020
generate
 98%|█████████▊| 1204/1232 [14:53<00:23,  1.17it/s]processing 1204th semantic_sys file
1204
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MANY IF NOT ALL THE ELEMENTS OF THE PRE SOCRATIC PHILOSOPHY ARE INCLUDED IN THE TIMAEUS
2024-04-02 06:38:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-960-0012.json
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([167.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([195.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([224.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([254.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:315
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 315, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-960-0012
generate
 98%|█████████▊| 1205/1232 [14:54<00:28,  1.05s/it]processing 1205th semantic_sys file
1205
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TELL US SAID THE OTHER THE WHOLE STORY AND WHERE SOLON HEARD THE STORY
2024-04-02 06:38:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-961-0009.json
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([12.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([59.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([76.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([115.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([207.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:257
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 257, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-961-0009
generate
 98%|█████████▊| 1206/1232 [14:55<00:25,  1.01it/s]processing 1206th semantic_sys file
1206
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT THE MEMORY OF THEIR EXPLOITS HAS PASSED AWAY OWING TO THE LAPSE OF TIME AND THE EXTINCTION OF THE ACTORS
2024-04-02 06:38:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-961-0008.json
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([45.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([140.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([236.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([271.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([307.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:381
T - mask_len:tensor([344.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 381, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-961-0008
generate
 98%|█████████▊| 1207/1232 [14:56<00:23,  1.06it/s]processing 1207th semantic_sys file
1207
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THIS IS THE EXPLANATION OF THE SHALLOWS WHICH ARE FOUND IN THAT PART OF THE ATLANTIC OCEAN
2024-04-02 06:38:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 1208th semantic_sys file
1208
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SOLON MARVELLED AND DESIRED TO BE INFORMED OF THE PARTICULARS
2024-04-02 06:38:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 1209th semantic_sys file
1209
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NINE THOUSAND YEARS HAVE ELAPSED SINCE SHE FOUNDED YOURS AND EIGHT THOUSAND SINCE SHE FOUNDED OURS AS OUR ANNALS RECORD
2024-04-02 06:38:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 1210th semantic_sys file
1210
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND NOW HE DESIRES TO SEE THE IDEAL STATE SET IN MOTION HE WOULD LIKE TO KNOW HOW SHE BEHAVED IN SOME GREAT STRUGGLE
2024-04-02 06:38:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-961-0001.json
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([32.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([49.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([122.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([184.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([256.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([294.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([334.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:414
T - mask_len:tensor([374.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 414, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-961-0001
generate
 98%|█████████▊| 1211/1232 [14:57<00:11,  1.89it/s]processing 1211th semantic_sys file
1211
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WILL BRIEFLY DESCRIBE THEM TO YOU AND YOU SHALL READ THE ACCOUNT OF THEM AT YOUR LEISURE IN THE SACRED REGISTERS
2024-04-02 06:38:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-961-0016.json
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([39.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([96.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([120.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([145.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([173.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([263.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:326
T - mask_len:tensor([295.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 326, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-961-0016
generate
 98%|█████████▊| 1212/1232 [14:58<00:11,  1.75it/s]processing 1212th semantic_sys file
1212
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SOCRATES BEGINS THE TIMAEUS WITH A SUMMARY OF THE REPUBLIC
2024-04-02 06:38:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([27], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-961-0000.json
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([50.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([81.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([98.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([116.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([136.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([156.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:219
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 219, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-961-0000
generate
 98%|█████████▊| 1213/1232 [14:58<00:11,  1.72it/s]processing 1213th semantic_sys file
1213
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE MOST FAMOUS OF THEM ALL WAS THE OVERTHROW OF THE ISLAND OF ATLANTIS
2024-04-02 06:38:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:14 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-961-0018.json
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([36.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([69.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([110.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([134.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([186.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([213.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([242.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:300
T - mask_len:tensor([271.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 300, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-961-0018
generate
 99%|█████████▊| 1214/1232 [14:59<00:11,  1.62it/s]processing 1214th semantic_sys file
1214
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE GENEALOGIES WHICH YOU HAVE RECITED TO US OUT OF YOUR OWN ANNALS SOLON ARE A MERE CHILDREN'S STORY
2024-04-02 06:38:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-961-0011.json
top_k_know_token:70
known_token_update:False
T:522
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:522
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:522
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:522
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:522
T - mask_len:tensor([62.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:522
T - mask_len:tensor([88.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:522
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:522
T - mask_len:tensor([153.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:522
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:522
T - mask_len:tensor([232.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:522
T - mask_len:tensor([276.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:522
T - mask_len:tensor([323.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:522
T - mask_len:tensor([371.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:522
T - mask_len:tensor([421.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:522
T - mask_len:tensor([471.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 522, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-961-0011
generate
 99%|█████████▊| 1215/1232 [15:00<00:12,  1.40it/s]processing 1215th semantic_sys file
1215
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT IN EGYPT THE TRADITIONS OF OUR OWN AND OTHER LANDS ARE BY US REGISTERED FOR EVER IN OUR TEMPLES
2024-04-02 06:38:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-961-0010.json
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([47.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([146.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([177.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([210.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([246.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([282.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([320.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:397
T - mask_len:tensor([359.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 397, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-961-0010
generate
 99%|█████████▊| 1216/1232 [15:01<00:12,  1.30it/s]processing 1216th semantic_sys file
1216
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MANY LAWS EXIST AMONG US WHICH ARE THE COUNTERPART OF YOURS AS THEY WERE IN THE OLDEN TIME
2024-04-02 06:38:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-961-0015.json
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([95.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([118.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([170.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([199.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([228.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([259.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:321
T - mask_len:tensor([290.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 321, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-961-0015
generate
 99%|█████████▉| 1217/1232 [15:02<00:11,  1.27it/s]processing 1217th semantic_sys file
1217
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND WHAT WAS THE SUBJECT OF THE POEM SAID THE PERSON WHO MADE THE REMARK
2024-04-02 06:38:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-961-0006.json
top_k_know_token:70
known_token_update:False
T:202
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:202
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:202
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:202
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:202
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:202
T - mask_len:tensor([35.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:202
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:202
T - mask_len:tensor([60.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:202
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:202
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:202
T - mask_len:tensor([107.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:202
T - mask_len:tensor([125.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:202
T - mask_len:tensor([144.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:202
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:202
T - mask_len:tensor([183.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 202, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-961-0006
generate
 99%|█████████▉| 1218/1232 [15:03<00:11,  1.22it/s]processing 1218th semantic_sys file
1218
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE SUBJECT WAS A VERY NOBLE ONE HE DESCRIBED THE MOST FAMOUS ACTION IN WHICH THE ATHENIAN PEOPLE WERE EVER ENGAGED
2024-04-02 06:38:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-961-0007.json
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([25.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([94.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([117.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([142.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([169.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([227.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:319
T - mask_len:tensor([288.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 319, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-961-0007
generate
 99%|█████████▉| 1219/1232 [15:04<00:11,  1.12it/s]processing 1219th semantic_sys file
1219
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OBSERVE AGAIN WHAT CARE THE LAW TOOK IN THE PURSUIT OF WISDOM SEARCHING OUT THE DEEP THINGS OF THE WORLD AND APPLYING THEM TO THE USE OF MAN
2024-04-02 06:38:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-961-0017.json
top_k_know_token:70
known_token_update:False
T:433
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:433
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:433
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:433
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:433
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:433
T - mask_len:tensor([73.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:433
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:433
T - mask_len:tensor([127.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:433
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:433
T - mask_len:tensor([193.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:433
T - mask_len:tensor([229.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:433
T - mask_len:tensor([268.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:433
T - mask_len:tensor([308.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:433
T - mask_len:tensor([349.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:433
T - mask_len:tensor([391.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 433, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-961-0017
generate
 99%|█████████▉| 1220/1232 [15:05<00:11,  1.06it/s]processing 1220th semantic_sys file
1220
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT I WOULD NOT SPEAK AT THE TIME BECAUSE I WANTED TO REFRESH MY MEMORY
2024-04-02 06:38:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-961-0021.json
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([9.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([23.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([33.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([44.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([71.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([86.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([102.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:192
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 192, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-961-0021
generate
 99%|█████████▉| 1221/1232 [15:06<00:09,  1.16it/s]processing 1221th semantic_sys file
1221
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WILL IF TIMAEUS APPROVES I APPROVE
2024-04-02 06:38:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([31], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_2961-961-0003.json
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([13.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([55.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([83.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:103
T - mask_len:tensor([93.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 103, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_2961-961-0003
generate
 99%|█████████▉| 1222/1232 [15:06<00:07,  1.27it/s]processing 1222th semantic_sys file
1222
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: INSTEAD OF BUT SIX REGULARLY AFFILIATED MEMBERS AND AT MOST TWO SCORE OF ADHERENTS THE ORGANIZATION NUMBERS TODAY MANY HUNDRED THOUSAND SOULS
2024-04-02 06:38:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4077-13751-0002.json
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([21.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([58.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([111.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([143.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([216.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([301.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([345.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([392.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:486
T - mask_len:tensor([439.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 486, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4077-13751-0002
generate
 99%|█████████▉| 1223/1232 [15:07<00:07,  1.14it/s]processing 1223th semantic_sys file
1223
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OH WHAT A RECORD TO READ WHAT A PICTURE TO GAZE UPON HOW AWFUL THE FACT
2024-04-02 06:38:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4077-13751-0017.json
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([19.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([29.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([56.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([72.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([90.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([109.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([152.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([174.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([198.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:245
T - mask_len:tensor([221.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 245, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4077-13751-0017
generate
 99%|█████████▉| 1224/1232 [15:08<00:06,  1.22it/s]processing 1224th semantic_sys file
1224
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ITS ORIGIN WAS SMALL A GERM AN INSIGNIFICANT SEED HARDLY TO BE THOUGHT OF AS LIKELY TO AROUSE OPPOSITION
2024-04-02 06:38:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4077-13751-0001.json
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([17.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([46.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([65.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([87.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([141.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([171.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([237.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([309.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:383
T - mask_len:tensor([346.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 383, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4077-13751-0001
generate
 99%|█████████▉| 1225/1232 [15:09<00:05,  1.20it/s]processing 1225th semantic_sys file
1225
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ON THE SIXTH OF APRIL EIGHTEEN THIRTY THE CHURCH OF JESUS CHRIST OF LATTER DAY SAINTS WAS FORMALLY ORGANIZED AND THUS TOOK ON A LEGAL EXISTENCE
2024-04-02 06:38:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4077-13751-0000.json
top_k_know_token:70
known_token_update:False
T:538
T - mask_len:tensor([3.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:538
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:538
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:538
T - mask_len:tensor([41.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:538
T - mask_len:tensor([64.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:538
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:538
T - mask_len:tensor([123.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:538
T - mask_len:tensor([158.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:538
T - mask_len:tensor([197.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:538
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:538
T - mask_len:tensor([285.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:538
T - mask_len:tensor([333.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:538
T - mask_len:tensor([382.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:538
T - mask_len:tensor([434.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:538
T - mask_len:tensor([486.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 538, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4077-13751-0000
generate
100%|█████████▉| 1226/1232 [15:10<00:05,  1.09it/s]processing 1226th semantic_sys file
1226
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: TO THE FERVENT LATTER DAY SAINT A TEMPLE IS NOT SIMPLY A CHURCH BUILDING A HOUSE FOR RELIGIOUS ASSEMBLY
2024-04-02 06:38:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4077-13751-0010.json
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([6.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([24.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([37.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([52.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([70.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([91.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([137.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([163.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([219.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([248.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:308
T - mask_len:tensor([278.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 308, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4077-13751-0010
generate
100%|█████████▉| 1227/1232 [15:11<00:04,  1.10it/s]processing 1227th semantic_sys file
1227
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEIR SUFFERINGS HAVE NEVER YET BEEN FITLY CHRONICLED BY HUMAN SCRIBE
2024-04-02 06:38:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4077-13751-0013.json
top_k_know_token:70
known_token_update:False
T:183
T - mask_len:tensor([1.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:183
T - mask_len:tensor([4.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:183
T - mask_len:tensor([8.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:183
T - mask_len:tensor([14.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:183
T - mask_len:tensor([22.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:183
T - mask_len:tensor([31.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:183
T - mask_len:tensor([42.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:183
T - mask_len:tensor([54.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:183
T - mask_len:tensor([67.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:183
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:183
T - mask_len:tensor([97.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:183
T - mask_len:tensor([113.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:183
T - mask_len:tensor([130.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:183
T - mask_len:tensor([148.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:183
T - mask_len:tensor([166.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 183, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4077-13751-0013
generate
100%|█████████▉| 1228/1232 [15:12<00:03,  1.21it/s]processing 1228th semantic_sys file
1228
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE ARMY FOUND THE PEOPLE IN POVERTY AND LEFT THEM IN COMPARATIVE WEALTH
2024-04-02 06:38:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4077-13754-0000.json
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([10.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([18.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([27.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([38.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([51.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([66.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([100.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([119.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([139.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([159.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([181.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:224
T - mask_len:tensor([203.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 224, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4077-13754-0000
generate
100%|█████████▉| 1229/1232 [15:12<00:02,  1.23it/s]processing 1229th semantic_sys file
1229
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MOREOVER HAD THE PEOPLE BEEN INCLINED TO REBELLION WHAT GREATER OPPORTUNITY COULD THEY HAVE WISHED
2024-04-02 06:38:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4077-13754-0003.json
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([15.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([26.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([40.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([77.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([99.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([124.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([150.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([179.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([209.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([240.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([272.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:337
T - mask_len:tensor([304.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 337, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4077-13754-0003
generate
100%|█████████▉| 1230/1232 [15:13<00:01,  1.22it/s]processing 1230th semantic_sys file
1230
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ALREADY A NORTH AND A SOUTH WERE TALKED OF WHY NOT SET UP ALSO A WEST
2024-04-02 06:38:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4077-13754-0004.json
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([5.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([11.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([20.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([30.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([57.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([74.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([92.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([112.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([133.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([155.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([178.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([202.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:250
T - mask_len:tensor([226.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 250, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4077-13754-0004
generate
100%|█████████▉| 1231/1232 [15:14<00:00,  1.21it/s]processing 1231th semantic_sys file
1231
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AT THE INCEPTION OF PLURAL MARRIAGE AMONG THE LATTER DAY SAINTS THERE WAS NO LAW NATIONAL OR STATE AGAINST ITS PRACTISE
2024-04-02 06:38:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-02 06:38:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_4077-13754-0009.json
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([2.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([7.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([16.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([28.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([43.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([61.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([82.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([106.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([132.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([161.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([191.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([223.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([257.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([291.], device='cuda:0')
top_k_know_token:70
known_token_update:False
T:361
T - mask_len:tensor([326.], device='cuda:0')
top_k_know_token:70
known_token_update:False
torch.Size([1, 361, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts_first_top2_fixed_seed/baseline/baseline/alongtime-base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_steps_16_2024-04-02_14:22:56
sys_file:gen_4077-13754-0009
generate
100%|██████████| 1232/1232 [15:15<00:00,  1.18it/s]100%|██████████| 1232/1232 [15:15<00:00,  1.35it/s]
