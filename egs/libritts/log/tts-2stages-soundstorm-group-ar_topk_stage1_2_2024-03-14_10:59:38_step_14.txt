Current working directory: /home/v-zhijunjia/CodecGen
Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (numpy 1.24.0 (/home/v-zhijunjia/.local/lib/python3.10/site-packages), Requirement.parse('numpy!=1.19.3,<1.24; sys_platform == "linux"'), {'azureml-dataset-runtime'}).
2024-03-14 02:59:42 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
/home/v-zhijunjia/miniconda3/envs/valle-4-23/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MiniBatchKMeans from version 0.24.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
only_antoregressive is True
add_prenet is False
self.ar_text_prenet : Identity()
add_prenet：False
self.encoder_layers:6
self.decoder_layers：6
only_antoregressive is True
add_prenet is False
self.ar_text_prenet : None
add_prenet：False
[]
  0%|          | 0/64 [00:00<?, ?it/s]processing 0th semantic_sys file
0
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT WAS THAT ALL HER REWARD ONE OF THE LADIES ASKED
2024-03-14 03:00:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:00:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
224
[17, 17, 296, 159, 159, 159, 159, 457, 43, 364, 364, 364, 276, 276, 346, 346, 141, 141, 141, 141, 120, 120, 120, 282, 37, 37, 185, 269, 342, 342, 342, 97, 97, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 80, 20, 20, 127, 45, 45, 45, 45, 45, 385, 457, 14, 14, 411, 287, 297, 297, 297, 297, 297, 297, 297, 297, 297, 293, 293, 293, 293, 58, 58, 72, 72, 156, 156, 156, 156, 156, 245, 245, 42, 147, 147, 380, 288, 288, 288, 324, 301, 378, 43, 43, 364, 276, 276, 153, 153, 153, 153, 372, 372, 372, 372, 396, 396, 37, 37, 24, 24, 131, 404, 439, 439, 439, 439, 439, 78, 78, 20, 170, 28, 28, 20, 20, 28, 2, 2, 2, 2, 2, 20, 2, 20, 163, 163, 163, 20, 316, 20, 316, 316, 20, 73, 73, 289, 320, 7, 364, 276, 174, 174, 174, 174, 348, 94, 199, 223, 223, 223, 130, 402, 198, 198, 22, 283, 283, 455, 455, 251, 241, 241, 431, 431, 171, 171, 171, 252, 325, 325, 41, 41, 324, 324, 318, 368, 342, 342, 168, 483, 14, 411, 411, 145, 145, 145, 376, 376, 376, 376, 376, 460, 460, 169, 169, 169, 169, 150, 39, 86, 433, 433, 86, 86, 238, 6, 6, 75, 227, 419, 439, 439]
torch.Size([1, 222, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_121-127105-0036
generate
  2%|▏         | 1/64 [00:09<10:00,  9.54s/it]processing 1th semantic_sys file
1
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE WAS A UNANIMOUS GROAN AT THIS AND MUCH REPROACH AFTER WHICH IN HIS PREOCCUPIED WAY HE EXPLAINED
2024-03-14 03:00:11 | WARNING | phonemizer | words count mismatch on 100.0% of the linebefore_semantic:
after is :
400
[17, 17, 296, 114, 0, 0, 222, 378, 378, 43, 345, 345, 141, 141, 141, 141, 281, 453, 9, 168, 44, 44, 44, 219, 219, 219, 219, 485, 485, 374, 374, 10, 10, 10, 479, 331, 331, 365, 365, 365, 365, 365, 330, 388, 94, 199, 469, 469, 203, 53, 459, 459, 459, 459, 271, 31, 54, 54, 142, 142, 221, 336, 336, 208, 79, 79, 380, 380, 499, 84, 496, 496, 350, 413, 413, 413, 94, 199, 415, 415, 415, 415, 35, 35, 401, 401, 82, 127, 114, 258, 258, 258, 258, 258, 271, 271, 39, 54, 54, 390, 390, 390, 390, 18, 112, 427, 56, 247, 247, 126, 126, 326, 326, 326, 326, 326, 101, 101, 149, 228, 82, 82, 83, 83, 55, 55, 55, 322, 67, 67, 212, 131, 472, 472, 196, 217, 217, 70, 383, 383, 383, 383, 383, 383, 35, 310, 107, 447, 447, 397, 42, 42, 42, 147, 147, 380, 380, 288, 278, 278, 215, 215, 35, 35, 401, 401, 82, 74, 190, 190, 190, 487, 380, 380, 499, 496, 496, 496, 274, 413, 233, 233, 233, 82, 310, 107, 107, 107, 447, 447, 427, 427, 56, 247, 312, 126, 126, 23, 408, 408, 408, 391, 391, 20, 20, 20, 412, 83, 145, 145, 145, 460, 460, 460, 460, 169, 402, 402, 35, 272, 272, 300, 382, 382, 245, 43, 43, 364, 345, 407, 407, 407, 407, 407, 407, 143, 36, 310, 107, 107, 447, 483, 483, 440, 188, 340, 340, 340, 116, 33, 58, 183, 183, 183, 257, 257, 257, 257, 257, 281, 9, 142, 221, 336, 336, 336, 82, 190, 190, 488, 288, 288, 324, 464, 464, 180, 106, 405, 405, 206, 206, 178, 35, 458, 192, 485, 485, 469, 469, 215, 129, 259, 74, 437, 437, 265, 265, 265, 265, 265, 85, 85, 146, 146, 24, 24, 131, 472, 133, 364, 364, 364, 276, 276, 109, 109, 403, 403, 403, 403, 403, 207, 207, 207, 246, 246, 19, 19, 19, 454, 454, 454, 414, 414, 414, 82, 80, 80, 80, 82, 373, 373, 451, 451, 451, 30, 30, 30, 30, 30, 3, 3, 3, 3, 3, 197, 197, 197, 188, 188, 188, 154, 154, 154, 154, 96, 96, 96, 482, 482, 482, 105, 105, 336, 336, 425, 425, 386, 386, 431, 431, 290, 290, 290, 290, 290, 290, 434, 434, 434, 339, 303, 303, 303, 2torch.Size([1, 352, 16])
output_dir is /home/v-zhijunjoutput_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_121-127105-0003
generate
  3%|▎         | 2/64 [00:24<13:33, 13.12s/it]processing 2th semantic_sys file
2
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE AWKWARD THING WAS THAT THEY HAD PRACTICALLY NO OTHER RELATIONS AND THAT HIS OWN AFFAIRS TOOK UP ALL HIS TIME
2024-03-14 03:00:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:00:26 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
before_semantic:
after is :
364
[17, 296, 127, 5, 448, 448, 448, 464, 464, 106, 106, 284, 405, 405, 405, 206, 178, 35, 458, 208, 441, 109, 109, 313, 313, 314, 314, 401, 401, 401, 82, 127, 214, 214, 214, 214, 214, 214, 214, 214, 214, 328, 328, 200, 200, 195, 195, 117, 404, 404, 225, 225, 225, 80, 82, 7, 345, 141, 141, 141, 281, 453, 9, 9, 198, 45, 45, 45, 45, 45, 35, 35, 198, 127, 114, 0, 0, 0, 0, 0, 3, 3, 58, 58, 110, 110, 254, 254, 254, 254, 314, 129, 129, 259, 74, 190, 488, 488, 488, 488, 488, 460, 178, 178, 96, 96, 82, 272, 469, 469, 469, 458, 458, 208, 359, 166, 166, 166, 166, 301, 10, 10, 309, 331, 331, 231, 231, 231, 231, 231, 88, 88, 88, 493, 493, 493, 493, 493, 216, 300, 300, 382, 382, 245, 42, 147, 147, 456, 456, 456, 301, 26, 251, 241, 431, 431, 431, 403, 171, 171, 171, 252, 99, 99, 436, 436, 60, 60, 298, 298, 275, 275, 379, 303, 471, 471, 471, 471, 49, 269, 390, 390, 18, 112, 112, 427, 56, 82, 312, 312, 312, 187, 187, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 260, 260, 260, 163, 163, 163, 163, 163, 140, 140, 316, 140, 140, 73, 140, 140, 83, 83, 55, 55, 55, 322, 322, 466, 466, 45, 45, 45, 45, 45, 325, 183, 257, 257, 257, 257, 257, 281, 9, 9, 168, 168, 106, 106, 350, 350, 350, 350, 350, 350, 350, 413, 413, 413, 413, 195, 195, 117, 335, 440, 440, 255, 255, 255, 349, 349, 234, 234, 261, 25, 470, 470, 264, 264, 264, 264, 468, 468, 468, 304, 304, 304, 304, 185, 49, 269, 54, 54, 86, 238, 6, 108, 377, 295, 295, 295, 295, 143, 458, 144, 27, 230, 230, 230, 230, 230, 215, 215, 35, 402, 483, 14, 411, 297, 297, 297, 297, 297, 297, 293, 293, 58, 58, 183, 257, 257, 257, 257, 31, 31, 54, 86, 86, 238, 6, 108, 119, 119, 103, 103, 103, 103, 103, 103, 103,torch.Size([1, 345, 16])
output_dir is /home/v-zhijunjia/data/tts_test_ltorch.Size([1, 362, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_121-127105-0028
generate
  5%|▍         | 3/64 [00:39<14:08, 13.91s/it]processing 3th semantic_sys file
3
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I COULD WRITE TO MY MAN AND ENCLOSE THE KEY HE COULD SEND DOWN THE PACKET AS HE FINDS IT
2024-03-14 03:00:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:00:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enrbefore_semantic:
after is :
382
[17, 296, 296, 111, 111, 438, 438, 143, before_semantic:
after is :
466
[17, 296, 296, 111, 111, 438, 143, 458, 144, 389, 389, 389, 389, 314, 314, 133, 147, 147, 380, 380, 499, 499, 428, 428, 428, 146, 146, 358, 358, 457, 457, 401, 401, 82, 108, 108, 119, 119, 351, 374, 374, 374, 374, 132, 132, 399, 70, 70, 46, 46, 46, 46, 46, 438, 399, 217, 217, 473, 473, 136, 136, 136, 136, 136, 136, 282, 282, 282, 282, 282, 388, 303, 303, 117, 48, 48, 417, 170, 170, 170, 170, 28, 28, 28, 28, 140, 2, 2, 2, 2, 2, 2, 2, 2, 2, 140, 2, 366, 366, 140, 140, 366, 366, 366, 140, 316, 316, 316, 140, 316, 73, 73, 289, 140, 209, 83, 55, 55, 55, 322, 67, 67, 335, 335, 411, 411, 145, 145, 432, 330, 330, 33, 33, 90, 90, 76, 458, 208, 208, 425, 386, 386, 386, 431, 496, 496, 496, 496, 496, 274, 274, 274, 274, 185, 49, 269, 9, 9, 97, 198, 198, 22, 5, 5, 455, 143, 458, 458, 445, 445, 445, 351, 213, 213, 213, 213, 213, 246, 246, 246, 246, 246, 246, 246, 19, 19, 454, 454, 454, 78, 170, 170, 170, 28, 28, 28, 28, 28, 28, 140, 28, 28, 362, 362, 362, 362, 140, 362, 362, 140, 362, 362, 362, 362, 140, 362, 362, 362, 362, 218, 218, 218, 218, 140, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 140, 218, 366, 366, 366, 366, 140, 366, 366, 366, 366, 366, 366, 140, 366, 366, 140, 366, 366, 366, 366, 366, 366, 316, 316, 316, 316, 316, 73, 73, 289, 289, 373, 451, 451, 30, 30, 30, 422, 143, 144, 389, 389, 389, 389, 314, 478, 478, 232, 232, 172, 115, 273, 273, 432, 432, 432, 330, 348, 64, 64, 212, 384, 180, 180, 315, 315, 315, 450, 450, 413, 348, 466, 466, 22, 283, 283, 455, 455, 129, 259, 74, 74, 437, 351, 351, 486, 486, 486, 486, 460, 460, 178, 178, 458, 192, 192, 277, 277, 277, 277, 385, 385, 233, 233, 233, 227, 419, 439, 439, 78, 170, 170, 47, 47, 140, 47, 47, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 316, 140, 316, 316, 316, 73, 73, 73, 289, 209, 209, 83, 253, 253, 253, 253, 253, 453, 9, 9, 451, 451, 30, 30, 30, 422, 422, 349, 234, 261, 25, 25, 480, 480, 480, 480, 480, 299, 299, 299, 339, 71, 71, 49, 9, 168, 168, 106, 428, 428, 428, 146, 146, 252, 457, 457, 401, 401, 75, 108, 119, 119, 351, 213, 213, 213, 213, 213, 246, 246, 246, 246, 246, 246, 19, 19, 19, 454]
torch.Size([1, 464, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_121-127105-0005
generate
  6%|▋         | 4/64 [00:59<16:13, 16.22s/it]processing 4th sembefore_semantic:
after is :
410
[17, 296, 296, 287, 284, 284, 428, 428, 146, 146, 146, 252, 143, 36, 36, 449, 449, 41, 41, 324, 324, 422, 422, 162, 162, 232, 232, 232, 172, 172, 172, 115, 273, 470, 315, 315, 315, 315, 450, 413, 348, 64, 212, 34, 191, 191, 236, 314, 32, 32, 239, 384, 371, 180, 180, 106, 481, 481, 481, 293, 293, 175, 175, 175, 431, 431, 428, 428, 428, 428, 428, 428, 146, 358, 358, 358, 233, 233, 233, 233, 75, 227, 227, 227, 419, 419, 419before_semantic:
after is :
463
[17, 17, 296, 287, 287, 284, 284, 428, 428, 146, 146, 252, 143, 35, 449, 449, 41, 324, 324, 422, 186, 162, 68, 68, 68, 68, 115, 273, 470, 470, 315, 315, 315, 315, 315, 450, 413, 413, 64, 212, 131, 191, 191, 191, 191, 314, 314, 401, 401, 82, 82, 384, 371, 180, 106, 106, 481, 481, 387, 293, 175, 251, 241, 431, 431, 284, 265, 265, 265, 428, 428, 428, 428, 85, 85, 146, 358, 385, 385, 233, 233, 227, 419, 419, 439, 78, 170, 170, 170, 28, 140, 28, 140, 28, 140, 2, 2, 2, 140, 2, 2, 2, 2, 2, 140, 2, 366, 366, 366, 366, 366, 140, 366, 140, 366, 316, 316, 140, 73, 73, 289, 289, 209, 209, 213, 213, 213, 213, 213, 213, 252, 422, 186, 162, 162, 232, 232, 68, 68, 68, 68, 115, 115, 273, 470, 470, 315, 315, 315, 315, 315, 450, 450, 413, 64, 212, 34, 191, 191, 191, 191, 314, 314, 478, 478, 66, 482, 482, 482, 482, 482, 482, 238, 238, 336, 336, 336, 161, 161, 79, 79, 79, 487, 288, 288, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 434, 434, 434, 434, 434, 434, 434, 434, 339, 339, 339, 471, 471, 310, 107, 107, 395, 483, 440, 89, 89, 446, 446, 67, 67, 335, 14, 14, 14, 82, 411, 411, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297, 293, 293, 122, 216, 22, 283, 283, 455, 455, 399, 70, 138, 138, 138, 138, 138, 138, 387, 387, 387, 186, 186, 162, 162, 68, 68, 68, 68, 115, 115, 273, 273, 84, 84, 84, 84, 84, 84, 16, 16, 16, 274, 274, 274, 98, 98, 13, 229, 247, 312, 312, 187, 187, 187, 187, 187, 187, 187, 187, 2, 140, 2, 2, 2, 2, 2, 140, 2, 2, 140, 316, 316, 140, 73, 140, 289, 320, 354, 420, 420, 422, 143, 458, 144, 27, 27, 351, 151, 151, 151, 240, 368, 453, 453, 168, 69, 223, 223, 130, 402, 402, 183, 183, 257, 257, 257, 257, 281, 453, 9, 142, 196, 196, 217, 217, 217, 473, 65, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 434, 434, 434, 434, 434, 434, 339, 339, 33, 90, 90, 465, 144, 27, 27, 121, 121, 121, 33, 33, 394, 394, 212, 239, 239, 384, 371, 278, 278, 278, 278, 278, 99, 99, 436, 436, 436, 60, 60, 298, 298, 116, 116, 250, 250, 250, 364, 345, 407, 407, 407, 407, 407, 36, 310, 107, 447, 397, 397, 364, 364, 364, 276, 276, 276, 346, 346, 346, 346, 346, 346, 346, 346, 265, 265, 265, 206, 206, 206, 282, 282, 282, 37, 37, 185, 185, 185, 185, 269, 433, 160, 160, 160, 112, 427]
torch.Size([1, 461, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_before_semantic:
after is :
366
[17, 296, 127, 114, 0, 0, 378, 378, 347, 347, 347, 347, 347, 245, 245, 129, 129, 74, 74, 425, 386, 386, 431, 432, 330, 330, 94, 199, 41, 324, 464, 464, 462, 462, 462, 402, 402, 401, 259, 74, 74, 351, 213, 213, 213, 252, 215, 35, 259, 354, 100, 100, 100, 497, 497, 497, 122, 122, 401, 401, 82, 108, 377, 377, 344, 344, 374, 374, 374, 132, 132, 132, 58, 58, 58, 72, 110, 110, 139, 139, 139, 139, 139, 293, 293, 215, 35, 35, 401, 401, 82, 354, 159, 159, 159, 159, 285, 285, 255, 223, 130, 402, 402, 221, 82, 208, 208, 441, 441, 441, 153, 153, 372, 372, 396, 396, 186, 39, 54, 54, 86, 238, 198, 22, 283, 283, 448, 448, 219, 464, 464, 180, 319, 319, 319, 319, 348, 200, 248, 248, 248,before_semantic:
after is :
336
[17, 17, 296, 114, 0, 0, 378, 345, 347, 347, 347, 245, 129, 129, 259, 74, 425, 425, 386, 386, 431, 432, 330, 330, 348, 76, 449, 449, 41, 41, 324, 464, 462, 462, 462, 402, 402, 221, 401, 82, 74, 351, 213, 213, 213, 213, 252, 215, 259, 29, 100, 100, 497, 497, 497, 122, 36, 36, 108, 377, 344, 344, 344, 374, 374, 132, 58, 58, 72, 72, 110, 110, 139, 139, 139, 139, 293, 293, 293, 215, 215, 233, 233, 419, 427, 82, 82, 312, 312, 126, 292, 292, 292, 23, 23, 408, 408, 149, 149, 228, 140, 140, 140, 159, 159, 159, 159, 285, 34, 255, 130, 130, 402, 402, 221, 82, 208, 441, 441, 441, 153, 153, 153, 372, 396, 313, 186, 39, 86, 238, 6, 198, 22, 5, 5, 448, 219, 219, 219, 180, 180, 319, 319, 319, 319, 348, 348, 248, 248, 251, 241, 431, 431, 171, 171, 171, 171, 252, 325, 325, 41, 41, 41, 324, 3, 58, 183, 489, 489, 489, 489, 422, 99, 338, 338, 395, 389, 389, 389, 389, 314, 90, 90, 144, 27, 180, 84, 496, 274, 236, 236, 239, 384, 371, 180, 315, 315, 315, 315, 450, 413, 94, 199, 199, 257, 257, 257, 281, 453, 9, 142, 221, 336, 144, 180, 180, 151, 151, 151, 173, 173, 29, 29, 396, 313, 116, 94, 459, 459, 459, 459, 271, 271, 39, 54, 54, 390, 390, 18, 427, 56, 247, 312, 126, 292, 292, 292, 23, 23, 23, 23, 101, 149, 149, 228, 140, 140, 320, 345, 389, 389, 389, 389, 314, 314, 32, 32, 354, 420, 420, 420, 420, 324, 3, 464, 340, 340, 340, 33, 394, 478, 162, 232, 172, 224, 494, 494, 494, 129, 129, 259, 74, 190, 190, 487, 288, 288, 288, 360, 434, 434, 434, 203, 53, 53, 255, 255, 255, 255, 38, 164, 164, 164, 164, 106, 106, 153, 153, 153, 372, 372, 372, 467, 469, 469, 469, 325, 325, 41, 41, 41, 19, 19, 19, 19, 454]
torch.Size([1, 334, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_121-before_semantic:
after is :
323
[17, 17, 296, 127, 5, 5, 455, 38, 349, 234, 261, 25, 498, 498, 498, 498, 396, 186, 150, 54, 238, 6, 272, 223, 223, 223, 130, 198, 127, 124, 124, 124, 124, 124, 318, 368, 9, 9, 221, 6, 119, 351, 351, 151, 151, 151, 178, 310, 310, 107, 50, 50, 50, 50, 50, 49, 9, 9, 221, 336, 27, 27, 121, 121, 116, 33, 394, 90, 4, 4, 280, 470, 403, 403, 403, 403, 171, 171, 171, 246, 246, 246, 246, 246, 252, 24, 314, 314, 198, 45, 45, 45, 45, 35, 198, 127, 5, 5, 455, 42, 42, 147, 380, 288, 278, 278, 457, 457, 242, 242, 242, 195, 33, 394, 478, 478, 232, 2before_semantic:
after is :
365
[17, 296, 22, 5, 455, 349, 205, 205, 261, 261, 25, 498, 498, 498, 498, 498, 396, 169, 186, 39, 54, 238, 6, 6, 272, 223, 223, 130, 198, 198, 127, 124, 124, 124, 124, 124, 31, 54, 86, 221, 6, 75, 108, 119, 351, 351, 151, 151, 151, 178, 35, 310, 310, 107, 107, 395, 50, 50, 50, 50, 185, 269, 9, 142, 221, 336, 144, 27, 121, 121, 33, 33, 394, 90, 4, 4, 4, 280, 470, 403, 403, 403, 403, 171, 171, 171, 171, 246, 252, 252, 24, 314, 314, 198, 198, 45, 45, 45, 45, 35, 198, 22, 5, 455, 42, 42, 147, 380, 288, 278, 278, 457, 457, 242, 242, 33, 33, 394, 478, 478, 232, 232, 232, 238, 238, 6, 272, 470, 470, 470, 171, 171, 252, 457, 457, 457, 196, 291, 291, 291, 291, 379, 457, 457, 401, 401, 321, 75, 108, 119, 295, 295, 295, 295, 143, 458, 192, 180, 230, 230, 230, 230, 215, 35, 35, 401, 198, 22, 283, 455, 236, 129, 259, 108, 108, 119, 351, 351, 171, 171, 171, 171, 464, 139, 139, 302, 375, 375, 375, 98, 13, 229, 229, 247, 312, 312, 187, 292, 292, 292, 292, 23, 23, 23, 23, 23, 408, 408, 391, 391, 140, 140, 140, 412, 83, 415, 415, 415, 285, 44, 44, 236, 129, 129, 259, 74, 74, 441, 441, 153, 153, 387, 387, 299, 299, 299, 358, 243, 233, 75, 227, 419, 419, 225, 225, 225, 225, 412, 412, 83, 145, 145, 460, 460, 169, 402, 402, 35, 272, 272, 300, 382, 406, 406, 467, 467, 428, 428, 146, 146, 252, 143, 129, 259, 108, 108, 119, 119, 351, 213, 213, 213, 213, 213, 246, 246, 246, 246, 19, 19, 454, 454, 454, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 373, 72, 110, 110, 110, 254, 254, 254, 254, 240, 325, 34, 340, 340, 340, 94, 199, 44, 44, 399, 217, 217, 473, 473, 136, 136, 365, 365, 365, 330, 94, 199, 300, 382, 382, 245, 245, 8, 354, 420, 420, 420, 416, 416, 144, 180, 180, 180, 319, 319, 319, 282, 282, 388, 303, 195, 303, 117, 48, 48, 417]
torch.Size([1, 363, 16])
output_dir ibefore_semantic:
after is :
327
[17, 17, 296, 152, 152, 152, 139, 139, 175, 81, 81, 444, 213, 213, 213, 213, 213, 213, 318, 368, 368, 342, 342, 224, 494, 134, 134, 359, 359, 166, 166, 166, 166, 324, 301, 236, 32, 239, 310, 107, 395, 180, 180, 151, 151, 151, 240, 240, 24, 24, 24, 310, 107, 447, 447, 397, 133, 364, 364, 276, 346, 346, 346, 346, 265, 85, 85, 85, 85, 146, 146, 378, 378, 43, 364, 345, 409, 409, 409, 409, 116, 94, 219, 152, 152, 152, 152, 132, 58, 58, 183, 183, 286, 286, 286, 286, 286, 286, 286, 286, 468, 59, 59, 59, 59, 452, 263, 229, 247, 247, 126, 126, 326, 326, 326, 326, 326, 101, 101, 149, 228, 228, 140, 320, 354, 420, 420, 422, 143, 458, 144, 27, 351, 351, 151, 253, 368, 453, 453, 198, 198, 127, 22, 5, 5, 455, 38, 349, 164, 164, 164, 214, 214, 214, 214, 214before_semantic:
after is :
301
[17, 296, 219, 152, 152, 139, 139, 175, 175, 81, 81, 444, 213, 213, 213, 213, 318, 368, 453, 453, 168, 134, 359, 359, 81, 81, 474, 474, 324, 324, 422, 236, 239, 239, 107, 395, 395, 180, 180, 499, 151, 151, 151, 151, 151, 240, 240, 37, 24, 310, 107, 447, 397, 397, 364, 276, 346, 346, 181, 181, 181, 85, 85, 146, 378, 43, 345, 345, 409, 409, 409, 116, 33, 10, 219, 152, 152, 152, 152, 132, 58, 183, 183, 183, 286, 286, 286, 286, 286, 286, 468, 59, 245, 245, 8, 354, 420, 420, 420, 422, 143, 259, 144, 27, 351, 351, 151, 151, 151, 151, 151, 240, 368, 368, 453, 453, 198, 198, 198, 22, 5, 5, 455, 38, 164, 164, 164, 214, 214, 214, 214, 214, 214, 328, 200, 200, 248, 58, 110, 254, 254, 254, 254, 314, 314, 32, 239, 354, 137, 137, 137, 330, 330, 379, 394, 478, 478, 54, 172, 273, 344, 344, 344, 344, 344, 310, 310, 107, 395, 44, 44, 44, 44, 38, 38, 162, 232, 482, 105, 105, 336, 82, 445, 470, 470, 264, 264, 264, 264, 264, 264, 468, 468, 468, 59, 59, 59, 59, 452, 452, 263, 263, 414, 414, 414, 414, 414, 414, 414, 414, 47, 47, 47, 47, 140, 140, 140, 140, 140, 373, 451, 451, 30, 30, 30, 422, 143, 458, 144, 27, 121, 121, 121, 33, 394, 76, 259, 108, 119, 351, 278, 278, 278, 330, 330, 94, 398, 398, 485, 374, 374, 132, 37, 24, 314, 314, 401, 82, 108, 108, 377, 351, 374, 374, 374, 374, 132, 132, 349, 349, 234, 261, 25, 25, 470, 278, 278, 278, 178, 178, 96, 96, 270, 323, 142, 221, 196, 217, 429, 429, 429, 429, 429, 429, 19, 19, 19, 454, 454, 229, 414]
torch.Size([1, 299, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_before_semantic:
after is :
228
[17, 296, 400, 400, 30, 378, 378, 141, 141, 281, 281, 9, 198, 22, 283, 455, 399, 217, 70, 65, 65, 496, 496, 496, 186, 54, 238, 6, 272, 494, 255, 416, 416, 208, 79, 79, 288, 288, 288, 464, 134, 134, 134, 8, 100, 100, 100, 497, 43, 364, 364, 276, 276, 174, 174, 174, 399, 53, 473, 242, 116, 94, 199, 106, 111, 111, 111, 111, 438, 202, 202, 280, 34, 463, 463, 463, 463, 29, 242, 242, 10, 10, 10, 479, 331, 331, 84, 84, 350, 350, 413, 413, 94, 199, 340, 340, 116, 199, 58, 156, 156, 156, 156, 355, 236, 129, 82, 74, 492, 492, 368, 453, 453, 168, 278, 278, 278, 99, 99, 436, 436, 60, 298, 298, 298, 195, 195, 195, 117, 117, 48, 229, 82, 82, 2before_semantic:
after is :
259
[17, 17, 296, 296, 338, 400, 400, 400, 30, 378, 378, 141, 141, 141, 281, 453, 9, 9, 198, 22, 283, 455, 399, 217, 70, 65, 65, 496, 496, 169, 186, 54, 238, 6, 272, 255, 255, 416, 239, 144, 79, 79, 288, 288, 288, 288, 464, 134, 134, 134, 134, 8, 100, 100, 100, 497, 43, 364, 276, 174, 174, 174, 399, 53, 473, 242, 275, 116, 94, 199, 111, 111, 111, 438, 438, 173, 402, 335, 14, 14, 82, 411, 463, 463, 463, 463, 463, 463, 280, 29, 29, 382, 382, 313, 313, 10, 10, 309, 331, 331, 84, 84, 350, 350, 350, 413, 413, 94, 94, 199, 340, 340, 340, 116, 94, 199, 58, 156, 156, 156, 156, 245, 245, 129, 259, 74, 492, 492, 492, 368, 453, 453, 168, 168, 278, 278, 278, 99, 99, 436, 436, 60, 60, 298, 298, 298, 116, 195, 117, 117, 229, 82, 247, 126, 126, 326, 326, 101, 101, 408, 228, 20, 20, 373, 338, 400, 400, 400, 400, 30, 378, 378, 389, 389, 389, 389, 285, 202, 202, 202, 202, 402, 32, 32, 82, 354, 137, 137, 137, 137, 116, 33, 250, 250, 250, 364, 276, 276, 153, 498, 498, 498, 498, 498, 134, 216, 216, 216, 114, 41, 41, 324, 324, 3, 3, 3, 440, 440, 69, 223, 130, 130, 280, 34, 475, 475, 94, 475, 475, 475, 301, 378, 43, 364, 276, 181, 181, 181, 181, 240, 285, 34, 463, 463, 463, 463, 463, 280, 29, 334, 334, 59, 59, 59, 452, 452, 263, 263, 13]
tbefore_semantic:
after is :
327
[17, 17, 287, 111, 111, 111, 438, 438, 438, 143, 35, 36, 36, 108, 119, 351, 351, 278, 278, 378, 378, 43, 345, 141, 141, 141, 141, 281, 453, 453, 168, 168, 494, 494, 38, 31, 162, 68, 68, 68, 68, 115, 273, 278, 278, 278, 278, 53, 76, 76, 259, 74, 425, 359, 359, 474, 474, 474, 474, 324, 3, 301, 216, 198, 127, 45, 45, 45, 45, 45, 457, 310, 338, 338, 338, 400, 400, 400, 400, 30, 30, 422, 422, 186, 162, 68, 68, 68, 115, 273, 470, 120, 120, 120, 240, 314, 314, 314, 478, 478, 68, 68, 115, 115, 273, 273, 84, 84, 84, 84, 84, 16, 16, 375, 375, 98, 98, 13, 229, 82, 247, 312, 312, 126, 126, 292, 292, 292, 292, 292, 23, 23, 23, 23, 23, 23, 260, 260, 260, 260, 260, 260, 391, 391, 391, 140, 140, 73, 140, 140, 140, 320, 354, 159, 159, 159, 159, 159, 159, 167, 167, 167, 35, 35, 40before_semantic:
after is :
351
[17, 17, 296, 296, 287, 287, 111, 111, 111, 438, 438, 143, 36, 108, 119, 119, 351, 351, 213, 213, 213, 213, 246, 246, 301, 301, 378, 43, 364, 345, 141, 141, 141, 141, 281, 281, 453, 9, 168, 242, 379, 379, 379, 478, 478, 478, 232, 172, 172, 115, 273, 273, 432, 278, 203, 53, 76, 76, 82, 74, 26, 359, 359, 474, 474, 166, 324, 301, 216, 216, 45, 45, 45, 45, 45, 457, 310, 310, 338, 338, 400, 400, 400, 400, 30, 422, 422, 186, 162, 232, 232, 172, 115, 273, 273, 470, 470, 120, 240, 240, 240, 314, 314, 478, 478, 66, 232, 232, 172, 115, 115, 273, 273, 84, 84, 84, 84, 16, 16, 16, 375, 375, 98, 98, 98, 13, 13, 170, 170, 170, 20, 20, 28, 28, 20, 20, 2, 2, 2, 2, 20, 2, 2, 2, 20, 163, 163, 163, 20, 163, 316, 20, 316, 73, 20, 73, 20, 320, 320, 159, 159, 159, 159, 159, 35, 35, 401, 82, 127, 127, 114, 114, 92, 92, 92, 92, 92, 92, 92, 460, 167, 385, 385, 457, 197, 197, 226, 82, 287, 287, 111, 111, 111, 111, 438, 438, 438, 339, 10, 10, 309, 398, 398, 398, 398, 374, 374, 374, 132, 132, 132, 186, 99, 99, 338, 338, 400, 400, 400, 400, 30, 30, 3, 58, 58, 110, 110, 110, 110, 254, 254, 254, 254, 240, 240, 314, 242, 242, 242, 195, 33, 243, 243, 243, 75, 227, 419, 419, 439, 78, 170, 20, 47, 47, 47, 20, 20, 47, 47, 20, 80, 73, 73, 20, 412, 287, 111, 111, 111, 438, 378, 43, 345, 345, 141, 141, 141, 281, 186, 99, 338, 338, 338, 338, 338, 338, 395, 395, 487, 498, 498, 498, 498, 498, 498, 59, 59, 59, 59, 59, 59, 452, 452, 452, 263, 263, 263, 225, 225, 80, 20, 80, 80, 412, 287, 111, 111, 111, 438, 438, 143, 458, 458, 144, 389, 389, 389, 314, 314, 478, 478, 232, 232, 232, 172, 115, 115, 267, 267, 267, 267, 267, 267, 246, 246, 246, 19, 19, 19,before_semantic:
after is :
648
[17, 296, 287, 111, 111, 111, 438, 438, 143, 36, 36, 108, 119, 119, 351, 213, 213, 213, 213, 213, 246, 246, 246, 246, 246, 246, 246, 19, 19, 454, 454, 229, 82, 247, 126, 126, 292, 292, 23, 326, 326, 101, 101, 101, 149, 149, 228, 140, 320, 7, 345, 141, 141, 141, 141, 141, 281, 453, 453, 453, 453, 453, 453, 198, 198, 127, 114, 258, 258, 258, 258, 258, 31, 342, 342, 224, 483, 483, 14, 411, 287, 284, 405, 206, 215, 215, 215, 96, 96, 66, 342, 224, 494, 494, 494, 494, 173, 280, 280, 418, 418, 418, 418, 418, 418, 418, 418, 99, 99, 436, 436, 60, 60, 298, 298, 298, 298, 116, 195, 195, 195, 195, 117, 117, 117, 117, 117, 117, 197, 7, 7, 127, 45, 45, 45, 45, 45, 45, 385, 457, 32, 32, 32, 239, 161, 161, 79, 79, 487, 487, 374, 374, 374, 132, 132, 132, 132, 132, 132, 132, 349, 349, 393, 155, 155, 165, 165, 165, 165, 165, 53, 53, 394, 394, 32, 239, 384, 371, 180, 151before_semantic:
after is :
496
[17, 17, 296, 296, 287, 111, 111, 438, 438, 143, 36, 108, 108, 119, 351, 213, 213, 213, 213, 246, 246, 301, 378, 43, 345, 141, 141, 141, 141, 281, 9, 198, 198, 127, 114, 258, 258, 258, 31, 54, 54, 142, 483, 14, 411, 411, 405, 405, 215, 215, 215, 96, 96, 54, 224, 224, 494, 494, 494, 173, 173, 280, 280, 418, 418, 418, 418, 418, 418, 418, 99, 99, 436, 436, 60, 60, 298, 298, 116, 195, 195, 466, 114, 45, 45, 45, 45, 457, 32, 239, 310, 161, 161, 79, 487, 189, 374, 374, 374, 132, 132, 132, 349, 393, 155, 165, 165, 165, 165, 165, 53, 394, 394, 32, 239, 384, 371, 180, 180, 151, 151, 416, 416, 458, 26, 359, 359, 81, 459, 459, 271, 271, 271, 39, 323, 390, 390, 18, 18, 112, 427, 56, 56, 20, 312, 187, 187, 187, 187, 391, 20, 391, 391, 73, 20, 20, 320, 7, 479, 331, 307, 307, 61, 61, 449, 449, 449, 34, 255, 255, 399, 217, 217, 473, 65, 213, 213, 213, 252, 325, 34, 485, 485, 485, 469, 385, 457, 457, 26, 26, 359, 359, 474, 474, 474, 474, 474, 19, 19, 19, 19, 19, 454, 454, 78, 170, 20, 170, 28, 20, 20, 20, 20, 20, 2, 2, 20, 20, 163, 163, 163, 20, 20, 73, 73, 20, 20, 320, 159, 159, 159, 159, 457, 457, 251, 241, 431, 431, 171, 171, 171, 252, 143, 36, 449, 449, 300, 382, 382, 382, 406, 467, 340, 340, 340, 466, 466, 22, 283, 448, 448, 14, 14, 411, 213, 213, 213, 213, 252, 173, 173, 402, 196, 196, 94, 176, 176, 176, 328, 328, 328, 200, 200, 117, 335, 335, 440, 440, 440, 44, 44, 44, 42, 42, 147, 147, 380, 288, 278, 215, 129, 129, 259, 74, 425, 425, 386, 386, 265, 265, 265, 265, 85, 85, 85, 85, 207, 207, 207, 19, 19, 454, 454, 454, 78, 170, 170, 20, 20, 312, 312, 312, 292, 292, 23, 23, 23, 23, 23, 101, 101, 391, 391, 228, 289, 20, 320, 45, 45, 45, 45, 45, 449, 449, 58, 110, 254, 254, 254, 254, 314, 198, 22, 22, 448, 448, 448, 14, 14, 411, 121, 121, 121, 33, 64, 76, 161, 161, 161, 487, 487, 487, 469, 186, 31, 54, 238, 6, 6, 272, 176, 176, 176, 328, 200, 200, 248, 76, 144, 144, 27, 370, 370, 370, 370, 370, 77, 77, 54, 224, 494, 494, 469, 469, 458, 208, 208, 441, 11, 11, 11, 11, 11, 379, 379, 243, 243, 77, 270, 323, 323, 238, 6, 6, 108, 377, 123, 123, 123, 123, 43, 345, 407, 407, 407, 407, 407, 310, 310, 107, 395, 106, 111, 111, 111, 438, 438, 143, 458, 144, 208, 441, 441, 481, 481, 481, 175,torch.Size([1, 646, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_natorch.Size([1, 494, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_121-127105-0000
generate
 17%|█▋        | 11/64 [02:53<15:33, 17.62s/it]processing 11th semantic_sys file
11
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WELL IF I DON'T KNOW WHO SHE WAS IN LOVE WITH I KNOW WHO HE WAS
2024-03-14 03:02:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:02:56 | WARNING | before_semantic:
after is :
216
[17, 296, 296, 276, 109, 109, 109, 443, 443, 139, 139, 293, 293, 175, 175, 118, 118, 118, 118, 118, 205, 2before_semantic:
after is :
202
[17, 17, 296, 296, 7, 364, 276, 109, 109, 443, 443, 443, 139, 139, 139, 139, 293, 293, 293, 375, 98, 98, 98, 98, 13, 13, 13, 13, 78, 170, 170, 20, 20, 20, 20, 20, 312, 187, 187, 187, 12, 12, 408, 408, 408, 391, 391, 20, 20, 289, 20, 412, 118, 118, 118, 118, 205, 25, 106, 111, 111, 111, 111, 438, 438, 236, 36, 371, 371, 84, 350, 350, 350, 413, 348, 457, 10, 309, 479, 331, 331, 84, 84, 84, 16, 16, 16, 274, 274, 58, 183, 183, 489, 181, 181, 132, 132, 186, 99, 338, 338, 400, 400, 400, 400, 30, 301, 378, 43, 345, 141, 141, 141, 141, 281, 453, 9, 168, 340, 340, 340, 340, 33, 250, 251, 251, 241, 431, 431, 266, 266, 266, 266, 173, 173, 402, 402, 345, 333, 333, 220, 220, 164, 168, 106, 111, 111, 111, 438, 438, 438, 10, 479, 331, 84, 84, 84, 16, 274, 274, 58, 183, 183, 181, 181, 181, 374, 132, 132, 58, 183, 451, 30, 30, 301, 301, 43, 364, 276, 276, 346, 346, 346, 265, 120, 120, 120, 37, 37, 185torch.Size([1, 214, 16])
output_dir is /home/v-zhijunjia/dtorch.Size([1, 200, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_121-127105-0022
generate
 19%|█▉        | 12/64 [03:02<12:59, 14.98s/it]processing 12th semantic_sys file
12
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE OTHERS RESENTED POSTPONEMENT BUT IT WAS JUST HIS SCRUPLES THAT CHARMED ME
2024-03-14 03:03:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:03:04 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tenbefore_semantic:
after is :
496
[17, 17, 127, 5, 448, 448, 448, 464, 464, 493, 493, 493, 493, 493, 493, 216, 216, 300, 300, 50, 50, 50, 50, 50, 50, 185, 185, 49, 269, 323, 390, 390, 390, 18, 18, 97, 97, 225, 225, 225, 225, 225, 225, 225, 225, 7, 7, 7, 147, 147, 456, 456, 456, 456, 368, 453, 9, 9, 168, 432, 432, 432, 432, 330, 330, 64, 76, 36, 449, 449, 191, 191, 191, 191, 314, 314, 314, 401, 401, 82, 74, 437, 437, 496, 496, 496, 496, 274, 186, 39, 54, 54, 142, 221, 336, 336, 74, 74, 437, 437, 496, 496, 496, 350, 413, 413, 348, 33, 250, 250, 217, 291, 291, 291, 291, 291, 291, 379, 243, 243, 233, 227, 227, 227, 419, 419, 419, 419, 419, 439, 439, 439, 439, 78, 78, 170, 140, 140, 140, 28, 28, 28, 28, 140, 341, 341, 341, 341, 341, 341, 341, 341, 341, 341, 341, 341, 369, 369, 140, 369, 369, 369, 369, 260, 260, 260, 260, 260, 260, 260, 391, 391, 228, 289, 289, 140, 320, 354, 159, 159, 159, 159, 285, 285, 34, 106, 284, 284, 265, 428, 85, 438, 438, 422, 143, 36, 36, 108, 108, 119, 351, 444, 444, 213, 213, 213, 213, 246, 246, 246, 246, 246, 246, 246, 246, 246, 246, 19, 19, 454, 454, 454, 454, 225, 225, 225, 225, 225, 225, 225, 225, 225, 80, 80, 320, 320, 345, 345, 141, 141, 141, 141, 141, 281, 281, 9, 142, 221, 221, 401, 401, 401, 310, 310, 310, 107, 107, 395, 395, 395, 180, 151, 151, 151, 169, 169, 150, 54, 54, 86, 238, 238, 6, 6, 272, 227, 419, 419, 439, 439, 439, 439, 439, 439, 78, 78, 140, 170, 140, 28, 140, 28, 28, 140, 341, 341, 341, 341, 341, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 260, 260, 260, 260, 260, 260, 260, 260, 391, 391, 391, 228, 140, 140, 373, 183, 183, 451, 257, 257, 257, 257, 257, 31, 162, 54, 482, 482, 482, 482, 482, 105, 105, 336, 336, 208, 79, 79, 487, 374, 374, 374, 132, 215, 215, 129, 259, 74, 29, 302, 302, 302, 302, 302, 375, 375, 375, 375, 185, 185, 185, 49, 269, 323, 390, 390, 18, 18, 18, 18, 112, 439, 439, 439, 439, 439, 78, 78, 170, 170, 140, 28, 28, 28, 140, 28, 2, 140, 2, 341, 341, 341, 341, 369, 369, 369, 12, 12, 12, 12, 12, 260, 260, 260, 260, 260, 260, 391, 391, 391, 228, 140, 289, 320, 7, 127, 114, 114, 92, 92, 92, 92, 92, 167, 167, 457, 401, 401, 401, 310, 107, 107, 107, 395, 395, 351, 106, 284, 306, 306, 306, 306, 306, 306, 306, 426, 426, 450, 413, 203, 53, 53, 53, 64, 64, 212, 212, 131, 131, 472, 196, 196, 217, 473, 429, 429, 429, 429, 429, 429, 429, 246, 246, 246, 246, 246, 19, 19, 19, 19, 19, 454, 454, 454, 454]
torch.Size([1, 494, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_121-127105-0006
generate
 20%|██        | 13/64 [03:21<14:41, 17.28s/it]processing 13th semantic_sys file
13
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SOMEONE ELSE TOLD A STORY NOT PARTICULARLY EFFECTIVE WHICH I SAW HE WAS NOT FOLLOWING
2024-03-14 03:03:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:03:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
199
[17, 17, 296, 66, 172, 115, 273, 231, 231, 231, 53, 250, 250, 174, 174, 174, 348, 94, 199, 180, 139, 139, 139, 293, 169, 186, 39, 86, 238, 6, 108, 119, 106, 424, 424, 424, 122, 122, 34, 44, 44, 38, 38, 162, 482, 238, 6, 272, 106, 153, 153, 153, 372, 372, 337, 337, 301, 339, 94, 331, 307, 307, 61, 167, 457, 35, 82, 74, 492, 492, 492, 236, 36, 108, 278, 278, 278, 143, 458, 445, 485, 134, 134, 134, 175, 81, 134, 134, 134, 134, 13before_semantic:
after is :
337
[17, 17, 296, 108, 108, 119, 119, 351, 374, 374, 374, 374, 132, 132, 132, 132, 132, 132, 216, 216, 127, 114, 114, 258, 258, 258, 258, 258, 271, 271, 271, 39, 39, 390, 390, 390, 390, 390, 18, 18, 112, 112, 56, 56, 20, 20, 312, 312, 187, 292, 292, 292, 23, 408, 408, 408, 391, 391, 228, 20, 20, 373, 373, 451, 257, 257, 257, 257, 257, 453, 9, 9, 168, 145, 145, 145, 365, 365, 365, 365, 330, 330, 379, 77, 77, 77, 342, 172, 224, 224, 334, 382, 382, 245, 43, 345, 141, 141, 141, 281, 281, 9, 142, 221, 336, 336, 74, 190, 190, 488, 488, 488, 426, 426, 426, 426, 426, 203, 53, 53, 76, 96, 36, 227, 227, 419, 419, 427, 56, 56, 56, 312, 312, 312, 187, 187, 23, 23, 23, 23, 23, 260, 260, 391, 391, 391, 228, 20, 289, 20, 209, 287, 287, 496, 496, 274, 274, 274, 349, 164, 164, 164, 164, 164, 164, 164, 164, 164, 25, 470, 470, 365, 365, 365, 365, 365, 360, 360, 434, 200, 243, 243, 233, 458, 192, 192, 192, 419, 419, 419, 419, 439, 439, 439, 78, 47, 20, 47, 20, 47, 47, 20, 47, 47, 20, 20, 80, 80, 80, 20, 289, 289, 144, 27, 91, 91, 91, 91, 206, 206, 240, 314, 196, 196, 309, 479, 331, 331, 84, 84, 84, 16, 16, 16, 375, 98, 98, 98, 13, 13, 13, 78, 170, 20, 20, 312, 312, 187, 187, 187, 12, 12, 12, 12, 260, 163, 163, 163, 163, 20, 163, 163, 20, 316, 316, 316, 73, 73, 289, 20, 209, 83, 55, 55, 322, 6before_semantic:
after is :
239
[17, 108, 119, 351, 374, 132, 132, 132, 216, 127, 114, 258, 258, 258, 31, 342, 54, 224, 257, 257, 257, 257, 453, 453, 168, 145, 145, 145, 365, 365, 330, 330, 379, 77, 77, 77, 54, 224, 224, 300, 334, 382, 382, 59, 59, 245, 245, 43, 345, 345, 141, 141, 281, 281, 142, 142, 221, 336, 82, 74, 190, 190, 488, 488, 426, 426, 203, 53, 76, 96, 36, 272, 34, 106, 496, 496, 274, 274, 349, 164, 164, 164, 164, 470, 365, 365, 365, 365, 360, 200, 76, 458, 192, 192, 472, 472, 472, 401, 401, 82, 144, 180, 91, 91, 91, 91, 206, 206, 240, 24, 131, 472, 472, 196, 309, 309, 479, 331, 331, 84, 84, 84, 84, 16, 16, 16, 16, 16, 16, 375, 375, 98, 98, 98, 98, 98, 13, 13, 78, 82, 170, 140, 140, 28, 140, 28, 2, 2, 2, 2, 2, 2, 2, 140, 2, 2, 2, 140, 163, 140, 163, 163, 163, 316, 316, 316, 73, 73, 73, 140, 209, 83, 55, 55, 322, 322, 67, 212, 34, 356, 356, 356, 281, 453, 198, 198, 22, 283, 283, 455, 42, 147, 147, 380, 443, 443, 178, 178, 458, 192, 192, 487, 382, 382, 313, 24, 131, 219, 219, 219, 485, 106, 153, 153, 153, 153, 153, 372, 372, 372, 59, 59, 304, 304, 185, 185, 185, 185, 269, 323, 390, 390, 18, 18, 18, 112, 112before_semantic:
after is :
467
[17, 17, 208, 208, 190, 487, 499, 499, 265, 265, 85, 146, 146, 24, 314, 131, 133, 133, 364, 276, 174, 174, 174, 174, 94, 199, 223, 223, 223, 130, 402, 198, 198, 22, 283, 283, 455, 43, 43, 364, 276, 276, 109, 109, 278, 278, 203, 53, 473, 473, 136, 275, 275, 116, 195, 117, 117, 117, 48, 48, 417, 414, 414, 170, 170, 170, 140, 28, 28, 28, 140, 28, 28, 28, 28, 28, 362, 362, 362, 140, 362, 362, 362, 140, 362, 362, 362, 140, 218, 218, 140, 218, 218, 218, 218, 218, 218, 218, 140, 366, 366, 366, 366, 366, 366, 140, 366, 140, 366, 366, 366, 366, 140, 316, 316, 316, 73, 73, 140, 373, 451, 30, 30, 422, 143, 259, 108, 295, 295, 295, 295, 295, 35, 35, 96, 196, 196, 309, 309, 479, 331, 231, 231, 231, 231, 274, 413, 10, 10, 479, 331, 331, 84, 496, 496, 274, 285, 285, 459, 459, 459, 31, 54, 54, 224, 69, 223, 223, 130, 402,before_semantic:
after is :
331
[17, 17, 296, 208, 190, 487, 499, 499, 499, 265, 265, 85, 85, 146, 146, 24, 131, 133, 364, 174, 174, 174, 174, 94, 199, 223, 223, 216, 22, 283, 283, 455, 43, 43, 364, 276, 109, 109, 278, 278, 278, 203, 473, 473, 275, 275, 275, 275, 388, 195, 195, 195, 117, 117, 117, 117, 404, 225, 225, 451, 451, 451, 30, 30, 30, 422, 143, 36, 108, 295, 295, 295, 295, 295, 458, 96, 196, 309, 309, 479, 331, 231, 231, 231, 231, 274, 274, 10, 10, 479, 331, 84, 84, 496, 496, 274, 252, 36, 36, 449, 459, 459, 459, 459, 31, 342, 342, 224, 69, 69, 223, 130, 402, 402, 72, 156, 156, 156, 156, 156, 156, 498, 498, 355, 355, 355, 355, 355, 452, 263, 263, 13, 78, 170, 170, 20, 20, 20, 20, 20, 312, 187, 12, 12, 12, 12, 12, 12, 12, 408, 408, 408, 408, 391, 391, 20, 20, 20, 373, 451, 451, 30, 30, 30, 301, 251, 251, 367, 367, 367, 367, 367, 96, 96, 36, 272, 415, 415, 415, 415, 457, 196, 196, 429, 429, 429, 429, 429, 429, 19, 19, 19, 454, 454, 454, 225, 225, 225, 225, 225, 80, 20, 80, 20, 20, 159, 159, 159, 159, 325, 34, 253, 253, 253, 453, 342, 168, 118, 118, 118, 118, 402, 402, 121, 121, 121, 121, 33, 394, 478, 232, 232, 232, 238, 6, 272, 470, 470, 470, 443, 443, 240, 325, 34, 69, 223, 223, 130, 402, 402, 196, 196, 217, 429, 429, 429, 429, 429, 429, 19, 19, 19, 454, 454, 225, 225, 225, 225, 225, 225, 373, 451, 451, 30, 30, 422, 162, 232, 172, 115, 273, 106, 106, 153, 387, 387, 43, 43, 181, 181, 18torch.Size([1, 465, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_torch.Size([1, 329, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_121-127105-0002
generate
 25%|██▌       | 16/64 [03:52<10:41, 13.36s/it]processing 16th semantic_sys file
16
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE WAS SOMETHING INDIVIDUAL ABOUT THE GREAT FARM A MOST UNUSUAL TRIMNESS AND CARE FOR DETAIL
2024-03-14 03:03:55 | WARNING | phonemizer | words count mismatchbefore_semantic:
after is :
376
[17, 17, 296, 127, 114, 0, 222, 378, 378, 345, 345, 141, 141, 281, 162, 54, 232, 232, 172, 172, 115, 231, 231, 231, 231, 231, 53, 76, 35, 164, 214, 214, 214, 214, 214, 200, 200, 200, 335, 335, 188, 188, 340, 121, 121, 121, 33, 394, 212, 239, 239, 384, 371, 371, 490, 278, 278, 173, 280, 280, 278, 278, 278, 278, 278, 278, 24, 239, 310, 107, 395, 134, 134, 134, 100, 100, 100, 100, 497, 497, 175, 175, 255, 255, 255, 8, 8, 354, 180, 180, 113, 113, 113, 113, 113, 113, 167, 35, 35, 401, 198, 22, 283, 455, 455, 416, 239, 208, 79, 79, 79, 484, 484, 484, 484, 484, 484, 252, 252, 457, 457, 90, 393, 393, 234, 234, 234, 261, 261, 25, 106, 284, 284, 306, 306, 306, 306, 306, 306, 396, 396, 396, 203, 203, 381, 381, 117, 48, 229, 229, 20, 247, 312, 312, 126, 1, 1, 1, 1, 1, 1, 1, 23, 101, 101, 101, 101, 149, 149, 228, 20, 412, 287, 287, 44, 44, 399, 399, 70, 70, 70, 70, 65, 65, 496, 496, 496, 274, 274, 186, 186, 54, 54, 238, 6, 272, 483, 483, 226, 440, 287, 287, 319, 319, 319, 319, 348, 33, 10, 10, 219, 219, 219, 219, 485, 485, 374, 374, 374, 374, 374, 374, 368, 368, 368, 107, 107, 395, 134, 134, 134, 100, 100, 100, 100, 497, 497, 122, 236, 36, 310, 161, 161, 161, 487, 487, 487, 288, 288, 278, 330, 203, 53, 64, 10, 10, 479, 459, 459, 459, 459, 271, 271, 31, 54, 54, 390, 390, 390, 390, 18, 112, 112, 427, 56, 56, 20, 20, 312, 312, 312, 292, 292, 292, 292, 292, 292, 1, 21, 21, 21, 408, 408, 408, 408, 391, 391, 20, 20, 412, 83, 83, 55, 55, 322, 322, 67, 90, 90, 129, 20, 144, 445, 445, 445, 351, 351, 264, 264, 264, 264, 468, 468, 468, 468, 245, 245, 349, 349, 234, 234, 155, 155, 332, 332, 332, 332, 396, 313, 236, 236, 239, 239, 239, 384, 371, 371, 213, 213, 213, 213, 252, 422, 143, 36, 108, 119, 119, 351, 351, 470, 470, 171, 264, 264, 264, 139, 139, 139, 139, 375, 375, 375, 98, 98, 13]
torch.Size([1, 374, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_237-134493-0015
generate
 27%|██▋       | 17/64 [04:08<11:36, 14.81s/it]processing 17th semantic_sys file
17
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HOW BROWN YOU'VE GOT SINCE YOU CAME HOME I WISH I HAD AN ATHLETE TO MOW MY ORCHARD
2024-03-1before_semantic:
after is :
299
[17, 17, 296, 268, 268, 268, 268, 268, 293, 274, 8, 8, 32, 354, 190, 190, 79, 380, 380, 380, 499, 315, 315, 315, 315, 315, 450, 450, 450, 413, 413, 348, 64, 219, 219, 152, 152, 152, 152, 152, 202, 402, 402, 221, 401, 82, 144before_semantic:
after is :
306
[17, 17, 296, 296, 268, 268, 268, 268, 268, 293, 274, 8, 32, 32, 32, 354, 190, 190, 79, 380, 380, 288, 315, 315, 315, 315, 315, 450, 450, 450, 413, 413, 413, 64, 64, 219, 219, 152, 152, 152, 152, 152, 202, 202, 402, 402, 32, 239, 144, 27, 180, 106, 405, 405, 405, 405, 206, 206, 167, 35, 478, 478, 232, 232, 172, 172, 115, 273, 273, 432, 432, 330, 379, 379, 77, 77, 54, 54, 142, 142, 219, 152, 152, 152, 152, 143, 129, 259, 144, 445, 445, 210, 210, 210, 210, 210, 210, 210, 434, 434, 434, 434, 203, 203, 381, 381, 117, 404, 58, 72, 72, 72, 72, 437, 350, 350, 350, 350, 350, 350, 350, 182, 182, 182, 182, 413, 413, 203, 381, 381, 381, 381, 381, 117, 404, 404, 13, 78, 140, 140, 140, 312, 187, 187, 187, 23, 23, 260, 260, 260, 391, 391, 391, 140, 140, 412, 287, 287, 111, 111, 111, 438, 378, 43, 43, 364, 276, 109, 109, 278, 278, 278, 99, 99, 436, 107, 395, 395, 111, 111, 111, 111, 438, 438, 58, 58, 110, 110, 110, 110, 254, 254, 240, 240, 325, 34, 44, 44, 44, 116, 94, 199, 199, 145, 145, 145, 486, 460, 460, 169, 169, 164, 164, 26, 26, 26, 359, 359, 81, 81, 444, 444, 213, 246, 246, 246, 358, 358, 233, 233, 82, 227, 227, 419, 419, 439, 225, 225, 225, 225, 80, 80, 140, 140, 108, 377, 377, 87, 87, 87, 87, 399, 217, 70, 70, 65, 65, 496, 496, 496, 274, 274, 274, 399, 399, 70, 70, 46, 46, 46, 46, 46, 438, 464, 464, 106, 106, 153, 153, 372, 372, 396, 396, 143, 36, 310, 107, 107, 395, 334, 382, 382, 59, 59, 59, 59, 37, 37, 24, 24, 24, 131, 419, 439, 439, 439]
torch.Size([1, 304, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_237-134493-0011
generate
 28%|██▊       | 18/64 [04:21<10:57, 14.30s/it]processing 18th semantic_sys file
18
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ANY ONE THEREABOUTS WOULD HAVE TOLD YOU THAT THIS WAS ONE OF THE RICHEST FARMS ON THE DIVIDE AND THAT THE Fbefore_semantic:
after is :
428
[17, 296, 296, 188, 475, 475, 475, 475, 94, 475, 475, 475, 324, 301, 378, 43, 276, 276, 174, 174, 174, 174, 174, 282, 282, 388, 195, 195, 117, 117, 117, 117, 197, 197, 197, 197, 7, 7, 127, 114, 114, 222, 222, 468, 406, 406, 467, 467, 255, 255, 8, 8, 354, 180, 180, 113,before_semantic:
after is :
400
[17, 17, 296, 296, 188, 475, 475, 475, 475, 94, 475, 475, 475, 324, 324, 301, 301, 43, 364, 364, 276, 276, 174, 174, 174, 174, 319, 348, 348, 466, 466, 466, 114, 114, 222, 222, 222, 406, 467, 467, 255, 255, 8, 354, 180, 180, 113, 113, 113, 113, 167, 167, 77, 270, 54, 142, 397, 397, 345, 389, 389, 389, 285, 34, 202, 202, 202, 402, 402, 401, 82, 108, 108, 119, 351, 351, 424, 424, 424, 424, 424, 424, 497, 122, 122, 24, 310, 107, 477, 477, 477, 477, 477, 477, 477, 132, 132, 98, 98, 98, 13, 229, 82, 247, 312, 312, 187, 187, 12, 12, 12, 12, 23, 23, 23, 23, 23, 101, 101, 149, 149, 140, 140, 140, 127, 45, 45, 45, 45, 45, 457, 457, 32, 127, 114, 258, 258, 258, 258, 258, 31, 54, 54, 142, 397, 141, 141, 141, 281, 453, 142, 397, 364, 276, 174, 174, 174, 174, 94, 199, 223, 223, 130, 402, 198, 198, 283, 455, 455, 42, 42, 147, 380, 288, 278, 278, 36, 310, 107, 395, 459, 459, 31, 54, 54, 142, 393, 393, 261, 25, 25, 284, 284, 284, 306, 306, 306, 306, 282, 282, 203, 203, 381, 381, 471, 471, 49, 269, 323, 390, 390, 18, 97, 483, 226, 226, 226, 226, 226, 140, 209, 287, 287, 125, 125, 125, 125, 125, 125, 125, 348, 195, 195, 466, 212, 22, 283, 455, 236, 239, 490, 490, 490, 490, 4, 280, 280, 106, 106, 265, 265, 265, 265, 265, 85, 85, 85, 299, 299, 37, 24, 131, 131, 483, 483, 226, 226, 82, 83, 55, 55, 322, 322, 466, 466, 45, 45, 45, 45, 457, 457, 198, 22, 5, 455, 349, 205, 234, 261, 25, 106, 284, 306, 306, 306, 306, 203, 203, 53, 29, 334, 334, 382, 245, 245, 43, 345, 141, 141, 141, 141, 281, 453, 168, 44, 44, 43, 364, 364, 276, 276, 174, 174, 174, 53, 473, 242, 242, 116, 33, 33, 335, 335, 14, 411, 411, 145, 145, 145, 486, 486, 175, 175, 81, 81, 469, 178, 416, 96, 96, 453, 453, 168, 470, 256, 256, 365, 365, 365, 330, 388, 64, 212, 212, 300, 495, 382, 467, 467, 255, 255, 8, 259, 259, 354, 498, 498, 498, 498, 498, 498, 396, 396, 416, 416, 96, 270, 269, 323, 224, 224, 275, 275, 275, 303, 303, 303, 48, 48, 48]
torch.Size([1, 398, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_237-134493-0017
generate
 30%|██▉       | 19/64 [04:39<11:29, 15.33s/it]processing 19th semantic_sys file
19
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HIS WIFE NOW LIES BESIDE HIM AND THE WHITE SHAFT THAT MARKS THEIR GRAVES GLEAMS ACROSS THE WHEAT FIELDS
2024-03-14 03:04:41 | WARNING | phonemizer | words count mismatch on 100.0% ofbefore_semantic:
after is :
345
[17, 17, 296, 451, 257, 257, 257, 257, 281, 453, 142, 142, 397, 364, 276, 276, 346, 346, 346, 346, 428, 428, 428, 146, 146, 358, 358, 358, 352, 352, 402, 2before_semantic:
after is :
339
[17, 17, 373, 257, 257, 281, 453, 9, 142, 133, 364, 276, 346, 346, 428, 428, 428, 146, 146, 358, 349, 352, 402, 221, 196, 196, 309, 479, 331, 331, 315, 315, 315, 450, 450, 293, 293, 251, 251, 241, 431, 265, 265, 265, 85, 85, 85, 146, 146, 368, 368, 453, 9, 221, 221, 259, 354, 420, 420, 422, 422, 162, 232, 172, 172, 273, 273, 265, 265, 428, 85, 146, 146, 252, 325, 325, 183, 183, 57, 57, 57, 57, 57, 57, 203, 381, 381, 117, 48, 48, 48, 417, 417, 417, 417, 237, 47, 140, 140, 47, 47, 140, 140, 435, 435, 435, 435, 435, 83, 83, 55, 322, 322, 466, 466, 22, 5, 455, 455, 43, 43, 364, 276, 276, 346, 346, 428, 428, 146, 146, 358, 457, 457, 478, 338, 338, 338, 338, 338, 395, 395, 470, 470, 486, 486, 486, 376, 376, 460, 460, 460, 169, 169, 169, 352, 352, 352, 352, 352, 6, 75, 75, 419, 427, 427, 140, 247, 312, 126, 292, 292, 292, 292, 23, 23, 23, 408, 408, 408, 391, 228, 140, 289, 320, 320, 127, 45, 45, 45, 45, 457, 457, 457, 70, 70, 70, 65, 65, 306, 306, 306, 396, 396, 396, 178, 96, 270, 270, 323, 86, 238, 221, 198, 127, 222, 222, 222, 222, 245, 416, 416, 239, 208, 208, 79, 79, 380, 288, 288, 403, 171, 171, 171, 246, 246, 318, 173, 173, 49, 49, 9, 142, 221, 221, 336, 208, 425, 386, 386, 431, 431, 360, 360, 360, 434, 434, 434, 434, 203, 203, 53, 471, 49, 49, 9, 168, 255, 255, 255, 143, 458, 208, 190, 487, 499, 499, 499, 405, 405, 206, 169, 150, 150, 86, 86, 238, 198, 22, 283, 283, 455, 43, 364, 276, 109, 109, 213, 213, 213, 252, 252, 457, 90, 393, 393, 234, 261, 25, 25, 485, 213, 213, 213, 286, 286, 139, 139, 139, 139, 375, 375, 375, 375, 122, 24, 471, 471, 270, 270, 433, 433, 160, 18, 112, 427, 56, 56, 140, 15]
torch.Size([1, 337, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_237-134493-0001
generate
 31%|███▏      | 20/64 [04:53<11:01, 15.04s/it]processing 20th semantic_sys file
20
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT IS SIXTEEN YEARS SINCE JOHN BERGSON DIED
2024-03-14 03:04:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:before_semantic:
after is :
186
[17, 17, 287, 111, 111, 438, 438, 143, 35, 259, 108, 119, 351, 213, 213, 213, 213, 246, 3, 464, 464, 356, 356, 281, 31, 162,before_semantic:
after is :
228
[17, 17, 296, 296, 287, 287, 284, 284, 284, 284, 265, 265, 265, 265, 265, 265, 265, 265, 85, 85, 85, 85, 85, 207, 207, 19, 19, 454, 454, 229, 414, 170, 140, 140, 140, 312, 312, 187, 12, 12, 12, 12, 12, 12, 12, 260, 260, 260, 260, 391, 149, 149, 140, 140, 412, 188, 177, 177, 177, 177, 325, 34, 356, 356, 356, 356, 281, 162, 162, 232, 232, 172, 172, 115, 273, 278, 278, 178, 143, 458, 96, 96, 86, 238, 6, 6, 272, 371, 444, 360, 360, 360, 360, 434, 434, 339, 339, 33, 33, 219, 219, 219, 286, 286, 286, 286, 286, 286, 286, 286, 286, 286, 468, 468, 304, 304, 304, 304, 185, 49, 269, 9, 97, 97, 225, 225, 197, 66, 66, 66, 172, 115, 273, 273, 432, 330, 330, 379, 33, 77, 77, 54, 86, 142, 238, 221, 336, 82, 310, 395, 180, 329, 329, 329, 329, 329, 426, 426, 426, 426, 426, 426, 282, 282, 282, 282, 388, 388, 195, 117, 117, 404, 225, 225, 225, 225, 80, 80, 80, 80, 80, 80, 140, 354, 354, 329, 498, 498, 498, 396, 396, 416, 96, 96, 270, 323, 224, 224, 242, 275, 275, 116, 33, 394, 212, 239, 384, 180, 180, 265, 265, 265, 265, 265, 265, 265, 85, 85, 85, 85, 207, 207, 37, 37, 24, 131, 404, 439]
torch.Size([1, 226, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_237-134493-0000
generate
 33%|███▎      | 21/64 [05:02<09:32, 13.30s/it]processing 21th semantic_sys file
21
args.target_mode==1 or args.target_mode==2
semantic nums is 1
syntbefore_semantic:
after is :
323
[17, 17, 296, 5, 448, 448, 448, 3, 14, 411, 145, 264, 264, 264, 264, 264, 264, 468, 468, 59, 467, 335, 440, 89, 89, 446, 446, 67, 466, 22, 22, 448, 448, 448, 14, 14, 411, 498, 498, 498, 498, 498, 498, 498, 396, 169, 169, 169, 164, 164, 164, 164, 164, 483, 226, 226, 20, 20, 287, 353, 353, 353, 353, 396, 313, 143, 458, 458, 445, 445, 445, 485, 485,before_semantic:
after is :
368
[17, 17, 296, 127, 5, 5, 448, 448, 448, 3, 3, 14, 411, 411, 264, 264, 264, 264, 264, 264, 264, 264, 468, 468, 468, 59, 59, 59, 59, 452, 452, 263, 225, 225, 225, 225, 440, 83, 89, 446, 446, 446, 466, 466, 22, 448, 448, 448, 448, 14, 411, 411, 498, 498, 498, 498, 498, 498, 498, 396, 396, 396, 169, 169, 164, 164, 164, 164, 164, 97, 483, 226, 226, 82, 209, 353, 353, 353, 353, 396, 245, 143, 458, 458, 445, 445, 445, 485, 485, 485, 485, 468, 468, 468, 337, 337, 337, 459, 459, 459, 271, 39, 54, 54, 86, 26, 26, 359, 166, 166, 166, 166, 301, 399, 217, 217, 473, 473, 476, 476, 476, 171, 171, 252, 252, 325, 325, 191, 191, 191, 191, 191, 37, 37, 24, 24, 131, 419, 404, 439, 439, 439, 78, 78, 170, 20, 170, 20, 20, 20, 20, 312, 187, 12, 12, 1, 1, 1, 1, 408, 408, 408, 149, 228, 20, 412, 83, 83, 55, 55, 322, 67, 199, 199, 121, 121, 121, 121, 33, 33, 394, 76, 108, 108, 119, 119, 351, 308, 308, 308, 308, 308, 396, 203, 53, 53, 176, 176, 135, 135, 200, 200, 248, 248, 212, 144, 180, 180, 106, 284, 481, 481, 481, 481, 182, 182, 375, 375, 375, 122, 122, 24, 131, 404, 404, 439, 439, 78, 229, 20, 20, 20, 312, 312, 312, 292, 292, 292, 1, 1, 1, 1, 1, 408, 408, 408, 149, 228, 20, 412, 83, 253, 253, 253, 253, 453, 453, 168, 168, 118, 118, 118, 118, 402, 198, 198, 22, 5, 5, 455, 43, 43, 276, 174, 174, 174, 174, 174, 319, 348, 33, 250, 250, 250, 347, 347, 347, 347, 347, 347, 347, 59, 59, 59, 59, 452, 452, 263, 263, 263, 225, 225, 78, 47, 20, 47, 47, 47, 20, 80, 80, 20, 320, 127, 22, 283, 455, 455, 129, 129, 259, 354, 190, 380, 380, 288, 288, 443, 443, 169, 169, 169, 164, 164, 164, 69, 69, 69, 130, 130, 198, 198, 22, 448, 448, 448, 448, 14, 14, 411, 493, 493, 493, 493, 493, 493, 216, 300, 300, 334, 334, 59, 59, 59, 452, 452, 263, 13]
torch.Size([1, 366, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_grbefore_semantic:
after is :
205
[17, 17, 188, 121, 121, 121, 33, 33, 394, 212, 384, 371, 444, 444, 213, 213, 213, 213, 246, 246, 246, 246, 246, 252, 24, 24, 131, 404, 183, 183, 183, 451, 451, 30, 30, 30, 30, 30, 3, 3, 58, 58, 110, 110, 254, 254, 254, 254, 314, 314, 26, 251, 251, 241, 367, 367, 367, 367, 367, 35, 96, 96, 82, 272, 34, 255, 255, 43, 43, 364, 276, 109, 109, 403, 403, 403, 403, 403, 207, 207, 207, 301, 378, 43, 345, 333, 333, 220, 220, 35, 198, 22, 283, 455, 455, 129, 129, 82, 74, 190, 492, 492, 492, 492, 492, 215, 215, 35, 35, 29, 459, 459, 4before_semantic:
after is :
189
[17, 17, 188, 121, 121, 121, 33, 33, 394, 212, 384, 371, 371, 444, 213, 213, 213, 246, 246, 246, 246, 252, 24, 24, 131, 404, 404, 225, 225, 225, 225, 225, 225, 225, 373, 373, 451, 451, 451, 30, 30, 30, 30, 3, 58, 58, 254, 254, 254, 254, 254, 314, 26, 251, 251, 241, 367, 367, 367, 367, 367, 96, 96, 401, 20, 272, 255, 255, 255, 43, 43, 276, 109, 109, 403, 403, 403, 403, 207, 207, 207, 301, 378, 43, 345, 333, 333, 220, 220, 401, 401, 20, 22, 283, 455, 455, 129, 20, 74, 190, 492, 492, 492, 492, 396, 215, 215, 259, 354, 29, 459, 459, 271, 31, 39, 54, 54, 172, 224, 69, 69, 223, 130, 130, 402, 196, 309, 479, 331, 331, 307, 307, 307, 61, 167, 167, 167, 457, 478, 66, 68, 172, 115, 267, 267, 267, 267, 267, 360, 135, 135, 135, 135, 200, 200, 200, 248, 335, 335, 14, 411, 287, 287, 428, 428, 146, 146, 252, 252, 143, 401, 401, 20, 108, 108, 119, 351, 213, 213, 213, 246, 246, 246, 246, 19, 19, 454, 454, 454]
torch.Size([1, 187, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_237-134493-0013
generate
 36%|███▌  before_semantic:
after is :
217
[17, 296, 296, 0, 222, 468, 406, 356, 356, 356, 356, 453, 9, 9, 168, 444, 357, 357, 357, 357, 173, 280, 29, 242, 116, 94, 199, 44, 44, 44, 43, 364, 364, 276, 276, 346, 346, 346, 428, 428, 146, 146, 252, 457, 457, 457, 42, 42, 147, 147, 380, 380, 499, 84, 496, 496, 496, 16, 16, 16, 274, 274, 274, 88, 88, 69, 462, 462, 130, 402, 402, 401, 401, 140, 354, 420, 420, 420, 324, 3, 58, 58, 72, 72, 437, 437, 284, 284, 265, 265, 265, 265, 265, 85, 85, 85, 85, 85, 299before_semantic:
after is :
230
[17, 17, 127, 114, 0, 222, 468, 406, 406, 467, 356, 356, 356, 281, 453, 9, 168, 168, 444, 357, 357, 357, 357, 173, 280, 29, 242, 116, 94, 199, 44, 44, 44, 43, 364, 364, 276, 276, 346, 346, 346, 428, 428, 428, 146, 146, 358, 457, 457, 457, 133, 133, 42, 42, 42, 147, 147, 147, 380, 380, 499, 499, 496, 496, 16, 16, 16, 16, 274, 88, 88, 88, 69, 462, 462, 462, 130, 402, 32, 32, 32, 32, 82, 354, 354, 420, 213, 213, 213, 324, 3, 58, 58, 72, 72, 437, 437, 284, 265, 265, 265, 265, 265, 85, 85, 85, 85, 85, 299, 299, 299, 173, 173, 185, 49, 49, 323, 168, 168, 340, 340, 340, 116, 466, 466, 22, 448, 448, 448, 448, 464, 106, 106, 153, 153, 153, 372, 372, 396, 396, 143, 36, 310, 107, 107, 395, 334, 334, 382, 313, 37, 24, 131, 34, 106, 125, 319, 319, 348, 64, 212, 300, 300, 494, 494, 216, 216, 216, 22, 283, 455, 43, 43, 364, 276, 276, 276, 346, 346, 481, 481, 481, 481, 293, 497, 497, 122, 10, 479, 331, 331, 319, 319, 167, 167, 457, 457, 401, 401, 82, 82, 108, 161, 161, 487, 487, 487, 288, 288, 288, 288, 213, 246, 246, 246, 246, 246, 246, 318, 318, 318, 185, 185, 269, 323, 323, 18, 18, 112, 439]
torch.Size([1, 228, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_237-134493-0018
generate
 38%|███▊      | 24/64 [05:34<07:21, 11.05s/it]processing 24th semantic_sys file
24
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT'S NOT MUCH OF A JOB FOR AN ATHLETE HERE I'VE BEEN TO TOWN AND BACK
2024-03-14 03:05:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:05:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
235
[17, 17, 296, 114, 114, 92, 92, 92, 240, 35, 77, 77, 342, 86, 86, 196, 196, 479, 331, 307, 307, 307, 61, 61, 167, 457, 457, 196, 217, 217, 70, 383, 383, 383, 383, 383, 35, 36, 310, 107, 395, 69, 223, 130, 280, 44, 44, 44, 236, 239, 310, 107, 395, 395, 180, 106, 499, 284, 405, 405, 405, 405, 206, 206, 206, 215, 215, 35, 393, 393, 155, 155, 332, 332, 332, 467, 44, 44, 44, 94, 199, 335, 14, 14, 411, 145, 145, 145, 486, 486, 460, 460, 169, 169, 164, 164, 26, 359, 359, 81, 81, 81, 444, 213, 213, 252, 252, 457, 457, 335, 183, 183, 451, 286, 286, 286, 286, 286, 286, 286, 468, 59, 59, 59, 59, 452, 452, 263, 229, 229, 247, 312, 126, 23, 23, 23, 101, 149, 149, 228, 20, 20, 20, 287, 287, 111, 111, 111, 438, 438, 202, 173, 402, 402, 221, 401, 82, 354, 137, 137, 137, 137, 137, 116, 33, 33, 394, 76, 76, 259, 108, 108, 119, 119, 351, 374, 374, 374, 132, 422, 143, 36, 108, 119, 119, 351, 351, 315, 315, 315, 315, 315, 450, 450, 450, 413, 413, 94, 335, 440, 440, 89, 89, 446, 446, 33, 394, 394, 32, 239, 354, 180, 180, 376, 376, 376, 376, 376, 376, 376, 376, 376, 460, 178, 178, 233, 233, 82, 192, 192, 419, 419, 439, 439, 439]
torch.Size([1, 233, 16])
output_dir isbefore_semantic:
after is :
298
[17, 17, 296, 296, 287, 287, 287, 287, 287, 287, 16, 16, 16, 16, 16, 16, 274, 88, 88, 335, 14, 14, 411, 411, 145, 463, 463, 463, 463, 463, 463, 280, 29, 382, 382, 313, 313, 186, 186, 162, 482, 172, 115, 344, 344, 344, 344, 344, 399, 70, 383, 383, 383, 383, 383, 310, 107, 447, 483, 14, 411, 411, 411, 350, 350, 350, 350, 350, 350, 350, 413, 348, 250, 359, 359, 81, 474, 474, 474, 474, 474, 19, 19, 19, 19, 454, 454, 229, 82, 247, 126, 126, 126, 292, 292, 292, 292, 23, 23, 23, 408, 408, 408, 408, 391, 391, 228, 20, 20, 373, 451, 451, 30, 30, 30, 30, 422, 422, 162, 232, 172, 172, 115, 444, 444, 444, 444, 444, 434, 434, 203, 53, 71, 71, 49, 9, 221, 221, 259, 144, 144, 27, 437, 437, 480, 480, 480, 480, 480, 480, 480, 480,before_semantic:
after is :
174
[17, 17, 296, 287, 287, 16, 16, 16, 88, 88, 88, 463, 463, 463, 463, 463, 29, 29, 382, 382, 313, 186, 162, 54, 172, 344, 344, 344, 344, 344, 399, 70, 383, 383, 383, 383, 383, 310, 107, 447, 483, 14, 411, 350, 350, 350, 350, 350, 250, 250, 359, 81, 166, 166, 324, 3, 183, 451, 451, 30, 30, 422, 186, 162, 232, 232, 172, 115, 444, 444, 444, 360, 434, 339, 339, 71, 49, 9, 142, 221, 82, 144, 27, 437, 437, 437, 480, 480, 480, 480, 480, 85, 299, 299, 299, 64, 212, 34, 462, 462, 462, 402, 162, 232, 232, 232, 238, 6, 272, 371, 470, 470, 403, 403, 171, 171, 171, 246, 246, 246, 252, 24, 24, 34, 89, 89, 446, 446, 33, 394, 478, 162, 232, 482, 105, 105, 82, 208, 441, 153, 153, 153, 153, 182, 497, 497, 122, 129, 82, 82, 108, 119, 351, 213, 213, 213, 213, 252, 36, 310, 107, 161, 161, 495, 495, 495, 41, 41, 41, 19, 19, 19, 454, 454]
torch.Size([1, 172, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_237-134500-0021
generate
 41%|████      | 26/64 [05:49<05:49,  9.21s/it]processing 26th semantic_sys file
26
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I CAN'T PLAY WITH YOU LIKE A LITTLE BOY ANY MORE HE SAID SLOWLY THAT'S WHAT YOU MISS MARIE
2024-03-14 03:05:51 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-1before_semantic:
after is :
288
[17, 17, 296, 287, 111, 111, 438, 143, 129, 458, 445, 445, 351, 351, 365, 365, 365, 365, 330, 167, 457, 457, 401, 401, 82, 74, 42before_semantic:
after is :
312
[17, 17, 296, 287, 111, 111, 438, 143, 458, 144, 27, 27, 437, 437, 284, 284, 284, 426, 426, 426, 426, 413, 348, 64, 76, 131, 472, 472, 221, 401, 82, 74, 425, 425, 386, 470, 403, 403, 171, 171, 252, 301, 378, 345, 333, 333, 220, 220, 164, 164, 219, 477, 477, 477, 477, 477, 132, 132, 132, 26, 251, 241, 266, 266, 266, 266, 178, 458, 192, 44, 44, 251, 251, 241, 278, 278, 278, 278, 449, 302, 302, 497, 497, 8, 32, 259, 354, 354, 153, 153, 153, 153, 153, 387, 387, 387, 207, 207, 207, 19, 19, 454, 229, 229, 82, 247, 126, 126, 126, 292, 292, 292, 292, 23, 23, 23, 23, 23, 260, 260, 391, 391, 391, 20, 73, 73, 73, 289, 20, 209, 83, 475, 475, 475, 94, 475, 475, 475, 475, 301, 399, 217, 217, 70, 70, 138, 138, 138, 138, 138, 138, 182, 182, 182, 182, 375, 375, 375, 98, 98, 98, 13, 13, 78, 170, 20, 170, 20, 20, 312, 312, 187, 12, 12, 12, 12, 12, 12, 260, 260, 260, 163, 20, 163, 20, 163, 163, 20, 316, 20, 316, 73, 73, 20, 373, 451, 451, 30, 30, 422, 162, 232, 232, 172, 115, 273, 470, 120, 120, 240, 240, 314, 314, 478, 478, 232, 232, 232, 232, 482, 26, 26, 26, 241, 431, 84, 84, 496, 496, 496, 274, 274, 359, 359, 474, 474, 474, 474, 324, 301, 216, 216, 114, 114, 92, 92, 92, 92, 167, 167, 77, 77, 323, 142, 397, 397, 181, 181, 181, 181, 457, 219, 219, 219, 152, 152, 152, 132, 399, 399, 217, 217, 217, 217, 473, 65, 258, 258, 31, 39, 54, 86, 142, 142, 196, 217, 70, 65, 65, 329, 495, 406, 406, 406, 256, 256, 256, 256, 256, 256, 246, 246, 246, 246, 19, 19, 19, 454, 454, 454, 439, 439]
torch.Size([1, 310, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_237-134500-0036
generate
 42%|████▏     | 27/64 [06:01<06:14, 10.11s/it]processing 27th semantic_sys file
27
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHEN SHE USED TO TELL ME ABOUT HIM I ALWAYS WONDERED WHETHER SHE WASN'T A LITTLE IN LOVE WITH HIMbefore_semantic:
after is :
313
[17, 17, 296, 345, 409, 409, 409, 409, 67, 394, 478, 338, 338, 338, 400, 400, 400, 400, 30, 30, 219, 219, 219, 219, 485, 374, 374, 374, 374, 132, 132, 132, 132, 318, 368, 49, 269, 54, 86, 238, 6, 336, 108, 108, 377, 344, 344, 344, 344before_semantic:
after is :
251
[17, 296, 409, 409, 409, 409, 67, 478, 478, 338, 338, 400, 400, 400, 400, 30, 219, 219, 219, 219, 485, 485, 374, 374, 374, 132, 132, 132, 318, 368, 49, 9, 238, 6, 82, 108, 108, 377, 344, 344, 344, 374, 132, 422, 143, 259, 108, 108, 119, 119, 351, 351, 139, 139, 139, 293, 293, 293, 399, 399, 429, 429, 429, 429, 464, 464, 255, 255, 8, 8, 180, 180, 113, 113, 113, 113, 167, 285, 58, 183, 183, 57, 57, 57, 57, 57, 203, 381, 381, 381, 117, 48, 48, 417, 417, 82, 170, 244, 392, 392, 392, 392, 392, 392, 392, 392, 392, 392, 73, 73, 244, 412, 287, 287, 111, 111, 438, 438, 464, 464, 106, 297, 297, 297, 297, 297, 43, 345, 109, 109, 109, 171, 318, 368, 453, 142, 397, 133, 276, 174, 174, 319, 319, 348, 64, 64, 300, 300, 382, 382, 313, 24, 24, 131, 133, 133, 364, 345, 109, 181, 181, 181, 216, 216, 300, 300, 300, 382, 313, 186, 99, 338, 338, 400, 400, 400, 400, 30, 301, 378, 43, 345, 141, 141, 141, 141, 141, 281, 453, 9, 168, 242, 242, 116, 94, 199, 44, 44, 44, 251, 251, 241, 241, 431, 278, 278, 285, 285, 302, 302, 302, 497, 175, 175, 81, 340, 340, 116, 33, 250, 250, 241, 241, 431, 266, 266, 266, 173, 8, 402, 402, 133, 345, 333, 333, 220, 220, 164, 164, 183, 57, 57, 57, 57, 57, 57, 203, 381, 48, 48, 417]
torch.Size([1, 249, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_237-134500-0022
generate
 44%|████▍     | 28/64 [06:10<05:56,  9.90s/it]processing 28th semantic_sys file
28
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT EMIL IF I UNDERSTAND THEN ALL OUR GOOD TIMES ARE OVER WE CAN NEVER DO NICE THINGS TOGETHER ANY MORE
2024-03-14 03:06:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:06:13 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
360
[17, 296, 159, 159, 159, 159, 385, 457, 457, 401, 401, 226, 226, 226, 226, 140, 140, 411, 145, 329, 329, 329, 329, 329, 329, 53, 53, 65, 134, 134, 175, 175, 81, 118, 118, 118, 118, 205, 25, 106, 111, 111, 111, 111, 438, 464, 464, 464, 319, 319, 348, 64, 64, 212, 494, 494, 38, 162, 232, 232, 232, 238, 6, 336, 371, 470, 470, 294, 294, 294, 294, 294, 282, 282, 388, 388, 195, 195, 212, 212, 131, 419, 427, 82, 247, 126, 126, 326, 326, 326, 326, 326, 101, 101, 149, 228, 228, 82, 320, 127, 127, 114, 361, 361, 322, 94, 199, 106, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297, 293, 175, 175, 106, 353, 353, 353, 353, 206, 416, 32, 32, 32, 32, 144, 484, 484, 484, 484, 314, 314, 401, 401, 82, 108, 119, 119, 437, 437, 103, 103, 103, 103, 103, 103, 85, 299, 299, 203, 53, 471, 49, 49, 9, 168, 353, 353, 353, 353, 406, 467, 467, 410, 410, 410, 410, 410, 410, 410, 410, 173, 280, 29, 29, 355, 355, 355, 452, 263, 229, 82, 247, 126, 126, 326, 326, 101, 101, 101, 149, 228, 228, 140, 140, 7, 345, 345, 152, 152, 152, 143, 458, 192, 389, 389, 389, 116, 33, 10, 10, 10, 309, 309, 309, 479, 331, 463, 463, 463, 463, 463, 280, 29, 29, 469, 236, 239, 384, 371, 371, 374, 374, 374, 132, 132, 10, 10, 309, 309, 479, 331, 265, 265, 428, 428, 428, 146, 146, 358, 186, 39, 39, 86, 232, 232, 232, 68, 68, 164, 164, 164, 214, 214, 214, 214, 214, 328, 200, 200, 200, 200, 471, 471, 49, 49, 9, 238, 6, 82, 377, 87, 87, 87, 416, 239, 445, 180, 180, 443, 443, 493, 216, 216, 300, 300, 355, 355, 335, 14, 226, 226, 82, 411, 411, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 475, 324, 301, 301, 399, 217, 217, 70, 70, 138, 138, 138, 138, 138, 138, 138, 182, 182, 182, 182, 182, 182, 375, 98, 98, 98, 98, 13]
torch.Size([1, 358, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_237-134500-0037
generate
 45%|████▌     | 29/64 [06:25<06:35, 11.30s/it]processing 29th semantic_sys file
29
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND EMIL MOWED HIS WAY SLOWLY DOWN TOWARD THE CHERRY TREES
2024-03-14 03:06:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2before_semantic:
after is :
179
[17, 17, 296, 83, 55, 55, 322, 67, 212, 131, 335, 411, 145, 329, 329, 329, 329, 53, 53, 65, 302, 302, 497, 497, 497, 399, 217, 217, 70, 6before_semantic:
after is :
184
[17, 17, 296, 55, 55, 322, 67, 67, 335, 14, 14, 411, 145, 329, 329, 329, 329, 329, 53, 473, 65, 139, 139, 139, 293, 293, 293, 293, 399, 399, 217, 217, 217, 70, 70, 70, 65, 65, 496, 496, 496, 274, 274, 274, 274, 285, 325, 34, 459, 257, 281, 281, 9, 142, 397, 397, 364, 276, 109, 109, 403, 171, 171, 252, 186, 162, 54, 54, 482, 482, 26, 26, 26, 241, 431, 431, 496, 496, 496, 274, 274, 175, 359, 474, 474, 474, 324, 301, 236, 239, 239, 371, 180, 180, 315, 315, 315, 315, 450, 450, 450, 413, 413, 413, 195, 195, 394, 76, 401, 401, 82, 108, 377, 377, 123, 123, 43, 364, 276, 153, 153, 153, 372, 372, 396, 313, 314, 314, 198, 22, 283, 283, 455, 236, 129, 310, 310, 107, 107, 395, 395, 351, 264, 264, 468, 468, 468, 337, 337, 324, 324, 422, 143, 259, 310, 161, 161, 161, 487, 487, 487, 288, 288, 213, 213, 246, 246, 246, 246, 318, 318, 185, 185, 269, 269, 323, 390, 18, 112, 427, 56, 140, 140, 140]
torch.Size([1, 182, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_237-134500-0014
generate
 47%|████▋     | 30/64 [06:32<05:40, 10.01s/it]processing 30th semantic_sys file
30
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WISH YOU WEREN'T SO RESTLESS AND DIDN'T GET SO WORKED UP OVER THINGS SHE SAID SADLY
2024-03-14 03:06:34 | WARNING | phonemizer | words count mismatbefore_semantic:
after is :
281
[17, 296, 111, 111, 111, 378, 378, 43, 364, 276, 345, 109, 278, 186, 99, 99, 338, 338, 395, 152, 152, 378, 378, 43, 364, 364, 276, 276, 174, 174, 319, 319, 330, 167, 457,before_semantic:
after is :
201
[17, 17, 296, 111, 111, 111, 438, 378, 43, 345, 109, 109, 278, 278, 99, 99, 447, 338, 338, 400, 152, 152, 378, 378, 345, 109, 109, 308, 308, 330, 330, 379, 457, 457, 478, 478, 68, 68, 115, 344, 344, 344, 344, 344, 344, 274, 42, 42, 147, 380, 288, 443, 443, 169, 150, 150, 86, 238, 26, 26, 262, 262, 262, 262, 262, 31, 342, 224, 224, 89, 89, 322, 33, 394, 212, 384, 371, 371, 278, 314, 116, 242, 33, 33, 394, 212, 239, 445, 180, 180, 443, 443, 167, 457, 457, 478, 478, 68, 68, 344, 344, 344, 344, 344, 43, 43, 276, 109, 109, 498, 498, 498, 498, 178, 457, 96, 96, 82, 449, 449, 180, 230, 230, 230, 230, 230, 215, 35, 82, 29, 106, 106, 410, 410, 410, 410, 410, 173, 29, 29, 469, 469, 38, 164, 164, 214, 214, 214, 214, 200, 200, 200, 248, 186, 99, 338, 338, 400, 400, 400, 30, 422, 162, 68, 68, 115, 470, 179, 120, 240, 314, 314, 478, 478, 68, 68, 115, 273, 470, 486, 486, 486, 460, 460, 240, 24, 26, 26, 359, 359, 474, 474, 474, 474, 19, 19, 454, 454, 229, 140, 140]
torch.Size([1, 199, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_25_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_237-134500-0033
generate
 48%|████▊     | 31/64 [06:40<05:10,  9.40s/it]processing 31th semantic_sys file
31
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT WON'T LAST IT WILL GO AWAY AND THINGS WILL BE JUST AS THEY USED TO
2024-03-14 03:06:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:06:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
209
[17, 17, 296, 114, 92, 92, 92, 92, 167, 457, 457, 364, 276, 109, 350, 350, 350, 350, 413, 413, 457, 457, 457, 251, 241, 431, 431, 376, 376, 376, 376, 376, 460, 1before_semantic:
after is :
328
[17, 17, 296, 127, 114, 92, 92, 92, 92, 92, 167, 457, 43, 364, 276, 276, 174, 350, 350, 350, 350, 413, 413, 413, 457, 457, 457, 251, 241, 241, 431, 431, 376, 376, 376, 376, 376, 376, 376, 376, 460, 169, 169, 150, 150, 54, 54, 238, 6, 272, 272, 106, 111, 111, 111, 111, 111, 111, 111, 85, 146, 146, 207, 3, 454, 454, 454, 414, 414, 414, 414, 414, 414, 414, 414, 414, 47, 47, 47, 47, 47, 2, 2, 2, 140, 140, 2, 2, 2, 140, 316, 140, 316, 140, 316, 140, 73, 289, 289, 82, 108, 108, 119, 351, 351, 213, 213, 213, 301, 378, 378, 345, 345, 100, 497, 497, 497, 122, 8, 144, 27, 180, 84, 84, 84, 16, 16, 88, 88, 88, 255, 255, 255, 43, 43, 43, 364, 276, 109, 109, 109, 403, 403, 403, 403, 403, 403, 207, 207, 207, 207, 207, 207, 19, 454, 454, 454, 454, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 28, 28, 28, 28, 28, 28, 2, 2, 362, 362, 362, 140, 362, 140, 362, 362, 362, 362, 362, 362, 366, 366, 366, 140, 366, 366, 140, 366, 366, 140, 366, 366, 366, 366, 316, 316, 316, 316, 73, 140, 412, 412, 83, 55, 55, 322, 322, 67, 394, 76, 465, 465, 465, 164, 214, 214, 214, 214, 214, 360, 200, 200, 200, 471, 49, 49, 9, 142, 397, 345, 345, 389, 389, 497, 497, 8, 8, 420, 420, 420, 422, 236, 239, 310, 395, 395, 395, 151, 151, 151, 169, 150, 150, 54, 86, 86, 272, 272, 253, 253, 253, 253, 253, 453, 9, 9, 198, 114, 114, 0, 0, 0, 0, 171, 171, 252, 219, 219, 219, 219, 485, 485, 374, 374, 374, 374, 186, 186, 54, 54, 86, 238, 6, 272, 377, 87, 87, 87, 374, 374, 374, 132, 132, 132, 132, 132, 98, 98, 13, 414, 414, 414, 414, 414]
torch.Size([1, 326, 16])
output_dir is /homebefore_semantic:
after is :
138
[17, 17, 287, 111, 111, 319, 203, 53, 394, 90, 186, 338, 338, 395, 395, 487, 498, 498, 498, 406, 467, 467, 145, 145, 329, 329, 175, 81, 81, 469, 154, 416, 96, 96, 453, 453, 470, 470, 329, 365, 365, 330, 348, 64, 212, 161, 495, 423, 423, 423, 423, 423, 58, 58, 72, 437, 496, 496, 496, 496, 215, 215, 35, 82, 96, 270, 323, 9, 219, 152, 152, 152, 378, 345, 389, 389, 497, 38, 162, 162, 232, 232, 238, 82, 272, 470, 470, 403, 403, 171, 171, 464, 464, 125, 125, 125, 125, 348, 58, 183, 183, 286, 286, 286, 286, 468, 313, 186, 99, 338, 400, 400, 400, 30, 301, 399, 217, 70, 473, 65, 498, 498, 498, 203, 203, 53, 29, 334, 334, 59, 37, 37, 24, 131, 419, 439, 78, 140]
torch.Size([1, 136, 16])
output_dir is /home/v-zhijunjibefore_semantic:
after is :
172
[17, 17, 296, 287, 287, 111, 319, 203, 53, 394, 186, 99, 338, 338, 338, 395, 395, 487, 498, 153, 153, 387, 372, 406, 467, 467, 145, 486, 329, 329, 175, 175, 81, 81, 154, 416, 96, 96, 453, 453, 168, 470, 329, 365, 365, 365, 365, 329, 64, 212, 161, 495, 423, 423, 423, 58, 58, 72, 72, 437, 496, 496, 496, 496, 496, 274, 215, 233, 233, 82, 270, 270, 323, 323, 323, 97, 97, 219, 152, 152, 152, 378, 345, 389, 389, 497, 38, 162, 162, 232, 482, 238, 6, 272, 470, 470, 403, 403, 171, 464, 464, 464, 125, 125, 125, 94, 58, 183, 183, 183, 286, 286, 286, 286, 286, 286, 468, 59, 59, 59, 452, 452, 263, 263, 78, 78, 170, 140, 47, 140, 47, 47, 47, 140, 316, 140, 140, 289, 373, 373, 338, 338, 400, 400, 400, 400, 301, 301, before_semantic:
after is :
192
[17, 17, 296, 287, 111, 111, 438, 438, 129, 129, 259, 74, 190, 190, 487, 288, 288, 403, 171, 171, 252, 252, 349, 349, 234, 155, 332, 332, 332, 332, 219, 219, 219, 477, 477, 477, 477, 477, 477, 132, 132, 132, 98, 98, 13, 13, 170, 170, 170, 20, 20, 20, 28, 28, 20, 20, 2, 20, 2, 2, 2, 2, 20, 2, 2, 20, 2, 2, 20, 366, 366, 20, 366, 366, 366, 20, 316, 316, 316, 20, 73, 73, 20, 320, 159, 159, 159, 159, 314, 198, 127, 114, 92, 92, 92, 240, 35, 77, 77, 86, 86, 196, 479, 307, 307, 307, 307, 61, 167, 35, 198, 22, 283, 283, 38, 162, 162, 232, 172, 115, 273, 470, 290, 290, 290, 434, 434, 203, 53, 473, 253, 253, 253, 281, 453, 9, 168, 118, 118, 118, 118, 349, 205, 402, 219, 219, 152, 152, 152, 132, 143, 129, 129, 82, 74, 190, 190, 487, 288, 288, 171, 252, 252, 314, 219, 222, 222, 222, 222, 186, 162, 162, 232, 172, 115, 273, 279, 279, 279, 279, 279, 279, 293, 293, 169, 352, 352,before_semantic:
after is :
239
[17, 17, 296, 287, 111, 111, 111, 438, 438, 143, 129, 129, 259, 74, 190, 190, 190, 190, 487, 288, 288, 288, 171, 171, 252, 252, 422, 349, 393, 205, 155, 332, 332, 332, 332, 219, 219, 219, 477, 477, 477, 477, 477, 477, 132, 132, 132, 132, 98, 98, 98, 13, 13, 170, 170, 20, 20, 47, 47, 47, 20, 20, 47, 20, 20, 316, 20, 73, 73, 289, 20, 320, 159, 159, 159, 159, 314, 35, 401, 401, 401, 127, 127, 114, 92, 92, 92, 92, 92, 240, 35, 35, 77, 77, 342, 86, 86, 142, 196, 309, 309, 479, 479, 331, 307, 307, 307, 307, 61, 61, 167, 35, 35, 401, 198, 22, 22, 283, 455, 38, 162, 162, 68, 68, 68, 68, 68, 115, 115, 273, 470, 290, 290, 290, 290, 290, 290, 434, 434, 434, 434, 203, 203, 381, 117, 335, 335, 226, 226, 226, 226, 226, 20, 20, 209, 145, 253, 253, 253, 253, 253, 253, 453, 342, 342, 168, 118, 118, 118, 118, 118, 402, 402, 402, 219, 152, 152, 152, 152, 132, 143, 129, 129, 401, 401, 20, 74, 74, 190, 190, 487, 487, 288, 288, 403, 171, 171, 171, 171, 246, 252, 252, 24, 24, 219, 219, 222, 222, 222, 382, 313, 313, 186, 162, 232, 232, 68, 68, 115, 273, 279, 279, 279, 279, 279, 279, 375, 375, 375, 169, 352, 352, 352, 352, 352, 352, 352, 352, 112]
torch.Size([1, 237, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_237-134500-0040
generate
 53%|█████▎    | 34/64 [07:09<04:50,  9.69s/it]processing 34th semantic_sys file
34
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I GET TIRED OF SEEING MEN AND HORSES GOING UP AND DOWN UP AND DOWN
2024-03-14 03:07:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:07:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
175
[140, 296, 111, 111, 111, 438, 416, 458, 445, 180, 443, 240, 240, 143, 35, 82, 108, 119, 119, 351, 265, 265, 265, 265, 265, 265, 85, 85, 146, 240, 285, 34, 34, 223, 223, 38, 162, 162, 232, 172, 115, 267, 267, 267, 267, 267, 360, 135, 135, 135, 135, 200, 200, 248, 248, 217, 217, 473, 136, 136, 136, 136, 136, 136, 330, 388, 94, 199, 89, 89, 446, 116, 33, 90, 58, 58, 72, 441, 153, 153, 153, 387, 387, 387, 169, 150, 54, 54, 224, 50, 50, 50, 50, 49, 9, 142, 221, 82, 144, 180, 180, 84, 496, 88, 176, 135, 135, before_semantic:
after is :
273
[17, 17, 261, 380, 288, 288, 365, 365, 360, 200, 76, 76, 458, 208, 133, 42, 147, 147, 380, 288, 443, 240, 240, 314, 131, 335, 14, 411, 188, 360, 360, 200, 200, 248, 212, 81, 81, 81, 469, 186, 99, 447, 447, 447, 482, 482, 482, 482, 482, 26, 26, 26, 241, 431, 431, 84, 84, 496, 496, 274, 175, 359, 359, 474, 474, 474, 474, 474, 19, 19, 454, 454, 229, 20, 247, 312, 126, 292, 292, 292, 292, 23, 23, 23, 408, 408, 149, 149, 20, 20, 412, 83, 55, 55, 322, 67, 466, 466, 22, 283, 455, 399, 399, 70, 138, 138, 138, 138, 138, 138, 372, 372, 396, 58, 183, 451, 30, 30, 301, 301, 42, 42, 147, 147, 380, 288, 443, 443, 240, 285, 285, 255, 255, 8, 8, 354, 180, 113, 113, 113, 113, 113, 450, 167, 167, 457, 457, 198, 114, 258, 258, 258, 31, 54, 86, 238, 6, 336, 384, 490, 490, 490, 4, 280, 280, 153, 153, 153, 153, 153, 387, 372, 372, 396, 396, 271, 186, 39, 54, 390, 390, 390, 18, 112, 427, 56, 56, 20, 20, 312, 187, 187, 187, 408, 408, 391, 391, 20, 20, 20, 20, 20, 144, 445, 351, 351, 343, 171, 171, 252, 252, 39, 39, 54, 86, 86, 238, 198, 22, 448, 448, 448, 448, 464, 464, 145, 365, 365, 365, 365, 360, 200, 248, 248, 212, 29, 495before_semantic:
after is :
301
[17, 296, 190, 380, 380, 288, 365, 365, 365, 365, 360, 200, 76, 76, 458, 208, 133, 42, 147, 147, 288, 288, 213, 213, 246, 246, 246, 246, 246, 252, 24, 131, 335, 14, 411, 411, 188, 360, 360, 360, 200, 200, 248, 248, 26, 359, 359, 81, 81, 459, 459, 271, 99, 99, 447, 447, 447, 482, 482, 482, 482, 482, 26, 26, 26, 241, 431, 84, 84, 496, 496, 274, 274, 274, 359, 359, 359, 474, 474, 474, 474, 474, 19, 19, 19, 19, 454, 454, 229, 140, 247, 126, 126, 292, 292, 292, 292, 292, 23, 23, 23, 23, 408, 408, 408, 391, 140, 140, 412, 83, 83, 55, 55, 322, 322, 67, 466, 466, 22, 5, 455, 399, 399, 70, 70, 138, 138, 138, 138, 138, 138, 138, 372, 372, 372, 396, 396, 313, 313, 58, 183, 451, 451, 30, 30, 301, 301, 42, 42, 42, 147, 147, 380, 380, 288, 443, 443, 120, 240, 240, 325, 34, 255, 255, 8, 8, 354, 180, 113, 113, 113, 113, 167, 167, 35, 401, 401, 198, 114, 258, 258, 258, 31, 31, 86, 86, 238, 6, 272, 490, 490, 490, 4, 280, 280, 106, 153, 153, 1before_semantic:
after is :
263
[17, 17, 296, 310, 395, 395, 151, 151, 169, 150, 150, 86, 238, 6, 6, 272, 472, 472, 66, 66, 68, 68, 68, 68, 105, 105, 196, 217, 473, 189, 189, 189, 139, 139, 139, 293, 293, 293, 293, 122, 216, 22, 283, 283, 455, 43, 43, 364, 276, 276, 346, 346, 346, 265, 265, 85, 85, 146, 146, 139, 139, 293, 497, 122, 122, 131, 472, 133, 42, 147, 147, 147, 380, 288, 496, 496, 496, 496, 274, 274, 368, 368, 368, 453, 168, 50, 50, 50, 50, 50, 50, 50, 185, 185, 185, 269, 433, 433, 160, 112, 112, 427, 20, 247, 312, 126, 292, 292, 292, 292, 292, 23, 23, 23, 23, 23, 23, 23, 23, 101, 101, 101, 149, 228, 20, 20, 20, 20, 127, 0, 0, 0, 0, 464, 353, 353, 353, 353, 353, 14, 14, 14, 14, 411, 411, 411, 297, 297, 297, 297, 297, 293, 293, 293, 43, 345, 109, 109, 109, 403, 171, 318, 318, 318, 49, 162, 232, 232, 232, 172, 115, 344, 344, 344, 344, 344, 344, 186, 186, 162, 232, 232, 232, 482, 482, 105, 105, 336, 336, 354, 106, 265, 428, 428, 146, 146, 358, 186, 39, 342, 342, 342, 224, 41, 41, 41, 324, 324, 3, 3, 14, 14, 411, 145, 145, 145, 460, 460, 460, 460, 169, 402, 402, 402, 6, 272, 272, 300, 382, 382, 406, 406, 467, 467, 44, 44, 245, 42, 42, 147, 147, 380, 288, 290, 290, 290, 290, 290, 434, 434, 434, 434, 434, 339, 303, 303, 117, 117, 48, 48, 417, 417, 417]
torch.Sizbefore_semantic:
after is :
243
[17, 17, 296, 310, 395, 395, 180, 151, 151, 151, 169, 150, 150, 54, 86, 238, 6, 6, 272, 472, 472, 66, 66, 232, 482, 105, 105, 196, 217, 473, 65, 189, 139, 139, 139, 139, 293, 293, 293, 122, 216, 22, 283, 283, 455, 43, 43, 276, 276, 276, 346, 346, 346, 265, 265, 85, 85, 85, 139, 139, 293, 293, 122, 122, 131, 133, 133, 147, 147, 380, 380, 288, 496, 496, 496, 496, 496, 274, 274, 368, 368, 269, 9, 224, 50, 50, 50, 50, 50, 50, 50, 185, 185, 269, 269, 390, 18, 112, 112, 56, 20, 56, 20, 20, 312, 187, 187, 12, 12, 12, 12, 12, 260, 260, 260, 260, 260, 391, 391, 20, 20, 20, 289, 20, 20, 127, 0, 0, 0, 0, 0, 464, 353, 353, 353, 353, 245, 14, 14, 14, 411, 411, 297, 297, 297, 297, 297, 297, 293, 293, 43, 345, 109, 109, 109, 324, 318, 186, 162, 162, 232, 172, 115, 3before_semantic:
after is :
240
[17, 17, 287, 111, 111, 111, 111, 438, 438, 251, 251, 241, 266, 266, 266, 266, 266, 266, 252, 143, 458, 192, 472, 472, 472, 401, 82, 108, 108, 377, 344, 344, 374, 374, 374, 132, 422, 143, 36, 108, 119, 119, 437, 106, 405, 405, 405, 405, 206, 206, 178, 458, 192, 472, 472, 221, 36, 108, 108, 377, 377, 344, 344, 374, 374, 132, 132, 132, 143, 458, 144, 27, 27, 437, 437, 437, 306, 306, 306, 306, 306, 396, 396, 396, 467, 302, 302, 302, 302, 497, 175, 81, 255, 255, 8, 354, 180, 113, 113, 113, 113, 167, 167, 457, 457, 196, 196, 309, 309, 309, 398, 398, 398, 398, 398, 374, 374, 132, 219, 219, 219, 219, 485, 485, 153, 153, 153, 153, 372, 372, 372, 396, 396, 178, 233, 233, 192, 192, 419, 419, 427, 229, 20, 312, 312, 126, 292, 292, 292, 292, 292, 292, 292, 23, 23, 23, 408, 408, 408, 408, 391, 391, 228, 20, 20, 20, 83, 55, 55, 322, 67, 250, 250, 250, 181, 181, 181, 181, 285, 285, 44, 44, 38, 349, 234, 234, 261, 25, 180, 443, 443, 139, 175, 175, 175, 81, 84, 84, 84, 496, 274, 274, 143, 458, 144, 445, 389, 389, 389, 116, 33, 394, 212, 384, 371, 374, 374, 374, 374, 301, 216, 216, 114, 114, 264, 264, 264, 264, 264, 264, 468, 59, 59, 59, 452, 452, 452, before_semantic:
after is :
284
[17, 17, 296, 287, 287, 111, 111, 111, 438, 251, 251, 241, 266, 266, 266, 266, 146, 178, 35, 96, 401, 401, 82, 75, 108, 377, 377, 87, 87, 87, 236, 129, 259, 108, 119, 119, 437, 437, 405, 405, 405, 405, 206, 178, 178, 35, 96, 96, 401, 82, 75, 108, 377, 344, 344, 344, 374, 374, 132, 132, 143, 458, 144, 144, 27, 437, 437, 437, 306, 306, 306, 306, 306, 306, 306, 396, 396, 396, 467, 302, 302, 302, 302, 375, 375, 375, 375, 98, 98, 98, 13, 13, 225, 225, 225, 225, 225, 225, 225, 225, 412, 412, 287, 287, 255, 255, 8, 8, 354, 354, 180, 113, 113, 113, 113, 167, 167, 167, 457, 196, 309, 309, 479, 398, 398, 374, 374, 374, 219, 219, 219, 219, 485, 485, 153, 153, 153, 372, 372, 372, 396, 396, 396, 178, 178, 233, 458, 192, 419, 419, 439, 439, 439, 78, 78, 170, 170, 20, 20, 28, 28, 28, 28, 28, 28, 28, 20, 20, 362, 362, 362, 362, 362, before_semantic:
after is :
517
[17, 17, 296, 287, 111, 111, 438, 438, 143, 129, 259, 445, 445, 351, 351, 365, 365, 365, 330, 330, 457, 457, 401, 259, 74, 190, 190, 190, 487, 288, 288, 403, 403, 403, 171, 252, 252, 143, 36, 108, 108, 119, 119, 351, 374, 374, 374, 374, 374, 374, 374, 132, 132, 132, 132, 132, 132, 98, 98, 98, 98, 13, 13, 13, 78, 78, 140, 140, 47, 47, 47, 140, 140, 140, 73, 73, 289, 373, 373, 110, 110, 202, 202, 202, 202, 202, 202, 402, 198, 198, 22, 283, 283, 455, 38, 164, 164, 164, 164, 214, 214, 214, 214, 214, 214, 214, 328, 328, 200, 200, 200, 200, 471, 471, 185, 185, 49, 269, 390, 390, 18, 112, 427, 56, 140, 312, 312, 187, 187, 187, 187, 187, 187, 187, 260, 391, 149, 149, 228, 289, 289, 140, 209, 287, 111, 111, 111, 438, 438, 378, 43, 364, 276, 276, 346, 346, 426, 426, 426, 426, 426, 206, 206, 167, 457, 457, 131, 183, 451, 451, 451, 30, 30, 30, 422, 162, 162, 232, 172, 115, 273, 470, 120, 120, 240, 240, 314, 478, 478, 232, 232, 232, 172, 26, 26, 386, 386, 431, 431, 84, 496, 496, 496, 496, 274, 359, 359, 359, 474, 474, 474, 474, 474, 19, 19, 19, 19, 454, 454, 454, 78, 78, 140, 170, 140, 28, 140, 28, 28, 28, 140, 341, 341, 341, 341, 341, 341, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 260, 260, 260, 260, 260, 260, 260, 391, 391, 391, 228, 140, 289, 289, 209, 209, 55, 55, 322, 67, 212, 131, 111, 111, 111, 438, 4before_semantic:
after is :
466
[17, 17, 296, 287, 111, 111, 111, 438, 438, 143, 458, 458, 445, 445, 351, 351, 365, 365, 365, 365, 330, 330, 167, 457, 457, 401, 401, 82, 74, 190, 487, 487, 288, 403, 403, 403, 171, 171, 252, 422, 143, 36, 108, 108, 119, 119, 351, 485, 374, 374, 374, 374, 374, 374, 374, 132, 132, 132, 132, 132, 132, 98, 98, 98, 98, 225, 225, 72, 72, 110, 110, 202, 202, 202, 202, 202, 173, 198, 198, 198, 22, 283, 455, 455, 38, 349, 164, 164, 164, 214, 214, 214, 214, 214, 214, 328, 200, 200, 200, 471, 49, 49, 342, 168, 168, 111, 111, 111, 438, 378, 43, 364, 276, 276, 174, 174, 174, 426, 426, 426, 426, 282, 282, 282, 282, 388, 243, 243, 243, 227, 227, 419, 427, 427, 56, 56, 56, 56, 47, 47, 47, 47, 20, 47, 47, 20, 20, 73, 73, 20, 20, 373, 451, 451, 30, 30, 30, 30, 422, 186, 162, 232, 232, 68, 68, 115, 273, 470, 470, 120, 120, 120, 120, 120, 120, 37, 37, 24, 131, 404, 404, 439, 439, 78, 414, 414, 414, 47, 47, 20, 47, 47, 20, 20, 20, 80, 373, 373, 66, 66, 232, 68, 68, 26, 26, 251, 241, 431, 431, 84, 84, 496, 496, 496, 274, 274, 175, 359, 359, 474, 474, 474, 474, 474, 474, 246, 19, 19, 19, 454, 454, 454, 414, 414, 414, 414, 414, 47, 47, 47, 47, 20, 20, 47, 47, 20, 73, 73, 20, 20, 83, 83, 55, 55, 322, 322, 94, 199, 111, 111, 111, 111, 438, 438, 378, 43, 364, 276, 276, 174, 350, 350, 350, 350, 413, 457, 457, 457, 259, 74, 190, 190, 190, 487, 487, 288, 288, 403, 403, 171, 252, 301, 10, 10, 309, 479, 331, 307, 307, 307, 307, 307, 61, 61, 167, 167, 167, 457, 35, 36, 108, 108, 377, 377, 87, 87, 87, 87, 374, 374, 374, 374, 132, 132, 132, 58, 58, 58, 72, 110, 110, 202, 202, 202, 202, 202, 202, 202, 173, 402, 198, 198, 114, 114, 57, 57, 57, 57, 203, 53, 10, 10, 10, 309, 479, 331, 307, 307, 307, 307, 307, 307, 61, 61, 167, 167, 167, 35, 35, 414, 197, 197, 226, 226, 226, 209, 118, 118, 118, 118, 118, 205, 261, 25, 106, 111, 111, 111, 111, 438, 438, 438, 314, 314, 32, 32, 239, 384, 371, 371, 365, 365, 365, 365, 365, 365, 282, before_semantic:
after is :
329
[17, 296, 296, 44, 44, 44, 44, 8, 32, 32, 32, 354, 190, 190, 380, 288, 288, 278, 278, 278, 150, 39, 54, 54, 86, 105, 105, 336, 336, 208, 133, 364, 276, 109, 109, 278, 278, 330, 330, 388, 195, 195, 195, 64, 64, 212, 131, 34, 254, 254, 254, 254, 254, 314, 90, 90, 259, 144, 27, 351, 351, 319, 319, 319, 203, 53, 70, 65, 230, 230, 230, 230, 230, 230, 230, 215, 215, 233, 233, 233, 233, 233, 82, 82, 419, 419, 439, 439, 78, 78, 170, 140, 28, 140, 28, 140, 2, 140, 140, 2, 2, 140, 140, 341, 369, 369, 369, 369, 369, 21, 21, 21, 21, 408, 149, 149, 149, 228, 228, 289, 289, 209, 83, 55, 55, 55, 322, 322, 67, 67, 250, 250, 345, 345, 141, 141, 141, 281, 281, 9, 9, 142, 221, 336, 161, 79, 79, 380, 499, 499, 499, 265, 85, 85, 85, 146, 146, 173, 173, 280, 176, 176, 135, 135, 200, 248, 248, 76, 129, 259, 259, 74, 437, 437, 437, 151, 151, 169, 349, 349, 352, 25, 41, 324, 324, 324, 301, 378, 43, 364, 276, 346, 346, 346, 428, 428, 428, 146, 146, 252, 457, 457, 90, 401, 401, 401, 144, 144, 208, 425, 386, 386, 386, 431, 315, 315, 315, 315, 450, 450, 450, 274, 274, 274,before_semantic:
after is :
284
[17, 17, 296, 287, 44, 44, 44, 8, 8, 32, 354, 190, 190, 380, 288, 288, 278, 278, 271, 150, 39, 342, 342, 86, 105, 336, 458, 208, 133, 364, 276, 109, 109, 109, 278, 278, 330, 388, 195, 195, 195, 195, 64, 212, 131, 34, 254, 254, 254, 254, 314, 90, 90, 259, 144, 27, 27, 351, 351, 319, 319, 203, 53, 70, 65, 230, 230, 230, 230, 230, 230, 215, 215, 35, 233, 233, 419, 419, 439, 439, 439, 78, 78, 170, 20, 20, 312, 312, 312, 187, 187, 187, 12, 12, 12, 260, 260, 260, 163, 163, 163, 20, 316, 20, 20, 20, 73, 20, 20, 83, 83, 55, 55, 322, 67, 67, 250, 250, 345, 345, 141, 141, 141, 281, 453, 9, 9, 142, 32, 239, 161, 161, 79, 79, 499, 499, 499, 265, 265, 85, 85, 146, 146, 173, 173, 280, 176, 176, 135, 200, 200, 248, 248, 465, 259, 74, 437, 437, 437, 319, 319, 169, 349, 205, 205, 261, 41, 41, 324, 324, 301, 301, 43, 364, 276, 346, 346, 428, 428, 428, 146, 146, 358, 457, 457, 401, 401, 401, 144, 208, 208, 208, 386, 386, 386, 431, 431, 315, 315, 315, 315, 315, 315, 450, 450, 450, 450, 413, 413, 37, 24, 471, 471, 49, 49, 433, 433, 97, 97, 225, 226, 226, 226, 226, 20, 209, 287, 287, 255, 255, 143, 458, 144, 208, 190, 487, 499, 499, 499, 405, 405, 206, 169, 150, 150, 342, 86, 238, 198, 198, 198, 22, 22, 283, 455, 38, 162, 68, 68, 105, 105, 144, 180, 180, 180, 265, 265, 265, 265, 26before_semantic:
after is :
294
[17, 17, 296, 0, 0, 0, 0, 301, 378, 42, 147, 456, 456, 456, 416, 416, 239, 445, 445, 445, 180, 290, 290, 290, 290, 290, 290, 290, 434, 434, 434, 434, 434, 339, 195, 195, 195, 212, 212, 131, 472, 472, 198, 127, 114, 222, 222, 222, 406, 406, 467, 255, 255, 255, 129, 129, 82, 74, 437, 437, 437, 306, 306, 306, 306, 306, 306, 206, 167, 35, 131, 472, 196, 196, 291, 291, 291, 291, 291, 291, 379, 243, 243, 227, 227, 483, 226, 226, 82, 440, 255, 255, 236, 129, 82, 74, 74, 437, 437, 351, 486, 486, 486, 468, 406, 11, 11, 11, 11, 379, 243, 243, 26, 26, 26, 359, 474, 474, 474, 474, 474, 19, 19, 454, 454, 229, 82, 247, 312, 312, 187, 292, 292, 12, 12, 12, 12, 12, 260, 260, 260, 391, 391, 140, 140, 73, 140, 140, 140, 320, 345, 333, 333, 220, 220, 216, 180, 113, 113, 113, 113, 113, 167, 167, 457, 35, 401, 384, 490, 490, 490, 490, 162, 54, 232, 482, 482, 238, before_semantic:
after is :
311
[17, 17, 296, 0, 0, 0, 0, 301, 378, 42, 147, 456, 456, 456, 456, 416, 239, 239, 445, 445, 180, 290, 290, 290, 290, 290, 290, 434, 434, 434, 434, 434, 434, 339, 339, 195, 195, 195, 212, 212, 131, 404, 404, 404, 404, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 7, 7, 127, 114, 114, 222, 222, 468, 468, 406, 467, 467, 255, 255, 215, 129, 82, 74, 74, 437, 437, 306, 306, 306, 306, 396, 396, 396, 457, 457, 457, 196, 196, 291, 291, 291, 291, 291, 291, 379, 243, 243, 233, 227, 419, 419, 419, 439, 439, 439, 78, 78, 82, 82, 47, 47, 140, 140, 140, 2, 140, 316, 316, 140, 73, 73, 73, 140, 140, 209, 287, 255, 255, 255, 215, 129, 82, 74, 74, 351, 351, 351, 264, 264, 264, 468, 468, 11, 11, 11, 11, 11, 11, 11, 457, 457, 457, 359, 359, 359, 474, 474, 474, 474, 474, 324, 3, 301, 378, 43, 364, 345, 333, 333, 220, 220, 216, 216, 114, 180, 113, 113, 113, 113, 113, 167, 167, 457, 457, 32, 239, 490, 490, 490, 490, 38, 162, 232, 482, 238, 6, 272, 371, 470, 498, 498, 498, 498, 498, 396, 396, 215, 8, 8, 29, 176, 176, 135, 135, 135, 200, 200, 248, 248, 212, 198, 22, 283, 455, 58, 72, 72, 268, 268, 268, 268, 268, 268, 268, 268, 169, 150, 39, 54, 54, 142, 142, 72, 72, 437, 424, 424, 424, 424, 424, 424, 182, 182, 182, 497, 122, 122, 122, 122, 131, 483, 483, 440, 440, 69, 69, 462, 462, 130, 402, 402, 32, 32, 239, 445, 445, 180, 93, 290, 171, 171, 434, 434, 203, 53, 250, 250, 250before_semantic:
after is :
402
[17, 17, 17, 296, 66, 482, 482, 238, 6, 6, 310, 485, 485, 374, 374, 374, 252, 36, 449, 449, 134, 134, 359, 359, 474, 474, 474, 474, 324, 3, 3, 3, 197, 197, 364, 345, 345, 141, 141, 281, 281, 142, 221, 336, 354, 354, 62, 62, 62, 62, 438, 438, 183, 183, 183, 257, 257, 257, 257, 31, 232, 232, 232, 172, 172, 273, 273, 106, 265, 265, 265, 265, 85, 85, 85, 299, 299, 299, 24, 24, 131, 483, 440, 188, 340, 340, 116, 94, 199, 44, 44, 349, 349, 234, 261, 425, 425, 386, 431, 486, 376, 376, 376, 460, 460, 460, 169, 169, 99, 436, 436, 436, 447, 112, 112, 56, 56, 56, 170, 20, 20, 28, 20, 20, 20, 20, 20, 2, 20, 20, 163, 20, 163, 163, 20, 20, 73, 73, 20, 20, 412, 83, 83, 55, 322, 322, 67, 212, 127, 361, 361, 361, 361, 361, 361, 388, 67, 195, 195, 117, 117, 197, 197, 7, 127, 127, 0, 0, 0, 301, 8, 8, 354, 106, 496, 496, 496, 496, 496, 169, 164, 164, 221, 221, 336, 354, 420, 420, 416, 458, 445, 210, 210, 210, 210, 330, 388, 33, 90before_semantic:
after is :
660
[17, 17, 296, 296, 66, 482, 482, 482, 238, 6, 272, 470, 374, 374, 374, 374, 132, 285, 26, 26, 359, 359, 359, 474, 474, 474, 474, 324, 3, 301, 378, 43, 364, 345, 345, 141, 141, 141, 281, 281, 9, 142, 221, 336, 354, 354, 62, 62, 62, 62, 62, 62, 62, 85, 85, 146, 438, 58, 183, 183, 183, 183, 257, 257, 257, 257, 257, 31, 162, 232, 232, 232, 232, 172, 172, 115, 273, 273, 265, 265, 265, 265, 265, 265, 265, 265, 265, 85, 85, 85, 299, 299, 299, 37, 24, 24, 131, 404, 404, 439, 439, 439, 78, 78, 140, 170, 140, 28, 28, 140, 28, 28, 140, 2, 140, 341, 341, 341, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 260, 408, 408, 391, 391, 228, 140, 140, 412, 188, 188, 340, 340, 94, 199, 44, 44, 38, 349, 349, 234, 234, 261, 425, 425, 425, 386, 431, 431, 431, 486, 486, 376, 376, 376, 376, 376, 376, 460, 460, 460, 169, 169, 169, 99, 99, 338, 338, 338, 338, 338, 338, 338, 18, 18, 112, 112, 439, 78, 78, 170, 140, 28, 140, 28, 28, 140, 28, 28, 140, 362, 362, 140, 362, 140, 362, 140, 362, 362, 362, 362, 140, 362, 362, 218, 140, 218, 218, 218, 140, 218, 218, 218, 140, 366, 218, 366, 140, 366, 366, 366, 366, 366, 366, 366, 366, 366, 140, 366, 140, 316, 316, 316, 316, 140, 73, 73, 289, 412, 412, 83, 55, 55, 322, 322, 67, 466, 466, 361, 361, 361, 361, 361, 361, 348, 466, 466, 466, 466, 114, 0, 0, 0, 0, 0, 0, 301, 8, 8, 239, 354, 106, 106, 496, 496, 496, 496, 496, 274, 274, 169, 164, 164, 164, 164, 221, 221, 336, 354, 354, 420, 420, 416, 416, 239, 445, 210, 210, 210, 210, 210, 210, 210, 210, 282, 282, 388, 388, 195, 195, 394, 90, 90, 393, 234, 234, 234, 234, 261, 261, 25, 444, 213, 213, 213, 213, 252, 139, 175, 359, 176, 176, 176, 135, 135, 200, 200, 200, 464, 464, 255, 255, 255, 8, 8, 8, 354, 180, 113, 113, 113, 113, 113, 113, 113, 450, 167, 35, 35, 401, 401, 198, 127, 114, 57, 57, 57, 203, 53, 53, 394, 3before_semantic:
after is :
446
[17, 17, 296, 296, 276, 153, 153, 153, 372, 372, 372, 467, 467, 467, 242, 242, 64, 64, 465, 108, 449, 242, 242, 242, 116, 33, 394, 478, 478, 232, 232, 105, 105, 336, 336, 354, 470, 189, 496, 496, 496, 496, 274, 274, 35, 35, 35, 96, 472, 198, 198, 127, 127, 114, 180, 151, 151, 151, 151, 151, 169, 169, 150, 39, 54, 54, 390, 390, 390, 18, 97, 397, 397, 336, 364, 345, 333, 333, 333, 220, 220, 31, 162, 232, 232, 172, 115, 224, 273, 494, 154, 416, 416, 96, 196, 196, 479, 331, 278, 278, 278, 278, 169, 349, 352, 469, 469, 469, 469, 143, 458, 192, 11, 11, 11, 11, 379, 379, 471, 77, 77, 269, 86, 86, 238, 6, 6, 108, 377, 377, 344, 344, 344, 374, 374, 374, 132, 132, 132, 186, 99, 99, 338, 338, 338, 338, 395, 395, 395, 84, 84, 84, 496, 496, 274, 274, 274, 43, 43, 364, 147, 147, 380, 499, 499, 284, 405, 405, 405, 206, 206, 206, 215, 8, 29, 242, 275, 275, 275, 116, 303, 303, 117, 117, 48, 48, 414, 414, 414, 170, 170, 20, 20, 28, 20, 20, 28, 28, 20, 20, 20, 2, 20, 2, 20, 163, 163, 20, 163, 20, 20, 316, 20, 73, 73, 20, 20, 127, 45, 45, 45, 45, 45, 45, 325, 183, 183, 451, 30, 30, 30, 30, 378, 378, 345, 141, 141, 141, 281, 281, 9, 9, 221, 196, 309, 309, 479, 479, 331, 307, 307, 307, 307, 307, 61, 61, 167, 167, 35, 35, 35, 401, 259, 108, 377, 377, 377, 374, 374, 374, 374, 374, 132, 132, 422, 143, 164, 164, 164, 214, 214, 214, 214, 360, 360, 200, 248, 76, output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0028
generate
 66%|██████▌   | 42/64 [09:03<06:45, 18.42s/it]processing 42th semantic_sys file
42
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WARRENTON SPOKE THUS WITH SIGNIFICANCE TO SHOW ROBIN THAT HE WAS NOT TO THINK GEOFFREY'S CLAIMS TO THE ESTATE WOULD BE PASSED BY
2024-03-14 03:09:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:09:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/torch.Size([1, 444, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispbefore_semantic:
after is :
462
[17, 296, 296, 276, 276, 153, 153, 372, 372, 406, 467, 467, 242, 242, 64, 76, 465, 108, 449, 242, 275, 275, 275, 116, 195, 195, 394, 478, 478, 162, 232, 232, 482, 105, 105, 336, 354, 470, 189, 496, 496, 496, 274, 274, 35, 96, 96, 198, 198, 127, 114, 180, 151, 151, 151, 151, 169, 169, 150, 150, 54, 54, 390, 390, 18, 97, 97, 225, 56, 56, 80, 80, 80, 80, 321, 320, 345, 333, 333, 333, 220, 220, 220, 478, 66, 232, 172, 172, 224, 494, 494, 154, 416, 416, 196, 196, 479, 278, 278, 278, 278, 349, 205, 25, 469, 469, 469, 469, 458, 192, 11, 11, 11, 11, 379, 379, 243, 77, 269, 54, 390, 18, 112, 112, 56, 56, 56, 56, 47, 47, 140, 140, 2, 2, 140, 140, 316, 316, 140, 73, 73, 321, 75, 108, 108, 377, 374, 374, 374, 374, 132, 132, 186, 186, 338, 338, 338, 395, 395, 395, 84, 84, 496, 496, 274, 274, 274, 42, 42, 147, 147, 380, 499, 499, 405, 405, 405, 206, 215, 215, 29, 29, 242, 275, 275, 116, 303, 303, 117, 404, 13, 229, 414, 170, 170, 140, 187, 187, 187, 187, 187, 187, 187, 12, 12, 12, 12, 12, 12, 12, 12, 260, 260, 260, 391, 391, 391, 73, 73, 140, 321, 127, 45, 45, 45, 45, 325, 183, 451, 30, 30, 30, 378, 378, 345, 141, 141, 141, 281, 453, 9, 196, 309, 309, 479, 307, 307, 307, 307, 61, 167, 167, 457, 35, 401, 259, 108, 108, 377, 344, 374, 374, 374, 374, 132, 422, 349, 164, 164, 164, 164, 214, 214, 214, 214, 214, 360, 360, 328, 328, 243, 233, 192, 192, 419, 439, 439, 439, 439, 78, 170, 170, 28, 28, 28, 140, 2, 2, 2, 2, 140, 2, 2, 140, 2, 140, 163, 163, 163, 140, 316, 316, 316, 73, 73, 73, 321, 320, 310, 107, 329, 329, 329, 329, 329, 329, 329, 205, 155, 29, 495, 382, 313, 368, 31, 9, 142, 221, 336, 208, 208, 386, 386, 431, 290, 290, 290, 290, 434, 434, 203, 53, 471, 49, 49, 9, 238, 6, 6, 377, 123, 123, 216, 216, 22, 448, 448, 448, 464, 464, 255, 38, 31, 162, 54, 482, 238, 6, 272, 470, 470, 171, 171, 171, 358, 358, 385, 131, 419, 439, 439, 414, 414, 47, 47, 140, 47, 140, 80, 80, 320, 7, 7, 364, 345, 389, 389, 389, 314, 314, 32, 239, 354, 420, 420, 420, 301, 301, 129, 259, 74, 74, 311, 311, 311, 311, 311, 311, 311, 311, 169, 150, 150, 86, 238, 6, 6, 472, 472, 221, 336, 354, 354, 62, 62, 265, 265, 265, 265, 265, 85, 85, 85, 85, 207, 207, 19, 454, 454, 13, 414, 414]
torch.Size([1, 460, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0035
generate
 67%|██████▋   | 43/64 [09:22<06:31, 18.66s/it]processing 43th semantic_sys file
43
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE HOURS PASSED WEARILY BY AND MOVEMENT COULD YET BE HEARD ABOUT THE HALL
2024-03-14 03:09:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 44th semantic_sys file
44
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FROM THE BLACKNESS BEHIND THE LIGHT THEY HEARD A VOICE WARRENTON'S
2024-03-14 03:09:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:09:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([60], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
291
[17, 17, 165, 165, 165, 165, 165, 466, 466, 466, 22, 283, 455, 455, 8, 259, 354, 425, 425, 386, 431, 431, 376, 376, 376, 460, 460, 178, 35, 35, 96, 196, 196, 94, 459, 459, 459, 271, 271, 39, 54, 54, 142, 142, 221, 336, 336, 354, 420, 420, 324, 422, 58, 58, 72, 437, 437, 480, 480, 480, 480, 480, 480, 480, 85, 299, 299, 299, 299, 299, 339, 339, 64, 64, 212, 212, 212, 131, 404, 404, 404, 404, 404, 404, 263, 13, 78, 170, 170, 170, 20, 20, 20, 28, 20, 20, 2, 2, 2, 2, 2, 2, 2, 2, 20, 2, 163, 20, 163, 20, 316, 316, 316, 316, 20, 73, 73, 20, 320, 127, 127, 5, 5, 455, 455, 251, 251, 251, 241, 431, 431, 431, 428, 428, 428, 428, 428, 428, 146, 146, 358, 358, 358, 358, 233, 233, 233, 233, 75, 227, 227, 419, 419, 419, 419, 439, 439, 78, 78, 20, 47, 47, 20, 47, 47, 47, 47, 20, 47, 47, 316, 316, 316, 73, 20, 73, 289, 320, 127, 127, 0, 0, 0, 0, 422, 422, 58, 72, 72, 72, 498, 498, 498, 498, 498, 498, 498, 396, 396, 396, 396, 313, 37, 24, 24, 131, 131, 483, 483, 440, 440, 44, 44, 44, 44, 130, 130, 280, 280, 280, 343, 343, 343, 343, 343, 343, 343, 343, 343, 358, 358, 358, 186, 39, 54, 54, 54, 390, 390, 390, 390, 390, 18, 18, 18, 18, 97, 97, 97, 97, 225, 225, 80, 80, 20, 80, 80, 80, 80, 320, 7, 364, 276, 276, 153, 153, 153, 372, before_semantic:
after is :
360
[17, 17, 296, 451, 451, 30, 30, 464, 464, 121, 121, 53, 394, 76, 259, 259, 74, 425,torch.Size([1, 289, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0029
generate
 70%|███████   | 45/64 [09:34<04:03, 12.83s/it]processing 45th semantic_sys file
45
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ROBIN CAREFULLY DESCENDED THE LADDER AND FOUND HIMSELF SOON UPON FIRM ROCKY GROUND
2024-03-14 03:09:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:09:36 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
225
[17, 17, 296, 147, 380, 499, 329, 329, 215, 8, 29, 242, 242, 116, 33, 90, 90, 465, 445, 445, 351, 351, 264, 264, 264, 468, 245, 349, 349, 262, 262, 262, 262, 359, 359, 166, 166, 166, 301, 236, 239, 490, 490, 490, 490, 162, 54, 172, 115, 432, 432, 432, 330, 64, 212, 34, 191, 191, 314, 314, 22, 283, 283, 455, 455, 251, 241, 431, 431, 486, 376, 376, 376, 240, 285, 285, 334, 334, 334, 59, 59, 59, 452, 263, 263, 229, 82, 247, 312, 126, 126, 292, 292, 292, 292, 23, 23, 23, 23, 408, 408, 149, 149, 140, 140, 83, 55, 322, 67, 90, 393, 205, 261, 25, 180, 315, 315, 315, 450, 450, 348, 64, 131, 34, 57, 203, 53, 394, 186, 162, 54, 172, 273, 279, 279, 279, 279, 293, 293, 402, 478, 162, 482, 172, 115, 273, 374, 374, 374, 374, 132, 132, 413, 94, 199, 255, 255, 129, 259, 74, 125, 125, 125, 125, 125, 348, 394, 90, 393, 234, 261, 25, 498, 498, 498, 498, 396, 203, 203, 53, 250, 147, 147, 380, 499, 405, 405, 206, 178, 458, 458, 192, 41, 324, 324, 416, 239, 144, 208, 79, 79, 380, 380, 288, 315, 315, 315, 315, 450, 450, 450, 413, 413, 413, 303, 303, 243, 243, 131, 419, 419, 439, 439, 439, 439]
torch.Size([1, 223, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0027
generate
 72%|███████▏  | 46/64 [09:44<03:36, 12.05s/it]processing 46th semantic_sys file
46
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE IMPLORES US TO BE DISCREET AS THE GRAVE IN THIS MATTER FOR IN SOOTbefore_semantic:
after is :
308
[17, 17, 296, 0, 0, 0, 0, 301, 301, 216, 127, 114, 361, 361, 361, 330, 388, 33, 33, 250, 42, 42, 147, 147, 456, 456, 456, 456, 456, 339, 10, 10, 398, 398, 398, 398, 398, 374, 374, 374, 132, 132, 132, 132, 132, 37, 314, 314, 198, 127, 114, 222, 222, 222, 222, 313, 313, 236, before_semantic:
after is :
482
[17, 17, 296, 451, 451, 30, 30, 464, 464, 121, 121, 121, 53, 394, 394, 76, 74, 425, 425, 425, 386, 386, 153, 153, 153, 153, 153, 387, 387, 387, 387, 71, 71, 368, 49, 9, 142, 219, 477, 477, 477, 477, 477, 132, 132, 132, 132, 132, 98, 98, 98, 98, 13, 229, 229, 247, 312, 312, 126, 292, 292, 292, 23, 1, 23, 23, 23, 23, 260, 260, 260, 391, 391, 20, 20, 316, 20, 20, 20, 73, 20, 20, 20, 209, 83, 145, 443, 443, 443, 443, 169, 150, 150, 54, 54, 86, 238, 6, 6, 336, 75, 108, 108, 377, 377, 377, 374, 374, 374, 374, 374, 374, 374, 132, 132, 132, 132, 132, 132, 8, 32, 32, 32, 354, 420, 420, 420, 420, 420, 301, 236, 239, 239, 384, 490, 490, 490, 490, 490, 31, 162, 54, 482, 482, 105, 105, 336, 336, 79, 79, 487, 288, 288, 288, 213, 213, 358, 358, 358, 233, 233, 233, 20, 227, 227, 419, 427, 427, 56, 247, 312, 312, 126, 292, 292, 292, 292, 292, 23, 23, 23, 23, 23, 23, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 391, 391, 391, 228, 20, 20, 412, 83, 83, 253, 253, 253, 281, 453, 198, 198, 22, 5, 5, 455, 416, 416, 208, 79, 79, 79, 380, 380, 288, 288, 403, 171, 171, 171, 171, 246, 246, 246, 246, 318, 173, 173, 173, 280, 340, 340, 340, 116, 466, 466, 114, 258, 258, 258, 31, 54, 54, 142, 142, 221, 336, 196, 217, 473, 65, 486, 486, 486, 460, 460, 460, 285, 285, 300, 334, 382, 59, 245, 245, 349, 349, 155, 155, 332, 332, 332, 406, 467, 467, 340, 340, 340, 116, 33, 33, 394, 394, 478, 478, 162, 482, 482, 482, 482, 482, 115, 115, 273, 374, 374, 374, 374, 374, 374, 132, 132, 132, 132, 132, 132, 132, 132, 216, 216, 216, 127, 114, 114, 257, 257, 257, 257, 257, 368, 453, 9, 9, 142, 26, 26, 251, 251, 241, 241, 431, 431, 265, 428, 428, 428, 428, 146, 146, 358, 358, 358, 352, 352, 352, 352, 352, 352, 352, 352, 97, 483, 226, 226, 20, 209, 188, 356, 356, 356, 356, 356, 356, 356, 356, 356, 356, 318, 185, 368, 49, 453, 9, 9, 168, 340, 340, 340, 116, 466, 466, 466, 22, 283, 455, 455, 72, 72, 72, 72, 72, 437, 437, 284, 481, 481, 481, 481, 175, 175, 175, 81, 84, 84, 84, 84, 1before_semantic:
after is :
412
[17, 17, 296, 373, 451, 257, 257, 257, 257, 31, 342, 86, 86, 238, 336, 336, 108, 119, 351, 351, 84, 84, 84, 496, 496, 274, 274, 274, 413, 413, 413, 379, 471, 471, 471, 49, 49, 269, 433, 433, 160, 97, 97, 225, 225, 225, 225, 225, 225, 225, 225, 7, 7, 147, 147, 380, 380, 189, 189, 210, 210, 210, 210,output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0039
generate
 73%|███████▎  | 47/64 [10:06<04:11, 14.77s/it]processing 47th semantic_sys file
47
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY THEN RENEWED THEIR JOURNEY AND UNDER THE BETTER LIGHT MADE A SAFE CROSSING OF THE STABLE ROOFS
2024-03-14 03:10:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:10:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
355
[17, 17, 296, 127, 0, 0, 0, 0, 301, 216, 216, 127, 114, 114, 361, 361, 361, 361, 330, 330, 388, 388, 195, 195, 195, 250, 250, 147, 147, 456, 456, 456, 456, 116, 10, 479, 398, 398, 398, 374, 374, 374, 132, 132, 132, 132, 132, 132, 132, 37, 24, 24, 24, 131, 404, 404, 404, 439, 225, 225, 225, 225, 225, 225, 225, 80, 80, 20, 20, 320, 127, 222, 222, 222, 222, 222, 313, 236, 239, 310, 107, 107, 395, 395, 498, 498, 498, 498, 498, 396, 313, 94, 199, 41, 41, 41, 324, 3, 464, 89, 89, 446, 446, 94, 199, 335, 14, 14, 411, 411, 319, 319, 319, 319, 348, 64, 64, 212, 300, 300, 382, 313, 216, 216, 22, 283, 455, 455, 8, 239, 354, 180, 180, 443, 443, 443, 285, 285, 300, 382, 382, 245, 251, 251, 251, 241, 241, 431, 431, 428, 428, 428, 428, 428, 146, 146, 358, 385, 233, 233, 233, 233, 20, 227, 227, 419, 419, 419, 419, 439, 439, 439, 439, 439, 237, 237, 237, 237, 237, 237, 237, 20, 20, 2, 2, 2, 20, 20, 163, 20, 163, 163, 163, 20, 20, 316, 316, 20, 73, 73, 20, 320, 7, 217, 217, 473, 476, 476, 476, 476, 476, 476, 476, 246, 246, 246, 246, 246, 252, 24, 325, 131, 483, 483, 440, 440, 44, 44, 44, 44, 38, 162, 232, 232, 232, 172, 172, 115, 273, 470, 470, 171, 171, 171, 171, 358, 358, 358, 358, 349, 352, 352, 402, 221, 401, 401, 82, 208, 208, 208, 208, 190, 190, 190, 487, 499, 499, 499, 405, 206, 169, 150, 150, 54, 54, 54, 224, 176, 176, 176, 176, 328, 328, 200, 200, 200, 195, 117, 117, 335, 483, 440, 440, 69, 69, 69, 223, 130, 130, 198, 198, 22, 283, 455, 38, 162, 232, 232, 482, 238, 6, 272, 470, 470, 171, 171, 171, 252, 252, 8, 29, 100, 100, 497, 497, 497, 42, 42, 42, 147, 380, 380, 380, 374, 374, 132, 132, 132, 358, 349, 352, 352, 270, 270, 270, 390,before_semantic:
after is :
333
[17, 296, 2torch.Size([1, 353, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0021
generate
 75%|███████▌  | 48/64 [10:22<03:59, 14.98s/it]processing 48th semantic_sys file
48
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HIS TONES RANG PLEASANTLY ON WARRENTON'S EARS AND FORTHWITH A GOOD FELLOWSHIP WAS HERALDED BETWEEN THEM
2024-03-14 03:10:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:10:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
379
[17, 17, 296, 373, 451, 257, 257, 257, 31, 54, 86, 238, 6, 108, 119, 119, 351, 351, 84, 84, 496, 496, 496, 413, 413, 339, 64, 471, 49, 9, 142, 42, 42, 147, 380, 380, 189, 189, 189, 365, 365, 365, 328, 200, 200, 248, 248, 76, 465, 74, 425, 425, 386, 386, 151, 151, 151, 368, 368, 453, 168, 11, 11, 379, 457, 457, 359, 359, 359, 474, 474, 474, 474, 474, 19, 19, 19, 454, 454, 229, 229, 247, 126, 126, 126, 23, 23, 23, 101, 101, 101, 149, 149, 228, 140, 412, 287, 287, 125, 125, 125, 125, 125, 348, 33, 33, 250, 250, 250, 364, 364, 364, 364, 276, 276, 153, 153, 153, 372, 372, 372, 467, 467, 242, 242, 64, 64, 76, 108, 449, 242, 242, 242, 116, 116, 33, 33, 394, 368, 453, 453, 9, 168, 286, 286, 286, 286, 286, 286, 286, 286, 334, 59, 59, 59, 304, 304, 304, 185, 185, 185, 269, 323, 390, 390, 18, 18, 112, 112, 56, 56, 56, 56, 28, 140, 28, 140, 140, 140, 2, 2, 2, 140, 2, 140, 163, 163, 140, 163, 316, 140, 316, 73, 140, 140, 412, 83, 83, 55, 55, 55, 322, 322, 67, 394, 90, 393, 393, 234, 234, 261, 25, 148, 148, 148, 148, 372, 372, 396, 169, 169, 164, 164, 164, 397, 397, 345, 333, 333, 220, 220, 220, 164, 44, 44, 44, 416, 416, 32, 32, 32, 239, 144, 484, 484, 484, 484, 484, 240, 314, 314, 90, 393, 393, 234, 234, 234, 261, 25, 470, 470, 443, 139, 139, 175, 175, 81, 81, 84, 496, 496, 274, 186, 99, 338, 338, 395, 395, 470, 459, 120, 120, 215, 215, 233, 233, 233, 82, 419, 427, 229, 247, 247, 126, 126, 23, 23, 101, 101, 149, 228, 228, 289, 140, 320, 141, 141, 141, 141, 281, 281, 54, 9, 142, 183, 72, 72, 72, 72, 110, 110, 264, 264, 468, 468, 406, 406, 467, 302, 302, 302, 497, 122, 122, 122, 34, 191, 191, 191, 314, 314, 314, 32, 32, 32, 354, 354, 278, 278, 278, 385, 457, 457, 133, 364, 364, 345, 109, 360, 360, 360, 339, 339, 466, 466, 466, 114, 114, 57, 57, 57, 57, 203, 381, 381, 381, 48, 48, 48]
torch.Size([1, 377, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0037
generate
 77%|███████▋  | 49/64 [10:37<03:47, 15.16s/it]processing 49th semantic_sys file
49
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FITZOOTH'S HAND RESTED AT LAST UPON THE TOP RUNG OF A LADDER AND SLOWLY THE TRUTH CAME TO HIM
2024-03-14 03:10:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:10:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
331
[17, 17, 296, 296, 261, 25, 278, 278, 278, 278, 143, 35, 478, 478, 66, 68, 172, 115, 273, 374, 374, 374, 374, 374, 252, 143, 35, 270, 270, 342, 342, 142, 183, 72, 72, 110, 294, 294, 294, 294, 294, 294, 294, 294, 294, 282, 282, 388, 388, 64, 64, 212, 131, 133, 42, 42, 42, 147, 147, 147, 380, 288, 443, 443, 443, 169, 150, 150, 86, 86, 86, 238, 6, 272, 191, 191, 191, 191, 325, 34, 415, 415, 415, 415, 415, 415, 457, 457, 251, 251, 251, 241, 241, 431, 431, 376, 376, 376, 376, 376, 376, 376, 376, 376, 282, 282, 169, 150, 150, 86, 238, 6, 272, 255, 255, 236, 129, 259, 74, 437, 125, 125, 125, 125, 125, 125, 125, 125, 348, 466, 466, 22, 283, 283, 455, 236, 129, 259, 108, 119, 119, 437, 437, 405, 405, 405, 405, 206, 206, 215, 215, 35, 35, 29, 29, 42, 147, 147, 147, 380, 380, 499, 319, 319, 319, 319, 413, 200, 200, 200, 69, 69, 69, 223, 130, 280, 44, 44, 44, 251, 251, 251, 241, 431, 431, 486, 486, 376, 376, 376, 376, 460, 240, 285, 300, 334, 334, 59, 452, 452, 263, 229, 414, 247, 312, 126, 126, 292, 292, 292, 1, 1, 1, 1, 1, 408, 408, 408, 149, 228, 140, 140, 412, 83, 55, 322, 322, 67, 478, 478, 232, 232, 482, 482, 26, 26, 26, 241, 241, 431, 431, 84, 84, 496, 16, 16, 274, 274, 359, 359, 359, 474, 474, 474, 474, 474, 324, 3, 301, 216, 216, 22, 5, 455, 455, 236, 129, 310, 161, 161, 161, 161, 487, 487, 487, 374, 374, 374, 374, 132, 358, 186, 352, 352, 352, 221, 221, 82, 445, 445, 210, 210, 210, 210, 210, 210, 210, 210, 434, 434, 339, 394, 394, 76, 259, 108, 377, 377, 123, 123, 123, 123, 132, 58, 58, 183, 57, 57, 57, 57, 57, 282, 282, 282, 203, 381, 381, 381, 48, 48, 48]
torch.Size([1, 329, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0026
generate
 78%|███████▊  | 50/64 [10:51<03:27, 14.83s/it]processing 50th semantic_sys file
50
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ROBIN FITZOOTH SAW THAT HIS DOUBTS OF WARRENTON HAD BEEN UNFAIR AND HE BECAME ASHAMED OF HIMSELF FOR HARBORING THEM
2024-03-14 03:10:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:10:53 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
382
[17, 17, 296, 296, 7, 147, 380, 329, 329, 329, 329, 329, 215, 8, 29, 242, 242, 116, 33, 394, 76, 393, 234, 234, 261, 25, 25, 278, 278, 385, 35, 478, 478, 232, 232, 232, 172, 172, 115, 115, 273, 374, 374, 374, 132, 358, 186, 164, 164, 164, 66, 66, 482, 482, 172, 172, 115, 273, 106, 106, 481, 481, 481, 481, 182, 182, 182, 293, 293, 122, 216, 127, 45, 45, 45, 325, 325, 183, 257, 257, 257, 257, 257, 453, 9, 221, 221, 82, 82, 384, 371, 180, 180, 315, 315, 113, 450, 450, 450, 167, 167, 35, 270, 270, 270, 390, 390, 224, 168, 69, 69, 462, 130, 402, 402, 133, 364, 276, 276, 153, 153, 372, 372, 372, 406, 467, 467, 469, 469, 64, 64, 465, 108, 449, 242, 275, 275, 275, 116, 303, 303, 117, 117, 48, 48, 48, 417, 417, 82, 82, 170, 170, 140, 140, 140, 28, 140, 28, 140, 2, 2, 2, 140, 140, 2, 140, 2, 366, 140, 366, 366, 140, 316, 316, 316, 316, 140, 73, 73, 140, 412, 83, 254, 254, 254, 254, 314, 32, 239, 354, 137, 137, 137, 137, 94, 199, 199, 319, 319, 319, 348, 33, 394, 90, 349, 234, 234, 234, 261, 25, 470, 470, 264, 264, 264, 264, 264, 264, 264, 264, 468, 59, 59, 59, 452, 452, 263, 263, 263, 263, 225, 225, 237, 237, 237, 237, 237, 47, 47, 47, 47, 80, 80, 80, 140, 412, 83, 55, 55, 322, 67, 212, 131, 451, 451, 30, 30, 301, 8, 354, 420, 420, 420, 422, 143, 458, 445, 210, 210, 210, 210, 210, 210, 203, 53, 53, 44, 44, 44, 38, 99, 338, 338, 338, 338, 338, 395, 470, 290, 290, 290, 290, 290, 290, 290, 290, 434, 434, 434, 203, 203, 381, 195, 195, 212, 212, 34, 69, 223, 223, 130, 402, 183, 57, 57, 203, 53, 394, 478, 162, 162, 482, 172, 115, 273, 279, 279, 279, 279, 279, 279, 293, 169, 349, 352, 393, 393, 155, 155, 332, 332, 332, 245, 58, 72, 72, 72, 437, 306, 306, 306, 306, 396, 396, 8, 8, 29, 495, 495, 495, 467, 176, 176, 135, 135, 200, 248, 248, 248, 114, 57, 57, 57, 203, 381, 381, 381, 48, 48, 48, 417, 417]
torch.Size([1, 380, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0036
generate
 80%|███████▉  | 51/64 [11:07<03:16, 15.08s/it]processing 51th semantic_sys file
51
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MOST OF ALL ROBIN THOUGHT OF HIS FATHER WHAT WOULD HE COUNSEL
2024-03-14 03:11:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:11:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
283
[17, 17, 296, 217, 70, 65, 65, 496, 496, 496, 496, 274, 274, 274, 186, 186, 54, 86, 238, 6, 272, 494, 223, 223, 223, 130, 280, 280, 106, 106, 297, 297, 297, 297, 297, 297, 297, 297, 293, 293, 497, 497, 42, 42, 42, 147, 147, 380, 380, 499, 499, 405, 405, 206, 206, 215, 8, 29, 242, 242, 242, 116, 33, 394, 394, 478, 164, 164, 164, 164, 164, 25, 106, 106, 405, 405, 405, 405, 206, 206, 285, 285, 69, 223, 223, 223, 130, 402, 402, 183, 183, 257, 257, 257, 257, 257, 257, 31, 342, 342, 86, 142, 393, 393, 205, 205, 205, 205, 261, 25, 25, 91, 91, 91, 91, 91, 91, 91, 206, 206, 493, 493, 216, 300, 300, 300, 334, 382, 245, 245, 43, 43, 364, 364, 364, 276, 276, 181, 181, 181, 181, 181, 181, 167, 167, 385, 233, 233, 233, 233, 75, 227, 419, 419, 439, 439, 78, 170, 170, 28, 28, 28, 28, 140, 140, 2, 140, 2, 140, 2, 140, 2, 140, 163, 163, 140, 316, 140, 316, 140, 73, 140, 73, 140, 7, 7, 7, 364, 276, 276, 430, 430, 430, 430, 430, 240, 385, 385, 233, 36, 227, 227, 419, 419, 419, 439, 439, 439, 78, 170, 170, 140, 47, 47, 47, 47, 47, 47, 47, 47, 140, 316, 316, 73, 73, 73, 289, 320, 7, 364, 345, 430, 430, 430, 430, 430, 430, 325, 131, 183, 183, 451, 30, 30, 30, 30, 324, 422, 422, 143, 458, 82, 144, 445, 445, 351, 351, 351, 315, 315, 450, 450, 413, 413, 379, 243, 77, 77, 77, 433, 68, 224, 224, 302, 302, 302, 375, 375, 375, 375, 98, 98, 98]
torch.Size([1, 281, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0002
generate
 81%|████████▏ | 52/64 [11:18<02:48, 14.04s/it]processing 52th semantic_sys file
52
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AS ANY IN ENGLAND I WOULD SAY SAID GAMEWELL PROUDLY THAT IS IN HIS DAY
2024-03-14 03:11:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:11:21 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
201
[17, 17, 296, 253, 253, 253, 253, 453, 453, 168, 168, 475, 475, 475, 94, 94, 475, 475, 475, 324, 324, 3, 464, 464, 340, 340, 116, 94, 199, 199, 145, 360, 360, 360, 200, 200, 248, 212, 26, 359, 359, 81, 275, 275, 275, 116, 64, 64, 212, 131, 483, 483, 14, 287, 111, 111, 111, 111, 438, 378, 43, 345, 389, 389, 389, 314, 314, 478, 478, 66, 68, 172, 115, 273, 470, 403, 403, 171, 252, 186, 186, 162, 342, 342, 115, 273, 470, 120, 120, 240, 314, 314, 90, 90, 401, 82, 445, 445, 180, 290, 290, 290, 290, 434, 203, 203, 250, 250, 250, 276, 276, 109, 109, 139, 139, 139, 293, 293, 122, 129, 129, 20, 74, 190, 190, 488, 499, 315, 315, 315, 450, 450, 413, 122, 26, 26, 26, 359, 359, 474, 474, 474, 324, 301, 301, 216, 127, 114, 114, 92, 92, 92, 240, 285, 325, 34, 356, 356, 281, 453, 342, 168, 340, 340, 340, 340, 116, 33, 33, 199, 257, 257, 257, 257, 31, 342, 86, 238, 336, 20, 384, 371, 93, 93, 93, 93, 93, 93, 207, 207, 207, 207, 207, 19, 19, 19, 454, 454, 13, 20, 20]
torch.Size([1, 199, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0011
generate
 83%|████████▎ | 53/64 [11:26<02:13, 12.15s/it]processing 53th semantic_sys file
53
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WILL WHISPERED ROBIN OPENING HIS DOOR AS HE SPOKE ARE YOU READY
2024-03-14 03:11:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:11:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([54], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
221
[17, 296, 296, 345, 389, 389, 389, 497, 43, 43, 364, 364, 276, 109, 109, 278, 278, 31, 54, 54, 105, 105, 336, 82, 354, 29, 382, 382, 382, 313, 313, 24, 131, 133, 42, 42, 42, 42, 42, 147, 147, 147, 147, 380, 499, 499, 284, 405, 405, 405, 405, 206, 206, 215, 215, 8, 354, 242, 275, 275, 275, 116, 195, 195, 195, 117, 117, 404, 225, 225, 225, 225, 225, 225, 80, 80, 80, 80, 80, 140, 140, 287, 287, 410, 410, 410, 410, 410, 215, 215, 129, 82, 29, 29, 242, 242, 94, 199, 176, 135, 135, 200, 200, 248, 183, 183, 257, 257, 257, 257, 257, 453, 9, 9, 221, 336, 384, 371, 106, 106, 153, 153, 153, 153, 153, 182, 182, 372, 372, 59, 59, 452, 452, 263, 263, 263, 225, 225, 225, 225, 225, 225, 225, 412, 83, 83, 253, 253, 253, 253, 253, 253, 342, 342, 183, 451, 451, 30, 30, 30, 422, 186, 232, 232, 482, 105, 105, 336, 82, 354, 106, 189, 496, 496, 496, 274, 274, 143, 458, 192, 192, 106, 106, 353, 353, 353, 396, 313, 219, 219, 219, 477, 477, 477, 132, 132, 42, 42, 42, 147, 147, 380, 288, 443, 443, 240, 325, 325, 41, 41, 41, 19, 19, 19, 454, 454, 454, 439, 439, 439, 78]
torch.Size([1, 219, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0020
generate
 84%|████████▍ | 54/64 [11:35<01:52, 11.21s/it]processing 54th semantic_sys file
54
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY MOVED THEREAFTER CAUTIOUSLY ABOUT THE HUT GROPING BEFORE AND ABOUT THEM TO FIND SOMETHING TO SHOW THAT WARRENTON HAD FULFILLED HIS MISSION
2024-03-14 03:11:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:11:37 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
450
[17, 17, 296, 0, 0, 0, 0, 301, 399, 217, 217, 473, 65, 374, 374, 374, 132, 173, 173, 402, 198, 198, 114, 222, 222, 222, 406, 406, 467, 145, 145, 460, 460, 169, 169, 402, 96, 272, 300, 382, 245, 245, 458, 144, 27, 437, 437, 405, 405, 405, 206, 206, 169, 99, 436, 436, 459, 459, 459, 31, 54, 54, 26, 359, 474, 474, 474, 464, 255, 255, 8, 354, 180, 113, 113, 113, 113, 167, 35, 35, 198, 22, 283, 455, 455, 72, 72, 72, 72, 437, 437, 151, 151, 151, 167, 167, 385, 233, 233, 75, 227, 419, 419, 439, 439, 439, 439, 78, 78, 170, 140, 140, 140, 312, 312, 312, 292, 292, 292, 292, 292, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 260, 260, 260, 260, 260, 391, 391, 316, 316, 140, 140, 73, 73, 140, 140, 320, 208, 79, 380, 380, 496, 496, 215, 215, 35, 354, 176, 176, 135, 135, 200, 248, 248, 212, 354, 420, 255, 255, 349, 349, 234, 234, 261, 25, 148, 148, 148, 148, 148, 148, 372, 372, 372, 59, 59, 452, 452, 452, 263, 263, 263, 225, 225, 225, 225, 225, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 225, 237, 225, 225, 225, 225, 225, 412, 412, 83, 55, 55, 322, 67, 199, 255, 255, 8, 8, 354, 180, 180, 113, 113, 113, 450, 167, 35, 35, 401, 198, 114, 57, 57, 203, 53, 394, 394, 76, 465, 259, 108, 377, 377, 344, 344, 374, 374, 132, 132, 349, 349, 234, 234, 261, 25, 480, 480, 480, 480, 480, 480, 85, 299, 299, 299, 339, 195, 195, 394, 212, 478, 66, 172, 172, 273, 231, 231, 231, 231, 76, 76, 198, 214, 214, 214, 214, 248, 76, 129, 259, 108, 377, 344, 344, 374, 374, 374, 132, 132, 132, 186, 186, 338, 338, 338, 338, 338, 338, 338, 395, 395, 470, 84, 84, 84, 84, 84, 16, 16, 274, 274, 274, 216, 216, 45, 45, 45, 45, 457, 457, 364, 276, 276, 153, 153, 372, 372, 372, 467, 467, 469, 469, 116, 64, 76, 36, 449, 449, 275, 275, 275, 275, 195, 195, 195, 117, 404, 404, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 72, 110, 254, 254, 254, 254, 314, 314, 90, 393, 205, 261, 25, 25, 494, 494, 349, 349, 205, 261, 25, 25, 278, 139, 139, 139, 497, 497, 122, 122, 131, 183, 257, 257, 257, 257, 257, 9, 9, 142, 196, 217, 473, 65, 278, 278, 99, 99, 436, 436, 60, 298, 298, 275, 303, 303, 48, 48, 48, 417, 417]
torch.Size([1, 448, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0024
generate
 86%|████████▌ | 55/64 [11:55<02:03, 13.76s/it]processing 55th semantic_sys file
55
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE WAS IN DEEP CONVERSE WITH THE CLERK AND ENTERED THE HALL HOLDING HIM BY THE ARM
2024-03-14 03:11:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:11:57 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
316
[17, 296, 451, 30, 30, 301, 378, 378, 345, 141, 141, 141, 141, 281, 453, 9, 168, 168, 340, 340, 340, 116, 33, 394, 394, 32, 32, 239, 384, 371, 371, 213, 213, 213, 213, 252, 215, 215, 35, 401, 401, 401, 82, 144, 27, 27, 27, 437, 370, 370, 370, 370, 370, 370, 348, 348, 64, 394, 90, 4, 4, 280, 280, 498, 498, 498, 498, 498, 498, 396, 396, 271, 186, 39, 54, 323, 142, 397, 397, 345, 333, 333, 220, 220, 35, 198, 22, 283, 455, 455, 129, 259, 144, 208, 208, 208, 386, 386, 386, 431, 498, 498, 498, 498, 396, 396, 178, 178, 233, 233, 233, 233, 82, 144, 419, 419, 439, 439, 78, 78, 170, 140, 140, 28, 140, 2, 2, 140, 2, 140, 2, 2, 2, 140, 163, 163, 163, 163, 163, 140, 140, 73, 73, 73, 140, 412, 83, 55, 55, 322, 322, 67, 335, 335, 14, 411, 145, 145, 432, 330, 330, 348, 64, 76, 36, 449, 300, 300, 382, 382, 313, 313, 314, 314, 314, 22, 22, 283, 455, 455, 58, 72, 72, 72, 72, 437, 437, 481, 481, 481, 481, 481, 481, 481, 182, 182, 182, 182, 182, 182, 182, 375, 375, 375, 375, 98, 98, 98, 98, 225, 225, 225, 225, 225, 225, 72, 72, 72, 72, 72, 72, 72, 424, 424, 424, 424, 424, 424, 424, 424, 497, 122, 122, 122, 34, 176, 176, 135, 135, 200, 248, 248, 183, 183, 183, 183, 57, 57, 57, 57, 57, 57, 57, 282, 282, 282, 203, 381, 381, 117, 117, 117, 48, 414, 414, 414, 414, 47, 47, 47, 47, 140, 80, 80, 80, 140, 7, 7, 354, 62, 62, 62, 62, 62, 62, 216, 216, 22, 283, 448, 448, 448, 464, 464, 180, 180, 284, 284, 306, 306, 306, 306, 306, 306, 306, 59, 59, 203, 203, 303, 381, 381, 381, 48, 48, 48]
torch.Size([1, 314, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_rbefore_semantic:
after is :
652
[17, 296, 127, 0, 0, 0, 0, 378, 378, 347, 347, 347, 347, 467, 467, 467, 255, 215, 215, 129, 259, 74, 74, 437, 437, 437, 125, 125, 125, 125, 125, 125, 125, 348, 348, 466, 466, 466, 22, 283, 455, 455, 4, 4, 4, 4, 280, 498, 498, 498, 498, 498, 498, 498, 498, 498, 396, 396, 396, 37, 37, 24, 24, 310, 107, 395, 69, 69, 69, 223, 130, 280, 44, 44, 44, 116, 94, 335, 14, 14, 411, 411, 411, 410, 410, 410, 410, 215, 215, 259, 29, 242, 242, 242, 116, 394, 76, 310, 161, 161, 161, 487, 487, 487, 288, 486, 486, 486, 460, 460, 460, 215, 215, 233, 233, 233, 419, 419, 439, 439, 78, 170, 170, 140, 28, 140, 28, 28, 140, 28, 28, 140, 362, 362, 140, 362, 362, 140, 140, 362, 362, 140, 362, 362, 140, 362, 362, 218, 218, 218, 140, 218, 218, 140, 366, 366, 366, 366, 366, 140, 366, 140, 366, 140, 366, 366, 366, 366, 140, 366, 366, 366, 366, 140, 316, 316, 316, 73, 289, 412, 412, 83, 340, 340, 340, 466, 466, 22, 283, 455, 38, 349, 205, 234, 234, 261, 261, 25, 106, 284, 306, 306, 306, 372, 372, 396, 396, 245, 143, 458, 144, 144, 208, 441, 441, 153, 153, 153, 387, 387, 387, 348, 199, 334, 334, 334, 59, 59, 452, 452, 263, 263, 225, 197, 197, 226, 82, 287, 287, 69, 69, 223, 223, 130, 130, 198, 198, 22, 283, 283, 455, 455, 72, 72, 72, 72, 72, 437, 437, 437, 405, 405, 405, 206, 206, 167, 385, 385, 233, 233, 233, 233, 233, 233, 75, 227, 419, 419, 439, 439, 439, 78, 78, 170, 28, 140, 28, 28, 140, 2, 140, 2, 341, 341, 341, 341, 341, 341, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 260, 260, 260, 260, 391, 149, 228, 412, 412, 83, 55, 55, 322, 67, 394, 478, 478, 232, 232, 232, 482, 238, 6, 6, 272, 371, 485, 374, 374, 374, 374, 252, 143, 36, 449, 449, 134, 134, 359, 359, 359, 81, 474, 474, 474, 474, 474, 246, 19, 19, 19, 19, 454, 454, 454, 454, 78, 78, 47, 47, 47, 47, 140, 80, 80, 373, 373, 110, 254, 254, 254, 254, 254, 254, 314, 129, 36, 161, 161, 161, 161, 487, 487, 288, 189, 189, 215, 215, 35, 35, 96, 96, 272, 34, 106, 410, 410, 410, 410, 410, 173, 29, 29, 313, 313, 216, 216, 22, 448, 448, 448, 448, 3, 14, 411, 411, 145, 443, 443, 443, 120, 120, 120, 120, 37, 37, 24, 24, 24, 310, 107, 107, 447, 447, 97, 483, 483, 440, 440, 440, 69, 69, 69, 223, 130, 402, 198, 198, 22, 283, 283, 455, 42, 42, 147, 456, 456, 456, 456, 456, 301, 173, 4, 280, 280before_semantic:
after is :
367
[17, 296, 127, 114, 361, 264, 468, 468, 468, 245, 245, 8, 354, 354, 255, 255, 38, 349, 205, 261, 25, 25, 189, 189, 139, 139, 293, 175, 175, 81, 44, 44, 44, 94, 199, 145, 145, 145, 365, 365, 360, 360, 200, 76, 96, 99, 436, 436, 395, 459, 459, 459, 271, 31, 54, 54, 224, 224, 121, 121, 116, 199, 300, 382, 382, 313, 173, 8, 280, 485, 485, 485, 485, 485, 374, 132, 132, 399, 217, 473, 473, 258, 258, 258, 31, 31, 54, 238, 238, 161, 161, 161, 459, 459, 459, 271, 31, 54, 54, 142, 142, 393, 393, 261, 25, 470, 278, 278, 240, 143, 36, 478, 478, 482, 172, 172, 224, 224, 273, 374, 374, 374, 132, 132, 358, 169, 164, 164, 164, 164, 164, 164, 164, 97, 97, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 287, 287, 287, 287, 306, 306, 306, 396, 396, 396, 313, 416, 416, 485, 485, 485, 374, 374, 88, 88, 176, 176, 135, 328, 200, 248, 248, 393, 393, 234, 234, 261, 25, 148, 148, 148, 148, 148, 148, 182, 182, 182, 372, 372, 372, 372, 59, 59, 59, 452, 452, 263, 263, 13, 78, 170, 170, 140, 28, 28, 140, 28, 28, 28, 140, 2, 2, 140, 140, 2, 140, 140, 2, 140, 140, 366, 140, 366, 140, 366, 140, 316, 316, 316, 73, 140, 412, 412, 83, 83, 55, 55, 55, 322, 94, 199, 255, 255, 255, 416, 416, 239, 445, 445, 485, 360, 360, 360, 360, 330, 379, 77, 77, 54, 54, 86, 238, 6, 198, 22, 283, 283, 455, 38, 162, 54, 105, 105, 336, 208, 441, 441, 153, 346, 346, 91, 265, 85, 85, 146, 146, 300, 382, 382, 304, 313, 49, 142, 221, 221, 259, 74, 190, 190, 488, 488, 488, 488, 405, 405, 206, 206, 206, 240, 24, 310, 107, 395, 469, 469, 469, 178, 178, 233, 96, 401, 82, 75, 227, 419, 483, 483, 226, 188, 188, 340, 340, 340, 94, 44, 44, 44, 44, 8, 8, 354, 190, 380, 380, 288, 288, 443, 120, 120, 169, 169, 169, 164, 352, 352, 352, 352, 352, 352, 112, 112]
torch.Size([1, 365, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0001
generate
 91%|█████████ | 58/64 [12:30<01:15, 12.54s/it]processing 58th semantic_sys file
58
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY WERE UPON THE VERGE OF AN OPEN TRAP IN THE FAR CORNER OF THE HUT AND STUTELEY HAD TRIPPED OVER THE EDGE OF THE REVERSED FLAP MOUTH OF THIS PIT
2024-03-14 03:12:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:12:32 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([26], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
495
[17, 17, 127, 0, 0, 0, 0, 378, 378, 347, 347, 347, 347, 467, 255, 255, 215, 129, 259, 74, 74, 437, 437, 125, 125, 125, 125, 125, 125, 125, 348, 348, 466, 466, 466, 283, 283, 455, 4, 4, 4, 280, 280, 498, 498, 498, 498, 498, 498, 498, 498, 396, 396, 396, 37, 24, 24, 310, 107, 395, 69, 69, 223, 130, 280, 44, 44, 44, 116, 199, 335, 14, 411, 411, 410, 410, 410, 410, 215, 215, 259, 354, 242, 242, 242, 116, 33, 33, 394, 394, 465, 161, 161, 161, 161, 487, 487, 487, 487, 288, 288, 486, 486, 376, 376, 376, 460, 460, 460, 215, 215, 233, 233, 233, 419, 419, 439, 439, 439, 78, 78, 170, 140, 140, 28, 28, 140, 140, 28, 28, 140, 362, 362, 140, 362, 140, 341, 341, 341, 341, 369, 140, 369, 369, 369, 369, 163, 163, 163, 163, 163, 163, 316, 316, 140, 73, 289, 412, 412, 188, 340, 340, 340, 466, 466, 22, 283, 455, 38, 349, 234, 234, 234, 234, 261, 25, 106, 106, 284, 306, 306, 306, 372, 372, 396, 396, 245, 245, 129, 458, 144, 208, 208, 441, 441, 441, 153, 153, 153, 153, 387, 387, 387, 94, 94, 300, 382, 382, 382, 406, 467, 69, 69, 223, 130, 130, 198, 198, 22, 283, 455, 455, 72, 72, 72, 72, 72, 437, 437, 405, 151, 151, 206, 167, 385, 385, 233, 233, 233, 233, 233, 75, 227, 227, 419, 419, 419, 439, 439, 439, 78, 78, 170, 28, 28, 140, 28, 140, 2, 2, 2, 140, 341, 341, 341, 369, 369, 369, 369, 369, 369, 369, 369, 369, 408, 408, 408, 149, 149, 412, 83, 55, 55, 322, 67, 33, 394, 478, 478, 162, 232, 232, 232, 482, 238, 6, 336, 272, 371, 485, 374, 374, 374, 132, 252, 325, 26, 26, 359, 359, 359, 474, 474, 474, 474, 324, 19, 19, 3, 3, 183, 183, 254, 254, 254, 254, 314, 314, 129, 36, 161, 161, 161, 161, 190, 487, 487, 288, 189, 278, 215, 215, 35, 35, 96, 401, 401, 401, 75, 272, 34, 410, 410, 410, 410, 410, 410, 280, 29, 29, 382, 313, 216, 216, 22, 448, 448, 448, 448, 3, 14, 411, 145, 145, 443, 443, 443, 240, 24, 24, 310, 107, 395, 69, 69, 130, 216, 22, 283, 455, 455, 42, 42, 147, 456, 456, 456, 456, 4, 4, 4, 280, 280, 498, 498, 498, 498, 498, 396, 396, 186, 39, 54, 54, 86, 238, 6, 272, 393, 393, 234, 261, 425, 425, 386, 431, 431, 486, 376, 376, 460, 460, 215, 215, 35, 401, 401, 401, 196, 217, 70, 473, 65, 315, 315, 315, 315, 450, 450, 450, 169, 169, 169, 352, 164, 164, 164, 69, 69, 69, 130, 130, 198, 198, 114, 258, 258, 258, 31, 54, 54, 142, 221, 221, 336, 336, 74, 74, 351, 351, 278, 278, 120, 120, 385, 385, 385, 233, 233, 233, 75, 227, 419, 419, 439]
torch.Size([1, 493, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0025
generate
 92%|█████████▏| 59/64 [12:53<01:18, 15.71s/it]processing 59th semantic_sys file
59
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE WILL GO OUT TOGETHER TO THE BOWER THERE IS A WAY DOWN TO THE COURT FROM MY WINDOW
2024-03-14 03:12:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:12:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
266
[17, 17, 345, 152, 152, 152, 301, 378, 378, 345, 389, 389, 389, 497, 497, 416, 32, 32, 144, 27, 180, 84, 84, 496, 88, 88, 88, 106, 113, 113, 113, 113, 113, 167, 167, 35, 35, 401, 75, 377, 377, 123, 123, 416, 416, 239, 445, 445, 180, 180, 443, 493, 493, 493, 216, 216, 300, 300, 334, 334, 59, 59, 59, 452, 452, 263, 229, 229, 82, 312, 312, 187, 187, 187, 23, 23, 260, 391, 391, 391, 140, 73, 73, 140, 140, 75, 108, 377, 377, 374, 374, 374, 374, 374, 132, 132, 132, 132, 216, 216, 22, 22, 283, 455, 455, 8, 32, 239, 354, 180, 180, 486, 486, 486, 315, 315, 450, 450, 450, 450, 182, 182, 372, 372, 334, 59, 59, 452, 452, 263, 229, 229, 82, 312, 187, 187, 187, 391, 391, 391, 140, 140, 289, 320, 7, 127, 127, 0, 0, 222, 468, 468, 406, 467, 356, 356, 356, 281, 281, 453, 168, 168, 44, 44, 43, 43, 364, 276, 109, 109, 403, 403, 403, 171, 171, 252, 252, 314, 239, 384, 371, 180, 180, 315, 315, 315, 315, 450, 450, 450, 450, 413, 413, 195, 195, 394, 76, 465, 108, 377, 377, 123, 123, 123, 216, 22, 283, 455, 455, 129, 82, 144, 208, 441, 441, 441, 153, 153, 153, 372, 372, 372, 396, 396, 385, 233, 131, 472, 393, 155, 165, 165, 165, 165, 399, 53, 70, 46, 46, 46, 46, 438, 378, 43, 364, 276, 109, 109, 278, 330, 116, 64, 64, 64, 212, 384, 180, 84, 84, 84, 84, 375, 98, 98, 98, 13]
torch.Size([1, 264, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0016
generate
 94%|█████████▍| 60/64 [13:04<00:56, 14.18s/it]processing 60th semantic_sys file
60
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: CRIED HE WAVING THE LANTHORN BEFORE HIM TO MAKE SURE THAT THESE WERE NO GHOSTS IN FRONT OF HIM
2024-03-14 03:13:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:13:06 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
392
[17, 17, 296, 208, 208, 190, 190, 487, 499, 499, 499, 265, 265, 85, 85, 146, 146, 146, 252, 24, 131, 131, 183, 183, 451, 451, 30, 30, 30, 30, 301, 301, 43, 364, 364, 276, 276, 109, 109, 109, 171, 171, 171, 171, 252, 252, 173, 173, 280, 176, 176, 176, 176, 328, 328, 200, 200, 200, 248, 248, 212, 198, 22, 283, 283, 283, 455, 251, 251, 251, 241, 241, 431, 431, 365, 365, 365, 365, 365, 282, 388, 348, 64, 76, 76, 164, 164, 164, 106, 106, 153, 153, 387, 387, 372, 372, 396, 396, 388, 388, 195, 195, 394, 394, 212, 354, 354, 255, 255, 255, 349, 349, 205, 205, 261, 25, 148, 148, 148, 148, 148, 372, 396, 313, 313, 58, 183, 183, 183, 57, 57, 57, 57, 57, 57, 57, 282, 203, 203, 381, 381, 381, 381, 117, 404, 404, 13, 78, 170, 170, 20, 28, 20, 20, 28, 20, 20, 2, 20, 20, 20, 163, 20, 20, 163, 20, 316, 316, 20, 73, 20, 20, 289, 20, 108, 108, 119, 119, 351, 374, 374, 374, 374, 374, 374, 374, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 98, 98, 98, 98, 98, 197, 197, 197, 197, 197, 7, 7, 7, 217, 217, 473, 473, 476, 476, 476, 476, 476, 143, 143, 458, 458, 96, 96, 338, 338, 338, 338, 395, 395, 395, 487, 498, 498, 498, 498, 498, 498, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 452, 313, 313, 216, 216, 127, 45, 45, 45, 45, 45, 45, 35, 35, 401, 401, 20, 127, 114, 124, 124, 124, 124, 124, 124, 318, 318, 318, 318, 318, 49, 9, 142, 397, 397, 347, 347, 347, 347, 347, 313, 10, 10, 10, 309, 479, 331, 231, 231, 231, 231, 231, 274, 416, 32, 32, 32, 239, 144, 180, 180, 496, 496, 496, 496, 496, 496, 274, 358, 186, 39, 39, 39, 86, 86, 238, 238, 6, 270, 270, 270, 270, 270, 270, 390, 390, 390, 18, 18, 97, 97, 483, 226, 20, 209, 188, 340, 340, 340, 340, 33, 33, 90, 90, 349, 234, 234, 261, 25, 487, 499, 499, 319, 319, 319, 348, 64, 76, 36, 449, 69, 223, 223, 130, 402, 402, 183, 57, 57, 57, 57, 57, 57, 57, 57, 203, 381, 381, 381, 381, 381, 48, 48]
torch.Size([1, 390, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0031
generate
 95%|█████████▌| 61/64 [13:18<00:42, 14.24s/it]processing 61th semantic_sys file
61
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WILL CRIED HE SOFTLY AND STUTELEY WHO HAD CHOSEN HIS COUCH ACROSS THE DOOR OF HIS YOUNG MASTER'S CHAMBER SPRANG UP AT ONCE IN ANSWER
2024-03-14 03:13:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:13:20 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([46], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
537
[17, 17, 296, 345, 345, 389, 389, 389, 143, 129, 458, 144, 208, 208, 190, 190, 487, 499, 499, 499, 265, 265, 265, 85, 85, 85, 146, 146, 24, 131, 183, 451, 451, 30, 30, 422, 162, 162, 68, 68, 115, 115, 273, 106, 405, 405, 405, 169, 169, 352, 352, 352, 352, 26, 26, 26, 359, 359, 474, 474, 474, 474, 474, 19, 19, 19, 454, 454, 454, 225, 225, 225, 225, 225, 225, 225, 225, 412, 83, 83, 89, 446, 322, 67, 394, 478, 478, 66, 68, 68, 238, 6, 6, 272, 485, 485, 374, 374, 374, 252, 143, 36, 36, 449, 449, 494, 494, 134, 359, 359, 359, 474, 474, 474, 474, 474, 19, 19, 19, 19, 454, 454, 454, 78, 20, 170, 170, 20, 20, 312, 312, 312, 292, 292, 292, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 260, 260, 260, 260, 260, 391, 391, 20, 228, 20, 373, 373, 489, 489, 489, 88, 254, 254, 254, 254, 314, 36, 310, 310, 107, 107, 395, 395, 351, 84, 84, 496, 496, 496, 496, 496, 274, 368, 368, 453, 342, 224, 168, 242, 242, 116, 94, 199, 257, 257, 257, 257, 31, 342, 342, 221, 221, 336, 144, 445, 351, 351, 351, 486, 315, 315, 315, 315, 450, 450, 450, 450, 413, 413, 233, 233, 233, 310, 310, 107, 107, 107, 18, 18, 112, 439, 439, 78, 56, 20, 170, 20, 20, 20, 312, 312, 312, 12, 12, 12, 12, 12, 12, 12, 12, 12, 260, 260, 260, 260, 260, 260, 391, 391, 20, 20, 20, 412, 412, 287, 255, 255, 143, 458, 144, 208, 208, 190, 487, 499, 499, 499, 405, 405, 169, 150, 150, 86, 86, 238, 6, 198, 22, 283, 283, 455, 236, 239, 239, 384, 371, 106, 153, 153, 153, 153, 153, 153, 387, 387, 406, 406, 467, 69, 223, 130, 130, 402, 402, 183, 257, 257, 257, 257, 257, 453, 9, 9, 219, 219, 219, 464, 180, 180, 319, 319, 319, 319, 348, 200, 248, 248, 248, 217, 217, 70, 65, 65, 284, 284, 284, 284, 460, 460, 169, 169, 150, 150, 39, 86, 238, 6, 6, 272, 272, 300, 334, 334, 334, 304, 304, 304, 185, 185, 269, 269, 323, 323, 18, 18, 18, 112, 112, 427, 56, 56, 20, 312, 312, 187, 187, 187, 187, 12, 12, 12, 260, 260, 260, 260, 391, 391, 20, 20, 289, 289, 20, 75, 310, 107, 107, 395, 395, 351, 290, 290, 290, 290, 290, 434, 434, 434, 339, 339, 64, 212, 212, 354, 29, 334, 334, 334, 355, 355, 355, 452, 263, 263, 263, 225, 225, 225, 225, 225, 225, 225, 373, 66, 66, 482, 482, 105, 105, 336, 336, 354, 189, 189, 189, 189, 189, 189, 189, 189, 189, 328, 200, 200, 200, 199, 180, 230, 230, 230, 230, 230, 215, 35, 35, 354, 415, 415, 415, 415, 415, 36, 131, 472, 397, 397, 364, 276, 174, 174, 174, 174, 319, 319, 379, 379, 379, 243, 77, 77, 342, 342, 224, 224, 340, 340, 340, 116, 94, 199, 145, 145, 365, 365, 365, 365, 330, 379, 379, 243, 243, 77, 77, 77, 433, 390, 390, 390, 390, 390, 160, 160, 18, 18, 112, 112, 112, 439]
torch.Size([1, 535, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0015
generate
 97%|█████████▋| 62/64 [13:36<00:30, 15.39s/it]processing 62th semantic_sys file
62
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOUNG FITZOOTH HAD BEEN COMMANDED TO HIS MOTHER'S CHAMBER SO SOON AS HE HAD COME OUT FROM HIS CONVERSE WITH THE SQUIRE
2024-03-14 03:13:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:13:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
353
[17, 17, 296, 219, 219, 180, 180, 319, 319, 319, 348, 200, 248, 248, 90, 349, 205, 205, 261, 261, 25, 278, 278, 385, 457, 457, 478, 66, 232, 172, 172, 115, 115, 273, 374, 374, 374, 374, 374, 132, 132, 358, 358, 164, 164, 164, 97, 110, 254, 254, 254, 254, 314, 314, 32, 354, 137, 137, 137, 137, 33, 90, 90, 76, 259, 144, 27, 27, 121, 399, 399, 217, 217, 473, 65, 365, 365, 365, 365, 330, 388, 64, 212, 34, 191, 191, 191, 314, 314, 314, 401, 401, 401, 140, 75, 108, 377, 377, 377, 123, 123, 123, 374, 374, 374, 132, 132, 132, 132, 132, 132, 98, 98, 13, 229, 82, 247, 312, 126, 126, 292, 292, 292, 23, 23, 408, 408, 408, 391, 228, 140, 140, 140, 373, 257, 257, 257, 257, 453, 9, 221, 196, 217, 70, 65, 493, 493, 493, 493, 216, 216, 300, 300, 382, 313, 313, 186, 99, 447, 238, 6, 310, 107, 107, 395, 351, 290, 290, 290, 290, 290, 434, 339, 53, 53, 212, 29, 334, 382, 382, 59, 59, 452, 263, 263, 229, 414, 247, 312, 187, 187, 23, 23, 23, 408, 391, 391, 140, 140, 373, 66, 66, 482, 172, 115, 344, 344, 344, 344, 344, 274, 274, 186, 162, 162, 232, 482, 172, 172, 115, 273, 374, 374, 374, 374, 132, 132, 413, 339, 94, 199, 199, 253, 253, 253, 253, 453, 9, 9, 451, 30, 30, 30, 464, 254, 254, 254, 314, 90, 129, 259, 144, 27, 351, 319, 319, 203, 53, 53, 65, 113, 113, 113, 113, 450, 167, 457, 393, 393, 155, 155, 165, 165, 165, 165, 53, 53, 257, 257, 257, 31, 9, 142, 221, 336, 144, 27, 437, 437, 370, 370, 370, 370, 370, 370, 348, 64, 394, 212, 280, 280, 498, 498, 498, 498, 59, 59, 271, 186, 39, 54, 323, 142, 397, 397, 333, 333, 333, 220, 129, 259, 22, 22, 283, 38, 162, 162, 482, 105, 105, 336, 208, 441, 153, 153, 346, 346, 91, 91, 85, 85, 85, 264, 264, 334, 334, 334, 59, 452, 452, 452, 263, 13]
torch.Size([1, 351, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0000
generate
 98%|█████████▊| 63/64 [13:45<00:13, 13.36s/it]processing 63th semantic_sys file
63
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE WAS NO CHANCE TO ALTER HIS SLEEPING ROOM TO ONE NEARER TO GAMEWELL'S CHAMBER
2024-03-14 03:13:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-14 03:13:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
361
[17, 17, 127, 0, 0, 222, 378, 378, 141, 141, 141, 281, 281, 9, 9, 196, 196, 309, 479, 331, 231, 231, 231, 231, 231, 231, 231, 16, 16, 16, 274, 274, 274, 274, 122, 236, 36, 36, 310, 107, 107, 107, 395, 351, 351, 365, 365, 365, 365, 365, 365, 282, 282, 282, 379, 379, 243, 77, 77, 433, 433, 86, 238, 6, 6, 272, 108, 377, 377, 374, 374, 374, 374, 132, 88, 14, 14, 14, 411, 411, 481, 481, 481, 481, 293, 293, 122, 122, 35, 35, 259, 108, 449, 300, 300, 334, 334, 334, 59, 59, 59, 59, 452, 452, 263, 225, 225, 225, 225, 225, 183, 183, 257, 257, 257, 257, 31, 162, 162, 68, 68, 68, 26, 26, 26, 386, 81, 444, 213, 213, 252, 215, 215, 35, 259, 176, 176, 176, 135, 328, 200, 200, 248, 248, 248, 147, 380, 380, 288, 288, 288, 288, 374, 374, 132, 132, 203, 203, 381, 381, 381, 381, 117, 48, 48, 13, 229, 229, 20, 20, 312, 187, 187, 187, 187, 391, 20, 20, 73, 73, 289, 20, 20, 108, 108, 377, 377, 123, 374, 374, 374, 374, 132, 132, 43, 43, 364, 276, 174, 174, 174, 174, 174, 174, 174, 282, 282, 388, 388, 195, 195, 195, 117, 404, 404, 225, 225, 225, 225, 225, 80, 80, 20, 20, 7, 309, 398, 398, 398, 398, 398, 398, 468, 468, 468, 468, 382, 382, 382, 382, 382, 59, 59, 59, 59, 59, 452, 452, 263, 263, 225, 225, 225, 80, 80, 80, 20, 20, 108, 108, 377, 351, 374, 374, 374, 374, 374, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 98, 98, 98, 98, 13, 13, 225, 225, 225, 80, 80, 80, 20, 20, 144, 445, 445, 180, 290, 290, 290, 290, 434, 203, 203, 250, 250, 250, 276, 276, 346, 346, 346, 346, 139, 139, 139, 139, 293, 293, 293, 497, 185, 49, 269, 342, 86, 86, 86, 238, 221, 336, 336, 310, 310, 107, 395, 351, 351, 290, 290, 290, 290, 434, 434, 203, 53, 53, 212, 29, 29, 334, 334, 334, 59, 59, 59, 59, 452, 452, 452, 263, 263]
torch.Size([1, 359, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/group_ar/nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_15_steps_14_groupar_2024-03-14_10:59:38
sys_file:gen_61-70970-0013
generate
100%|██████████| 64/64 [13:51<00:00, 11.22s/it]100%|██████████| 64/64 [13:51<00:00, 12.99s/it]
