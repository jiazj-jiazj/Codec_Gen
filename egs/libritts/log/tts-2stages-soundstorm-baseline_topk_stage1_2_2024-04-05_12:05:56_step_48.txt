Current working directory: /home/v-zhijunjia/CodecGen
Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (numpy 1.24.0 (/home/v-zhijunjia/.local/lib/python3.10/site-packages), Requirement.parse('numpy!=1.19.3,<1.24; sys_platform == "linux"'), {'azureml-dataset-runtime'}).
2024-04-05 04:05:59 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
/home/v-zhijunjia/miniconda3/envs/valle-4-23/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MiniBatchKMeans from version 0.24.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
only_antoregressive is True
add_prenet is False
self.ar_text_prenet : Identity()
add_prenet：False
self.encoder_layers:6
self.decoder_layers：6
only_antoregressive is True
add_prenet is False
self.ar_text_prenet : None
add_prenet：False
[]
  0%|          | 0/1232 [00:00<?, ?it/s]processing 0th semantic_sys file
0
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE IS UNDER SAIL BUT SHE IS COUNT TIMASCHEFF'S YACHT HE WAS RIGHT
2024-04-05 04:06:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-04-05 04:06:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
/home/v-zhijunjia/data/tts_test_librispeech/nar_test/filtered_4s_10s-test-spk-wer_sem/sem_gen_5105-28240-0003.json
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
top_k_know_token:70
known_token_update:False
  0%|          | 0/1232 [00:01<?, ?it/s]
