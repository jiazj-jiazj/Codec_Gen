Current working directory: /home/v-zhijunjia/CodecGen
Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (numpy 1.24.0 (/home/v-zhijunjia/.local/lib/python3.10/site-packages), Requirement.parse('numpy!=1.19.3,<1.24; sys_platform == "linux"'), {'azureml-dataset-runtime'}).
2024-03-11 08:54:28 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
/home/v-zhijunjia/miniconda3/envs/valle-4-23/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MiniBatchKMeans from version 0.24.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
only_antoregressive is True
add_prenet is False
self.ar_text_prenet : Identity()
add_prenet：False
self.encoder_layers:6
self.decoder_layers：6
only_antoregressive is True
add_prenet is False
self.ar_text_prenet : None
add_prenet：False
[]
  0%|          | 0/64 [00:00<?, ?it/s]processing 0th semantic_sys file
0
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT WAS THAT ALL HER REWARD ONE OF THE LADIES ASKED
2024-03-11 08:54:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:54:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
188
[17, 296, 159, 159, 159, 457, 43, 364, 345, 141, 141, 141, 281, 453, 9, 9, 198, 127, 114, 114, 92, 92, 92, 92, 240, 285, 285, 335, 14, 14, 411, 297, 297, 297, 297, 297, 297, 293, 293, 293, 58, 58, 72, 72, 156, 156, 156, 156, 245, 245, 42, 42, 147, 456, 456, 456, 456, 301, 43, 364, 364, 276, 276, 153, 153, 153, 153, 153, 153, 387, 372, 372, 372, 59, 59, 59, 37, 37, 24, 24, 404, 404, 439, 78, 78, 170, 170, 140, 140, 140, 187, 187, 187, 187, 187, 187, 260, 260, 260, 391, 391, 140, 73, 73, 140, 321, 320, 7, 276, 174, 174, 174, 174, 94, 199, 223, 223, 223, 130, 198, 22, 283, 455, 455, 251, 251, 251, 241, 431, 431, 403, 171, 171, 171, 252, 252, 325, 34, 41, 41, 41, 318, 318, 318, 185, 49, 269, 342, 9, 97, 97, 483, 483, 226, 226, 226, 226, 321, 209, 145, 145, 145, 145, 376, 376, 376, 376, 376, 376, 460, 460, 169, 169, 150, 39, 86, 86, 105, 105, 336, 96, 96, 96, 321, 75, 227, 419, 419]
torch.Size([1, 186, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_30_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_121-127105-0036
generate
  2%|▏         | 1/64 [00:03<04:08,  3.94s/it]processing 1th semantic_sys file
1
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE WAS A UNANIMOUS GROAN AT THIS AND MUCH REPROACH AFTER WHICH IN HIS PREOCCUPIED WAY HE EXPLAINED
2024-03-11 08:54:48 before_semantbefore_semantic:
after is :
382
[17, 17, 296, 127, 114, 0, 222, 378, 378, 345, 141, 141, 281, 453, 168, 168, 44, 44, 219, 219, 485, 485, 374, 236, 10, 479, 331, 331, 486, 486, 486, 460, 330, 94, 199, 469, 469, 203, 53, 459, 459, 459, 271, 271, 39, 39, 390, 390, 390, 390, 390, 18, 18, 97, 97, 225, 225, 225, 225, 225, 225, 225, 225, 225, 80, 80, 80, 80, 20, 20, 144, 208, 79, 79, 380, 380, 499, 84, 496, 496, 496, 413, 413, 413, 413, 195, 195, 195, 117, 117, 404, 404, 225, 225, 225, 225, 225, 225, 412, 83, 415, 415, 415, 415, 35, 401, 20, 127, 114, 114, 258, 258, 258, 258, 271, 271, 39, 39, 390, 390, 390, 390, 18, 18, 112, 112, 427, 56, 20, 20, 312, 312, 312, 292, 292, 292, 292, 292, 292, 292, 292, 21, 21, 21, 21, 23, 23, 23, 260, 260, 260, 391, 391, 391, 20, 20, 20, 20, 83, 83, 55, 55, 322, 67, 250, 217, 70, 383, 383, 383, 383, 383, 310, 107, 447, 447, 397, 397, 147, 147, 380, 278, 278, 215, 129, 259, 74, 190, 495, 495, 380, 380, 288, 256, 496, 496, 274, 274, 385, 233, 233, 310, 107, 107, 107, 447, 97, 97, 225, 225, 225, 225, 412, 412, 83, 145, 145, 460, 460, 460, 169, 402, 96, 272, 300, 382, 382, 245, 43, 43, 345, 407, 407, 407, 407, 407, 143, 36, 310, 310, 107, 107, 447, 97, 97, 225, 225, 225, 225, 225, 225, 188, 188, 188, 340, 340, 340, 94, 199, 257, 257, 257, 257, 281, 9, 142, 221, 336, 336, 74, 190, 488, 488, 488, 324, 464, 464, 180, 284, 405, 206, 206, 178, 458, 192, 192, 485, 469, 469, 129, 20, 74, 74, 437, 265, 265, 265, 265, 85, 85, 146, 37, 24, 131, 133, 133, 364, 276, 276, 109, 109, 403, 403, 403, 403, 403, 207, 207, 207, 207, 19, 19, 19, 454, 454, 454, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 373, 451, 451, 451, 30, 30, 30, 30, 464, 154, 154, 154, 96, 96, 96, 54, 482, 105, 105, 336, 336, 425, 386, 386, 386, 431, 290, 290, 290, 290, 290, 434, 434, 434, 339, 303, 243, 243, 131, 227, 419, 439, 439, 439, 439]
torch.Size([1, 380, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_121-127105-000before_semantic:
after is :
418
[17, 17, 296, 127, 448, 448, 448, 14, 14, 411, 284, 284, 405, 405, 206, 178, 35, 458, 208, 441, 441, 109, 382, 313, 314, 314, 401, 401, 164, 164, 214, 214, 214, 214, 214, 214, 214, 328, 328, 200, 200, 195, 195, 195, 117, 117, 117, 117, 48, 48, 417, 417, 417, 417, 417, 417, 237, 47, 47, 47, 47, 47, 20, 47, 47, 47, 47, 20, 316, 20, 73, 73, 20, 320, 7, 7, 345, 141, 141, 141, 281, 281, 9, 9, 9, 198, 45, 45, 45, 45, 45, 35, 401, 401, 127, 127, 114, 0, 0, 0, 0, 0, 3, 3, 58, 110, 254, 254, 254, 254, 254, 314, 314, 401, 40before_semantic:
after is :
306
[17, 17, 127, 448, 448, 448, 14, 14, 411, 284, 284, 405, 405, 206, 206, 178, 35, 35, 35, 441, 441, 109, 109, 313, 314, 314, 129, 401, 259, 164, 164, 214, 214, 214, 214, 214, 328, 328, 200, 200, 250, 250, 250, 345, 141, 141, 141, 141, 281, 453, 9, 9, 198, 198, 45, 45, 45, 45, 45, 457, 35, 259, 127, 114, 0, 0, 0, 0, 3, 58, 58, 110, 254, 254, 254, 254, 314, 129, 129, 82, 74, 190, 488, 488, 488, 488, 488, 460, 178, 178, 35, 35, 36, 449, 469, 469, 469, 143, 458, 208, 359, 166, 166, 166, 166, 324, 301, 10, 10, 309, 479, 231, 231, 231, 231, 231, 88, 88, 493, 493, 493, 493, 493, 216, 300, 300, 382, 245, 42, 42, 147, 456, 456, 456, 251, 251, 241, 431, 431, 403, 171, 171, 418, 252, 99, 99, 436, 436, 60, 298, 298, 298, 379, 471, 471, 471, 49, 269, 390, 390, 112, 427, 56, 56, 247, 312, 126, 292, 292, 292, 23, 23, 408, 408, 391, 391, 140, 140, 140, 412, 83, 83, 55, 55, 322, 67, 466, 466, 45, 45, 45, 45, 45, 325, 183, 183, 257, 257, 257, 257, 257, 453, 9, 9, 483, 14, 411, 411, 350, 350, 350, 350, 350, 413, 94, 199, 255, 255, 349, 349, 205, 205, 261, 25, 470, 264, 264, 264, 468, 468, 468, 304, 304, 304, 185, 49, 54, 86, 238, 6, 108, 377, 295, 295, 295, 295, 143, 458, 192, 192, 180, 230, 230, 230, 215, 215, 35, 35, 483, 14, 14, 82, 411, 297, 297, 297, 297, 297, 297, 297, 297, 293, 293, 497, 58, 183, 183, 257, 257, 257, 257, 31, 31, 86, 86, 6, 272, 119, 119, 103, 103, 103, 103, 103, 103, 103, 85, 299, 2torch.Size([1, 416, 16])
output_dir is /home/v-zhijunjia/data/output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_121-127105-0028
generate
  5%|▍         | 3/64 [00:17<06:22,  6.27s/it]processing 3th semantic_sys file
3
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I COULD WRITE TO MY MAN AND ENCLOSE THE KEY HE COULD SEND DOWN THE PACKET AS HE FINDS IT
2024-03-11 08:55:02 |before_semantic:
after is :
321
[17, 17, 287, 287, 111, 111, 111, 438, 438, 143, 458, 144, 389, 389, 389, 389, 314, 314, 133, 147, 147, 380, 499, 428, 428, 428, 146, 146, 252, 457, 457, 401, 401, 401, 401, 4before_semantic:
after is :
318
[17, before_semantic:
after is :
366
[17, 17, 296, 287, 287, 111, 111, 111, 438, 438, 458, 192, 389, 389, 389, 314, 133, 42, 147, 147, 380, 499, 499, 428, 428, 428, 146, 146, 358, 358, 358, 233, 36, 227, 227, 472, 472, 472, 221, 336, 82, 75, 108, 377, 377, 123, 123, 123, 374, 374, 132, 399, 70, 70, 46, 46, 46, 46, 46, 438, 438, 399, 217, 217, 473, 473, 136, 136, 136, 136, 136, 136, 136, 136, 136, 282, 282, 282, 282, 282, 388, 388, 195, 195, 195, 195, 195, 117, 117, 117, 117, 117, 117, 117, 117, 117, 404, 404, 225, 225, 225, 197, 226, 140, 140, 209, 209, 83, 83, 194, 194, 194, 194, 194, 194, 194, 194, 282, 282, 282, 388, 195, 195, 64, 212, 131, 131, 404, 483, 197, 226, 226, 226, 226, 140, 140, 140, 188, 188, 121, 121, 121, 121, 33, 33, 394, 394, 76, 465, 208, 208, 208, 386, 386, 386, 386, 431, 496, 496, 496, 496, 496, 496, 496, 274, 274, 274, 274, 318, 368, 49, 9, 9, 198, 198, 22, 283, 455, 455, 143, 129, 259, 445, 445, 445, 351, 213, 213, 213, 213, 246, 246, 246, 246, 246, 3, 3, 183, 451, 30, 30, 30, 422, 458, 144, 389, 389, 389, 389, 314, 478, 478, 162, 232, 172, 172, 115, 273, 432, 432, 330, 330, 348, 64, 64, 212, 384, 371, 180, 180, 315, 315, 315, 315, 450, 450, 413, 413, 466, 466, 22, 283, 283, 455, 129, 129, 82, 74, 74, 351, 351, 486, 486, 460, 460, 178, 178, 458, 192, 192, 277, 277, 277, 277, 385, 385, 233, 233, 233, 82, 75, 227, 227, 419, 419, 419, 419, 419, 419, 439, 225, 225, 225, 225, 225, 225, 225, 412, 83, 83, 253, 253, 253, 253, 253, 253, 453, 54, 54, 183, 451, 30, 30, 30, 30, 422, 349, 205, 205, 261, 25, 25, 480, 480, 480, 480, 480, 85, 85, 299, 299, 299, 339, 339, 471, 471, 49, 269, 9, 168, 483, 483, 14, 411, 411, 287, 287, 284, 265, 428, 85, 146, 146, 252, 252, 143, 143, 36, 108, 108, 119, 119, 351, 213, 213, 213, 213, 246, 246, 246, 246, 19, 19, 19, 454, 454]
torch.Size([1, 364, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_121-127105-0005
generate
  6%|▋         | 4/64 [00:25<06:46, before_semantic:
after is :
325
[17, 17, 296, 287, 287, 284, 265, 265, 428, 428, 146, 146, 358, 358, 358, 233, 36, 227, 419, 419, 439, 78, 78, 170, 140, 140, 28, 140, 28, 28, 140, 140, 2, 140, 2, 140, before_semantic:
after is :
390
[17, 17, 296, 296, 287, 284, 284, 265, 428, 428, 428, 428, 146, 358, 358, 358, 358, 233, 36, 227, 227, 419, 419, 419, 439, 439, 78, 170, 140, 140, 140, 28, 140, 140, 28, 140, 140, 2, 2, 2, 2, 140, 140, 163, 163, 140, 163, 163, 140, 163, 316, 316, 316,before_semantic:
after is :
440
[17, 17, 296, 287, 287, 284, 284, 265, 428, 428, 146, 146, 146, 358, 143, 35, 36, 36, 227, 419, 419, 439, 78, 170, 170, 170, 140, 28, 140, 28, 140, 2, 140, 2, 2, 140, 2, 140, 2, 2, 2, 2, 140, 366, 366, 366, 366, 366, 366, 140, 316, 316, 140, 316, 316, 73, 140, 373, 373, 373, 451, 451, 30, 30, 30, 30, 422, 422, 186, 162, 162, 232, 232, 172, 115, 273, 273, 315, 315, 315, 450, 450, 413, 413, 64, 212, 34, 191, 191, 191, 236, 314, 32, 32, 239, 384, 371, 180, 180, 106, 284, 481, 481, 481, 293, 293, 293, 293, 497, 497, 497, 335, 335, 14, 14, 411, 287, 287, 284, 284, 265, 428, 428, 146, 146, 146, 358, 143, 36, 449, 449, 41, 41, 41, 324, 324, 324, 422, 422, 186, 162, 232, 232, 172, 115, 115, 273, 273, 315, 315, 315, 450, 450, 413, 64, 64, 212, 34, 191, 191, 191, 191, 314, 314, 478, 478, 482, 482, 482, 238, 6, 336, 161, 79, 487, 487, 288, 288, 290, 290, 290, 290, 290, 434, 434, 434, 434, 339, 339, 195, 471, 471, 310, 310, 107, 447, 427, 427, 247, 247, 312, 126, 292, 292, 292, 1, 23, 23, 408, 408, 408, 149, 228, 140, 412, 83, 83, 55, 55, 55, 322, 67, 212, 131, 335, 14, 14, 411, 411, 411, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297, 293, 293, 293, 497, 122, 216, 22, 283, 283, 455, 455, 399, 399, 70, 70, 138, 138, 138, 138, 138, 138, 138, 138, 372, 372, 372, 396, 396, 186, 186, 162, 482, 482, 172, 115, 273, 273, 84, 84, 84, 84, 16, 16, 16, 274, 274, 274, 8, 8, 354, 420, 420, 422, 143, 259, 144, 27, 351, 351, 151, 151, 151, 151, 240, 368, 453, 453, 168, 69, 223, 223, 130, 280, 257, 257, 257, 257, 257, 453, 9, 142, 221, 196, 217, 473, 473, 290, 290, 290, 290, 290, 434, 434, 434, 339, 339, 33, 90, 90, 465, 144, 27, 121, 121, 121, 33, 33, 394, 212, 239, 384, 278, 278, 278, 278, 99, 99, 436, 436, 60, 60, 298, 298, 298, 298, 116, 195, 195, 195, 117, 404, 404, 229, 247, 247, 126, 126, 292, 292, 292, 292, 292, 23, 1, 1, 23, 101, 101, 149, 149, 149, 228, 2before_semantic:
after is :
449
[17, 17, 296, 127, 0, 0, 0, 378, 378, 347, 347, 347, 347, 245, 129, 129, 259, 74, 74, 425, 386, 386, 431, 319, 319, 330, 94, 199, 41, 324, 324, 464, 464, 462, 462, 462, 402, 402, 401, 401, 259, 74, 74, 351, 213, 213, 213, 213, 252, 252, 215, 35, 354, 29, 100, 100, 100, 100, 375, 375, 98, 98, 98, 98, 13, 13, 414, 414, 47, 20, 47, 47, 20, 47, 47, 47, 20, 47, 47, 20, 20, 316, 316, 20, 73, 73, 73, 289, 75, 108, 377, 377, 344, 344, 374, 374, 132, 132, 58, 58, 58, 72, 110, 110, 268, 139, 1before_semantic:
after is :
366
[17, 17, 296, 114, 0, 0, 378, 345, 347, 347, 347, 347, 129, 129, 259, 74, 425, 425, 386, 386, 431, 432, 432, 330, 330, 94, 199, 41, 324, 464, 464, 462, 462, 462, 402, 402, 221, 259, 74, 74, 351, 213, 213, 213, 252, 215, 35, 259, 29, 100, 100, 100, 497, 497, 122, 122, 129, 401, 401, 82, 108, 108, 377, 344, 344, 374, 374, 374, 132, 132, 132, 58, 58, 72, 72, 110, 110, 443, 139, 139, 139, 139, 293, 293, 215, 215, 233, 259, 354, 419, 419, 439, 439, 439, 78, 47, 140, 47, 140, 1before_semantic:
after is :
345
[17, 296, 127, 0, 222, 378, 345, 347, 347, 347, 245, 129, 129, 74, 425, 386, 386, 319, 319, 319, 348, 199, 41, 324, 464, 462, 462, 462, 402, 221, 259, 259, 74, 351, 213, 213, 213, 252, 252, 215, 259, 354, 100, 100, 100, 497, 497, 497, 122, 122, 36, 108, 108, 377, 344, 344, 374, 374, 132, 132, 58, 58, 72, 72, 72, 110, 268, 139, 481, 481, 293, 293, 293, 293, 215, 233, 233, 233, 419, 419, 439, 439, 439, 78, 170, 170, 140, 140, 28, 140, 140, 2, 2, 2, 2, 2, 140, 2, 2, 2, 2, 140, 316, 140, 316, 140, 73, 73, 140, 320, 159, 159, 159, 285, 255, 255, 402, 402, 221, 458, 208, 441, 441, 441, 153, 153, 372, 372, 396, 396, 186, 39, 54, 86, 86, 221, 198, 22, 5, 5, 448, 448, 219, 219, 464, 180, 180, 319, 319, 319, 348, 200, 248, 248, 248, 251, 241, 431, 431, 171, 171, 171, 252, 325, 325, 41, 324, 324, 3, 58, 183, 489, 489, 489, 489, 422, 99, 338, 338, 395, 389, 389, 389, 314, 90, 239, 144, 180, 84, 496, 496, 274, 236, 236, 239, 384, 180, 180, 315, 315, 315, 315, 450, 450, 413, 413, 199, 253, 253, 253, 253, 453, 9, 142, 221, 144, 27, 180, 151, 151, 151, 173, 280, 29, 29, 396, 313, 116, 94, 459, 459, 459, 271, 271, 39, 39, 433, 390, 390, 18, 112, 427, 56, 56, 247, 312, 126, 292, 292, 292, 292, 292, 23, 23, 23, 23, 101, 408, 391, 391, 228, 140, 289, 320, 320, 345, 389, 389, 389, 389, 314, 32, 239, 354, 420, 420, 420, 420, 246, 246, 3, 3, 3, 188, 188, 340, 340, 33, 394, 478, 478, 232, 172, 224, 494, 494, 236, 129, 259, 74, 190, 190, 487, 288, 288, 360, 360, 434, 434, 203, 53, 53, 65, 255, 255, 255, 38, 349, 164, 164, 164, 25, 106, 106, 153, 153, 153, 372, 372, 372, 467, 469, 469, 469, 325, 41, 41, 41, 41, 19, 19, 19, 454, 454, 454]
torch.Size([1, 343, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54before_semantic:
after is :
360
[17, 17, 296, 5, 5, 455, 349, 349, 205, 205, 261, 25, 498, 498, 498, 498, 396, 186, 186, 54, 238, 6, 272, 494, 494, 223, 216, 216, 114, 124, 124, before_semantic:
after is :
454
[17, 17, 296, 5, 5, 38, 349, 205, 205, 261, 25, 25, 498, 498, 498, 498, 396, 186, 186, 39, 86, 86, 238, 6, 272, 272, 69, 223, 130, 130, 402, 198, 198, 127, 114, 124, 124, 124, 124, 124, 318, 318, 31, 342, 342, 86, 86, 238, 6, 108, 119, 351, 351, 151, 151, 151, 240, 178, 35, 36, 310, 107, 107, 395, 50, 50, 50, 50, 50, 50, 50, 50, 50, 185, 185, 269, 433, 433, 433, 160, 160, 97, 97,before_semantic:
after is :
363
[17, 296, 22, 5, 455, 38, 349, 205, 261, 25, 25, 498, 498, 498, 396, 186, 186, 54, 238, 6, 272, 494, 494, 223, 216, 216, 124, 124, 124, 124, 124, 31, 54, 238, 6, 272, 119, 351, 151, 151, 151, 240, 35, 310, 107, 395, 50, 50, 50, 49, 9, 142, 221, 144, 27, 27, 121, 121, 116, 33, 394, 4, 4, 280, 470, 470, 403, 403, 403, 171, 171, 207, 246, 246, 252, 24, 24, 131, 404, 229, 229, 82, 312, 126, 126, 292, 292, 292, 292, 23, 23, 23, 23, 23, 23, 260, 260, 260, 260, 260, 260, 391, 391, 391, 140, 73, 140, 320, 45, 45, 45, 45, 45, 35, 198, 127, 5, 5, 455, 42, 42, 147, 380, 288, 278, 278, 385, 242, 242, 242, 33, 33, 478, 162, 232, 232, 238, 6, 384, 470, 470, 171, 171, 171, 252, 252, 457, 196, 291, 291, 291, 291, 291, 379, 457, 457, 197, 401, 82, 108, 108, 295, 295, 295, 295, 295, 458, 144, 192, 230, 230, 215, 215, 35, 198, 22, 283, 283, 236, 236, 259, 108, 119, 119, 351, 351, 171, 171, 171, 171, 464, 139, 139, 302, 375, 375, 375, 98, 98, 13, 229, 82, 247, 312, 126, 126, 23, 23, 23, 408, 408, 391, 391, 140, 228, 412, 412, 83, 415, 415, 415, 415, 285, 44, 44, 236, 129, 259, 74, 74, 441, 441, 441, 153, 153, 153, 387, 428, 299, 299, 358, 358, 385, 457, 335, 226, 226, 82, 209, 145, 145, 460, 460, 460, 460, 402, 35, 272, 300, 382, 382, 245, 14, 14, 411, 145, 428, 428, 428, 146, 146, 252, 252, 457, 401, 259, 108, 119, 119, 351, 213, 213, 213, 246, 246, 246, 246, 246, 19, 19, 454, 229, 229, 247, 126, 126, 126, 23, 23, 408, 408, 391, 391, 228, 140, 140, 412, 373, 110, 110, 110, 254, 254, 254, 240, 240, 325, 34, 340, 340, 340, 94, 199, 44, 44, 44, 399, 473, 65, 136, 136, 365, 365, 330, 94, 300, 382, 382, 245, 8, 8, 420, 420, 420, 416, 416, 445, 180, 180, 180, 319, 319, 319, 319, 282, 388, 303, 303, 303, 303, 48, 48, 417]
torch.Size([1, 361, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_before_semantic:
after is :
294
[17, 17, 296, 219, 152, 152, 139, 139, 293, 293, 335, 14, 411, 411, 213, 213, 213, 213, 213, 368, 368, 342, 168, 494, 134, 359, 175, 81, 166, 166, 166, 324, 422, 239, 239, 310, 107, 395, 395, 180, 151, 151, 151, 151, 240, 240, 24, 310, 107, 447, 397, 397, 364, 276, 276, 346, 346, 346, 265, 265, 265, 85, 85, 146, 438, 378, 43, 364, 345, 409, 409, 409, 116, 33, 219, 152, 152, 152, 152, 132, 58, 58, 183, 183, 286, 286, 286, 286, 286, 468, 468, 59, 245, 8, 8, 354, 420, 420, 422, 143, 458, 144, 27, 351, 351, 151, 151, 240, 368, 368, 453, 198, 198, 22, 5, 5, 455, 38before_semantic:
after is :
466
[17, 17, 296, 219, 152, 152, 139, 139, 175, 175, 81, 81, 444, 213, 213, 213, 213, 213, 213, 318, 368, 368, 453, 9, 26, 26, 359, 359, 166, 166, 166, 324, 324, 422, 236, 239, 310, 310, 107, 395, 395, 180, 151, 284, 265, 265, 265, 206, 206, 206, 240, 24, 310, 107, 447, 397, 397, 364, 276, 346, 346, 346, 346, 265, 265, 265, 265, 265, 85, 85, 85, 85, 85, 207, 207, 207, 207, 207, 207, 207, 19, 454, 454, 454, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 7, 7, 7, 7, 364, 364, 364, 276, 276, 109, 109, 409, 409, 330, 330, 388, 33, 33, 33, 219, 219, 219, 219, 219, 152, 152, 152, 152, 374, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 98, 98, 98, 98, 13, 13, 13, 78, 170, 170, 140, 28, 140, 28, 28, 28, 28, 140, 28, 140, 362, 362, 140, 362, 362, 140, 140, 341, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 260, 260, 260, 260, 163, 391, 391, 391, 73, 140, 140, 373, 373, 183, 183, 451, 286, 286, 286, 286, 286, 286, 286, 286, 286, 468, 468, 468, 468, 59, 59, 59, 59, 59, 59, 245, 245, 8, 8, 354, 420, 420, 422, 143, 458, 144, 27, 27, 351, 151, 151, 151, 240, 368, 368, 453, 9, 198, 198, 198, 22, 5, 5, 5, 38, 38, 164, 164, 164, 164, 214, 214, 214, 214, 214, 214, 214, 328, 328, 200, 200, 248, 58, 58, 110, 110, 254, 254, 254, 254, 254, 314, 32, 32, 239, 137, 137, 137, 137, 137, 137, 33, 33, 478, 478, 162, 232, 232, 232, 232, 232, 172, 172, 172, 115, 344, 344, 344, 344, 344, 344, 35, 36, 310, 107, 107, 395, 44, 44, 44, 38, 162, 162, 232, 232, 482, 482, 105, 105, 336, 336, 445, 470, 470, 264, 264, 264, 264, 264, 264, 264, 264, 264, 264, 264, 468, 59, 59, 59, 59, 59, 452, 452, 452, 263, 263, 263, 263, 263, 225, 225, 225, 237, 237, 47, 47, 47, 140, 47, 80, 140, 373, 373, 373, 373, 451, 451, 451, 30, 30, 30, 30, 422, 143, 458, 458, 144, 27, 121, 121, 121, 33, 394, 76, 465, 108, 119, 119, 351, 351, 432, 432, 330, 330, 339, 219, 398, 398, 398, 374, 374, 132, 132, 37, 314, 314, 32, 401, 401, 82, 108, 108, 377, 377, 344, 344, 374, 374, 374, 132, 132, 349, 349, 349, 234, 234, 234, 261, 261, 25, 470, 278, 278, 278, 178, 178, 458, 458, 96, 270, 323, 323, 142, 142, 196, 217, 429, 429, 429, 42before_semantic:
after is :
369
[17, 17, 296, 296, 338, 400, 400, 400, 30, 301, 378, 345, 345, 141, 141, 141, 281, 281, 9, 198, 198, 22, 283, 455, 455, 399, 70, 65, 65, 496, 496, 496, 169, 186, 54, 238, 6, 272, 255, 255, 255, 416, 416, 79, 79, 79, 288, 288, 288, 288, 464, 134, 134, 134, 8, 8, 100, 100, 100, 497, 497, 497, 43, 364, 364, 276, 276, 174, 174, 174, 174, 399, 53, 53, 473, 275, 275, 116, 195, 195, 195, 117, 117, 404, 404, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 287, 287, 111, 111, 111, 111, 438, 202, 173, 280, 280, 463, 463, 463, 463, 463, 280, 29, 29, 382, 313, 313, 10, 10, 479, 331, 331, 84, 350, 350, 350, 413, 413, 348, 94, 199, 340, 340, 340, 116, 33, 58, 58, 156, 156, 156, 156, 156, 156, 245, 245, 129, 129, 82, 74, 492, 492, 492, 368, 453, 453, 9, 168, 470, 278, 278, 418, 271, 99, 9before_semantic:
after is :
283
[17, 17, 296, 373, 338, 400, 400, 400, 378, 378, 141, 141, 141, 281, 9, 198, 198, 22, 283, 455, 455, 399, 217, 70, 65, 65, 496, 496, 496, 274, 186, 54, 238, 6, 272, 255, 255, 416, 416, 208, 79, 79, 288, 288, 288, 288, 464, 134, 134, 134, 8, 100, 100, 100, 497, 497, 43, 364, 364, 276, 174, 174, 174, 399, 53, 473, 242, 275, 116, 195, 195, 117, 117, 117, 404, 225, 225, 226, 20, 20, 20, 20, 209, 287, 287, 111, 111, 111, 438, 202, 202, 402, 335, 14, 14, 411, 463, 463, 463, 463, 463, 280, 29, 29, 382, 313, 10, 10, 10, 309, 479, 331, 84, 84, 350, 350, 350, 413, 413, 94, 199, 340, 340, 340, 116, 199, 58, 156, 156, 156, 156, 156, 2before_semantic:
after is :
348
[17, 17, 296, 296, 287, 287, 111, 111, 111, 111, 438, 438, 143, 36, 108, 119, 119, 351, 213, 213, 213, 301, 378, 43, 345, 141, 141, 141, 281, 453, 168, 168, 494, 494, 457, 478, 478, 66, 68, 68, 68, 115, 273, 273, 278, 278, 203, 53, 53, 76, 76, 259, 74, 26, 359, 359, 359, 474, 474, 474, 474, 19, 19, 19, 454, 454, 229, 82, 82, 247, 312, 312, 187, 292, 292, 292, 292, 292, 292, 292, 292, 292, 23, 23, 23, 408, 408, 408, 391, 391, 228, 140, 140, 320, 127, 45, 45, 45, 45, 310, 338, 338, 400, 400, 400, 400, 30, 422, 422, 162, 68, 68, 68, 68, 68, 68, 115, 273, 470, 470, 120, 120, 120, 120, 120, 120, 120, 37, 37, 37, 24, 24, 131, 404, 404, 225, 225, 225, 225, 225, 373, 66, 66, 66, 68, 68,torch.Size([1, 281, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_121-127105-0011
generate
 14%|█▍        | 9/64 [01:06<07:09,  7.80s/it]processing 9th semantic_sys file
9
args.target_mode=before_semantic:
after is :
292
[17, 296, 287, 111, 111, 438, 438, 143, 36, 36, 108, 371, 485, 485, 374, 374, 378, 43, 345, 345, 141, 141, 281, 31, 162, 232, 68, 68, 115, 273, 273, 278, 203, 53, 53, 76, 76, 465, 74, 425, 359, 359, 474, 474, 474, 324, 301, 216, 216, 127, 114, 45, 45, 45, 457, 457, 99, 338, 338, 400, 400, 400, 30, 422, 422, 162, 162, 232, 172, 115, 273, 470, 120, 120, 240, 314, 314, 478, 478, before_semantic:
after is :
307
[17, 296, 287, 287, 111, 111, 438, 438, 143, 36, 36, 108, 119, 351, 213, 213, 213, 301, 378, 378, 345, 141, 141, 141, 281, 281, 453, 168, 242, 242, 379, 379, 478, 478, 232, 232, 232, 172, 115, 273, 273, 432, 432, 330, 203, 53, 76, 76, 259, 26, 359, 359, 474, 474, 474, 474, 474, 19, 19, 19, 454, 454, 229, 82, 247, 126, 126, 126, 292, 292, 292, 292, 292, 292, 23, 23, 23, 23, 408, 408, 408, 391, 228, 228, 140, 140, 320, 127, 45, 45, 45, 45, 45, 143, 310, 310, 107, 400, 400, 400, 30, 422, 186, 162, 232, 172, 115, 273, 470, 120, 120, 240, 240, 314, 478, 478, 232, 172, 115, 273, 273, 84, 84, 84, 16, 16, 16, 274, 98, 98, 98, 13, 13, 414, 414, 414, 170, 140, 140, 312, 312, 187, 187, 12, 12, 12, 12, 260, 260, 260, 391, 391, 228, 289, 140, 320, 159, 159, 159, 159, 314, 239, 127, 114, 45, 45, 45, 45, 285, 34, 111, 111, 111, 438, 438, 10, 10, 398, 398, 398, 398, 398, 374, 374, 132, 132, 132, 132, 98, 98, 98, 13, 414, 414, 414, 414, 47, 47, 140, 47, 140, 140, 47, 47, 140, 316, 316, 140, 373, 373, 373, 33before_semantic:
after is :
798
[17, 17, 296, 296, 287, 287, 284, 265, 265, 428, 85, 146, 146, 146, 252, 252, 143, 36, 108, 449, 119, 351, 444, 213, 213, 213, 246, 246, 246, 246, 246, 246, 246, 246, 19, 19, 454, 454, 454, 225, 225, 225, 80, 80, 80, 20, 20, 7, 7, 345, 141, 141, 141, 281, 281, 453, 9, 198, 198, 127, 114, 258, 258, 258, 258, 258, 31, 342, 342, 342, 168, 106, 106, 284, 284, 405, 405, 206, 206, 215, 215, 215, 96, 368, 453, 168, 494, 494, 469, 173, 173, 280, 280, 418, 418, 418, 418, 418, 418, 418, 418, 99, 99, 436, 436, 60, 60, 298, 298, 298, 298, 116, 195, 195, 195, 195, 117, 117, 117, 117, 117, 197, 197, 197, 20, 80, 20, 80, 80, 20, 20, 127, 114, 45, 45, 45, 45, 240, 314, 314, 239, 310, 161, 161, 79, 79, 487, 487, 374, 374, 374, 374, 374, 132, 132, 132, 132, 132, 132, 132, 132, 132, 98, 98, 98, 98, 197, 197, 197, 197, 197, 197, 80, 20, 80, 20, 80, 80, 20, 155, 165, 165, 165, 165, 165, 165, 165, 203, 53, 53, 394, 394, 32, 239, 239, 384, 371, 180, 180, 151, 151, 151, 151, 240, 416, 416, 416, 96, 359, 359, 359, 81, 81, 459, 459, 459, 459, 271, 271, 271, 39, 39, 433, 433, 160, 97, 97, 483, 226, 226, 226, 226, 20, 7, 309, 479, 479, 307, 307, 307, 307, 307, 307, 61, 61, 167, 167, 35, 35, 335, 440, 188, 188, 121, 121, 121, 399, 217, 217, 217, 217, 473, 65, 213, 213, 213, 213, 2before_semantic:
after is :
645
[17, 296, 296, 287, 111, 111, 438, 438, 143, 36, 36, 108, 119, 351, 444, 444, 213, 213, 246, 246, 246, 246, 301, 378, 43, 345, 345, 141, 141, 141, 281, 453, 9, 9, 198, 198, 127, 114, 258, 258, 258, 258, 31, 342, 342, 342, 224, 483, 483, 14, 411, 411, 287, 284, 284, 405, 405, 206, 215, 215, 215, 96, 368, 453, 453, 168, 494, 494, 494, 173, 173, 4, 280, 418, 418, 418, 418, 418, 418, 418, 418, 252, 99, 99, 99, 436, 436, 60, 60, 298, 298, 298, 298, 116, 195, 466, 466, 114, 45, 45, 45, 45, 385, 457, 32, 32, 239, 161, 161, 79, 487, 487, 189, 189, 374, 132, 132, 349, 349, 205, 155, 155, 165, 165, 165, 53, 394, 394, 32, 239, 384, 180, 180, 151, 151, 151, 240, 416, 416, 208, 359, 359, 81, 459, 271, 31, 31, 342, 342, 238, 221, 196, 479, 479, 331, 307, 307, 307, 307, 307, 61, 206, 206, 206, 240, 285, 34, 34, 255, 255, 255, 399, 217, 217, 473, 65, 213, 213, 213, 213, 213, 252, 325, 34, 485, 324, 485, 464, 464, 134, 457, 457, 457, 359, 359, 474, 474, 474, 474, 324, 246, 3, 301, 301, 8, 8, 159, 159, 159, 159, 159, 457, 457, 251, 251, 251, 241, 431, 431, 171, 171, 171, 171, 252, 252, 325, 34, 334, 334, 382, 59, 59, 467, 335, 440, 188, 188, 340, 340, 340, 116, 466, 466, 466, 22, 283, 448, 448, 448, 3, 14, 14, 411, 411, 411, 213, 213, 213, 213, 213, 213, 213, 213, 213, 213, 173, 173, 173, 402, 196, 196, 94, 199, 176, 176, 176, 328, 328, 328, 328, 328, 200, 200, 200, 117, 117, 404, 229, 82, 247, 126, 126, 126, 292, 292, 292, 292, 292, 292, 292, 23, 23, 23, 23, 23, 260, 260, 260, 260, 260, 260, 391, 391, 391, 140, 140, 140, 140, 412, 287, 287, 44, 44, 44, 42, 42, 147, 147, 147, 380, 288, 278, 278, 278, 215, 215, 129, 259, 74, 425, 425, 386, 386, 431, 265, 265, 265, 265, 265, 265, 85, 85, 85, 85, 207, 207, 207, 207, 3, 216, 216, 216, 114, 45, 45, 45, 45, 45, 58, 58, 72, 72, 72, 72, 72, 110, 110, 110, 110, 254, 254, 254, 254, 254, 254, 120, 120, 120, 120, 282, 282, 282, 282, 37, 37, 24, 24, 24, 131, 404, 404, 439, 225, 225, 225, 225, 225, 80, 140, 140, 140, 7, 127, 127, 5, 448, 448, 448, 448, 3, 14, 411, 411, 121, 121, 121, 121, 121, 64, 76, 36, 161, 161, 487, 487, 487, 469, 186, 31, 162, 86, 238, 6, 272, 272, 176, 176, 176, 176, 328, 200, 200, 248, 76, 465, 144, 27, 27, 437, 437, 370, 370, 370, 370, 370, 370, 370, 348, 77, 77, 342, 342, 224, 494, 494, 469, 469, 458, 458, 208, 208, 441, 441, 11, 11, 11, 11, 11, 11, 11, 379, 379, 243, 77, 77, 433, 433, 433, 160, 97, 97, 197, 197, 197, 197, 80, 80, 140, 108, 108, 108, 377, 377, 123, 123, 123, 374, 374, 374, 374, 132, 132, 132, 132, 132, 132, 132, 132, 43, 43, 364, 364, 364, 345, 407, 407, 407, 407, 407, 407, 407, 407, 385, 385, 233, 310, 310, 107, 107, 447, 447, 97, 483, 226, 226, 140, 226, 226, 226, 226, 226, 140, 209, 287, 111, 111, 111, 111, 111, 438, 438, 438, 143, 458, 458, 144, 27, 27, 437, 437, 481, 481, 481, 481, 481, 481, 481, 481, 182, 182, 182, 182, 375, 375, 375, 375, 98, 98, 483, 483, 226, 226, 226, 140, 140, 209, 287, 255, 255, 255, 236, 236, 129, 36, 108, 119, 119, 351, 432, 432, 432, 432, 432, 330, 330, 64, 76, 76, 310, 436, 436, 60, 60, 298, 298, 275, 275, 303, 303, 303, 303, 117, 48, 48, 48]
torch.Size([1, 643, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stagbefore_semantic:
after is :
209
[17, 17, 296, 296, 345, 109, 109, 443, 443, 443, 139, 175, 175, 81, 118, 118, 118, 118, 205, 261, 25, 111, 111, 111, 111, 438, 236, 239, 259, 384, 371, 180, 84, 350, 350, 350, 274, 413, 167, 457, 457, 196, 309, 479, 331, 84, 84, 84, 84, 16, 16, 274, 274, 274, 58, 183, 183, 183, 489, 489, 489, 374, 132, 132, 132, 186, 99, 338, 338, 400, 400, 400, 30, 378, 43, 345, 141, 141, 281, 453, 342, 9, 168, 340, 340, 116, 33, 33, 250, 251, 251, 241, 241, 431, 266, 266, 266, 266, 266, 266, 266, 293, 293, 173, 173, 402, 402, 402, 345, 333, 333, 333, 220,before_semantic:
after is :
245
[17, 17, 296, 296, 7, 7, 364, 364, 364, 276, 109, 109, 443, 443, 443, 139, 139, 139, 139, 375, 375, 375, 98, 98, 98, 13, 414, 414, 82, 82, 312, 312, 312, 187, 187, 187, 187, 187, 187, 187, 12, 163, 163, 140, 163, 163, 140, 163, 163, 163, 316, 140, 316, 140, 316, 140, 73, 140, 140, 209, 118, 118, 118, 118, 118, 118, 261, 25, 106, 111, 111, 111, 111, 438, 438, 236, 239, 239, 384, 371, 180, 84, 350, 350, 350, 413, 413, 348, 76, 465, 465, 196, 196, 196, 196, 309, 309, 479, 479, 331, 84, 84, 84, 84, 16, 16, 16, 16, 274, 98, 98, 58, 183, 183, 489, 489, 489, 489, 132, 132, 186, 99, 99, 338, 338, 400, 400, 400, 400, 30, 301, 301, 378, 43, 345, 141, 141, 141, 141, 281, 453, 342, 342, 168, 340, 340, 340, 116, 33, 33, 250, 251, 251, 241, 431, 266, 266, 266, 266, 266, 266, 173, 173, 402, 402, 402, 345, 333, 333, 333, 220, 220, 164, 164, 164, 106, 111, 111, 111, 111, 438, 438, 339, 10, 10, 479, 331, 84, 84, 84, 84, 274, 274, 274, 58, 183, 183, 183, 489, 489, 489, 132, 132, 132, 58, 183, 183, 451, 30, 30, 30, 301, 378, 43, 364, 364, 276, 276, 346, 141, 141, 141, 120, 120, 120, 120, 282, 37, 37, 185, 185, 185, 269, 433, 433, 433, 160, 160, 160, 112, 112, 56, 56, 5before_semantic:
after is :
289
[17, 17, 296, 5, 448, 448, 464, 464, 493, 493, 493, 493, 216, 300, 300, 300, 304, 304, 49, 269, 142, 142, 397, 456, 456, 456, 186, 186, 162, 232, 68, 115, 273, 273, 432, 432, 432, 330, 388, 64, 76, 449, 449, 191, 191, 191, 314, 314, 129, 259, 259, 74, 437, 437, 437, 496, 496, 274, 274, 186, 39, 342, 86, 142, 221, 336, 336, 74, 74, 437, 437, 496, 496, 496, 274, 274, 413, 348, 250, 217, 291, 291, 291, 291, 291, 291, 388, 379, 243, 243, 227, 227, 419, 427, 56, 247, 126, 126, 126, 326, 23, 101, 101, 149, 149, 228, 228, 20, 20, 320, 159, 159, 159, 159, 240, 285, 34, 145, 145, 284, 265, 265, 85, 85, 146, 146, 438, 422, 143, 36, 108, 119, 119, 351, 213, 213, 213, 213, 213, 246, 246, 246, 246, 246, 246, 19, 19, 19, 454, 454, 229before_semantic:
after is :
212
[17, 296, 127, 448, 448, 448, 464, 464, 493, 493, 493, 493, 493, 216, 300, 300, 300, 304, 304, 304, 185, 49, 269, 142, 142, 397, 456, 456, 456, 186, 162, 162, 172, 115, 273, 432, 432, 330, 64, 76, 449, 191, 191, 191, 314, 314, 401, 401, 82, 259, 74, 437, 437, 496, 496, 496, 274, 186, 39, 54, 142, 105, 336, 336, 354, 106, 106, 426, 426, 426, 413, 348, 250, 250, 291, 291, 291, 291, 291, 379, 243, 243, 227, 419, 419, 439, 439, 225, 225, 225, 225, 225, 225, 225, 80, 289, 140, 140, 354, 159, 159, 159, 285, 285, 34, 111, 111, 438, 438, 143, 36, 108, 119, 119, 444, 444, 213, 213, 246, 246, 246, 301, 378, 345, 141, 141, 141, 281, 281, 9, 238, 221, 336, 310, 395, 395, 151, 151, 169, 150, 238, 6, 272, 272, 257, 257, 257, 257, 162, 162, 482, 482, 105, 105, 336, 79, 487, 487, 374, 374, 215, 215, 129, 82, 29, 302, 497, 497, 497, 49, 453, 9, 198, 198, 114, before_semantic:
after is :
255
[17, 17, 17, 296, 66, 66, 172, 115, 273, 231, 231, 231, 231, 231, 53, 250, 250, 174, 174, 174, 174, 348, 94, 199, 145, 443, 139, 139, 139, 293,torch.Size([1, 210, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_121-127105-0006
generate
 20%|██        | 13/64 [01:40<06:24,  7.53s/it]processing 13th semantic_sys file
13
args.target_mode==1 or args.targbefore_semantic:
after is :
246
[17, 17, 296, 296, 66, 68, 68, 68, 68, 68, 115, 273, 231, 231, 231, 231, 231, 53, 250, 345, 174, 174, 174, 348, 94, 199, 145, 145, 315, 139, 139, 450, 293, 293, 169, 150, 342, 86, 86, 238, 6, 272, 119, 119, 351, 424, 424, 424, 424, 122, 122, 34, 44, 44, 38, 162, 162, 232, 482, 482, 238, 238, 6, 272, 470, 106, 153, 153, 372, 372, 372, 467, 337, 337, 41, 41, 19, 3, before_semantic:
after is :
222
[17, 17, 296, 296, 66, 68, 172, 172, 115, 231, 231, 231, 231, 231, 53, 250, 250, 174, 174, 174, 174, 94, 199, 145, 443, 139, 139, 139, 293, 293, 186, 39, 54, 86, 238, 6, 108, 119, 119, 437, 424, 424, 424, 424, 497, 122, 122, 34, 44, 44, 38, 162, 232, 232, 238, 6, 272, 470, 153, 153, 153, 372, 372, 467, 337, 337, 301, 339, 94, 479, 331, 284, 405, 405, 206, 167, 167, 35, 35, 259, 74, 492, 492, 492, 236, 129, 259, 108, 119, 351, 278, 278, 278, 143, 458, 192, 485, 134, 134, 134, 175, 81, 300, 300, 134, 134, 134, 359, 359, 166, 166, 166, 166, 464, 464, 255, 255, 38, 349, 234, 234, 261, 25, 470, 151, 151, 178, 178, 35, 96, 82, 272, 34, 191, 191, 459, 173, 173, 173, 402, 402, 402, 133, 364, 345, 407, 407, 407, 407, 310, 107, 395, 111, 111, 111, 111, 438, 186, 162, 232, 172, 115, 273, 106, 405, 405, 206, 58, 183, 451, 30, 30, 378, 378, 345, 141, 141, 141, 281, 453, 196, 196, 479, 331, 307, 307, 307, 61, 167, 167, 457, 90, 393, 234, 261, 25, 106, 481, 481, 481, 481, 481, 175, 175, 81, 134, 134, 88, 88, 176, 176, 176, 176, 328, before_semantic:
after is :
391
[17, 17, 296, 108, 108, 377, 377, 374, 374, 374, 374, 374, 132, 132, 216, 216, 127, 114, 114, 258, 258, 258, 258, 271, 271, 39, 54, 54, 54, 390, 97, 97, 97, 225, 225, 183, 183, 451, 451, 257, 257, 257, 257, 368, 453, 9, 9, 168, 483, 145, 145, 145, 365, 365, 365, 330, 330, 379, 77, 77, 77, 54, 54, 224, 224, 300, 334, 382, 382, 245, 245, 43, 43, 364, 345, 345, 141, 141, 141, 141, 281, 281, 269, 54, 9, 142, 142, 221, 336, 336, 336, 336, 74, 190, 190, 190, 488before_semantic:
after is :
284
[108, 377, 374, 374, 374, 374, 374, 132, 132, 132, 132, 132, 216, 216, 114, 114, 258, 258, 258, 258, 31, 54, 54, 54, 224, 224, 257, 257, 257, 257, 257, 368, 453, 9, 168, 168, 145, 145, 145, 365, 365, 365, 330, 330, 77, 77, 77, 323, 224, 300, 334, 334, 382, 59, before_semantic:
after is :
322
[17, 17, 108, 377, 351, 374, 374, 374, 132, 132, 132, 216, 216, 127, 114, 114, 258, 258, 258, 258, 271, 31, 39, 54, 54, 54, 224, 97, 183, 183, 257, 257, 257, 257, 257, 453, 9, 9, 168, 106, 106, 106, 284, 284, 365, 365, 426, 426, 413, 379, 77, 77, 77, 323, 323, 323, 224, 224, 334, 334, 355, 355, 355, 355, 355, 355, 452, 263, 263, 13, 78, 170, 170, 20, 20, 20, 312, 312, 187, 187, 12, 12, 23, 23, 23, 23, 101, 101, 391, 391, 228, 289, 20, 20, 345, 345, 141, 141, 281, 281, 9, 142, 221, 221, 336, 336, 259, 74, 190, 190, 190, 488, 488, 488, 426, 426, 53, 53, 53, 76, 76, 96, 96, 36, 108, 377, 377, 87, 87, 87, 38, 38, 164, 164, 164, 164, 164, 470, 470, 486, 365, 365, 360, 200, 200, 200, 457, 457, 457, 401, 32, 32, 32, 239, 144, 180, 180, 91, 91, 91, 206, 240, 314, 314, 314, 196, 196, 196, 309, 479, 331, 331, 84, 84, 84, 84, 84, 16, 16, 16, 16, 274, 98, 98, 98, 98, 13, 13, 13, 78, 20, 20, 170, 20, 312, 20, 312, 312, 292, 292, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 260, 260, 260, 260, 260, 260, 260, 260, 391, 391, 391, 20, 20, 289, 412, 412, 83, 83, 55, 55, 322, 322, 67, 212, 131, 335, 14, 411, 411, 188, 356, 356, 356, 356, 281, 281, 453, 9, 9, 198, 198, 22, 283, 455, 455, 42, 42, 42, 42, 147, 147, 380, 380, 443, 443, 178, 143, 458, 458, 192, 192, 192, 242, 469, 191, 314, 314, 314, 239, 131, 219, 219, 485, 485, 106, 153, 153, 153, 153, 153, 182, 182, 182, 182, 182, 182, 387, 387, 185, 185, 185, 185, 269, 269, 323, 323, 390, 18, 18, 18, 112, 112, 439, 439, 237, 237]
torch.Size([1, 320, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_121-127105-0007
generate
 23%|██▎       | 15/64 [01:51<05:22,  6.57s/it]processing 15th semantic_sbefore_semantic:before_semantic:
after is :
308
[17, 17, 296, 208, 208, 190, 487, 499, 499, 265, 265, 85, 85, 85, 146, 146, 24, 314, 133, 133, 345, 174, 174, 174, 348, 94, 199, 223, 223, 216, 216, 22, 283, 455, 43, 364, 364, 276, 109, 109, 278, 278, 203, 53, 473, 136, 275, 275, 116, 195, 117, 404, 183, 451, 451, 30, 30, 422, 143, 36, 108, 295, 295, 295, 295, 143, 458, 96, 196, 196, 309, 479, 331, 231, 231, 231, 274, 413, 10, 10, 10, 479, 331, 331, 84, 496, 496, 4before_semantic:
after is :
330
[17, 17, 208, 208, 190, 190, 499, 499, 499, 265, 265, 265, 265, 85, 85, 146, 146, 146, 24, 314, 133, 133, 364, 276, 174, 174, 174, 174, 94, 223, 223, 223, 216, 22, 283, 455, 43, 364, 364, 276, 109, 278, 278, 203, 399, 473, 473, 136, 275, 116, 33, 404, 183, 183, 451, 30, 30, 422, 143, 36, 108, 295, 295, 295, 295, 295, 458, 96, 196, 196, 309, 309, 309, 309, 309, 309, 479, 331, 231, 231, 231, 231, 231, 231, 274, 274, 413, 413, 10, 10, 309, 479, 331, 84, 84, 84, 496, 496, 274, 252, 36, 449, 449, 459, 459, 459, 271, 31, 54, 224, 168, 69, 223, 130, 130, 402, 402, 72, 156, 156, 156, 156, 156, 498, 498, 355, 355, 355, 355, 355, 452, 263, 229, 82, 247, 126, 126, 326, 326, 326, 326, 326, 101, 101, 149, 228, 82, 451, 451, 30, 30, 301, 251, 251, 367, 367, 367, 367, 367, 96, 96, 272, 415, 415, 415, 415, 457, 196, 217, 429, 429, 429, 429, 19, 19, 19, 454, 229, 82, 247, 312, 126, 292, 292, 23, 23, 23, 101, 101, 149, 228, 82, 320, 159, 159, 159, 159, 449, 449, 253, 253, 253, 253, 453, 168, 118, 118, 118, 118, 280, 34, 340, 340, 116, 33, 478, 478, 232, 232, 232, 238, 6, 272, 470, 470, 470, 443, 240, 240, 34, 69, 223, 130, 402, 402, 196, 217, 217, 217, 473, 429, 429, 429, 429, 429, 246, 246, 246, 246, 246, 19, 19, 19, 454, 454, 229, 140, 140, 312, 187, 408, 149, 140, 373, 451, 30, 30, 30, 422, 162, 232, 232, 172, 115, 273, 106, 153, 153, 153, 182, 182, 182, 182, 182, 182, 43, 364, 364, 181, 181, 181, 181, 181, 449, 449, 30, 30, 30, 422, 162, 162, 482, 105, 105, 336, 82, 354, 470, 189, 496, 496, 496, 274, 143, 458, 192, 192, 106, 223, 223, 223, 223, 223, 173, 352, 352, 352, 419, 439, 78]
torch.Size([1, 328, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16before_semantic:
after is :
316
[17, 296, 127, 0, 0, 222, 378, 378, 345, 141, 141, 141, 281, 162, 232, 232, 232, 172, 115, 273, 231, 231, 231, 231, 231, 53, 53, 76, 35, 401, 401, 214, 214, 214, 214, 328, 200, 200, 464, 464, 121, 116, 33, 394, 212, 239, 384, 490, 278, 278, 278, 173, 280, 280, 469, 469, 236, 310, 107, 395, 134, 134, 134, 100, 100, 100, 100, 175, 175, 255, 255, 255, 8, 8, 354, 180, 180, 113, 113, 113, 113, 113, 450, 167, 167, 35, 35, 401, 401, 401, 401, 20, 127, 283, 455, 455, 129, 82, 208, 208, 79, 79, 484, 484, 484, 484, 484, 484, 484, 358, 358, 457, 233before_semantic:
after is :
316
[17, 17, 296, 114, 0, 222, 378, 345, 141, 141, 141, 281, 162, 232, 232, 172, 115, 273, 231, 231, 231, 231, 53, 76, 35, 164, 214, 214, 214, 214, 200, 200, 335, 335, 440, 188, 121, 116, 33, 394, 212, 384, 371, 490, 490, 173, 280, 278, 278, 278, 278, 310, 310, 395, 395, 134, 134, 134, 100, 100, 100, 497, 497, 497, 255, 255, 8, 354, 354, 180, 113, 113, 113, 113, 167, 35, 35, 198, 22, 283, 455, 416, 458, 144, 208, 79, 79, 484, 484, 484, 484, 484, 484, 358, 358, 358, 385, 233, 233, 197, 197, 20, 20, 197, 197, 197, 197, 393, 234, 234, 234, 234, 234, 261, 261, 25, 106, 284, 284, 284, 284, 306, 306, 306, 306, 396, 396, 396, 203, 203, 53, 335, 335, 440, 440, 44, 44, 44, 399, 399, 217, 70, 65, 65, 496, 496, 496, 274, 186, 54, 54, 238, 6, 272, 483, 440, 319, 319, 319, 348, 33, 10, 219, 219, 219, 219, 485, 374, 374, 374, 368, 368, 107, 395, 134, 134, 134, 100, 100, 100, 497, 497, 122, 129, 36, 161, 161, 161, 161, 161, 487, 487, 288, 288, 278, 203, 53, 53, 10, 10, 479, 459, 459, 459, 459, 271, 271, 39, 39, 390, 390, 390, 18, 112, 112, 427, 56, 20, 247, 312, 126, 292, 292, 23, 23, 408, 408, 149, 149, 20, 412, 83, 83, 55, 446, 446, 67, 33, 90, 90, 129, 82, 144, 445, 445, 445, 351, 351, 264, 264, 264, 468, 468, 245, 245, 349, 349, 234, 234, 155, 155, 332, 148, 148, 148, 148, 372, 372, 372, 59, 59, 452, 263, 263, 229, 20, 20, 312, 187, 187, 187, 187, 408, 408, 408, 391, 20, 289, 289, 20, 75, 384, 371, 213, 213, 213, 252, 143, 36, 108, 119, 351, 351, 351, 470, 264, 139, 139, 139, 139, 375, 375, 98, 98, 98, 13]
torch.Size([1, 314, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_202before_semantic:
after is :
249
[17, 17, 17, 268, 268, 268, 268, 293, 215, 8, 32, 32, 32, 354, 190, 380, 380, 499, 315, 315, 315, 450, 450, 413, 413, 64, 64, 219, 219, 152, 152, 152, 152, 202, 402, 402, 221, 82, 144, 27, 180, 405, 405, 405, 206, 167, 167, 35, 478, 478, 66, 232, 172, 172, 115, 273, 278, 330, 379, 64, 76, 310, 310, 107, 107, 477, 152, 152, 132, 143, 129, 259, 82, 445, 445, 210, 210, 210, 210, 210, 203, 53, 53, 58, 58, 72, 72, 437, 350, 350, 350, 350, 350, 350, 350, 182, 182, 182, 413, 203, 381, 381, 381, 117, 48, 13, 13, 229, 82, 312, 312, 187, 187, 18before_semantic:
after is :
544
[17, 296, 296, 268, 268, 268, 268, 268, 268, 268, 293, 293, 274, 8, 8, 32, 354, 190, 190, 380, 380, 380, 499, 499, 315, 315, 315, 315, 450, 450, 450, 413, 413, 413, 413, 413, 413, 413, 195, 195, 117, 117, 117, 48, 48, 417, 417, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 435, 435, 211, 211, 211, 211, 21, 21, 21, 408, 408, 408, 149, 228, 228, 289, 289, 320, 7, 219, 152, 152, 152, 152, 202, 402, 402, 221, 144, 144, 180, 180, 405, 405, 405, 206, 167, 167, 35, 478, 66, 68, 172, 115, 273, 273, 432, 432, 432, 330, 379, 379, 243, 77, 77, 433, 433, 390, 390, 160, 18, 112, 112, 439, 439, 439, 439, 237, 237, 237, 237, 237, 28, 28, 140, 140, 28, 28, 28, 362, 140, 362, 362, 362, 362, 362, 140, 362, 362, 140, 362, 362, 362, 362, 362, 362, 218, 218, 218, 140, 218, 218, 218, 218, 218, 140, 218, 218, 218, 218, 218, 218, 218, 218, 140, 366, 366, 366, 140, 366, 140, 366, 366, 366, 366, 366, 366, 366, 140, 366, 366, 366, 316, 140, 316, 316, 316, 316, 73, 73, 289, 320, 219, 219, 152, 152, 152, 152, 143, 143, 458, 144, 445, 445, 210, 210, 210, 210, 210, 210, 210, 203, 203, 53, 53, 58, 58, 72, 72, 72, 437, 350, 350, 350, 350, 350, 350, 350, 350, 182, 413, 203, 203, 381, 381, 117, 117, 117, 48, 48, 417, 417, 417, 417, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 2, 2, 2, 2, 140, 2, 2, 2, 140, 366, 366, 366, 366, 366, 366, 366, 140, 366, 366, 316, 316, 316, 316, 316, 73, 73, 73, 289, 209, 287, 287, 111, 111, 111, 438, 438, 378, 43, 364, 364, 276, 109, 109, 278, 278, 278, 278, 271, 271, 99, 99, 338, 338, 338, 338, 338, 447, 18, 112, before_semantic:
after is :
434
[17, 296, 296, 188, 188, 475, 475, 475, 475, 94, 475, 475, 475, 301, 378, 43, 276, 174, 174, 174, 174, 174, 348, 348, 466, 466, 127, 114, 114, 264, 264, 468, 468, 467, 467, 255, 255, 8, 8, 354, 180, 113, 113, 113, 113, 113, 450, 167, 77, 270, 54, 142, 142, 397, 397, 345, 345, 389, 389, 389, 285, 202, 202, 202, 202, 402, 402, 221, 401, 82, 108, 119, 119, 351, 106, 424, 424, 424, 424, 424, 497, 122, 122, 122, 131, 219, 477, 477, 477, 477, 477, 132, 132, 132, 216, 216, 127, 45, 45, 45, 45, 45, 35, 35, 401, 82, 127, 127, 114, 258, 258, 258, 258, 258, 31, 54, 54, 54, 142, 397, 397, 345, 141, 141, 141, 281, 281, 9, 142, 397, 364, 276, 174, 174, 174, 174, 174, 94, 199, 223, 223, 223, 130, 198, 198, 22, 283, 283, 455, 455, 42, 42, 147, 147, 147, 288, 278, 278, 278, 143, 310, 310, 107, 107, 395, 459, 459, 459, 31, 31, 54, 86, 238, 6, 272, 393, 393, 261, 261, 25, 106, 284, 306, 306, 306, 306,torch.Size([1, 542, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134493-0011
generate
 28%|██▊       | 18/64 [02:18<06:33,  8.55s/it]processing 18th semantic_sys file
18
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ANY ONE THEREABOUTS WOULD HAVE TOLD YOU THAT THIS WAS ONE OF THE RICHEST FARMS ON THE DIVIDE AND THAT THE FARMER WAS A WOMAN ALEXANDRA BERGSON
2024-03-11 08:57:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:57:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
421
[17, 296, 296, 83, 475, 475, 475, 94, 475, 475, 475, 301, 378, 43, 276, 174, 174, 174, 174, 174, 282, 388, 388, 195, 195, 117, 117, 117, 48, 417, 417, 225, 225, 225, 80, 80, 140, 320, 127, 114, 0, 222, 406, 467, 467, 255, 255, 8, 354, 180, 180, 113, 113, 113, 450, 167, 167, 77, 270, 54, 142, 397, 397, 345, 345, 389, 389, 285, 34, 202, 202, 202, 402, 402, 221, 75, 108, 119, 119, 351, 424, 424, 424, 424, 424, 497, 122, 122, 122, 310, 107, 107, 477, 477, 477, 477, 477, 477, 132, 132, 98, 263, 13, 229, 140, 312, 312, 312, 187, 187, 12, 292, 292, 292, 23, 23, 23, 23, 23, 408, 408, 391, 391, 228, 140, 140, 320, 127, 45, 45, 45, 45, 35, 259, 127, 114, 258, 258, 258, 31, 54, 54, 142, 397, 397, 345, 141, 141, 141, 281, 9, 9, 142, 133, 364, 276, 174, 174, 174, 174, 94, 199, 223, 223, 130, 402, 198, 22, 283, 455, 455, 42, 147, 147, 288, 278, 278, 143, 36, 310, 107, 107, 395, 459, 459, 271, 31, 54, 86, 238, 6, 272, 472, 472, 393, 234, 261, 261, 25, 106, 284, 306, 306, 306, 306, 306, 396, 396, 203, 203, 381, 471, 471, 49, 269, 54, 390, 97, 483, 226, 226, 226, 209, 287, 125, 125, 125, 125, 125, 348, 466, 466, 22, 283, 455, 236, 239, 384, 490, 490, 490, 173, 280, 280, 106, 265, 265, 265, 265, 265, 265, 265, 265, 85, 85, 85, 85, 207, 207, 37, 24, 131, 404, 439, 78, 140, 140, 247, 312, 312, 292, 292, 292, 292, 292, 292, 292, 292, 21, 21, 21, 21, 408, 408, 408, 408, 391, 391, 140, 140, 412, 83, 83, 55, 322, 67, 466, 45, 45, 45, 45, 35, 198, 22, 5, 455, 349, 349, 234, 234, 261, 25, 106, 306, 306, 306, 306, 396, 203, 203, 53, 29, 334, 382, 59, 245, 43, 345, 345, 141, 141, 141, 281, 453, 9, 168, 44, 44, 44, 43, 364, 364, 276, 276, 174, 174, 174, 399, 53, 473, 242, 242, 116, 33, 33, 335, 14, 411, 145, 145, 145, 486, 486, 460, 175, 175, 81, 81, 469, 178, 458, 458, 96, 66, 172, 115, 470, 256, 365, 365, 365, 365, 330, 64, 64, 212, 161, 161, 495, 382, 423, 423, 423, 8, 8, 354, 354, 498, 498, 498, 498, 396, 396, 416, 416, 96, 270, 49, 54, 224, 224, 275, 275, 275, 303, 303, 303, 303, 48, 48, 417]
torch.Size([1, 419, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134493-0017
generate
 30%|██▉       | 19/64 [02:27<06:27,  8.61s/it]processing 19th semantic_sys file
19
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HIS WIFE NOW LIES BESIDE HIM AND THE WHITE SHAFT THAT MARKS THEIR GRAVES GLEAMS ACROSS THE WHEAT FIELDS
2024-03-11 08:57:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:57:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
458
[17, 296, 451, 257, 257, 257, 257, 281, 9, 142, 397, 364, 364, 276, 276, 346, 346, 346, 346, 265, 428, 428, 85, 146, 146, 358, 358, 358, 349, 352, 352, 352, 352, 352, 97, 97, 225, 225, 225, 225, 7, 7, 7, 309, 479, 331, 315, 315, 315, 315, 315, 450, 293, 293, 293, 293, 293, 251, 251, 241, 431, 431, 284, 265, 265, 265, 265, 85, 85, 85, 146, 146, 318, 368, 49, 9, 142, 221, 336, 354, 420, 420, 422, 422, 162, 232, 232, 172, 115, 273, 273, 265, 265, 265, 85, 85, 146, 146, 252, 24, 131, 183, 183, 183, 57, 57, 57, 57, 57, 57, 203, 381, 381, 381, 117, 404, 404, 13, 229, 82, 247, 312, 126, 292, 292, 292, 292, 292, 23, 23, 23, 408, 408, 408, 391, 391, 228, 140, 412, 412, 83, 83, 55, 55, 55, 322, 322, 67, 212, 212, 198, 22, 5, 455, 455, 43, 43, 364, 364, 276, 276, 276, 346, 346, 346, 346, 428, 428, 146, 146, 358, 358, 143, 36, 36, 227, 472, 472, 472, 472, 338, 338, 338, 338, 338, 338, 338, 395, 395, 470, 470, 470, 486, 486, 486, 376, 376, 460, 460, 460, 460, 169, 169, 352, 352, 352, 96, 6, 36, 227, 227, 419, 419, 419, 419, 439, 439, 439, 78, 78, 140, 140, 140, 140, 312, 312, 312, 341, 12, 12, 292, 292, 292, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 260, 260, 260, 260, 260, 391, 391, 391, 228, 140, 289, 320, 7, 127, 45, 45, 45, 45, 45, 45, 167, 457, 457, 457, 196, 196, 70, 70, 70, 65, 65, 306, 306, 306, 306, 396, 396, 396, 178, 233, 233, 96, 270, 270, 323, 390, 390, 390, 18, 97, 97, 97, 225, 225, 225, 225, 225, 225, 7, 127, 127, 127, 114, 222, 222, 222, 222, 468, 468, 245, 245, 416, 416, 32, 239, 208, 79, 79, 380, 380, 288, 288, 171, 171, 171, 171, 171, 246, 246, 318, 173, 173, 49, 49, 9, 9, 221, 221, 336, 144, 208, 425, 386, 386, 431, 444, 444, 360, 360, 360, 434, 434, 434, 434, 434, 203, 203, 381, 381, 471, 471, 185, 49, 269, 323, 323, 97, 483, 483, 440, 440, 255, 255, 255, 143, 129, 82, 208, 208, 190, 487, 499, 499, 405, 405, 405, 206, 169, 150, 150, 54, 86, 238, 198, 22, 283, 283, 455, 455, 43, 364, 364, 276, 109, 109, 213, 213, 213, 252, 252, 143, 131, 472, 472, 393, 234, 234, 234, 261, 261, 25, 485, 485, 213, 213, 213, 286, 286, 139, 139, 139, 139, 302, 375, 375, 375, 375, 375, 122, 122, 122, 270, 270, 270, 323, 323, 18, 18, 112]
torch.Size([1, 456, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134493-0001
generate
 31%|███▏      | 20/64 [02:37<06:36,  9.01s/it]processing 20th semantic_sys file
20
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT IS SIXTEEN YEARS SINCE JOHN BERGSON DIED
2024-03-11 08:57:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:57:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
168
[17, 17, 287, 287, 111, 111, 438, 438, 143, 36, 36, 108, 119, 119, 351, 213, 213, 213, 213, 246, 246, 3, 3, 335, 440, 188, 188, 356, 356, 356, 31, 162, 232, 68, 68, 115, 115, 273, 278, 278, 178, 458, 96, 96, 86, 238, 6, 82, 108, 119, 351, 360, 360, 360, 360, 339, 339, 33, 219, 219, 398, 286, 286, 286, 286, 286, 286, 286, 468, 59, 59, 59, 304, 304, 304, 185, 49, 269, 433, 433, 160, 97, 97, 226, 20, 20, 197, 373, 66, 66, 68, 115, 273, 273, 432, 330, 330, 379, 77, 77, 342, 86, 238, 238, 336, 310, 107, 395, 180, 329, 329, 329, 426, 426, 426, 206, 388, 348, 64, 394, 212, 354, 354, 498, 498, 498, 498, 396, 396, 416, 96, 96, 270, 342, 342, 224, 242, 275, 275, 116, 33, 33, 394, 212, 239, 384, 371, 180, 180, 265, 265, 265, 265, 265, 265, 85, 85, 85, 207, 207, 207, 37, 24, 131, 404, 439, 439, 78]
torch.Size([1, 166, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134493-0000
generate
 33%|███▎      | 21/64 [02:40<05:13,  7.28s/it]processing 21th semantic_sys file
21
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE AIR AND THE EARTH ARE CURIOUSLY MATED AND INTERMINGLED AS IF THE ONE WERE THE BREATH OF THE OTHER
2024-03-11 08:57:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:57:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
485
[17, 17, 127, 5, 448, 448, 448, 3, 3, 14, 411, 145, 145, 264, 264, 264, 264, 264, 264, 264, 264, 468, 468, 468, 59, 59, 59, 59, 59, 59, 452, 452, 263, 263, 225, 225, 225, 225, 225, 412, 412, 83, 83, 55, 55, 322, 322, 67, 212, 22, 5, 448, 448, 448, 3, 3, 14, 14, 411, 411, 498, 498, 498, 498, 498, 498, 498, 498, 396, 396, 169, 169, 169, 164, 164, 164, 164, 164, 164, 164, 164, 164, 164, 97, 483, 226, 226, 20, 20, 20, 287, 287, 353, 353, 353, 353, 353, 353, 396, 396, 396, 313, 143, 143, 458, 458, 445, 445, 445, 445, 445, 485, 485, 485, 485, 485, 485, 374, 374, 468, 468, 468, 468, 468, 337, 337, 337, 459, 459, 459, 459, 271, 31, 39, 342, 86, 86, 86, 26, 26, 26, 359, 359, 359, 359, 166, 166, 166, 166, 166, 166, 166, 324, 246, 246, 3, 3, 3, 3, 197, 197, 7, 217, 217, 217, 473, 473, 65, 476, 476, 476, 171, 171, 171, 252, 252, 325, 325, 34, 191, 191, 191, 191, 191, 37, 37, 37, 24, 24, 24, 131, 419, 404, 439, 439, 439, 439, 78, 78, 20, 20, 20, 20, 20, 20, 312, 312, 292, 292, 292, 292, 292, 21, 21, 21, 21, 21, 21, 21, 21, 21, 408, 408, 408, 149, 228, 20, 412, 83, 83, 55, 55, 55, 322, 67, 67, 212, 212, 34, 121, 121, 121, 121, 121, 33, 33, 394, 76, 465, 108, 108, 108, 119, 351, 351, 308, 308, 308, 308, 308, 308, 308, 308, 396, 396, 203, 399, 53, 473, 473, 176, 135, 135, 200, 200, 200, 248, 212, 212, 144, 180, 180, 180, 84, 84, 84, 84, 84, 84, 16, 16, 16, 16, 375, 375, 375, 375, 122, 122, 122, 131, 131, 404, 483, 483, 440, 440, 83, 83, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 368, 368, 368, 453, 453, 453, 168, 168, 118, 118, 118, 118, 118, 118, 402, 402, 198, 198, 198, 22, 22, 5, 455, 455, 43, 43, 364, 364, 364, 276, 276, 276, 174, 174, 174, 174, 174, 174, 174, 174, 282, 282, 282, 388, 195, 195, 195, 195, 195, 195, 195, 404, 404, 404, 404, 225, 225, 225, 225, 225, 225, 225, 225, 225, 7, 7, 364, 345, 347, 347, 347, 347, 347, 313, 216, 216, 216, 22, 22, 283, 455, 455, 455, 32, 32, 32, 32, 354, 354, 190, 190, 380, 380, 380, 288, 288, 443, 443, 443, 120, 120, 120, 169, 169, 150, 164, 352, 352, 352, 352, 352, 352, 97, 97, 483, 483, 440, 440, 69, 69, 69, 69, 69, 223, 130, 130, 198, 198, 22, 22, 448, 448, 448, 448, 464, 14, 411, 411, 493, 493, 493, 493, 493, 493, 493, 493, 216, 216, 300, 300, 300, 334, 334, 334, 59, 59, 59, 59, 59, 452, 452, 452, 263, 263, 263]
torch.Size([1, 483, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134493-0004
generate
 34%|███▍      | 22/64 [02:50<05:40,  8.10s/it]processing 22th semantic_sys file
22
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: INDEED HE HAD LOOKED AWAY WITH THE PURPOSE OF NOT SEEING IT
2024-03-11 08:57:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:57:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
156
[140, 296, 296, 188, 121, 121, 121, 67, 394, 212, 384, 371, 444, 213, 213, 213, 213, 246, 246, 252, 24, 131, 183, 183, 451, 451, 30, 30, 30, 30, 464, 254, 254, 254, 314, 26, 251, 251, 241, 367, 367, 367, 367, 96, 96, 82, 272, 34, 255, 255, 43, 364, 276, 276, 109, 109, 403, 403, 403, 403, 207, 301, 378, 43, 333, 333, 333, 220, 220, 164, 164, 22, 283, 455, 455, 129, 82, 82, 74, 492, 492, 492, 492, 492, 492, 215, 215, 35, 29, 459, 459, 459, 271, 39, 54, 54, 224, 224, 69, 223, 130, 402, 196, 309, 309, 309, 309, 479, 331, 307, 307, 307, 61, 167, 167, 457, 478, 478, 232, 232, 172, 172, 115, 267, 267, 267, 360, 135, 135, 135, 200, 464, 180, 106, 265, 265, 265, 428, 146, 438, 236, 36, 108, 108, 119, 351, 213, 213, 213, 213, 246, 19, 19, 19, 454, 454]
torch.Size([1, 154, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134493-0013
generate
 36%|███▌      | 23/64 [02:53<04:28,  6.54s/it]processing 23th semantic_sys file
23
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE IS EVEN A WHITE ROW OF BEEHIVES IN THE ORCHARD UNDER THE WALNUT TREES
2024-03-11 08:57:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:57:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
230
[17, 296, 296, 114, 0, 0, 468, 406, 406, 467, 356, 356, 356, 281, 453, 9, 9, 483, 483, 411, 411, 213, 213, 213, 357, 357, 173, 173, 280, 242, 242, 116, 116, 195, 195, 195, 195, 117, 335, 335, 226, 440, 44, 44, 44, 44, 44, 43, 364, 364, 276, 276, 346, 428, 428, 146, 146, 252, 143, 36, 472, 133, 42, 147, 147, 380, 380, 84, 496, 496, 496, 274, 274, 88, 88, 69, 462, 462, 462, 402, 402, 32, 32, 32, 82, 354, 420, 213, 213, 324, 3, 58, 58, 72, 437, 437, 265, 265, 265, 265, 265, 85, 85, 85, 85, 299, 299, 173, 173, 185, 185, 49, 269, 9, 9, 168, 340, 340, 340, 466, 466, 22, 448, 448, 448, 464, 106, 106, 153, 372, 372, 396, 313, 143, 310, 107, 107, 395, 334, 334, 382, 313, 37, 24, 24, 131, 404, 439, 439, 78, 82, 82, 312, 187, 187, 187, 187, 391, 391, 391, 140, 140, 412, 287, 287, 319, 319, 348, 212, 300, 300, 382, 313, 216, 216, 22, 283, 455, 43, 43, 364, 276, 276, 346, 346, 481, 481, 481, 293, 293, 497, 122, 10, 479, 331, 331, 151, 151, 167, 167, 457, 401, 82, 108, 161, 161, 487, 487, 487, 288, 288, 213, 246, 246, 246, 318, 318, 185, 185, 269, 390, 390, 18, 112, 112, 439, 56, 82, 421, 140]
torch.Size([1, 228, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134493-0018
generate
 38%|███▊      | 24/64 [02:57<03:55,  5.89s/it]processing 24th semantic_sys file
24
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT'S NOT MUCH OF A JOB FOR AN ATHLETE HERE I'VE BEEN TO TOWN AND BACK
2024-03-11 08:57:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:57:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
175
[17, 17, 296, 114, 114, 92, 92, 92, 92, 240, 35, 77, 342, 86, 221, 196, 479, 307, 307, 307, 61, 167, 457, 457, 70, 70, 383, 383, 383, 383, 383, 35, 310, 107, 107, 69, 223, 130, 280, 44, 44, 44, 236, 239, 310, 107, 395, 395, 106, 106, 284, 405, 405, 405, 405, 405, 206, 206, 206, 215, 215, 35, 393, 393, 155, 155, 332, 332, 332, 467, 467, 44, 44, 44, 199, 145, 145, 145, 486, 460, 460, 169, 169, 164, 164, 26, 359, 81, 81, 81, 324, 324, 252, 325, 183, 183, 451, 286, 286, 286, 286, 468, 468, 467, 111, 111, 111, 438, 202, 173, 402, 401, 82, 137, 137, 137, 137, 137, 116, 394, 76, 259, 108, 377, 344, 374, 374, 374, 422, 236, 36, 108, 119, 119, 351, 351, 315, 315, 315, 315, 315, 450, 450, 450, 413, 413, 94, 199, 89, 89, 446, 33, 394, 212, 354, 354, 180, 376, 376, 376, 376, 376, 376, 376, 460, 460, 178, 178, 233, 233, 20, 192, 419, 419, 439]
torch.Size([1, 173, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134493-0006
generate
 39%|███▉      | 25/64 [03:01<03:20,  5.14s/it]processing 25th semantic_sys file
25
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OH EVER SO MUCH ONLY HE SEEMS KIND OF STAID AND SCHOOL TEACHERY
2024-03-11 08:57:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:57:45 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([54], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
210
[17, 17, 296, 287, 287, 287, 16, 16, 16, 88, 88, 88, 109, 463, 463, 463, 463, 280, 29, 29, 382, 382, 313, 186, 186, 162, 232, 232, 172, 115, 344, 344, 344, 344, 344, 274, 399, 70, 70, 383, 383, 383, 383, 383, 383, 383, 35, 310, 107, 447, 483, 14, 411, 350, 350, 350, 350, 350, 350, 250, 359, 81, 81, 166, 324, 324, 3, 183, 183, 451, 451, 30, 30, 30, 422, 186, 162, 232, 172, 115, 444, 444, 444, 444, 434, 339, 53, 71, 71, 49, 142, 221, 221, 82, 144, 27, 27, 437, 437, 480, 480, 480, 480, 480, 480, 480, 480, 85, 299, 299, 299, 339, 64, 212, 34, 69, 462, 462, 130, 130, 478, 162, 232, 482, 482, 482, 238, 6, 82, 384, 470, 470, 470, 403, 403, 403, 403, 171, 171, 171, 207, 207, 207, 246, 252, 252, 24, 24, 131, 483, 483, 440, 440, 89, 89, 446, 446, 33, 33, 394, 478, 478, 162, 232, 482, 482, 105, 105, 336, 82, 208, 153, 153, 153, 153, 153, 182, 182, 182, 497, 497, 497, 122, 129, 129, 82, 108, 119, 351, 213, 213, 213, 213, 252, 143, 36, 310, 107, 161, 161, 495, 495, 495, 495, 41, 41, 41, 19, 19, 454]
torch.Size([1, 208, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134500-0021
generate
 41%|████      | 26/64 [03:05<03:05,  4.88s/it]processing 26th semantic_sys file
26
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I CAN'T PLAY WITH YOU LIKE A LITTLE BOY ANY MORE HE SAID SLOWLY THAT'S WHAT YOU MISS MARIE
2024-03-11 08:57:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:57:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
276
[17, 296, 111, 111, 438, 143, 458, 144, 27, 27, 437, 437, 389, 389, 389, 319, 319, 319, 348, 348, 64, 457, 131, 472, 221, 221, 82, 74, 74, 425, 386, 386, 431, 403, 403, 403, 403, 403, 207, 207, 207, 301, 378, 345, 333, 333, 220, 220, 164, 164, 219, 477, 477, 477, 477, 477, 132, 26, 251, 241, 266, 266, 266, 266, 266, 266, 178, 458, 192, 44, 44, 44, 251, 241, 278, 278, 278, 278, 449, 449, 302, 302, 497, 497, 497, 8, 8, 82, 354, 354, 153, 153, 153, 153, 153, 387, 387, 387, 403, 207, 207, 207, 207, 19, 19, 454, 454, 454, 225, 225, 225, 225, 225, 225, 225, 412, 412, 83, 83, 475, 475, 475, 475, 475, 475, 475, 475, 301, 399, 217, 217, 70, 138, 138, 138, 138, 138, 138, 138, 182, 182, 182, 182, 182, 375, 98, 98, 98, 98, 263, 225, 225, 225, 225, 225, 225, 225, 451, 451, 451, 30, 30, 422, 162, 232, 172, 115, 273, 470, 120, 120, 240, 314, 478, 478, 232, 232, 482, 26, 26, 26, 386, 431, 431, 84, 496, 496, 496, 274, 274, 359, 359, 474, 474, 474, 474, 19, 19, 19, 19, 454, 454, 454, 225, 225, 225, 225, 80, 20, 20, 20, 20, 127, 114, 114, 92, 92, 92, 92, 92, 167, 167, 457, 77, 77, 54, 142, 397, 397, 181, 181, 181, 181, 181, 181, 36, 310, 107, 107, 152, 152, 152, 301, 399, 217, 473, 65, 278, 258, 31, 54, 54, 142, 221, 196, 217, 473, 65, 65, 495, 495, 406, 406, 406, 337, 337, 41, 41, 41, 19, 19, 19, 454, 454, 13, 78]
torch.Size([1, 274, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134500-0036
generate
 42%|████▏     | 27/64 [03:11<03:13,  5.23s/it]processing 27th semantic_sys file
27
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHEN SHE USED TO TELL ME ABOUT HIM I ALWAYS WONDERED WHETHER SHE WASN'T A LITTLE IN LOVE WITH HIM
2024-03-11 08:57:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:57:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
315
[17, 17, 296, 409, 409, 409, 67, 76, 310, 338, 400, 400, 400, 30, 219, 219, 485, 485, 374, 374, 186, 186, 54, 238, 6, 272, 87, 87, 87, 129, 259, 75, 119, 119, 351, 351, 351, 139, 139, 139, 293, 293, 399, 399, 429, 429, 429, 429, 429, 464, 464, 255, 255, 8, 259, 354, 180, 113, 113, 113, 113, 113, 167, 285, 325, 183, 57, 57, 57, 57, 57, 203, 381, 381, 117, 48, 48, 417, 170, 170, 170, 140, 28, 28, 140, 28, 28, 28, 140, 362, 362, 362, 140, 362, 362, 140, 362, 362, 362, 362, 362, 362, 362, 218, 218, 140, 218, 218, 140, 218, 218, 218, 140, 366, 366, 366, 140, 366, 366, 140, 366, 366, 366, 366, 366, 366, 140, 366, 366, 366, 316, 316, 140, 316, 316, 73, 73, 140, 320, 412, 287, 111, 111, 111, 438, 464, 106, 106, 297, 297, 297, 297, 297, 43, 345, 109, 109, 109, 368, 281, 9, 142, 142, 133, 364, 364, 276, 276, 276, 174, 174, 319, 319, 348, 348, 64, 64, 64, 212, 212, 300, 300, 334, 334, 334, 59, 59, 37, 24, 24, 75, 131, 419, 439, 439, 78, 78, 170, 170, 28, 140, 2, 2, 2, 2, 140, 2, 2, 2, 140, 2, 140, 2, 163, 163, 163, 163, 163, 163, 316, 316, 316, 73, 73, 73, 140, 320, 320, 345, 109, 409, 443, 240, 216, 300, 300, 300, 382, 313, 186, 99, 338, 338, 400, 400, 400, 400, 30, 301, 378, 43, 345, 141, 141, 141, 141, 281, 9, 168, 168, 494, 494, 236, 36, 75, 108, 119, 351, 351, 486, 486, 139, 175, 175, 81, 81, 134, 134, 175, 175, 81, 89, 340, 116, 33, 250, 250, 241, 241, 266, 266, 266, 266, 266, 173, 402, 402, 402, 345, 345, 333, 220, 220, 164, 164, 183, 57, 57, 57, 57, 57, 203, 381, 48, 48]
torch.Size([1, 313, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134500-0022
generate
 44%|████▍     | 28/64 [03:17<03:14,  5.40s/it]processing 28th semantic_sys file
28
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT EMIL IF I UNDERSTAND THEN ALL OUR GOOD TIMES ARE OVER WE CAN NEVER DO NICE THINGS TOGETHER ANY MORE
2024-03-11 08:58:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:58:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
302
[17, 17, 296, 159, 159, 159, 159, 159, 167, 385, 457, 35, 35, 197, 197, 197, 197, 197, 184, 184, 20, 20, 20, 20, 20, 209, 329, 329, 329, 329, 329, 329, 53, 53, 65, 134, 134, 175, 175, 81, 81, 118, 118, 118, 118, 118, 205, 25, 106, 111, 111, 111, 111, 438, 438, 464, 464, 464, 319, 330, 348, 64, 212, 300, 300, 469, 469, 186, 162, 232, 232, 232, 238, 6, 272, 470, 470, 294, 294, 365, 330, 330, 388, 466, 212, 114, 361, 361, 361, 116, 199, 335, 14, 14, 411, 297, 297, 297, 297, 297, 297, 297, 297, 293, 175, 175, 81, 353, 353, 396, 245, 416, 416, 239, 484, 484, 484, 484, 236, 314, 314, 129, 259, 108, 119, 119, 437, 437, 103, 103, 103, 103, 103, 103, 85, 85, 85, 85, 299, 299, 203, 53, 471, 49, 49, 9, 168, 353, 353, 353, 353, 245, 14, 14, 14, 411, 410, 410, 410, 410, 410, 410, 173, 280, 29, 29, 382, 382, 245, 43, 43, 364, 345, 152, 152, 152, 152, 422, 458, 192, 389, 389, 389, 116, 10, 10, 10, 10, 309, 309, 479, 331, 463, 463, 463, 463, 463, 463, 29, 382, 382, 313, 313, 24, 239, 371, 371, 374, 374, 374, 301, 10, 10, 309, 479, 331, 331, 265, 428, 428, 428, 146, 146, 252, 186, 186, 39, 86, 86, 86, 238, 6, 336, 214, 214, 214, 214, 214, 328, 328, 200, 471, 471, 49, 269, 342, 86, 6, 6, 377, 87, 87, 87, 416, 259, 445, 180, 180, 443, 493, 493, 216, 300, 300, 382, 382, 335, 14, 411, 475, 475, 475, 475, 94, 475, 475, 475, 324, 301, 399, 217, 70, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 372, 372, 59, 59, 59, 452, 452, 263, 263, 13]
torch.Size([1, 300, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134500-0037
generate
 45%|████▌     | 29/64 [03:23<03:14,  5.56s/it]processing 29th semantic_sys file
29
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND EMIL MOWED HIS WAY SLOWLY DOWN TOWARD THE CHERRY TREES
2024-03-11 08:58:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:58:08 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
169
[17, 17, 83, 55, 55, 322, 322, 67, 335, 14, 411, 411, 329, 329, 329, 329, 329, 53, 53, 65, 302, 302, 497, 497, 399, 399, 70, 70, 65, 65, 496, 496, 496, 274, 274, 285, 285, 183, 257, 257, 257, 257, 281, 9, 9, 397, 133, 364, 109, 109, 403, 403, 403, 171, 171, 252, 186, 162, 232, 232, 232, 172, 26, 26, 386, 431, 431, 496, 496, 496, 175, 359, 474, 474, 166, 324, 301, 239, 239, 371, 180, 180, 315, 315, 315, 315, 315, 315, 450, 450, 450, 413, 413, 413, 303, 303, 117, 404, 404, 225, 225, 225, 80, 20, 20, 20, 108, 377, 123, 123, 43, 364, 276, 153, 153, 372, 372, 396, 240, 314, 198, 22, 283, 455, 236, 36, 310, 107, 107, 395, 351, 264, 264, 264, 468, 468, 468, 337, 337, 324, 422, 143, 82, 310, 161, 161, 487, 487, 487, 288, 288, 213, 213, 246, 246, 318, 318, 318, 185, 185, 185, 269, 390, 390, 390, 18, 18, 112, 439]
torch.Size([1, 167, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134500-0014
generate
 47%|████▋     | 30/64 [03:26<02:48,  4.96s/it]processing 30th semantic_sys file
30
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I WISH YOU WEREN'T SO RESTLESS AND DIDN'T GET SO WORKED UP OVER THINGS SHE SAID SADLY
2024-03-11 08:58:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:58:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
251
[17, 296, 296, 287, 111, 111, 111, 111, 438, 378, 43, 364, 345, 109, 278, 278, 99, 99, 338, 107, 395, 152, 152, 378, 378, 43, 364, 276, 109, 109, 319, 319, 330, 348, 457, 457, 478, 478, 66, 68, 172, 344, 344, 344, 344, 344, 344, 344, 274, 42, 42, 147, 147, 380, 380, 443, 443, 443, 169, 150, 150, 86, 86, 86, 26, 26, 262, 262, 262, 262, 262, 262, 39, 342, 342, 224, 89, 89, 89, 322, 67, 394, 212, 239, 384, 371, 371, 278, 278, 314, 196, 242, 242, 33, 33, 90, 90, 239, 445, 180, 180, 443, 443, 385, 385, 457, 478, 66, 68, 172, 115, 344, 344, 344, 344, 344, 344, 274, 274, 43, 43, 43, 276, 109, 109, 498, 498, 498, 178, 178, 96, 96, 82, 75, 449, 180, 230, 230, 230, 230, 230, 230, 230, 215, 215, 233, 233, 419, 427, 229, 82, 312, 126, 23, 23, 23, 101, 101, 149, 149, 228, 140, 140, 412, 287, 287, 410, 410, 410, 410, 410, 410, 410, 173, 173, 280, 29, 494, 494, 38, 38, 164, 164, 164, 164, 214, 214, 214, 214, 214, 328, 200, 200, 200, 248, 248, 186, 99, 338, 338, 400, 400, 400, 30, 422, 422, 162, 68, 68, 68, 115, 273, 470, 470, 120, 120, 120, 240, 314, 314, 478, 478, 68, 68, 68, 115, 273, 470, 486, 486, 486, 376, 460, 460, 240, 24, 26, 26, 359, 359, 359, 474, 474, 474, 474, 19, 19, 19, 454, 454, 454]
torch.Size([1, 249, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134500-0033
generate
 48%|████▊     | 31/64 [03:31<02:41,  4.89s/it]processing 31th semantic_sys file
31
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT WON'T LAST IT WILL GO AWAY AND THINGS WILL BE JUST AS THEY USED TO
2024-03-11 08:58:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:58:16 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
182
[17, 17, 296, 127, 114, 92, 92, 92, 92, 92, 167, 457, 457, 364, 276, 109, 109, 350, 350, 350, 350, 413, 457, 457, 251, 241, 431, 431, 376, 376, 376, 460, 460, 169, 150, 86, 238, 6, 6, 272, 106, 111, 111, 111, 438, 438, 143, 36, 36, 108, 119, 351, 213, 324, 301, 301, 378, 345, 389, 389, 389, 497, 122, 416, 239, 144, 180, 84, 496, 88, 88, 88, 88, 255, 255, 43, 43, 364, 109, 109, 109, 403, 403, 403, 207, 464, 464, 89, 89, 322, 67, 394, 76, 164, 164, 214, 214, 214, 214, 200, 200, 471, 49, 49, 9, 397, 397, 389, 389, 389, 8, 354, 420, 420, 420, 422, 236, 32, 32, 82, 310, 395, 395, 151, 151, 151, 169, 150, 86, 238, 6, 272, 253, 253, 253, 253, 453, 198, 198, 127, 0, 0, 0, 0, 219, 219, 219, 485, 485, 374, 374, 186, 186, 54, 238, 6, 272, 472, 472, 472, 336, 20, 108, 377, 377, 123, 123, 374, 374, 374, 132, 132, 132, 132, 98, 98, 13, 20, 20, 20, 15, 15]
torch.Size([1, 180, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134500-0039
generate
 50%|█████     | 32/64 [03:35<02:24,  4.51s/it]processing 32th semantic_sys file
32
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I'M SURE ALEXANDRA HOPES YOU WILL STAY ON HERE SHE MURMURED
2024-03-11 08:58:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:58:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
211
[17, 17, 287, 111, 111, 111, 438, 203, 53, 53, 90, 186, 338, 338, 338, 395, 395, 487, 498, 498, 498, 498, 396, 396, 313, 335, 14, 14, 411, 145, 145, 145, 329, 329, 175, 175, 81, 81, 469, 416, 458, 96, 342, 342, 224, 470, 470, 329, 329, 365, 330, 64, 212, 161, 161, 423, 423, 423, 423, 423, 58, 58, 72, 72, 437, 496, 496, 496, 496, 215, 215, 35, 96, 96, 323, 323, 142, 219, 152, 152, 152, 378, 378, 345, 389, 389, 497, 38, 162, 162, 68, 68, 68, 238, 82, 272, 470, 470, 470, 403, 403, 403, 403, 403, 403, 207, 207, 207, 207, 207, 3, 3, 335, 14, 440, 287, 125, 125, 125, 125, 348, 94, 58, 183, 183, 183, 451, 451, 451, 286, 286, 286, 286, 286, 286, 286, 286, 286, 468, 59, 59, 59, 59, 59, 59, 452, 452, 263, 229, 82, 247, 126, 126, 126, 326, 326, 408, 408, 408, 149, 228, 20, 20, 373, 373, 66, 66, 338, 338, 338, 338, 338, 338, 400, 400, 400, 400, 30, 30, 301, 399, 399, 217, 70, 65, 498, 498, 498, 498, 498, 498, 203, 203, 53, 53, 29, 334, 334, 334, 334, 37, 37, 37, 37, 24, 131, 404, 404, 439, 439, 439]
torch.Size([1, 209, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134500-0028
generate
 52%|█████▏    | 33/64 [03:38<02:14,  4.35s/it]processing 33th semantic_sys file
33
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I PRAY FOR YOU BUT THAT'S NOT THE SAME AS IF YOU PRAYED YOURSELF
2024-03-11 08:58:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:58:23 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([27], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
324
[17, 17, 296, 287, 111, 111, 111, 438, 215, 129, 129, 259, 74, 190, 190, 487, 288, 288, 288, 171, 252, 422, 349, 205, 155, 332, 332, 332, 332, 219, 219, 219, 477, 477, 477, 477, 477, 477, 132, 132, 132, 132, 98, 98, 98, 13, 13, 13, 13, 237, 237, 237, 237, 237, 237, 237, 237, 28, 28, 28, 28, 28, 28, 28, 362, 362, 362, 362, 362, 362, 362, 362, 362, 362, 362, 362, 140, 362, 362, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 316, 316, 316, 73, 289, 289, 289, 320, 159, 159, 159, 159, 35, 259, 127, 114, 92, 92, 92, 240, 35, 77, 342, 86, 221, 196, 309, 479, 307, 307, 307, 307, 61, 167, 35, 35, 198, 22, 283, 455, 38, 162, 162, 68, 172, 172, 273, 470, 290, 290, 290, 290, 434, 434, 434, 203, 53, 473, 253, 253, 253, 253, 453, 453, 168, 168, 118, 118, 118, 118, 349, 402, 402, 219, 219, 152, 152, 152, 301, 129, 259, 259, 74, 190, 190, 487, 288, 288, 171, 171, 252, 252, 24, 310, 107, 395, 222, 222, 222, 313, 186, 186, 162, 232, 172, 115, 273, 279, 279, 279, 279, 279, 279, 375, 169, 352, 352, 352, 352, 352, 352, 352, 352, 112, 439]
torch.Size([1, 322, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134500-0040
generate
 53%|█████▎    | 34/64 [03:45<02:32,  5.07s/it]processing 34th semantic_sys file
34
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I GET TIRED OF SEEING MEN AND HORSES GOING UP AND DOWN UP AND DOWN
2024-03-11 08:58:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:58:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
150
[17, 296, 111, 438, 416, 416, 445, 445, 278, 278, 385, 457, 457, 401, 82, 108, 119, 119, 437, 265, 265, 428, 428, 146, 146, 468, 382, 313, 313, 325, 223, 223, 130, 402, 162, 232, 172, 115, 267, 267, 267, 267, 360, 135, 135, 135, 135, 200, 248, 248, 217, 473, 473, 136, 136, 136, 136, 330, 94, 199, 89, 89, 446, 33, 90, 58, 72, 441, 153, 153, 153, 372, 396, 396, 186, 99, 54, 54, 50, 50, 50, 50, 49, 453, 9, 221, 336, 144, 180, 106, 88, 88, 88, 176, 135, 135, 200, 200, 464, 230, 230, 230, 230, 215, 82, 29, 89, 116, 33, 394, 212, 239, 371, 180, 315, 315, 315, 450, 450, 413, 94, 199, 230, 230, 230, 215, 82, 29, 242, 116, 33, 212, 384, 180, 180, 315, 315, 315, 315, 450, 450, 413, 413, 303, 48, 48, 13, 78, 244, 244]
torch.Size([1, 148, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134500-0032
generate
 55%|█████▍    | 35/64 [03:48<02:08,  4.43s/it]processing 35th semantic_sys file
35
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FRANK READ ENGLISH SLOWLY AND THE MORE HE READ ABOUT THIS DIVORCE CASE THE ANGRIER HE GREW
2024-03-11 08:58:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:58:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
453
[17, 17, 261, 380, 380, 499, 288, 365, 365, 365, 360, 200, 76, 458, 192, 472, 133, 42, 42, 42, 147, 147, 380, 288, 443, 443, 240, 240, 325, 335, 14, 411, 188, 121, 360, 360, 200, 248, 212, 81, 81, 81, 81, 459, 271, 271, 99, 447, 447, 447, 447, 482, 482, 482, 26, 26, 386, 386, 431, 431, 84, 496, 496, 274, 274, 359, 359, 359, 474, 474, 474, 474, 474, 19, 19, 19, 454, 454, 454, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 412, 83, 55, 55, 322, 67, 466, 466, 22, 283, 455, 455, 217, 217, 217, 70, 70, 70, 138, 138, 138, 138, 138, 138, 138, 138, 372, 372, 372, 59, 396, 313, 58, 183, 183, 451, 451, 30, 30, 30, 30, 301, 301, 42, 42, 42, 147, 147, 380, 380, 288, 443, 443, 120, 120, 120, 120, 120, 282, 282, 37, 37, 24, 131, 404, 439, 439, 439, 439, 439, 439, 439, 439, 237, 237, 237, 237, 237, 237, 28, 140, 28, 28, 140, 362, 362, 362, 362, 140, 362, 362, 140, 362, 140, 362, 140, 140, 362, 362, 218, 218, 140, 218, 218, 218, 218, 140, 218, 218, 218, 140, 218, 218, 218, 218, 218, 218, 140, 218, 218, 140, 218, 218, 140, 218, 218, 218, 218, 218, 218, 218, 218, 140, 366, 366, 366, 366, 366, 366, 366, 366, 140, 366, 366, 140, 366, 366, 366, 140, 366, 366, 366, 366, 366, 366, 366, 316, 316, 316, 316, 316, 316, 73, 73, 73, 289, 209, 209, 287, 287, 255, 255, 8, 8, 354, 180, 180, 113, 113, 113, 113, 450, 167, 35, 35, 401, 401, 127, 114, 258, 258, 258, 31, 54, 86, 238, 6, 272, 490, 490, 173, 4, 280, 280, 153, 153, 153, 153, 372, 372, 372, 396, 396, 271, 186, 39, 54, 390, 390, 390, 390, 390, 18, 18, 112, 112, 439, 439, 439, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 225, 225, 225, 80, 80, 80, 289, 320, 445, 445, 351, 343, 343, 171, 171, 252, 186, 39, 54, 86, 86, 198, 198, 22, 448, 448, 448, 464, 464, 145, 145, 365, 365, 360, 360, 200, 248, 212, 79, 79, 495, 382, 337, 337, 464, 464, 334, 382, 382, 245, 245, 183, 183, 451, 30, 30, 30, 30, 422, 416, 458, 208, 79, 79, 380, 380, 288, 288, 374, 374, 132, 132, 132, 132, 98, 98, 98, 98, 13]
torch.Size([1, 451, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134500-0000
generate
 56%|█████▋    | 36/64 [03:57<02:44,  5.89s/it]processing 36th semantic_sys file
36
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: JUST SMELL THE WILD ROSES THEY ARE ALWAYS SO SPICY AFTER A RAIN
2024-03-11 08:58:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:58:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
266
[17, 296, 395, 395, 151, 151, 151, 169, 150, 150, 54, 86, 238, 238, 6, 6, 478, 66, 66, 232, 232, 482, 105, 105, 336, 196, 473, 189, 189, 189, 189, 189, 139, 139, 139, 139, 293, 293, 293, 497, 122, 216, 22, 283, 455, 455, 43, 43, 364, 364, 276, 276, 346, 346, 346, 265, 265, 85, 85, 85, 139, 139, 293, 293, 122, 122, 122, 131, 133, 133, 147, 147, 380, 288, 496, 496, 496, 496, 274, 368, 368, 368, 453, 168, 168, 50, 50, 50, 50, 50, 50, 185, 185, 269, 269, 390, 390, 18, 112, 112, 427, 56, 56, 56, 56, 56, 47, 140, 2, 140, 140, 2, 2, 140, 316, 140, 73, 140, 140, 320, 7, 127, 0, 0, 0, 0, 464, 464, 353, 353, 353, 353, 353, 245, 14, 14, 14, 411, 411, 297, 297, 297, 297, 297, 297, 293, 293, 43, 43, 345, 109, 109, 109, 324, 324, 422, 186, 162, 162, 482, 482, 172, 115, 344, 344, 344, 344, 344, 274, 274, 186, 162, 162, 482, 482, 482, 105, 105, 336, 336, 354, 106, 265, 428, 428, 146, 146, 252, 186, 39, 39, 342, 224, 224, 224, 41, 41, 41, 41, 41, 19, 19, 19, 454, 454, 454, 414, 414, 82, 80, 80, 80, 82, 412, 83, 83, 145, 145, 460, 460, 460, 460, 169, 402, 402, 96, 36, 272, 300, 495, 495, 495, 406, 467, 467, 44, 44, 44, 245, 42, 42, 42, 147, 147, 380, 380, 288, 290, 290, 290, 290, 290, 290, 434, 434, 434, 434, 339, 303, 303, 303, 117, 48, 48, 48, 414]
torch.Size([1, 264, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134500-0006
generate
 58%|█████▊    | 37/64 [04:04<02:40,  5.96s/it]processing 37th semantic_sys file
37
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I LIKE TO TALK TO CARL ABOUT NEW YORK AND WHAT A FELLOW CAN DO THERE
2024-03-11 08:58:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:58:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
295
[17, 17, 287, 287, 111, 111, 111, 438, 438, 251, 251, 241, 266, 266, 266, 266, 266, 146, 252, 143, 458, 96, 96, 401, 82, 75, 108, 108, 377, 377, 344, 374, 374, 132, 422, 236, 129, 82, 75, 108, 108, 119, 119, 437, 437, 437, 405, 405, 405, 405, 206, 178, 178, 233, 233, 233, 82, 192, 192, 419, 419, 439, 439, 78, 78, 244, 47, 47, 244, 244, 244, 244, 73, 73, 73, 244, 75, 108, 377, 377, 344, 374, 374, 374, 374, 132, 132, 143, 458, 144, 144, 27, 27, 437, 437, 306, 306, 306, 306, 306, 306, 396, 396, 467, 467, 302, 302, 375, 375, 98, 98, 98, 98, 225, 225, 225, 225, 225, 225, 225, 225, 225, 412, 412, 287, 255, 255, 255, 8, 8, 239, 354, 180, 113, 113, 113, 113, 113, 450, 167, 167, 457, 457, 196, 196, 309, 479, 398, 398, 398, 374, 374, 132, 132, 219, 219, 219, 219, 485, 485, 106, 153, 153, 153, 372, 372, 372, 59, 59, 59, 452, 233, 233, 233, 233, 82, 144, 192, 419, 419, 439, 439, 78, 78, 170, 244, 244, 312, 312, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 260, 260, 163, 163, 244, 316, 316, 244, 73, 244, 244, 412, 412, 83, 55, 55, 322, 67, 250, 250, 364, 276, 181, 181, 181, 181, 285, 285, 44, 44, 44, 349, 349, 205, 234, 234, 261, 25, 180, 180, 443, 139, 175, 175, 175, 81, 84, 84, 496, 274, 143, 129, 458, 144, 445, 445, 389, 389, 389, 116, 33, 33, 394, 394, 212, 239, 384, 371, 371, 374, 374, 374, 374, 374, 132, 216, 216, 216, 114, 114, 114, 264, 264, 264, 264, 264, 264, 468, 59, 59, 452, 452, 452, 452, 263, 263]
torch.Size([1, 293, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134500-0024
generate
 59%|█████▉    | 38/64 [04:09<02:31,  5.84s/it]processing 38th semantic_sys file
38
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I CAN'T PRAY TO HAVE THE THINGS I WANT HE SAID SLOWLY AND I WON'T PRAY NOT TO HAVE THEM NOT IF I'M DAMNED FOR IT
2024-03-11 08:58:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:58:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
287
[17, 17, 296, 111, 111, 111, 438, 143, 458, 458, 445, 351, 351, 365, 365, 365, 330, 457, 457, 401, 401, 82, 74, 190, 487, 288, 288, 171, 252, 143, 143, 36, 108, 377, 374, 374, 374, 88, 58, 58, 110, 202, 202, 202, 202, 402, 198, 198, 22, 22, 283, 455, 38, 164, 164, 164, 214, 214, 214, 214, 214, 328, 200, 200, 471, 471, 49, 49, 342, 168, 168, 111, 111, 111, 438, 43, 364, 276, 276, 174, 174, 174, 319, 319, 167, 457, 457, 183, 451, 30, 30, 30, 422, 162, 342, 172, 115, 273, 179, 179, 240, 314, 314, 478, 478, 232, 232, 232, 26, 26, 26, 241, 431, 431, 84, 496, 496, 274, 274, 175, 359, 359, 474, 474, 474, 474, 19, 19, 19, 454, 454, 454, 225, 225, 80, 20, 20, 20, 83, 55, 322, 94, 199, 199, 111, 111, 438, 378, 43, 364, 276, 109, 174, 350, 350, 167, 457, 457, 457, 401, 82, 74, 190, 190, 487, 288, 403, 403, 403, 171, 252, 339, 94, 479, 331, 307, 307, 307, 61, 167, 457, 457, 82, 108, 108, 377, 377, 344, 374, 374, 132, 132, 58, 58, 110, 110, 202, 202, 202, 202, 173, 402, 198, 198, 127, 114, 57, 57, 203, 53, 10, 10, 309, 331, 307, 307, 307, 307, 61, 285, 285, 34, 118, 118, 118, 118, 402, 106, 111, 111, 111, 319, 203, 203, 64, 394, 212, 384, 371, 180, 365, 365, 365, 365, 282, 282, 203, 53, 394, 76, 393, 234, 155, 155, 332, 332, 332, 406, 406, 467, 499, 428, 428, 146, 146, 252, 143, 143, 36, 108, 119, 119, 351, 213, 213, 213, 246, 246, 246, 19, 19, 454, 454, 454, 78, 20, 20]
torch.Size([1, 285, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_237-134500-0041
generate
 61%|██████    | 39/64 [04:15<02:23,  5.74s/it]processing 39th semantic_sys file
39
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: A BRISK WIND HAD COME UP AND WAS DRIVING PUFFY WHITE CLOUDS ACROSS THE SKY
2024-03-11 08:59:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:59:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
224
[17, 296, 296, 44, 44, 44, 8, 8, 354, 190, 380, 380, 288, 278, 278, 31, 39, 54, 86, 105, 105, 336, 208, 208, 133, 364, 276, 109, 109, 109, 278, 330, 330, 330, 388, 195, 195, 64, 212, 131, 183, 110, 254, 254, 254, 254, 314, 131, 472, 221, 458, 144, 27, 27, 351, 319, 319, 319, 203, 53, 53, 70, 230, 230, 230, 230, 230, 230, 215, 233, 233, 82, 75, 419, 419, 427, 82, 247, 312, 126, 126, 292, 292, 292, 292, 23, 23, 408, 408, 408, 391, 391, 140, 412, 412, 83, 55, 322, 322, 250, 345, 345, 141, 141, 141, 281, 9, 142, 221, 161, 161, 79, 499, 499, 499, 428, 85, 146, 173, 173, 176, 135, 135, 200, 248, 248, 465, 465, 74, 437, 437, 437, 319, 169, 349, 352, 25, 41, 324, 324, 301, 378, 43, 276, 346, 346, 428, 428, 146, 146, 457, 457, 401, 401, 82, 144, 208, 425, 386, 386, 431, 315, 315, 315, 315, 450, 450, 450, 37, 37, 24, 77, 270, 323, 168, 255, 255, 143, 82, 208, 208, 190, 487, 499, 499, 405, 405, 169, 150, 54, 86, 86, 198, 198, 22, 283, 283, 38, 162, 68, 68, 105, 336, 144, 180, 180, 265, 265, 265, 265, 265, 85, 85, 85, 207, 207, 207, 19, 454, 454, 454, 439, 439, 78]
torch.Size([1, 222, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_tbefore_semantic:
after is :
732
[17, 17, 296, 296, 66, 482, 482, 238, 238, 6, 272, 371, 485, 485, 374, 374, 374, 374, 374, 252, 143, 449, 449, 449, 134, 134, 134, 134, 359, 359, 474, 474, 474, 474, 474, 474, 19, 19, 19, 19, 454, 454, 454, 78, 78, 170, 170, 20, 47, 20, 47, 20, 47, 47, 47, 20, 47, 47, 20, 316, 316, 20, 73, 73, 289, 320, 7, 345, 345, 141, 141, 141, 141, 281, 453, 9, 142, 221, 336, 336, 354, 354, 62, 62, 62, 62, 62, 62, 62, 62, 146, 146, 438, 58, 183, 183, 183, 183, 257, 257, 257, 257, 257, 257, 31, 31, 162, 232, 232, 232, 172, 172, 115, 115, 273, 273, 265, 265, 265, 265, 265, 85, 85, 85, 85, 299, 299, 37, 24, 24, 131, 34, 340, 340, 340, 116, 94, 199, 199, 44, 38, 349, 349, 234, 234, 261, 425, 425, 425, 386, 386, 431, 431, 486, 486, 376, 376, 376, 376, 460, 460, 169, 169, 169, 99, 99, 436, 436, 338, 338, 338, 18, 18, 112, 439, 78, 56, 56, 170, 20, 28, 20, 28, 28, 20, 28, 28, 20, 362, 362, 20, 362, 362, 20, 20, 362, 20, 362, 362, 20, 362, 362, 218, 218, 218, 20, 218, 218, 20, 218, 218, 218, 20, 218, 218, 218, 218, 218, 20, 218, 218, 218, 218, 20, 20, 218, 218, 218, 218, 20, 218, 218, 218, 218, 218, 20, 366, 20, 366, 366, 20, 366, 366, 20, 366, 366, 20, 366, 366, 366, 366, 366, 366, 20, 316, 316, 316, 316, 73, 73, 289, 289, 209, 83, 83, 55, 55, 55, 322, 322, 67, 67, 394, 394, 212, 212, 239, 127, 127, 114, 361, 361, 361, 361, 361, 361, 361, 282, 282, 282, 282, 388, 388, 195, 195, 195, 195, 195, 195, 117, 117, 404, 404, 225, 197, 197, 7, 7, 127, 127, 127, 0, 0, 0, 0, 0, 301, 301, 8, 32, 239, 354, 354, 106, 496, 496, 496, 496, 496, 496, 274, 274, 169, 169, 164, 164, 164, 164, 164, 164, 164, 97, 97, 97, 225, 225, 225, 225, 80, 80, 80, 80, 320, 354, 354, 420, 420, 420, 416, 416, 239, 445, 445, 210, 210, 210, 210, 210, 210, 210, 330, 330, 388, 33, 33, 394, 90, 90, 393, 393, 234, 234, 234, 261, 261, 25, 485, 444, 213, 213, 213, 286, 286, 139, 139, 175, 175, 175, 81, 176, 176, 176, 135, 135, 135, 328, 200, 200, 200, 248, 335, 440, 440, 255, 255, 8, 8, 354, 354, 180, 113, 113, 113, 113, 113, 113, 450, 167, 167, 35, 401, 401, 198, 127, 114, 114, 57, 57, 57, 57, 57, 203, 53, 53, 394, 394, 76, 465, 108, 108, 377, 377, 377, 374, 374, 374, 374, 374, 374, 374, 132, 132, 132, 132, 132, 132, 132, 98, 98, 98, 13, 13, 13, 78, 20, 170, 170, 20, 20, 28, 28, 28, 2, 20, 2, 2, 2, 2, 2, 2, 2, 2, 163, 20, 163, 163, 20, 316, 316, 316, 316, 316, 20, 73, 73, 73, 289, 209, 209, 145, 145, 145, 486, 486, 460, 460, 169, 150, 150, 54, 54, 54, 22before_semantic:
after is :
654
[17, 17, 296, 66, 66, 482, 482, 238, 6, 6, 272, 371, 485, 374, 374, 374, 374, 132, 285, 285, 26, 134, 134, 359, 474, 474, 474, 474, 324, 301, 378, 345, 345, 141, 141, 141, 281, 9, 142, 221, 336, 354, 354, 62, 62, 62, 62, 62, 146, 146, 257, 257, 257, 257, 257, 31, 232, 232, 172, 172, 115, 273, 273, 265, 265, 265, 265, 265, 265, 85, 85, 85, 85, 299, 299, 299, 37, 24, 24, 131, 404, 439, 78, 78, 170, 20, 20, 20, 312, 312, 312, 292, 292, 292, 292, 292, 292, 292, 292, 292, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 408, 408, 408, 149, 149, 228, 20, 412, 188, 188, 340, 340, 340, 94, 199, 44, 44, 38, 349, 234, 234, 261, 425, 425, 386, 431, 431, 486, 376, 376, 376, 460, 460, 169, 169, 99, 436, 436, 447, 395, 89, 89, 446, 116, 466, 466, 466, 361, 361, 361, 361, 361, 361, 388, 388, 195, 195, 195, 117, 117, 48, 48, 417, 417, 417, 417, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 20, 362, 362, 362, 362, 20, 20, 362, 362, 20, 362, 20, 362, 20, 362, 20, 20, 362, 218, 218, 218, 20, 218, 218, 218, 20, 218, 218, 218, 218, 218, 218, 218, 218, 20, 218, 218, 20, 218, 218, 20, 218, 20, 218, 218, 218, 218, 218, 20, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 20, 218, 218, 20, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 20, 218, 218, 218, 218, 218, 218, 218, 218, 20, 366, 366, 20, 366, 366, 366, 366, 366, 366, 20, 366, 366, 20, 366, 366, 20, 366, 20, 366, 366, 366, 20, 316, 316, 316, 316, 316, 73, 73, 289, 320, 127, 127, 5, 5, 455, 455, 32, 32, 239, 354, 354, 106, 106, 496, 496, 496, 496, 496, 274, 169, 169, 164, 164, 164, 164, 164, 164, 164, 97, 225, 225, 225, 225, 80, 80, 80, 80, 320, 354, 420, 420, 420, 416, 445, 210, 210, 210, 210, 330, 388, 33, 394, 90, 393, 234, 234, 261, 25, 485, 485, 485, 286, 139, 139, 175, 175, 81, 176, 176, 135, 328, 200, 200, 464, 255, 255, 8, 8, 354, 180, 113, 113, 113, 113, 113, 167, 35, 35, 198, 127, 114, 57, 57, 57, 203, 381, 381, 381, 381, 117, 48, 48, 48, 417, 170, 170, 170, 170, 20, 28, 28, 28, 28, 2, 2, 2, 2, 20, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 20, 2, 163, 163, 163, 20, 163, 163, 163, 163, 163, 163, 316, 316, 316, 316, 316, 73, 289, 289, 289, 75, 108, 377, 374, 374, 374, 374, 132, 88, 88, 145, 145, 145, 486, 486, 460, 169, 150, 54, 54, 224, 494, 494, 469, 313, 236, 36, 108, 119, 351, 290, 290, 290, 290, 434, 434, 339, 339, 466, 22, 22, 283, 455, 38, 99, 338, 338, 338, 395, 470, 470, 171, 171, 171, 171, 358, 358, 358, 215, 233, 233, 233, 354, 419, 419, 439, 439, 439, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 412, 83, 83, 89, 446, 446, 67, 33, 394, 90, 465, 259, 445, 445, 445, 351, 351, 264, 468, 468, 468, 468, 468, 469, 469, 178, 96, 96, 36, 36, 272, 300, 334, 334, 334, 59, 59, 59, 452, 452, 452, 263, 263, 263, 225, 225, 225, 225, 225, 225, 225, 412, 412, 69, 69, 223, 130, 130, 198, 198, 127, 114, 258, 258, 258, 258, 31, 54, 54, 142, 142, 4, 280, 280, 106, 106, 481, 424, 424, 182, 182, 182, 182, 375, 375, 122, 122, 233, 75, 227, 419, 419, 439]
torch.Size([1, 652, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0028
generate
 66%|██████▌   | 42/64 [04:43<03:19,  9.08s/it]processing 42th semantic_sys file
42
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WARRENTON SPOKE THUS WITH SIGNIFICANCE TO SHOW ROBIN THAT HE WAS NOT TO THINK GEOFFREY'S CLAIMS TO THE ESTATE WOULD BE PASSED BY
2024-03-11 08:59:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:59:28 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
513
[17, 17, 296, 296, 276, 276, 276, 153, 153, 153, 372, 372, 372, 467, 467, 467, 242, 242, 348, 64, 64, 76, 465, 108, 449, 242, 242, 275, 275, 275, 116, 195, 195, 195, 195, 195, 117, 117, 117, 117, 117, 117, 117, 197, 197, 478, 66, 66, 482, 482, 482, 482, 482, 105, 105, 105, 336, 336, 336, 354, 106, 496, 496, 496, 496, 274, 274, 143, 35, 35, 401, 401, 401, 401, 401, 20, 127, 127, 114, 180, 151, 151, 151, 151, 169, 169, 150, 39, 39, 54, 390, 390, 390, 18, 18, 112, 427, 56, 56, 247, 312, 126, 126, 292, 292, 292, 292, 292, 292, 23, 23, 23, 23, 408, 408, 391, 391, 20, 20, 20, 320, 345, 333, 333, 220, 220, 162, 232, 232, 172, 172, 115, 273, 278, 278, 416, 416, 196, 196, 196, 199, 278, 278, 278, 173, 280, 469, 469, 469, 469, 458, 192, 192, 11, 11, 11, 379, 379, 379, 471, 77, 77, 269, 390, 390, 390, 390, 390, 390, 390, 18, 97, 97, 97, 97, 97, 97, 97, 225, 225, 225, 225, 225, 225, 80, 20, 80, 20, 80, 20, 75, 108, 377, 377, 374, 374, 374, 132, 186, 186, 99, 338, 338, 395, 395, 84, 84, 84, 496, 496, 274, 274, 42, 42, 147, 147, 380, 499, 499, 405, 405, 405, 206, 206, 215, 8, 29, 242, 275, 275, 116, 195, 195, 195, 195, 195, 117, 404, 404, 263, 13, 78, 229, 20, 247, 312, 126, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 408, 408, 408, 391, 391, 20, 20, 20, 289, 320, 45, 45, 45, 45, 45, 325, 183, 183, 451, 30, 30, 30, 378, 378, 345, 141, 141, 141, 281, 453, 9, 196, 196, 309, 479, 331, 307, 307, 307, 307, 61, 61, 167, 167, 35, 35, 401, 401, 401, 401, 75, 108, 108, 377, 377, 344, 374, 374, 374, 374, 132, 422, 143, 164, 164, 164, 214, 214, 214, 360, 200, 200, 76, 76, 401, 401, 401, 401, 310, 107, 107, 395, 395, 329, 329, 329, 329, 329, 169, 349, 205, 155, 29, 29, 495, 382, 313, 313, 368, 269, 9, 142, 221, 221, 336, 144, 144, 208, 208, 425, 386, 386, 386, 431, 431, 290, 290, 290, 290, 434, 434, 434, 434, 434, 203, 381, 381, 471, 471, 185, 49, 269, 323, 323, 390, 18, 18, 18, 97, 225, 56, 56, 80, 80, 80, 20, 108, 377, 377, 123, 123, 374, 374, 216, 216, 22, 448, 448, 448, 464, 464, 255, 255, 38, 162, 232, 232, 482, 482, 238, 6, 272, 470, 470, 470, 171, 171, 171, 358, 358, 358, 385, 457, 133, 133, 345, 345, 389, 389, 389, 314, 314, 32, 239, 354, 420, 420, 420, 301, 143, 129, 259, 259, 74, 74, 351, 311, 311, 311, 311, 311, 311, 311, 311, 311, 169, 150, 150, 54, 86, 238, 6, 6, 472, 472, 221, 336, 354, 354, 62, 62, 62, 62, 62, 62, 85, 85, 207, 207, 19, 19, 19, 454, 454, 454]
torch.Size([1, 511, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0035
generate
 67%|██████▋   | 43/64 [04:54<03:24,  9.74s/it]processing 43th semantic_sys file
43
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE HOURS PASSED WEARILY BY AND MOVEMENT COULD YET BE HEARD ABOUT THE HALL
2024-03-11 08:59:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
An exception occurred: 'aɪʊɹ'
processing 44th semantic_sys file
44
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FROM THE BLACKNESS BEHIND THE LIGHT THEY HEARD A VOICE WARRENTON'S
2024-03-11 08:59:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:59:39 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([60], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
184
[17, 17, 165, 165, 165, 165, 466, 466, 22, 283, 455, 455, 8, 259, 354, 425, 425, 431, 376, 376, 376, 376, 460, 178, 178, 35, 96, 96, 196, 459, 459, 459, 271, 31, 342, 86, 221, 221, 336, 354, 420, 420, 422, 58, 72, 72, 72, 480, 480, 480, 480, 480, 85, 299, 299, 339, 64, 64, 212, 198, 198, 22, 283, 283, 455, 251, 251, 251, 241, 431, 431, 428, 428, 428, 146, 146, 358, 358, 358, 385, 233, 233, 197, 20, 20, 80, 20, 80, 20, 20, 127, 0, 0, 0, 0, 422, 422, 58, 72, 72, 498, 498, 498, 498, 498, 396, 396, 313, 24, 325, 34, 34, 44, 44, 173, 4, 280, 280, 343, 343, 343, 343, 343, 343, 343, 358, 358, 186, 39, 54, 54, 142, 397, 397, 336, 276, 276, 153, 153, 372, 372, 372, 467, 467, 242, 242, 116, 64, 76, 465, 108, 119, 351, 351, 256, 365, 365, 365, 365, 282, 282, 282, 282, 282, 379, 303, 303, 471, 471, 471, 471, 270, 433, 390, 390, 390, 18, 18, 112, 112, 56, 56, 56, 20]
torch.Size([1, 182, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sybefore_semantic:
after is :
528
[17, 17, 296, 451, 451, 30, 30, 30, 464, 464, 464, 121, 121, 121, 53, 53, 394, 76, 259, 74, 74, 425, 425, 425, 386, 386, 386, 153, 153, 153, 153, 387, 387, 387, 387, 71, 368, 49, 9, 142, 142, 219, 477, 477, 477, 477, 477, 477, 132, 132, 132, 98, 98, 98, 98, 13, 13, 78, 170, 170, 140, 28, 28, 140, 28, 140, 2, 140, 2, 2, 2, 2, 2, 2, 140, 163, 140, 163, 163, 163, 140, 163, 163, 316, 316, 140, 73, 73, 140, 140, 209, 83, 145, 443, 443, 443, 443, 169, 150, 150, 39, 54, 86, 86, 238, 6, 6, 108, 108, 377, 377, 87, 87, 87, 8, 8, 420before_semantic:
after is :
256
[17, 296, 296, 147, 380, 499, 499, 405, 405, 405, 206, 215, 215, 35, 29, 242, 242, 116, 33, 33, 394, 90, 76, 82, 144, 445, 445, 445, 351, 351, 264, 264, 264, 468, 468, 396, 169, 349, 349, 205, 262, 262, 262, 262, 359, 359, 359, 474, 474, 166, 166, 301, 301, 239, 384, 490, 490, 490, 490, 162, 232, 172, 172, 115, 273, 432, 432, 432, 330, 64, 64, 212, 191, 191, 191, 314, 198, 22, 22, 283, 455, 251, 251, 241, 431, 431, 486, 376, 376, 460, 460, 285, 285, 334, 334, 59, 59, 452, 452, 263, 229, 82, 82, 312, 312, 187, 292, 292, 292, 292, 292, 23, 23, 408, 408, 408, 149, 228, 140, 140, 83, 55, 55, 322, 67, 90, 393, 205, 261, 261, 25, 180, 315, 315, 315, 450, 413, 64, 212, 34, 34, 57, 57, 203, 53, 478, 162, 232, 172, 172, 115, 273, 279, 279, 279, 279, 293, 293, 169, 186, 162, 232, 232, 482, 172, 172, 115, 273, 374, 374, 374, 374, 132, 413, 94, 199, 255, 255, 236, 129, 259, 74, 437, 437, 125, 125, 125, 125, 125, 348, 33, 394, 90, 393, 234, 234, 234, 261, 25, 25, 498, 498, 498, 498, 498, 396, 396, 203, 203, 53, 250, 250, 147, 147, 380, 499, 499, 405, 405, 405, 405, 206, 178, 178, 35, 458, 192, 192, 41, 324, 324, 324, 301, 416, 32, 239, 208, 79, 79, 380, 288, 288, 315, 315, 315, 315, 315, 450, 450, 413, 413, 303, 243, 131, 419, 427]
torch.Size([1, 254, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0027
generate
 72%|███████▏  | 46/64 [05:04<01:48,  6.04s/it]processing 46th semantic_sys file
46
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE IMPLORES US TO BE DISCREET AS THE GRAVE IN THIS MATTER FOR IN SOOTH HIS LIFE IS IN THE HOLLOW OF OUR HANDS
2024-03-11 08:59:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:59:49 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
481
[17, 17, 296, 451, 451, 451, 30, 30, 464, 464, 121, 121, 53, 394, 76, 259, 74, 425, 425, 425, 386, 386, 153, 153, 153, 153, 387, 387, 387, 71, 71, 71, 49, 453, 142, 219, 477, 477, 477, 477, 477, 477, 477, 477, 132, 132, 132, 98, 98, 98, 13, 13, 170, 170, 20, 170, 28, 28, 20, 20, 20, 28, 28, 28, 20, 2, 20, 20, 2, 20, 2, 2, 20, 2, 2, 20, 366, 366, 366, 366, 20, 366, 366, 366, 20, 366, 316, 316, 316, 20, 316, 316, 73, 73, 20, 289, 209, 209, 83, 145, 253, 253, 253, 253, 150, 150, 54, 86, 238, 6, 336, 108, 377, 377, 374, 374, 374, 374, 374, 301, 8, 8, 354, 354, 420, 420, 420, 420, 246, 246, 246, 246, 246, 246, 246, 246, 19, 19, 454, 454, 454, 225, 225, 225, 225, 225, 225, 225, 80, 80, 80, 20, 384, 490, 490, 490, 490, 162, 54, 482, 482, 105, 105, 105, 336, 208, 79, 79, 487, 288, 288, 213, 213, 213, 246, 358, 358, 358, 233, 36, 36, 227, 227, 227, 419, 419, 419, 419, 439, 439, 225, 225, 225, 225, 225, 225, 412, 412, 83, 253, 253, 253, 253, 453, 453, 9, 198, 198, 22, 5, 5, 455, 416, 239, 208, 208, 79, 79, 380, 288, 288, 171, 171, 171, 252, 173, 173, 280, 34, 340, 340, 340, 116, 466, 466, 466, 114, 258, 258, 258, 258, 31, 342, 86, 142, 221, 196, 217, 70, 65, 486, 486, 460, 460, 169, 36, 449, 449, 449, 300, 334, 334, 334, 355, 355, 355, 355, 452, 452, 263, 263, 263, 13, 13, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 20, 20, 2, 2, 2, 20, 2, 20, 163, 20, 316, 316, 316, 20, 73, 73, 289, 373, 155, 155, 155, 332, 332, 332, 406, 467, 340, 340, 340, 33, 394, 394, 478, 478, 66, 482, 482, 482, 482, 482, 115, 115, 485, 485, 485, 485, 485, 374, 374, 374, 374, 132, 318, 318, 318, 368, 216, 164, 183, 183, 183, 257, 257, 257, 257, 453, 453, 9, 26, 26, 26, 251, 241, 431, 431, 265, 265, 428, 428, 85, 146, 358, 358, 358, 352, 352, 352, 352, 352, 352, 352, 352, 352, 112, 427, 229, 20, 247, 312, 312, 292, 292, 23, 23, 23, 23, 408, 408, 149, 228, 228, 289, 289, 209, 209, 188, 356, 356, 356, 281, 453, 168, 340, 340, 340, 466, 466, 466, 22, 283, 455, 455, 58, 72, 72, 72, 437, 437, 481, 481, 481, 175, 175, 81, 84, 84, 84, 88, 88, 88, 69, 69, 223, 130, 280, 280, 222, 222, 222, 222, 353, 353, 58, 58, 72, 72, 110, 294, 294, 294, 294, 294, 294, 282, 282, 388, 379, 303, 195, 471, 471, 471, 471, 49, 269, 433, 390, 390, 390, 18, 112, 112, 112, 56, 56]
torch.Size([1, 479, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0039
generate
 73%|███████▎  | 47/64 [05:14<02:01,  7.16s/it]processing 47th semantic_sys file
47
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY THEN RENEWED THEIR JOURNEY AND UNDER THE BETTER LIGHT MADE A SAFE CROSSING OF THE STABLE ROOFS
2024-03-11 08:59:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 08:59:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
275
[17, 296, 127, 0, 0, 0, 0, 301, 216, 216, 127, 361, 361, 361, 361, 361, 330, 348, 33, 250, 250, 147, 147, 456, 456, 456, 456, 10, 10, 398, 398, 398, 374, 374, 374, 132, 132, 314, 314, 198, 127, 222, 222, 222, 222, 313, 236, 239, 239, 310, 107, 395, 395, 498, 498, 498, 498, 396, 313, 94, 41, 41, 41, 324, 324, 3, 3, 3, 440, 440, 89, 55, 446, 322, 94, 335, 335, 411, 287, 319, 319, 319, 319, 348, 64, 212, 212, 300, 382, 382, 313, 313, 216, 216, 198, 22, 283, 455, 455, 8, 239, 259, 354, 180, 443, 443, 443, 443, 285, 285, 300, 382, 382, 382, 313, 313, 251, 251, 241, 241, 431, 431, 428, 428, 428, 428, 146, 358, 358, 358, 233, 131, 419, 427, 229, 82, 247, 312, 187, 187, 187, 408, 391, 140, 140, 140, 140, 320, 7, 217, 473, 476, 476, 476, 476, 252, 325, 325, 34, 44, 44, 38, 162, 162, 232, 232, 172, 172, 115, 273, 470, 171, 171, 171, 171, 252, 252, 349, 402, 402, 221, 221, 82, 208, 208, 208, 190, 190, 499, 499, 405, 405, 405, 405, 405, 206, 206, 150, 39, 54, 54, 224, 224, 176, 176, 176, 328, 328, 200, 200, 335, 335, 440, 440, 69, 69, 223, 130, 130, 198, 22, 22, 283, 455, 38, 162, 162, 482, 482, 238, 6, 272, 371, 470, 171, 171, 171, 171, 252, 252, 8, 8, 100, 100, 497, 497, 497, 497, 42, 42, 147, 147, 147, 380, 380, 288, 288, 496, 496, 496, 496, 274, 358, 358, 352, 352, 270, 270, 270, 323, 323, 18, 18, 112, 427]
torch.Size([1, 273, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0021
generate
 75%|███████▌  | 48/64 [05:20<01:47,  6.75s/it]processing 48th semantic_sys file
48
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HIS TONES RANG PLEASANTLY ON WARRENTON'S EARS AND FORTHWITH A GOOD FELLOWSHIP WAS HERALDED BETWEEN THEM
2024-03-11 09:00:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 09:00:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
285
[17, 17, 373, 257, 257, 257, 31, 54, 86, 238, 6, 108, 119, 119, 351, 84, 84, 496, 496, 274, 413, 413, 413, 379, 471, 471, 49, 9, 142, 397, 42, 42, 147, 380, 380, 189, 189, 189, 365, 365, 365, 282, 328, 328, 200, 200, 248, 248, 76, 465, 74, 425, 425, 386, 386, 151, 151, 151, 368, 453, 342, 224, 11, 11, 379, 379, 457, 457, 359, 359, 474, 474, 474, 324, 3, 464, 464, 125, 125, 125, 125, 348, 33, 250, 250, 364, 276, 276, 153, 372, 372, 372, 467, 467, 242, 116, 64, 76, 108, 119, 351, 242, 242, 116, 33, 394, 77, 453, 168, 168, 286, 286, 286, 286, 286, 286, 286, 468, 468, 59, 304, 304, 304, 304, 185, 185, 269, 269, 433, 160, 18, 97, 225, 225, 226, 226, 140, 140, 83, 83, 55, 55, 322, 322, 67, 90, 393, 205, 205, 261, 25, 148, 148, 148, 148, 372, 396, 169, 164, 164, 397, 397, 345, 333, 333, 220, 220, 164, 164, 44, 44, 44, 44, 416, 239, 82, 144, 484, 484, 484, 484, 314, 314, 90, 393, 393, 234, 261, 25, 25, 106, 481, 175, 175, 175, 431, 431, 496, 496, 274, 274, 186, 99, 436, 436, 436, 395, 459, 459, 459, 459, 215, 215, 129, 82, 82, 74, 397, 345, 345, 141, 141, 281, 281, 9, 9, 142, 72, 72, 72, 110, 264, 264, 468, 468, 406, 406, 467, 302, 302, 497, 497, 122, 122, 34, 191, 191, 191, 314, 314, 314, 32, 354, 354, 255, 236, 236, 36, 108, 119, 397, 441, 487, 360, 360, 360, 360, 434, 339, 339, 466, 466, 114, 57, 57, 57, 57, 203, 381, 381, 381, 48, 48, 417, 417]
torch.Size([1, 283, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0037
generate
 77%|███████▋  | 49/64 [05:26<01:38,  6.55s/it]processing 49th semantic_sys file
49
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FITZOOTH'S HAND RESTED AT LAST UPON THE TOP RUNG OF A LADDER AND SLOWLY THE TRUTH CAME TO HIM
2024-03-11 09:00:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 09:00:11 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
337
[17, 296, 25, 278, 278, 278, 278, 143, 35, 478, 478, 232, 232, 232, 172, 172, 115, 273, 374, 374, 374, 374, 374, 132, 132, 358, 358, 164, 164, 270, 270, 390, 390, 18, 18, 112, 112, 56, 56, 56, 47, 47, 140, 47, 140, 47, 140, 140, 140, 73, 140, 140, 373, 72, 72, 110, 294, 294, 294, 294, 294, 294, 294, 282, 282, 282, 388, 64, 212, 131, 133, 133, 42, 147, 147, 147, 380, 288, 443, 151, 151, 169, 150, 150, 54, 86, 238, 6, 272, 191, 191, 191, 325, 34, 415, 415, 415, 415, 415, 457, 457, 251, 251, 251, 241, 241, 431, 431, 376, 376, 376, 376, 376, 376, 376, 460, 169, 169, 150, 150, 86, 238, 6, 272, 255, 255, 236, 129, 259, 74, 437, 125, 125, 125, 125, 125, 125, 348, 466, 466, 22, 283, 455, 236, 129, 259, 108, 119, 119, 437, 437, 405, 405, 405, 405, 405, 206, 206, 215, 215, 35, 35, 29, 133, 147, 147, 380, 499, 499, 319, 319, 319, 319, 413, 413, 200, 200, 200, 69, 69, 223, 130, 280, 280, 44, 44, 251, 251, 251, 241, 431, 431, 486, 486, 376, 376, 460, 460, 285, 285, 334, 334, 59, 59, 452, 452, 263, 229, 82, 247, 126, 126, 126, 292, 292, 292, 292, 292, 292, 292, 23, 23, 23, 408, 408, 408, 408, 149, 228, 140, 412, 83, 55, 55, 322, 322, 67, 478, 478, 232, 232, 482, 482, 482, 26, 26, 251, 241, 431, 431, 84, 496, 496, 496, 274, 274, 175, 359, 359, 474, 474, 166, 166, 324, 301, 216, 216, 22, 283, 455, 455, 236, 36, 161, 161, 161, 161, 487, 487, 487, 487, 374, 374, 374, 374, 132, 132, 358, 358, 164, 164, 164, 472, 221, 82, 144, 445, 210, 210, 210, 210, 210, 210, 434, 203, 53, 394, 394, 76, 465, 108, 377, 377, 123, 123, 123, 374, 374, 132, 132, 132, 58, 183, 183, 57, 57, 57, 57, 57, 282, 203, 381, 381, 381, 48, 48, 417]
torch.Size([1, 335, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0026
generate
 78%|███████▊  | 50/64 [05:32<01:30,  6.49s/it]processing 50th semantic_sys file
50
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ROBIN FITZOOTH SAW THAT HIS DOUBTS OF WARRENTON HAD BEEN UNFAIR AND HE BECAME ASHAMED OF HIMSELF FOR HARBORING THEM
2024-03-11 09:00:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 09:00:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
332
[17, 296, 296, 380, 329, 329, 329, 8, 29, 242, 242, 116, 33, 90, 90, 393, 205, 261, 25, 278, 278, 278, 143, 478, 478, 232, 232, 232, 172, 172, 273, 374, 374, 374, 374, 132, 132, 358, 186, 164, 164, 164, 164, 97, 97, 225, 197, 197, 197, 197, 197, 66, 66, 232, 172, 172, 115, 273, 106, 106, 481, 481, 481, 182, 182, 182, 293, 293, 122, 216, 45, 45, 45, 45, 45, 325, 183, 183, 257, 257, 257, 257, 257, 281, 453, 9, 9, 221, 32, 239, 384, 180, 180, 315, 315, 113, 450, 450, 450, 167, 35, 270, 54, 54, 224, 69, 462, 130, 402, 402, 364, 276, 276, 276, 153, 327, 327, 372, 372, 406, 467, 467, 242, 116, 76, 36, 108, 449, 275, 275, 275, 275, 303, 303, 117, 404, 404, 225, 225, 110, 254, 254, 254, 254, 314, 314, 239, 137, 137, 137, 137, 94, 199, 319, 319, 319, 319, 348, 33, 394, 90, 393, 205, 261, 261, 25, 470, 264, 264, 264, 264, 264, 264, 264, 468, 468, 59, 59, 452, 452, 263, 229, 414, 414, 82, 312, 312, 187, 187, 187, 187, 187, 12, 12, 140, 12, 12, 140, 163, 163, 140, 391, 140, 140, 73, 140, 140, 412, 83, 55, 55, 322, 67, 67, 183, 451, 30, 30, 30, 30, 301, 301, 8, 354, 420, 420, 420, 422, 143, 259, 445, 210, 210, 210, 210, 210, 203, 53, 53, 44, 44, 44, 38, 99, 338, 338, 338, 338, 395, 470, 290, 290, 290, 290, 434, 434, 203, 64, 64, 212, 34, 223, 223, 223, 130, 280, 57, 57, 57, 203, 203, 53, 394, 478, 162, 232, 172, 115, 273, 279, 279, 279, 279, 279, 293, 293, 349, 349, 393, 155, 155, 332, 332, 332, 245, 58, 72, 72, 72, 437, 306, 306, 306, 306, 396, 396, 8, 29, 29, 495, 495, 406, 176, 176, 135, 135, 200, 248, 248, 248, 114, 114, 57, 57, 57, 203, 381, 381, 381, 48, 48, 417]
torch.Size([1, 330, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0036
generate
 80%|███████▉  | 51/64 [05:39<01:24,  6.48s/it]processing 51th semantic_sys file
51
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: MOST OF ALL ROBIN THOUGHT OF HIS FATHER WHAT WOULD HE COUNSEL
2024-03-11 09:00:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 09:00:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
170
[17, 17, 296, 7, 217, 217, 70, 473, 65, 496, 496, 496, 274, 274, 186, 39, 54, 86, 86, 6, 272, 223, 223, 223, 130, 280, 106, 106, 297, 297, 297, 297, 297, 293, 293, 293, 42, 42, 147, 147, 380, 499, 499, 405, 405, 405, 206, 215, 8, 29, 242, 242, 116, 33, 33, 394, 76, 164, 164, 164, 106, 106, 405, 405, 405, 206, 206, 285, 285, 223, 223, 130, 280, 257, 257, 257, 257, 31, 342, 9, 142, 393, 393, 205, 261, 25, 91, 91, 91, 91, 91, 91, 206, 493, 216, 300, 300, 334, 334, 59, 59, 452, 452, 263, 225, 225, 225, 80, 140, 140, 140, 7, 364, 181, 181, 181, 181, 181, 457, 457, 364, 364, 364, 364, 364, 276, 276, 389, 389, 389, 389, 240, 325, 34, 41, 30, 324, 324, 422, 143, 82, 445, 445, 351, 351, 351, 315, 315, 450, 450, 413, 413, 64, 76, 77, 77, 342, 224, 224, 302, 302, 302, 302, 375, 375, 375, 98, 98, 13, 13]
torch.Size([1, 168, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0002
generate
 81%|████████▏ | 52/64 [05:42<01:07,  5.61s/it]processing 52th semantic_sys file
52
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AS ANY IN ENGLAND I WOULD SAY SAID GAMEWELL PROUDLY THAT IS IN HIS DAY
2024-03-11 09:00:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 09:00:27 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
255
[17, 17, 296, 83, 253, 253, 253, 253, 253, 253, 368, 453, 453, 168, 168, 470, 475, 475, 475, 94, 94, 475, 475, 475, 324, 324, 464, 464, 340, 340, 116, 94, 199, 199, 360, 360, 360, 360, 360, 200, 248, 248, 248, 359, 359, 359, 81, 275, 275, 275, 275, 388, 195, 195, 195, 195, 212, 212, 212, 131, 404, 483, 483, 226, 82, 287, 287, 111, 111, 111, 438, 438, 378, 345, 389, 389, 389, 389, 314, 314, 478, 478, 232, 232, 172, 172, 115, 273, 470, 403, 403, 403, 403, 171, 171, 252, 422, 186, 162, 162, 232, 232, 172, 115, 273, 470, 470, 120, 120, 240, 240, 314, 314, 314, 90, 90, 32, 239, 445, 445, 180, 290, 290, 290, 290, 290, 434, 434, 203, 53, 250, 250, 250, 364, 276, 109, 109, 139, 139, 139, 293, 497, 497, 122, 129, 129, 82, 74, 190, 190, 190, 488, 488, 499, 315, 315, 315, 450, 450, 450, 413, 122, 314, 26, 26, 359, 359, 474, 474, 474, 474, 474, 19, 19, 19, 454, 454, 229, 82, 82, 312, 312, 187, 292, 292, 292, 292, 1, 1, 1, 1, 1, 408, 408, 408, 391, 391, 140, 140, 140, 140, 127, 114, 114, 92, 92, 92, 240, 240, 325, 34, 34, 356, 356, 356, 281, 281, 453, 9, 168, 340, 340, 340, 340, 116, 94, 199, 257, 257, 257, 257, 281, 453, 9, 221, 239, 384, 371, 93, 93, 93, 93, 93, 93, 93, 207, 207, 207, 207, 207, 19, 19, 19, 454, 454]
torch.Size([1, 253, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0011
generate
 83%|████████▎ | 53/64 [05:48<01:00,  5.53s/it]processing 53th semantic_sys file
53
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WILL WHISPERED ROBIN OPENING HIS Dbefore_semantic:
after is :
567
[17, 17, 296, 0, 0, 0, 0, 301, 301, 399, 217, 217, 473, 65, 374, 374, 374, 374, 374, 132, 173, 173, 402, 402, 198, 127, 114, 114, 264, 264, 264, 468, 468, 467, 467, 467, 145, 460, 460, 460, 460, 402, 35, 36, 272, 300, 382, 245, 245, 129, 259, 144, 27, 437, 437, 405, 405, 405, 405, 206, 206, 169, 99, 99, 436, 436, 395, 459, 459, 271, 31, 39, 54, 54, 26, 26, 359, 474, 474, 474, 474, 464, 464, 255, 255, 8, 8, 354, 180, 113, 113, 113, 113, 113, 167, 35, 35, 35, 198, 22, 283, 455, 58, 72, 72, 72, 437, 151, 151, 151, 240, 240, 314, 314, 90, 32, 239, 208, 79, 380, 380, 499, 496, 496, 496, 215, 215, 35, 259, 176, 176, 135, 135, 200, 248, 248, 212, 354, 420, 420, 420, 422, 349, 349, 234, 234, 261, 261, 25, 148, 148, 148, 148, 148, 148, 182, 182, 372, 372, 372, 59, 452, 452, 452, 263, 13, 414, 414, 414, 170, 170, 170, 28, 28, 28, 28, 140, 28, 140, 28, 140, 362, 362, 362, 140, 140, 362, 362, 140, 362, 140, 362, 362, 362, 362, 218, 218, 218, 218, 140, 366, 366, 140, 366, 366, 366, 366, 366, 140, 366, 140, 366, 366, 366, 366, 366, 316, 140, 316, 316, 140, 73, 289, 412, 412, 83, 55, 55, 322, 322, 199, 199, 255, 255, 255, 8, 8, 8, 354, 180, 113, 113, 113, 113, 450, 167, 35, 35, 35, 198, 127, 114, 57, 57, 57, 203, 53, 394, 394, 90, 76, 259, 108, 377, 377, 374, 374, 374, 374, 132, 132, 349, 349, 234, 234, 234, 234, 261, 261, 25, 106, 480, 480, 480, 480, 480, 480, 480, 480, 85, 85, 299, 299, 299, 299, 339, 64, 212, 212, 131, 419, 439, 439, 439, 78, 414, 414, 170, 170, 170, 28, 28, 28, 2, 2, 140, 2, 2, 2, 2, 140, 2, 2, 2, 2, 140, 163, 140, 316, 316, 316, 316, 73, 140, 373, 373, 373, 66, 66, 232, 172, 172, 115, 231, 231, 231, 231, 231, 231, 76, 35, 35, 35, 214, 214, 214, 214, 214, 200, 200, 248, 248, 76, 259, 108, 108, 377, 377, 374, 374, 374, 374, 374, 374, 132, 132, 132, 132, 186, 186, 99, 338, 338, 338, 338, 338, 395, 395, 470, 84, 84, 84, 84, 84before_semantic:
after is :
488
[17, 17, 296, 127, 0, 0, 0, 0, 301, 399, 217, 217, 473, 65, 65, 374, 374, 374, 374, 374, 374, 374, 132, 132, 132, 173, 173, 402, 402, 6, 272, 227, 472, 472, 198, 127, 114, 114, 264, 264, 468, 468, 406, 467, 467, 145, 460, 460, 460, 460, 169, 402, 96, 36, 272, 300, 382, 313, 143, 129, 458, 144, 27, 437, 437, 437, 405, 405, 405, 405, 206, 206, 169, 99, 99, 436, 395, 459, 459, 459, 31, 54, 54, 86, 26, 26, 359, 474, 474, 474, 474, 474, 464, 464, 255, 255, 255, 8, 354, 180, 180, 113, 113, 113, 113, 167, 35, 35, 198, 22, 283, 455, 455, 58, 72, 72, 72, 437, 437, 319, 319, 319, 167, 167, 457, 457, 90, 401, 401, 208, 79, 380, 380, 499, 496, 496, 215, 215, 35, 354, 176, 176, 135, 328, 200, 248, 248, 212, 354, 420, 420, 420, 422, 349, 349, 205, 261, 261, 148, 148, 148, 148, 148, 148, 148, 182, 372, 372, 372, 59, 59, 59, 452, 452, 263, 229, 20, 247, 312, 312, 126, 292, 292, 292, 292, 292, 1, 1, 1, 1, 1, 1, 1, 1, 408, 408, 408, 149, 149, 228, 20, 20, 20, 83, 55, 55, 55, 322, 67, 212, 131, 34, 255, 255, 236, 129, 354, 180, 180, 113, 113, 113, 113, 113, 167, 167, 35, 35, 401, 127, 114, 57, 57, 203, 53, 53, 394, 76, 465, 108, 108, 377, 119, 374, 374, 374, 374, 374, 374, 374, 132, 132, 132, 132, 132, 132, 349, 349, 234, 234, 234, 261, 25, 25, 480, 480, 480, 480, 480, 85, 299, 299, 299, 299, 339, 64, 212, 131, 472, 472, 232, 232, 172, 115, 273, 231, 231, 231, 231, 53, 53, 394, 76, 465, 465, 214, 214, 214, 214, 328, 200, 200, 248, 248, 76, 465, 108, 108, 377, 344, 344, 344, 374, 374, 374, 132, 132, 132, 186, 99, 338, 338, 338, 395, 395, 470, 84, 84, 84, 84, 84, 84, 84, 16, 16, 16, 16, 274, 274, 98, 98, 98, 13, 229, 20, 20, 312, 312, 312, 292, 292, 292, 292, 292, 1, 1, 1, 1, 23, 23, 101, 408, 391, 391, 228, 20, 20, 20, 127, 45, 45, 45, 45, 457, 457, 133, 364, 364, 276, 276, 276, 153, 153, 372, 372, 372, 406, 467, 467, 242, 330, 116, 64, 76, 465, 108, 449, 242, 275, 275, 275, 275, 275, 388, 195, 195, 195, 195, 117, 404, 58, 110, 254, 254, 254, 254, 254, 314, 131, 393, 393, 234, 234, 234, 261, 25, 25, 494, 494, 38, 349, 349, 234, 234, 261, 25, 470, 278, 278, 139, 139, 139, 139, 139, 293, 497, 122, 122, 131, 472, 183, 183, 183, 257, 257, 257, 257, 257, 453, 9, 142, 196, 217, 217, 217, 473, 65, 278, 278, 278, 278, 99, 99, 436, 436, 436, 60, 60, 298, 298, 275, 275, 303, 303, 303, 117, 48, 48]
torch.Size([1, 486, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0024
generate
 86%|████████▌ | 55/64 [06:02<00:59,  6.61s/it]processing 55th semantic_sys file
55
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE WAS IN DEEP CONVERSE WITH THE CLERK AND ENTERED THE HALL HOLDING HIM BY THE ARM
2024-03-11 09:00:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 09:00:47 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
225
[17, 17, 296, 296, 451, 451, 30, 378, 378, 345, 141, 141, 281, 453, 342, 342, 168, 340, 340, 340, 33, 394, 394, 239, 384, 371, 371, 213, 213, 252, 215, 35, 96, 401, 82, 144, 27, 27, 437, 370, 370, 370, 370, 370, 370, 348, 64, 90, 280, 29, 498, 498, 498, 498, 396, 271, 186, 54, 54, 142, 397, 397, 345, 333, 333, 220, 220, 35, 401, 82, 22, 283, 455, 455, 458, 458, 144, 208, 425, 386, 386, 431, 498, 498, 498, 498, 59, 59, 178, 233, 233, 82, 192, 419, 419, 427, 78, 170, 170, 20, 187, 187, 187, 187, 20, 187, 163, 163, 163, 20, 20, 391, 73, 20, 20, 412, 83, 83, 55, 322, 322, 67, 335, 335, 14, 145, 145, 432, 330, 330, 64, 76, 449, 300, 382, 382, 313, 313, 314, 198, 198, 22, 283, 455, 455, 72, 72, 437, 437, 481, 481, 481, 481, 481, 481, 481, 182, 182, 375, 375, 375, 98, 98, 225, 72, 72, 72, 424, 424, 424, 424, 424, 424, 122, 122, 34, 176, 135, 135, 200, 200, 183, 183, 57, 57, 57, 203, 53, 394, 212, 354, 354, 62, 62, 62, 62, 62, 146, 438, 216, 22, 283, 448, 448, 448, 464, 464, 106, 106, 306, 306, 306, 306, 306, 306, 59, 59, 59, 203, 203, 381, 381, 48, 404, 13]
torch.Size([1, 223, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0007
generate
 88%|████████▊ | 56/64 [06:07<00:48,  6.10s/it]processing 56th semantic_sys file
56
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NAY NAY LORDING ANSWERED WARRENTON WITH A HALF LAUGH
2024-03-11 09:00:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 09:00:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
167
[17, 17, 296, 7, 309, 479, 331, 331, 403, 403, 403, 171, 171, 171, 252, 301, 339, 10, 10, 479, 331, 331, 403, 403, 403, 403, 403, 207, 207, 207, 207, 19, 19, 454, 454, 454, 225, 225, 225, 80, 80, 80, 20, 20, 7, 251, 241, 241, 431, 153, 153, 387, 372, 372, 396, 313, 325, 34, 176, 176, 135, 328, 200, 200, 248, 335, 14, 411, 411, 145, 145, 365, 365, 365, 330, 330, 379, 77, 77, 54, 54, 224, 300, 300, 382, 313, 313, 314, 133, 133, 133, 364, 276, 276, 276, 153, 372, 372, 406, 406, 406, 467, 467, 469, 469, 236, 36, 108, 449, 242, 275, 275, 275, 116, 195, 250, 250, 250, 345, 333, 333, 220, 220, 164, 22, 44, 44, 44, 58, 72, 72, 72, 110, 110, 486, 486, 486, 460, 460, 460, 169, 169, 352, 352, 402, 26, 251, 241, 241, 431, 431, 376, 376, 376, 376, 376, 460, 460, 169, 169, 352, 352, 352, 352, 427, 229, 20]
torch.Size([1, 165, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0034
generate
 89%|████████▉ | 57/64 [06:10<00:36,  5.25s/it]processing 57th semantic_sys file
57
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE BEFELL AN ANXIOUS INTERVIEW MISTRESS FITZOOTH ARGUING FOR AND AGAINST THE SQUIRE'S PROJECT IN A BREATH
2024-03-11 09:00:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 09:00:55 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
347
[17, 17, 296, 127, 0, 0, 0, 240, 8, 8, 354, 420, 420, 422, 349, 349, 205, 261, 25, 25, 189, 189, 139, 139, 175, 175, 81, 44, 44, 44, 94, 199, 145, 145, 145, 365, 365, 360, 360, 200, 76, 96, 96, 99, 436, 395, 459, 459, 459, 31, 31, 342, 342, 224, 168, 121, 340, 116, 64, 76, 36, 449, 449, 494, 469, 469, 173, 173, 280, 485, 485, 485, 485, 485, 374, 132, 399, 217, 473, 473, 258, 258, 31, 31, 54, 86, 238, 6, 161, 161, 487, 459, 459, 31, 31, 342, 86, 142, 142, 393, 393, 261, 25, 278, 278, 278, 385, 457, 233, 478, 478, 66, 232, 172, 172, 224, 273, 374, 374, 374, 374, 374, 132, 358, 358, 164, 164, 164, 164, 97, 483, 226, 226, 226, 20, 209, 287, 284, 306, 306, 306, 306, 396, 396, 396, 416, 416, 458, 192, 485, 485, 485, 374, 88, 88, 176, 135, 135, 135, 200, 200, 248, 248, 393, 205, 234, 155, 155, 332, 332, 148, 148, 148, 148, 148, 182, 387, 372, 372, 372, 452, 263, 229, 247, 247, 126, 126, 126, 292, 292, 292, 292, 292, 292, 23, 23, 23, 23, 408, 408, 408, 149, 228, 20, 20, 20, 20, 83, 55, 55, 322, 67, 212, 131, 34, 255, 255, 416, 458, 445, 180, 432, 432, 432, 330, 379, 64, 77, 77, 77, 86, 86, 86, 238, 198, 198, 22, 22, 283, 455, 38, 162, 232, 232, 482, 105, 105, 336, 208, 208, 441, 153, 346, 346, 346, 91, 91, 265, 85, 85, 85, 146, 146, 464, 464, 334, 334, 334, 304, 304, 304, 49, 269, 9, 142, 142, 221, 336, 336, 20, 74, 190, 488, 488, 488, 488, 488, 206, 240, 24, 36, 310, 107, 395, 395, 470, 151, 151, 178, 178, 178, 96, 96, 20, 75, 227, 227, 483, 483, 226, 20, 188, 340, 340, 340, 94, 199, 44, 44, 236, 8, 259, 354, 190, 380, 380, 380, 288, 288, 443, 443, 120, 120, 169, 169, 169, 169, 164, 164, 164, 164, 352, 419, 419, 439, 439, 439]
torch.Size([1, 345, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0001
generate
 91%|█████████ | 58/64 [06:18<00:37,  6.20s/it]processing 58th semantic_sys file
58
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY WERE UPON THE VERGE OF AN OPEN TRAP IN THE FAR CORNER OF THE HUT AND STUTELEY HAD TRIPPED OVER THE EDGE OF THE REVERSED FLAP MOUTH OF THIS PIT
2024-03-11 09:01:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 09:01:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([26], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
439
[17, 296, 296, 127, 0, 0, 0, 378, 378, 347, 347, 347, 347, 467, 255, 215, 129, 259, 74, 74, 437, 125, 125, 125, 125, 125, 348, 466, 466, 466, 22, 283, 455, 455, 4, 4, 4, 280, 280, 498, 498, 498, 498, 498, 396, 396, 313, 24, 310, 107, 107, 395, 69, 223, 130, 130, 280, 44, 44, 44, 94, 199, 199, 106, 410, 410, 410, 215, 215, 259, 29, 242, 242, 242, 116, 33, 33, 394, 76, 310, 161, 161, 161, 161, 487, 487, 487, 487, 288, 288, 288, 120, 120, 120, 120, 282, 282, 215, 215, 321, 75, 354, 89, 340, 340, 116, 466, 22, 283, 455, 38, 349, 234, 234, 234, 261, 261, 25, 106, 306, 306, 306, 372, 396, 396, 245, 143, 458, 321, 144, 208, 208, 441, 441, 441, 153, 153, 153, 387, 387, 396, 94, 94, 300, 382, 382, 382, 467, 69, 69, 130, 130, 402, 198, 198, 22, 283, 455, 58, 72, 72, 72, 437, 437, 405, 405, 405, 405, 206, 206, 167, 167, 385, 233, 321, 75, 227, 419, 483, 440, 440, 89, 89, 446, 446, 67, 394, 478, 478, 232, 232, 482, 482, 482, 238, 238, 6, 272, 371, 470, 374, 374, 374, 374, 132, 457, 26, 26, 359, 359, 359, 474, 474, 474, 474, 474, 19, 19, 19, 454, 229, 140, 140, 247, 312, 126, 292, 292, 292, 326, 326, 326, 326, 326, 326, 326, 101, 101, 408, 149, 228, 140, 321, 412, 110, 254, 254, 254, 254, 314, 314, 36, 75, 108, 161, 161, 161, 487, 487, 288, 189, 189, 189, 215, 215, 96, 96, 75, 272, 472, 483, 14, 411, 411, 410, 410, 410, 410, 410, 410, 410, 173, 280, 280, 29, 382, 313, 216, 216, 22, 22, 283, 455, 455, 14, 14, 411, 411, 411, 145, 443, 120, 120, 120, 120, 120, 120, 120, 120, 120, 37, 37, 24, 24, 310, 107, 107, 395, 69, 69, 130, 130, 402, 198, 198, 22, 22, 283, 455, 455, 42, 147, 456, 456, 456, 456, 456, 4, 4, 4, 4, 4, 280, 280, 498, 498, 498, 498, 396, 396, 186, 186, 54, 54, 86, 238, 272, 472, 393, 393, 234, 261, 425, 425, 386, 431, 431, 376, 376, 376, 376, 460, 460, 167, 457, 457, 401, 321, 321, 7, 217, 217, 473, 65, 315, 315, 315, 315, 450, 450, 450, 169, 169, 164, 164, 164, 164, 164, 69, 69, 223, 130, 130, 198, 198, 198, 114, 258, 258, 258, 258, 31, 54, 86, 142, 221, 336, 321, 75, 74, 74, 351, 351, 351, 278, 120, 120, 120, 120, 385, 385, 385, 75, 75, 227, 419, 439, 78, 140]
torch.Size([1, 437, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0025
generate
 92%|█████████▏| 59/64 [06:28<00:35,  7.08s/it]processing 59th semantic_sys file
59
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE WILL GO OUT TOGETHER TO THE BOWER THERE IS A WAY DOWN TO THE COURT FROM MY WINDOW
2024-03-11 09:01:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 09:01:12 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
237
[17, 296, 345, 152, 152, 152, 378, 345, 389, 389, 497, 122, 416, 144, 180, 84, 496, 88, 88, 88, 106, 113, 113, 113, 167, 167, 35, 36, 377, 494, 87, 416, 416, 445, 180, 443, 443, 493, 493, 216, 300, 300, 382, 313, 236, 129, 259, 108, 108, 119, 119, 351, 374, 374, 374, 132, 132, 132, 216, 216, 22, 22, 283, 455, 455, 8, 354, 354, 180, 486, 486, 315, 315, 450, 450, 450, 182, 372, 372, 334, 59, 59, 59, 452, 263, 229, 82, 247, 126, 126, 292, 292, 292, 292, 292, 292, 23, 23, 23, 23, 23, 23, 23, 23, 260, 260, 260, 260, 260, 391, 391, 391, 140, 140, 140, 7, 7, 127, 127, 114, 0, 222, 468, 468, 406, 467, 356, 356, 281, 9, 9, 168, 255, 255, 43, 364, 276, 109, 109, 403, 403, 403, 171, 171, 252, 252, 314, 239, 384, 371, 180, 315, 315, 315, 315, 450, 413, 413, 394, 76, 108, 377, 377, 123, 123, 123, 123, 216, 22, 283, 283, 455, 455, 129, 82, 144, 208, 208, 441, 441, 441, 153, 153, 153, 153, 372, 372, 372, 396, 385, 233, 233, 131, 393, 393, 155, 155, 165, 165, 165, 165, 53, 70, 70, 46, 46, 46, 46, 438, 438, 43, 43, 364, 276, 109, 109, 278, 330, 116, 33, 64, 64, 212, 371, 180, 84, 84, 84, 84, 84, 16, 375, 98, 98, 98, 13, 13]
torch.Size([1, 235, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0016
generate
 94%|█████████▍| 60/64 [06:32<00:25,  6.35s/it]processing 60th semantic_sys file
60
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: CRIED HE WAVING THE LANTHORN BEFORE HIM TO MAKE SURE THAT THESE WERE NO GHOSTS IN FRONT OF HIM
2024-03-11 09:01:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 09:01:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
505
[17, 17, 296, 208, 208, 190, 487, 499, 499, 499, 499, 265, 265, 265, 85, 85, 85, 146, 146, 146, 24, 131, 183, 183, 451, 451, 30, 30, 30, 301, 378, 43, 364, 276, 109, 109, 109, 403, 171, 171, 171, 171, 252, 173, 173, 280, 176, 176, 135, 135, 200, 200, 248, 248, 212, 198, 22, 283, 455, 455, 251, 251, 241, 241, 431, 431, 365, 365, 365, 365, 365, 282, 282, 388, 388, 33, 394, 76, 465, 164, 164, 106, 106, 153, 153, 153, 153, 387, 387, 372, 372, 372, 59, 59, 59, 59, 59, 59, 59, 452, 452, 263, 263, 13, 78, 170, 170, 170, 28, 28, 28, 28, 140, 2, 2, 140, 2, 2, 2, 2, 2, 2, 2, 140, 366, 366, 140, 163, 163, 163, 163, 140, 316, 316, 316, 140, 73, 73, 140, 320, 7, 354, 420, 420, 420, 422, 349, 349, 205, 155, 25, 148, 148, 148, 148, 148, 372, 372, 396, 313, 58, 183, 183, 183, 183, 57, 57, 57, 57, 57, 57, 57, 57, 57, 282, 282, 282, 203, 203, 381, 381, 381, 117, 404, 404, 13, 78, 170, 140, 170, 28, 140, 28, 28, 28, 28, 28, 140, 2, 2, 2, 140, 2, 2, 2, 2, 2, 2, 140, 163, 163, 163, 163, 163, 163, 163, 163, 163, 316, 316, 140, 73, 73, 73, 289, 321, 321, 108, 108, 377, 377, 374, 374, 374, 374, 374, 132, 399, 399, 217, 473, 473, 476, 476, 476, 476, 476, 252, 143, 458, 458, 96, 99, 338, 338, 338, 395, 395, 395, 487, 498, 498, 498, 498, 498, 468, 59, 59, 59, 59, 59, 452, 452, 263, 263, 263, 13, 78, 170, 170, 170, 28, 28, 28, 28, 140, 28, 28, 140, 362, 140, 362, 362, 362, 140, 362, 362, 362, 362, 362, 362, 362, 362, 362, 362, 362, 218, 218, 218, 218, 140, 218, 218, 218, 218, 218, 218, 140, 218, 218, 140, 218, 218, 218, 218, 218, 218, 218, 218, 218, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 140, 366, 366, 366, 366, 366, 316, 140, 316, 73, 73, 289, 321, 320, 127, 45, 45, 45, 45, 45, 143, 401, 401, 321, 127, 114, 124, 124, 124, 124, 124, 124, 318, 368, 453, 9, 142, 397, 397, 347, 347, 347, 347, 313, 10, 10, 479, 479, 331, 231, 231, 231, 231, 231, 274, 274, 416, 239, 144, 27, 180, 180, 496, 496, 496, 496, 496, 496, 496, 274, 274, 271, 186, 39, 54, 54, 86, 238, 238, 6, 270, 270, 270, 270, 390, 390, 390, 18, 18, 18, 112, 112, 56, 56, 47, 47, 47, 47, 47, 47, 47, 47, 80, 80, 80, 80, 321, 209, 209, 188, 340, 340, 340, 340, 33, 394, 90, 393, 234, 234, 261, 25, 487, 487, 499, 319, 319, 319, 348, 64, 76, 449, 449, 69, 223, 223, 130, 402, 402, 183, 183, 57, 57, 57, 57, 57, 57, 57, 57, 282, 282, 282, 282, 203, 381, 381, 381, 381, 381, 48, 48]
torch.Size([1, 503, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0031
generate
 before_semantic:
after is :
473
[17, 296, 219, 219, 180, 180, 319, 319, 319, 348, 200, 200, 248, 90, 393, 393, 234, 234, 261, 25, 25, 278, 278, 278, 143, 36, 478, 478, 232, 232, 172, 115, 224, 485, 485, 374, 374, 374, 374, 132, 358, 358, 164, 164, 164, 97, 225, 225, 225, 225, 225, 110, 254, 254, 254, 254, 254, 314, 314, 32, 239, 354, 137, 137, 137, 137, 137, 33, 33, 90, 90, 76, 465, 144, 144, 27, 27, 255, 399, 399, 217, 217, 473, 65, 365, 365, 365, 365, 330, 330, 388, 64, 64, 64, 212, 34, 191, 191, 191before_semantic:
after is :
361
[17, 17, 296, 219, 219, 180, 180, 319, 31before_semantic:
after is :
579
[17, 17, 296, 345, 389, 389, 389, 497, 143, 129, 458, 144, 208, 208, 190, 190, 190, 487, 499, 499, 499, 265, 265, 265, 265, 85, 85, 85, 146, 146, 146, 24, 131, 183, 183, 451, 451, 30, 30, 30, 422, 162, 162, 232, 232, 172, 172, 115, 273, 106, 106, 405, 405, 405, 405, 206, 169, 169, 352, 352, 352, 352, 26, 359, 359, 359, 474, 474, 474, 474, 19, 19, 19, 19, 19, 454, 454, 78, 78, 170, 20, 170, 20, 28, 20, 28, 20, 20, 20, 20, 20, 341, 341, 12, 12, 12, 12, 21, 21, 21, 21, 21, 21, 408, 408, 408, 149, 149, 228, 20, 412, 83, 55, 55, 55, 322, 67, 394, 478, 478, 232, 232, 232, 238, 238, 6, 336, 272, 371, 485, 374, 374, 374, 374, 132, 252, 143, 36, 36, 449, 449, 134, 134, 134, 134, 359, 359, 359, 474, 474, 474, 474, 324, 3, 3, 183, 183, 489, 489, 489, 489, 489, 88, 58, 58, 110, 254, 254, 254, 254, 254, 314, 129, 36, 310, 107, 338, 338, 338, 338, 395, 395, 351, 84, 84, 496, 496, 496, 274, 368, 368, 368, 453, 168, 168, 275, 275, 116, 116, 33, 199, 58, 183, 257, 257, 257, 257, 31, 342, 342, 86, 221, 336, 336, 445, 445, 445, 445, 351, 351, 351, 486, 486, 486, 315, 450, 450, 450, 274, 274, 413, 233, 233, 233, 310, 310, 107, 107, 107, 447, 112, 427, 427, 56, 247, 312, 312, 126, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 292, 21, 21, 21, 21, 21, 21, 23, 23, 23, 101, 101, 149, 228, 228, 20, 412, 287, 255, 255, 255, 129, 129, 458, 144, 208, 208, 208, 190, 190, 487, 499, 499, 499, 405, 405, 206, 169, 169, 150, 39, 86, 86, 238, 6, 198, 22, 22, 283, 455, 455, 236, 32, 32, 239, 384, 371, 106, 153, 153, 153, 153, 153, 372, 372, 372, 372, 467, 467, 69, 223, 223, 130, 130, 402, 402, 183, 257, 257, 257, 257, 257, 257, 453, 9, 9, 219, 219, 219, 219, 219, 180, 180, 319, 319, 319, 319, 319, 413, 200, 248, 248, 248, 217, 217, 217, 473, 473, 65, 486, 486, 486, 460, 460, 169, 169, 150, 150, 86, 86, 238, 6, 272, 272, 334, 334, 334, 304, 304, 304, 185, 49, 269, 9, 142, 221, 221, 336, 310, 310, 107, 107, 107, 395, 395, 395, 290, 290, 290, 290, 290, 434, 434, 434, 434, 339, 53, 212, 212, 29, 334, 334, 334, 59, 59, 59, 59, 59, 452, 452, 263, 229, 82, 247, 312, 312, 126, 292, 292, 292, 292, 292, 292, 292, 23, 23, 23, 23, 23, 23, 23, 101, 101, 149, 391, 228, 20, 373, 373, 66, 66, 232, 232, 232, 482, 105, 105, 336, 336, 336, 354, 189, 189, 189, 189, 189, 189, 189, 189, 189, 365, 365, 328, 328, 200, 200, 200, 464, 230, 230, 230, 230, 230, 230, 230, 215, 215, 233, 401, 401, 20, 483, 483, 226, 209, 415, 415, 415, 415, 415, 415, 415, 457, 457, 364, 364, 364, 276, 276, 276, 174, 174, 174, 174, 319, 319, 330, 379, 243, 77, 77, 77, 433, 433, 433, 160, 97, 483, 226, 188, 188, 340, 340, 340, 116, 33, 335, 335, 411, 411, 145, 145, 145, 365, 365, 365, 330, 330, 379, 77, 77, 77, 342, 172, 224, 224, 334, 334, 334, 334, 59, 59, 59, 59, 452, 452, 452, 452, 263, 263, 263]
torch.Size([1, 577, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0015
generate
 97%|█████████▋| 62/64 [06:55<00:17,  8.87s/it]processing 62th semantic_sys file
62
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOUNG FITZOOTH HAD BEEN COMMANDED TO HIS MOTHER'S CHAMBER SO SOON AS HE HAD COME OUT FROM HIS CONVERSE WITH THE SQUIRE
2024-03-11 09:01:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 09:01:40 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
409
[17, 17, 296, 219, 219, 464, 180, 319, 319, 319, 319, 348, 348, 248, 248, 76, 349, 205, 205, 261, 25, 278, 278, 278, 385, 35, 77, 478, 66, 68, 68, 172, 115, 115, 444, 444, 374, 374, 374, 132, 132, 358, 169, 352, 352, 352, 352, 352, 97, 97, 225, 72, 72, 110, 254, 254, 254, 254, 254, 314, 314, 32, 239, 354, 137, 137, 137, 137, 137, 33, 33, 90, 76, 259, 144, 27, 27, 255, 255, 399, 217, 217, 473, 65, 365, 365, 365, 365, 365, 365, 330, 388, 64, 64, 212, 34, 191, 191, 191, 191, 37, 24, 24, 24, 404, 404, 229, 82, 82, 247, 126, 126, 23, 23, 408, 391, 391, 140, 140, 140, 140, 108, 377, 377, 123, 123, 123, 123, 132, 58, 183, 183, 257, 257, 257, 257, 281, 453, 142, 196, 196, 217, 70, 65, 493, 493, 493, 493, 493, 216, 300, 300, 300, 382, 304, 304, 313, 186, 186, 323, 142, 221, 221, 336, 310, 310, 107, 107, 395, 395, 290, 290, 290, 290, 290, 434, 434, 203, 53, 53, 212, 29, 334, 334, 334, 59, 59, 59, 59, 452, 263, 263, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 82, 373, 373, 66, 66, 66, 482, 172, 115, 344, 344, 344, 344, 344, 344, 274, 186, 186, 162, 162, 232, 482, 482, 172, 115, 273, 374, 374, 374, 374, 374, 374, 374, 132, 132, 132, 132, 413, 413, 413, 195, 195, 195, 195, 117, 404, 335, 483, 440, 440, 440, 253, 253, 253, 253, 253, 253, 453, 342, 9, 183, 451, 30, 30, 30, 30, 464, 464, 254, 254, 254, 254, 314, 314, 129, 259, 82, 144, 27, 351, 351, 319, 319, 319, 203, 53, 53, 65, 180, 113, 113, 113, 113, 450, 167, 167, 35, 393, 393, 393, 155, 155, 165, 165, 165, 165, 53, 53, 58, 183, 257, 257, 257, 257, 31, 9, 142, 221, 336, 144, 27, 27, 437, 370, 370, 370, 370, 370, 370, 370, 348, 33, 394, 90, 4, 280, 29, 498, 498, 498, 498, 396, 304, 271, 186, 39, 39, 323, 390, 390, 18, 18, 18, 112, 112, 56, 56, 56, 56, 80, 80, 140, 140, 320, 345, 333, 333, 220, 220, 220, 35, 35, 198, 22, 22, 283, 38, 38, 162, 482, 482, 105, 105, 336, 208, 441, 441, 153, 346, 346, 91, 265, 265, 85, 85, 85, 85, 334, 334, 334, 59, 59, 452, 452, 263, 263]
torch.Size([1, 407, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0000
generate
 98%|█████████▊| 63/64 [06:58<00:07,  7.14s/it]processing 63th semantic_sys file
63
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE WAS NO CHANCE TO ALTER HIS SLEEPING ROOM TO ONE NEARER TO GAMEWELL'S CHAMBER
2024-03-11 09:01:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-11 09:01:43 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
265
[17, 17, 296, 114, 0, 222, 468, 378, 345, 345, 141, 141, 281, 281, 9, 9, 142, 196, 309, 309, 309, 479, 231, 231, 231, 231, 231, 231, 231, 274, 274, 274, 236, 36, 310, 107, 107, 395, 395, 351, 365, 365, 365, 365, 365, 365, 282, 282, 379, 243, 243, 77, 77, 433, 86, 86, 238, 6, 82, 75, 108, 377, 377, 374, 374, 374, 374, 132, 132, 88, 14, 14, 411, 411, 481, 481, 481, 481, 481, 293, 122, 122, 36, 449, 449, 300, 300, 382, 382, 313, 58, 183, 183, 257, 257, 257, 257, 31, 162, 232, 232, 232, 172, 172, 26, 26, 359, 81, 444, 213, 213, 252, 215, 215, 82, 192, 176, 176, 176, 328, 200, 200, 248, 248, 248, 380, 380, 288, 288, 288, 374, 132, 203, 381, 381, 381, 381, 381, 117, 117, 117, 225, 80, 140, 140, 108, 377, 123, 123, 123, 123, 43, 43, 364, 276, 276, 174, 174, 174, 174, 174, 319, 388, 388, 195, 195, 195, 195, 195, 117, 117, 117, 117, 225, 225, 225, 7, 309, 398, 398, 398, 398, 398, 398, 468, 406, 406, 467, 467, 382, 382, 382, 313, 236, 129, 82, 108, 377, 377, 374, 374, 374, 132, 132, 416, 239, 144, 445, 180, 180, 290, 290, 171, 434, 203, 53, 250, 250, 276, 109, 109, 139, 139, 139, 139, 293, 497, 497, 49, 269, 54, 86, 142, 238, 6, 310, 107, 107, 395, 351, 290, 290, 290, 290, 434, 434, 53, 53, 53, 212, 29, 29, 334, 334, 59, 59, 59, 59, 452, 452, 263, 13, 78, 140, 140]
torch.Size([1, 263, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/ar/no-prompt-tts-2stages_topk_stage1_2_topk_stage2_10_steps_16_groupar_2024-03-11_16:54:25
sys_file:gen_61-70970-0013
generate
100%|██████████| 64/64 [07:00<00:00,  5.57s/it]100%|██████████| 64/64 [07:00<00:00,  6.57s/it]
