Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (numpy 1.24.0 (/home/v-zhijunjia/.local/lib/python3.10/site-packages), Requirement.parse('numpy!=1.19.3,<1.24; sys_platform == "linux"'), {'azureml-dataset-runtime'}).
2024-03-25 02:41:41 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
/home/v-zhijunjia/miniconda3/envs/valle-4-23/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MiniBatchKMeans from version 0.24.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
Current working directory: /home/v-zhijunjia/CodecGen
only_antoregressive is True
add_prenet is False
self.ar_text_prenet : Identity()
add_prenet：False
self.encoder_layers:6
self.decoder_layers：6
only_antoregressive is True
add_prenet is False
self.ar_text_prenet : None
add_prenet：False
[]
  0%|          | 0/64 [00:00<?, ?it/s]2024-03-25 02:42:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:42:00 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
  2%|▏         | 1/64 [00:06<06:37,  6.31s/it]2024-03-25 02:42:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:42:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
  3%|▎         | 2/64 [00:18<10:01,  9.70s/it]2024-03-25 02:42:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:42:17 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
  5%|▍         | 3/64 [00:31<11:28, 11.29s/it]2024-03-25 02:42:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:42:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
processing 0th semantic_sys file
0
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT WAS THAT ALL HER REWARD ONE OF THE LADIES ASKED
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
166
[17, 17, 296, 159, 159, 159, 159, 159, 457, 457, 457, 345, 345, 141, 141, 141, 281, 453, 9, 198, 198, 127, 114, 114, 92, 92, 92, 92, 240, 285, 335, 14, 14, 411, 411, 297, 297, 297, 297, 297, 297, 297, 293, 293, 293, 293, 58, 58, 72, 72, 156, 156, 156, 156, 156, 59, 59, 59, 59, 59, 59, 452, 452, 263, 263, 225, 225, 80, 20, 80, 80, 20, 7, 7, 147, 456, 456, 456, 456, 301, 378, 43, 364, 276, 276, 153, 153, 153, 372, 372, 396, 313, 24, 131, 133, 364, 364, 276, 174, 174, 174, 174, 348, 94, 199, 223, 223, 223, 216, 216, 22, 22, 283, 455, 455, 455, 251, 251, 241, 431, 431, 171, 171, 171, 171, 252, 325, 34, 41, 41, 324, 318, 318, 49, 342, 342, 483, 483, 226, 82, 411, 145, 145, 145, 376, 376, 376, 376, 376, 460, 169, 169, 169, 150, 150, 39, 433, 433, 86, 238, 6, 6, 20, 227, 419, 439]
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
torch.Size([1, 164, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_121-127105-0036
generate
processing 1th semantic_sys file
1
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE WAS A UNANIMOUS GROAN AT THIS AND MUCH REPROACH AFTER WHICH IN HIS PREOCCUPIED WAY HE EXPLAINED
enroll_x_lens:tensor([52], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
356
[17, 17, 296, 127, 114, 0, 0, 222, 378, 378, 345, 141, 141, 281, 453, 9, 168, 44, 44, 44, 219, 219, 219, 219, 219, 485, 485, 374, 374, 132, 132, 10, 10, 10, 309, 479, 331, 331, 486, 486, 486, 460, 240, 94, 199, 469, 469, 203, 53, 473, 459, 459, 271, 31, 54, 54, 142, 221, 221, 32, 32, 32, 208, 208, 79, 79, 79, 79, 380, 380, 380, 499, 84, 84, 496, 496, 496, 274, 413, 413, 413, 195, 195, 195, 199, 415, 415, 415, 415, 415, 457, 457, 7, 32, 4, 4, 4, 4, 114, 114, 258, 258, 258, 258, 120, 120, 120, 271, 271, 271, 39, 39, 390, 390, 390, 18, 112, 427, 82, 247, 126, 126, 292, 292, 23, 23, 23, 101, 101, 149, 149, 140, 412, 55, 55, 55, 322, 67, 67, 250, 217, 217, 70, 70, 383, 383, 383, 383, 383, 383, 35, 310, 447, 447, 397, 42, 147, 147, 456, 456, 456, 236, 129, 129, 259, 74, 190, 190, 487, 488, 499, 499, 496, 496, 496, 496, 274, 358, 358, 233, 310, 310, 107, 447, 427, 247, 247, 126, 126, 326, 101, 149, 149, 140, 412, 83, 145, 145, 460, 460, 460, 460, 169, 402, 402, 6, 36, 272, 494, 494, 378, 43, 43, 345, 345, 407, 407, 407, 407, 407, 143, 36, 310, 107, 107, 395, 340, 340, 340, 340, 116, 33, 58, 58, 183, 257, 257, 257, 257, 257, 257, 453, 142, 221, 221, 336, 140, 140, 74, 190, 190, 488, 488, 324, 464, 464, 106, 106, 405, 405, 405, 178, 178, 35, 458, 192, 485, 469, 469, 469, 215, 129, 259, 74, 437, 437, 265, 265, 265, 265, 265, 265, 85, 85, 146, 146, 24, 24, 131, 133, 364, 364, 364, 364, 276, 109, 109, 403, 403, 403, 403, 403, 207, 246, 246, 246, 3, 3, 183, 183, 451, 30, 30, 30, 30, 464, 154, 154, 154, 154, 96, 96, 96, 482, 482, 105, 105, 336, 82, 354, 425, 425, 386, 386, 431, 290, 290, 290, 290, 290, 290, 434, 434, 434, 434, 434, 434, 339, 339, 303, 303, 243, 212, 227, 419, 439]
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
torch.Size([1, 354, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_121-127105-0003
generate
processing 2th semantic_sys file
2
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE AWKWARD THING WAS THAT THEY HAD PRACTICALLY NO OTHER RELATIONS AND THAT HIS OWN AFFAIRS TOOK UP ALL HIS TIME
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
370
[17, 17, 296, 5, 448, 448, 448, 464, 14, 106, 106, 405, 405, 405, 405, 206, 206, 178, 35, 35, 208, 441, 109, 109, 313, 313, 314, 314, 478, 164, 164, 164, 214, 214, 214, 214, 214, 214, 328, 200, 200, 248, 250, 250, 345, 141, 141, 141, 141, 141, 141, 141, 368, 368, 368, 453, 453, 198, 45, 45, 45, 45, 45, 35, 35, 259, 127, 114, 0, 0, 0, 0, 0, 3, 58, 58, 110, 254, 254, 254, 254, 314, 314, 401, 82, 74, 190, 190, 488, 488, 488, 488, 488, 460, 460, 178, 178, 35, 35, 272, 469, 469, 469, 469, 458, 144, 208, 359, 166, 166, 166, 166, 301, 10, 10, 479, 331, 331, 231, 231, 231, 231, 231, 274, 88, 88, 14, 14, 411, 493, 493, 493, 493, 493, 216, 300, 300, 382, 245, 42, 42, 147, 456, 456, 134, 251, 251, 241, 431, 431, 151, 171, 171, 418, 252, 99, 436, 436, 436, 60, 60, 298, 298, 275, 379, 379, 471, 471, 471, 471, 49, 433, 433, 112, 427, 56, 56, 56, 56, 56, 56, 56, 28, 28, 20, 28, 28, 20, 20, 362, 362, 20, 20, 362, 20, 362, 20, 362, 20, 20, 362, 362, 362, 366, 20, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 20, 316, 316, 316, 73, 20, 20, 412, 83, 55, 55, 55, 322, 67, 466, 127, 45, 45, 45, 45, 45, 45, 240, 325, 183, 183, 257, 257, 257, 257, 257, 453, 9, 168, 483, 14, 411, 350, 350, 350, 350, 350, 350, 350, 413, 348, 94, 199, 255, 255, 255, 349, 349, 205, 261, 25, 25, 470, 264, 264, 264, 264, 264, 264, 264, 468, 468, 468, 304, 304, 304, 304, 304, 185, 49, 269, 9, 238, 6, 6, 108, 295, 295, 295, 295, 295, 295, 458, 192, 180, 180, 230, 230, 230, 230, 230, 215, 215, 35, 35, 335, 483, 14, 14, 297, 297, 297, 297, 297, 297, 297, 297, 293, 293, 58, 58, 183, 257, 257, 257, 257, 257, 257, 368, 31, 86, 86, 6, 272, 119, 119, 437, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 85, 85, 85, 299, 299, 299, 299, 303, 303, 303, 48, 48, 48]
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
torch.Size([1, 368, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_121-127105-0028
generate
processing 3th semantic_sys file
3
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize te  6%|▋         | 4/64 [00:40<10:48, 10.81s/it]2024-03-25 02:42:39   8%|▊         | 5/64 [00  8%|▊         | 5/64 [00:53<11:34, 11.77s/it]2024-03-25 02:42:52 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/  8%|▊         | 5/64 [00:58<13:14, 13.46s/it]2024-03-25 02:42:57   9%|▉         | 6/64 [01:  9%|▉         | 6/64 [01:09<12:54, 13.36s/it][17, 296, 296, 111, 111, 111, 438, 143, 458, 192, 389, 389, 389, 314, 133, 42, 147, 380, 499[17, 17, 287, 111, 111, 111, 438, 438, 143, 458, 144, 27, 389, 389, 389, 314, 133, 133, 42, 147, [17, 17, 296, 287, 111, 111, 438, 438, 143, 458, 192, 389, 389, 389, 314, 314, 133, 42, 147, 147, 380, 499, 499, 428, 428, 146, 252, 252, 143, 35, 401, 401, 82, 108, 108, 377, 377, 374, 374, 374, 374, 374, 132, 132, 399, 70, 70, 46, 46, 46, 46, 438, 438, 399, 217, 473, 473, 136, 136, 136, 136, 136, 282, 282, 282, 388, 94, 199, 89, 89, 446, 116, 199, 199, 121, 121, 121, 33, 90, 90, 465, 144, 208, 208, 425, 386, 386, 386, 496, 496, 496, 496, 274, 274, 274, 318, 368, 49, 9, 198, 198, 22, 283, 455, 455, 143, 458, 445, 445, 445, 351, 213, 213, 213, 213, 213, 246, 246, 246, 19, 19, 19, 454, 454, 229, 20, 20, 20, 312, 312, 187, 187, 187, 12, 12, 12, 12, 12, 12, 12, 12, 408, 408, 391, 391, 20, 20, 20, 20, 373, 451, 451, 30, 30, 30, 143, 458, 144, 389, 389, 389, 389, 314, 478, 478, 232, 232, 232, 232, 172, 172, 172, 273, 273, 432, 432, 432, 330, 330, 348, 64, 64, 64, 212, 212, 371, 180, 315, 315, 315, 315, 315, 450, 413, 348, 466, 466, 22, 283, 455, 455, 129, 259, 74, 74, 437, 437, 486, 486, 486, 460, 178, 178, 458, 192, 192, 277, 277, 277, 277, 385, 385, 233, 233, 197, 197, 197, 20, 80, 80, 20, 20, 83, 83, 253, 253, 253, 253, 453, 9, 168, 30, 30, 30, 422, 349, 205, 261, 25, 106, 480, 480, 480, 480, 299, 299, 339, 64, 212, 34, 34, 494, 494, 216, 216, 114, 114, 180, 428, 428, 428, 146, 146, 252, 143, 36, 108, 449, 119, 351, 213, 213, 213, 213, 213, 246, 246, 19, 19, 19, 454]
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
torch.Size([1, 289, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_10_steps_16_2024-03-25_10:41:38
sys_file:gen_121-127105-0005
generate
processing 4th semantic_sys file
4
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT SOUNDED DULL IT SOUNDED STRANGE AND ALL THE MORE SO BECAUSE OF HIS MAIN CONDITION WHICH WAS
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
391
[17, 17, 296, 287, 287, 284, 284, 428, 428, 146, 146, 252, 143, 36, 449, 449, 41, 41, 41, 324, 324, 324, 422, 186, 162, 232, 172, 172, 273, 273, 315, 315, 315, 450, 450, 413, 413, 64, 212, 34, 191, 191, 236, 314, 32, 239, 384, 371, 180, 106, 106, 481, 481, 481, 481, 182, 182, 182, 375, 375, 375, 375, 98, 98, 98, 98, 13, 225, 225, 225, 225, 225, 225, 225, 412, 287, 287, 287, 287, 111, 111, 111, 111, 438, 438, 143, 36, 36, 108, 119, 351, 213, 213, 213, 324, 422, 186, 162, 232, 172, 115, 273, 273, 315, 315, 315, 450, 413, 348, 64, 212, 34, 191, 191, 191, 314, 478, 478, 482, 482, 238, 6, 161, 161, 487, 487, 288, 288, 290, 290, 290, 290, 290, 434, 434, 434, 434, 339, 339, 195, 471, 310, 310, 107, 107, 447, 427, 427, 82, 247, 126, 126, 326, 326, 326, 326, 326, 326, 326, 101, 408, 408, 408, 149, 228, 140, 412, 83, 55, 55, 55, 322, 67, 212, 131, 106, 106, 297, 297, 297, 297, 293, 122, 216, 22, 283, 455, 399, 399, 70, 70, 138, 138, 138, 138, 138, 138, 387, 387, 186, 186, 162, 54, 172, 115, 273, 84, 84, 84, 84, 84, 16, 16, 274, 274, 274, 8, 8, 354, 420, 420, 422, 143, 458, 144, 27, 351, 351, 151, 151, 151, 368, 453, 453, 168, 69, 223, 223, 223, 130, 402, 402, 183, 257, 257, 257, 257, 257, 453, 9, 142, 196, 196, 217, 217, 217, 473, 65, 290, 290, 290, 290, 290, 434, 434, 434, 339, 339, 195, 195, 195, 90, 90, 76, 465, 144, 27, 27, 121, 121, 116, 33, 33, 394, 394, 212, 384, 371, 278, 278, 278, 278, 99, 99, 436, 436, 60, 60, 298, 298, 298, 298, 116, 195, 195, 195, 117, 117, 117, 48, 48, 48, 417, 417, 417, 237, 237, 237, 237, 140, 140, 28, 28, 140, 140, 2, 2, 2, 140, 140, 305, 140, 316, 140, 316, 140, 435, 435, 435, 7, 7, 7, 345, 407, 407, 407, 407, 143, 310, 107, 447, 397, 397, 364, 364, 276, 141, 346, 346, 346, 481, 481, 387, 387, 387, 206, 206, 206, 37, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 269, 323, 390, 390, 18, 18, 112, 439, 439, 78, 128]
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
torch.Size([1, 389, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_10_steps_16_2024-03-25_10:41:38
sys_file:gen_121-127105-0034
generate
processing 5th semantic_sys file
5
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE WERE PLENTY OF PEOPLE TO HELP BUT OF COURSE THE YOUNG LADY WHO SHOULD GO DOWN AS GOVERNESS WOULD BE IN SUPREME AUTHORITY
enroll_x_lens:tensor([33], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
384
[17, 296, 127, 0, 0, 0, 378, 378, 347, 347, 347, 347, 245, 245, 129, 129, 259, 74, 425, 386, 431, 432, 432, 330, 348, 64, 76, 449, 449, 41, 41, 324, 324, 464, 464, 462, 462, 130, 402, 402, 221, 401, 82, 74, 74, 351, 213, 213, 213, 252, 215, 129, 354, 29, 100, 497, 497, 122, 129, 36, 108, 108, 377, 344, 344, 374, 374, 374, 132, 132, 58, 58, 72, 110, 110, 139, 139, 139, 139, 293, 293, 215, 233, 233, 233, 419, 419, 439, 78, 170, 140, 140, 312, 312, 312, 187, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 260, 260, 260, 260, 260, 260, 391, 391, 228, 140, 289, 140, 320, 159, 159, 159, 159, 285, 285, 255, 130, 130, 402, 402, 221, 458, 208, 208, 441, 441, 153, 153, 372, 372, 396, 396, 271, 186, 39, 54, 54, 86, 238, 198, 198, 22, 5, 5, 448, 219, 219, 219, 464, 180, 319, 319, 319, 348, 200, 200, 248, 248, 248, 241, 431, 431, 171, 171, 171, 171, 252, 325, 41, 41, 324, 3, 58, 183, 489, 489, 489, 489, 422, 99, 338, 338, 389, 389, 389, 389, 314, 314, 90, 239, 144, 27, 84, 496, 496, 274, 236, 236, 239, 384, 180, 180, 180, 315, 315, 315, 450, 450, 413, 94, 199, 253, 253, 253, 281, 9, 142, 221, 336, 144, 180, 180, 151, 151, 173, 173, 280, 29, 29, 313, 116, 94, 199, 459, 459, 459, 459, 271, 271, 39, 39, 433, 390, 390, 390, 18, 112, 427, 56, 56, 247, 312, 126, 292, 292, 292, 23, 23, 408, 408, 391, 149, 149, 228, 289, 140, 320, 345, 389, 389, 389, 389, 314, 314, 32, 239, 354, 420, 420, 420, 420, 246, 246, 246, 246, 246, 3, 3, 3, 440, 188, 188, 340, 340, 340, 33, 33, 478, 478, 162, 232, 232, 172, 224, 494, 494, 494, 129, 129, 259, 74, 190, 190, 487, 288, 288, 360, 360, 434, 434, 434, 434, 434, 203, 203, 381, 381, 117, 404, 404, 225, 225, 225, 225, 225, 80, 80, 140, 140, 287, 287, 287, 255, 255, 38, 164, 164, 164, 164, 106, 106, 153, 153, 153, 372, 372, 372, 396, 469, 469, 325, 41, 41, 41, 41, 19, 19, 19, 454, 454]
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
torch.Size([1, 382, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_10_steps_16_2024-03-25_10:41:38
sys_file:gen_121-127105-0029
generate
processing 6th semantic_sys file
6
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE FIRST OF THESE TOUCHES CONVEYED THAT THE WRITTEN STATEMENT TOOK UP THE TALE AT A POINT AFTER IT HAD IN A MANNER BEGUN
enroll 11%|█         | 7/64 [01:23<13:20, 14.05s/it]2024-03-25 02:43:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:43:22 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
 12%|█▎        | 8/64 [01:34<12:02, 12.90s/it]2024-03-25 02:43:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:43:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
 14%|█▍        | 9/64 [01:43<10:56, 11.94s/it]2024-03-25 02:43:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:43:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
synthesize text: THE FIRST OF THESE TOUCHES CONVEYED Ttop_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_knosynthesize text: THE FIRST OF THESE TOUCHES CONVEYED THAT THE WRITTEN STATEMENT TOOK UP THE TALE AT A POINT AFTER IT HAD IN A MANNER BEGUN
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
337
[17, 296, 296, 5, 455, 38, 349, 205, 261, 25, 498, 498, 498, 498, 498, 396, 169, 186, 39, 86, 238, 6, 272, 69, 223, 223, 130, 198, 198, 124, 124, 124, 124, 124, 31, 9, 221, 6, 119, 351, 351, 151, 151, 151, 240, 310, 310, 107, 395, 50, 50, 50, 50, 50, 185, 49, 269, 9, 142, 221, 82, 144, 27, 27, 121, 121, 33, 394, 394, 4, 4, 280, 470, 470, 403, 403, 171, 171, 171, 246, 246, 252, 252, 314, 314, 198, 45, 45, 45, 45, 45, 35, 259, 22, 5, 455, 455, 42, 42, 147, 147, 380, 288, 278, 278, 385, 457, 242, 242, 242, 33, 33, 394, 478, 162, 232, 232, 238, 6, 272, 470, 470, 171, 171, 171, 252, 252, 457, 457, 196, 291, 291, 291, 291, 291, 385, 457, 401, 82, 108, 377, 295, 295, 295, 295, 143, 458, 192, 180, 230, 230, 230, 230, 215, 35, 35, 198, 22, 283, 283, 455, 236, 36, 108, 119, 119, 351, 351, 403, 171, 171, 171, 171, 139, 139, 139, 302, 375, 497, 497, 335, 335, 440, 440, 415, 415, 415, 415, 285, 44, 44, 44, 236, 129, 259, 74, 74, 441, 441, 441, 153, 153, 387, 387, 428, 299, 299, 358, 358, 358, 233, 131, 483, 226, 82, 209, 145, 145, 460, 460, 460, 460, 402, 402, 96, 272, 300, 300, 382, 406, 467, 467, 499, 265, 265, 265, 85, 85, 146, 146, 146, 252, 143, 36, 108, 119, 119, 213, 213, 213, 213, 213, 246, 246, 246, 246, 19, 454, 454, 229, 82, 247, 126, 126, 292, 292, 292, 23, 408, 408, 149, 228, 140, 140, 373, 110, 110, 254, 254, 254, 240, 325, 325, 34, 340, 340, 340, 94, 199, 44, 44, 399, 217, 473, 65, 136, 136, 136, 365, 330, 388, 199, 199, 334, 334, 382, 59, 59, 245, 245, 8, 8, 354, 420, 420, 420, 416, 416, 445, 180, 180, 180, 319, 319, 319, 319, 282, 282, 282, 282, 388, 303, 303, 303, 48, 48, 48]
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
torch.Size([1, 335, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_70_steps_16_2024-03-25_10:41:38
sys_file:gen_121-127105-0026
generate
processing 7th semantic_sys file
7
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOU'LL EASILY JUDGE WHY WHEN YOU HEAR BECAUSE THE THING HAD BEEN SUCH A SCARE HE CONTINUED TO FIX ME
enroll_x_lens:tensor([51], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
274
[17, 17, 296, 219, 152, 152, 139, 139, 175, 175, 81, 81, 444, 213, 213, 213, 213, 318, 368, 368, 453, 9, 26, 359, 359, 81, 166, 166, 166, 422, 422, 239, 239, 310, 107, 395, 395, 180, 151, 151, 151, 240, 240, 24, 310, 447, 447, 397, 133, 364, 364, 364, 276, 276, 346, 346, 346, 265, 265, 265, 265, 85, 85, 85, 85, 146, 378, 43, 345, 409, 409, 409, 116, 219, 219, 152, 152, 152, 152, 58, 183, 183, 183, 286, 286, 286, 286, 468, 468, 245, 245, 8, 354, 420, 420, 422, 143, 458, 144, 351, 494, 494, 368, 453, 453, 198, 22, 5, 5, 455, 38, 164, 164, 164, 214, 214, 214, 214, 214, 214, 328, 200, 248, 58, 110, 254, 254, 254, 314, 314, 32, 354, 137, 137, 137, 137, 33, 394, 478, 478, 232, 172, 115, 273, 344, 344, 344, 344, 35, 310, 107, 395, 44, 44, 38, 162, 232, 482, 105, 105, 336, 82, 445, 445, 470, 264, 264, 264, 264, 264, 264, 468, 468, 59, 59, 59, 452, 263, 229, 82, 247, 126, 126, 126, 326, 326, 326, 326, 326, 408, 408, 408, 149, 228, 140, 140, 373, 451, 451, 30, 30, 30, 422, 143, 458, 144, 27, 121, 121, 121, 33, 76, 76, 465, 108, 119, 119, 351, 278, 278, 360, 339, 398, 398, 398, 398, 374, 313, 314, 314, 314, 401, 82, 82, 108, 119, 119, 351, 374, 374, 374, 374, 132, 349, 349, 234, 261, 261, 25, 278, 278, 278, 178, 143, 96, 96, 270, 323, 142, 196, 217, 473, 429, 429, 429, 429, 429, 19, 19, 454, 454, 229, 140, 140]
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
torch.Size([1, 272, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_70_steps_16_2024-03-25_10:41:38
sys_file:gen_121-127105-0013
generate
processing 8th semantic_sys file
8
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SHE WAS THE MOST AGREEABLE WOMAN I'VE EVER KNOWN IN HER POSITION SHE WOULD HAVE BEEN WORTHY OF ANY WHATEVER
enroll_x_lens:tensor([58], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
314
[17, 17, 296, 373, 373, 338, 338, 338, 338, 400, 400, 400, 30, 30, 301, 378, 378, 345, 141, 141, 141, 141, 281, 453, 342, 198, 22, 283, 455, 455, 399, 217, 70, 65, 65, 65, 496, 496, 169, 169, 150, 86, 86, 238, 6, 272, 34, 255, 255, 416, 458, 208, 79, 79, 288, 288, 288, 288, 464, 134, 134, 134, 8, 354, 100, 100, 100, 497, 497, 43, 43, 364, 276, 276, 109, 174, 174, 203, 399, 53, 473, 275, 275, 275, 275, 303, 303, 303, 117, 48, 48, 417, 20, 170, 20, 20, 211, 20, 20, 187, 187, 187, 12, 12, 12, 260, 260, 260, 391, 391, 20, 20, 20, 289, 289, 20, 287, 287, 111, 111, 111, 438, 438, 173, 280, 280, 180, 463, 463, 463, 463, 280, 29, 29, 382, 382, 313, 313, 10, 10, 479, 331, 84, 84, 84, 350, 350, 413, 413, 94, 199, 340, 340, 116, 94, 58, 58, 156, 156, 156, 156, 245, 245, 129, 82, 74, 492, 492, 492, 368, 453, 342, 168, 470, 278, 418, 418, 99, 99, 436, 436, 436, 60, 60, 298, 298, 298, 275, 388, 303, 303, 117, 117, 48, 229, 229, 20, 312, 126, 126, 292, 292, 292, 292, 292, 292, 292, 23, 23, 23, 408, 408, 408, 408, 408, 391, 391, 20, 16%|█▌        | 10/64 [02:08<12:05, 13.43s/it]2024-03-25 02:44:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:44:07 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
[17, 17, 296, 296, 338, 338, 400, 400, 400, 400, 30, 30, 301, 301, 378, 43, 364, 364, 364, 364, 276, 276, 346, 346, 141, 141, 141, 141, 141, 206, 206, 206, 282, 37, 37, 185, 185, 185, 185, 269, 269, 390, 390, 390, 390, 18, 18, 112, 112, 56, 56, 56, 170, 28, 28, 20, 28, 28, 28, 20, 28, 28, 28, 28, 20, 362, 362, 362, 20, 362, 362, 362, 362, 362, 362, 20, 362, 218, 218, 218, 20, 218, 218, 218, 218, 218, 20, 218, 218, 218, 218, 218, 20, 218, 218, 218, 218, 218, 218, 218, 20, 218, 218, 218, 20, 366, 366, 366, 20, 366, 366, 366, 20, 366, 366, 20, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 316, 316, 316, 316, 316, 316, 73, 73, 73, 20, 320, 7, 127, 5, 5, 455, 399, 70, 70, 65, 65, 65, 319, 496, 274, 274, 186, 186, 54, 54, 238, 238, 6, 272, 255, 255, 416, 416, 239, 208, 79, 79, 79, 288, 288, 288, 288, 464, 464, 134, 134, 134, 134, 8, 8, 100, 100, 100, 497, 497, 497, 43, 43, 364, 276, 276, 276, 174, 174, 174, 174, 174, 53, 53, 473, 242, 275, 275, 275, 388, 195, 195, 117, 117, 48, 48, 48, 48, 48, 48, 417, 170, 170, 20, 170, 28, 20, 28, 28, 20, 28, 28, 20, 2, 20, 362, 362, 20, 362, 362, 362, 362, 20, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 20, 366, 366, 20, 316, 316, 20, 20, 316, 73, 73, 73, 289, 20, 209, 287, 111, 111, 111, 111, 438, 202, 173, 280, 280, 180, 463, 463, 463, 463, 463, 280, 29, 382, 382, 313, 313, 10, 10, 479, 479, 331, 84, 84, 84, 350, 350, 350, 413, 413, 413, 94, 199, 199, 89, 340, 340, 116, 94, 199, 156, 156, 156, 245, 245, 129, 259, 74, 492, 492, 492, 492, 368, 368, 453, 453, 453, 453, 168, 470, 278, 278, 278, 278, 278, 99, 99, 436, 436[17, 17, 296, 287, 111, 111, 438, 438, 236, 36, 108, 119, 119, 351, 351, 213, 213, 301, 378, 43, 364, 345, 141, 141, 141, 141, 281, 453, 342, 342, 224, 242, 242, 379, 379, 457, 478, 478, 68, 68, 115, 273, 278, 278, 278, 203, 53, 76, 76, 259, 74, 425, 359, 474, 474, 474, 324, 324, 301, 216, 198, 127, 45, 45, 45, 457, 310, 310, 338, 400, 400, 400, 30, 422, 422, 162, 68, 68, 115, 273, 470, 120, 240, 240, 314, 35, 401, 478, 66, 68, 68, 115, 273, 273, 84, 84, 84, 84, 16, 16, 274, 274, 98, 98, 13, 13, 414, 414, 170, 20, 20, 20, 20, 312, 187, 12, 12, 12, 23, 23, 23, 23, 101, 101, 149, 228, 20, 20, 20, 159, 159, 159, 216, 216, 127, 45, 45, 45, 285, 34, 111, 111, 111, 111, 438, 438, 10, 10, 10, 398, 398, 398, 398, 398, 374, 374, 132, 132, 186, 99, 338, 338, 400, 400, 400, 30, 3, 58, 58, 110, 254, 254, 254, 254, 314, 196, 242, 242, 379, 379, 243, 243, 36, 227, 483, 226, 226, 226, 226, 20, 287, 111, 111, 111, 438, 438, 378, 43, 364, 276, 276, 346, 346, 346, 481, 481, 206, 206, 206, 37, 185, 185, 269, 433, 433, 160, 97, 97, 225, 225, 225, 373, 373, 338, 338, 338, 338, 338, 395, 395, 106, 153, 153, 387, 387, 387, 406, 406, 467, 111, 111, 111, 438, 143, 458, 144, 389, 389, 389, 389, 314, 478, 478, 68, 68, 68, 68, 115, 267, 267, 267, 267, 267, 246, 246, 246, 246, 19, 19, 19, 454, 454, 13]
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
torch.Size([1, 271, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_121-127105-0012
generate
processing 10th semantic_sys file
10
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT WAS THIS OBSERVATION THAT DREW FROM DOUGLAS NOT IMMEDIATELY BUT LATER IN THE EVENING A REPLY THAT HAD THE INTERESTING CONSEQUENCE TO WHICH I CALL ATTENTION
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
568
[17, 17, 296, 296, 111, 111, 111, 438, 438, 143, 35, 36, 108, 119, 119, 351, 351, 213, 213, 213, 213, 246, 246, 301, 378, 378, 345, 141, 141, 141, 141, 281, 281, 453, 9, 198, 198, 127, 114, 258, 258, 258, 31, 342, 9, 168, 106, 106, 284, 405, 206, 215, 215, 96, 96, 54, 224, 494, 494, 494, 173, 173, 280, 280, 418, 418, 418, 418, 418, 418, 418, 99, 99, 436, 436, 60, 60, 298, 116, 116, 466, 466, 114, 45, 45, 45, 45, 385, 457, 457, 32, 32, 32, 239, 161, 161, 161, 79, 79, 79, 79, 487, 487, 374, 374, 374, 132, 132, 132, 132, 132, 349, 349, 393, 155, 165, 165, 165, 165, 53, 394, 394, 212, 239, 384, 180, 180, 151, 151, 151, 416, 416, 458, 208, 359, 81, 459, 459, 271, 31, 54, 86, 238, 196, 196, 479, 331, 307, 307, 307, 307, 61, 61, 167, 167, 457, 440, 440, 188, 121, 121, 121, 217, 217, 217, 217, 473, 65, 213, 213, 213, 252, 325, 34, 485, 485, 485, 485, 134, 457, 457, 359, 359, 474, 474, 474, 474, 474, 19, 19, 19, 19, 454, 454, 229, 20, 20, 312, 312, 126, 292, 292, 292, 292, 292, 292, 292, 21, 21, 21, 21, 23, 23, 101, 101, 101, 391, 391, 20, 20, 289, 20, 20, 354, 159, 159, 167, 167, 457, 457, 457, 251, 251, 251, 251, 241, 431, 431, 171, 171, 171, 171, 252, 252, 325, 300, 300, 382, 382, 382, 406, 406, 467, 467, 340, 340, 116, 466, 466, 22, 448, 448, 448, 448, 14, 14, 411, 411, 411, 213, 213, 213, 213, 213, 213, 213, 252, 252, 173, 173, 402, 196, 196, 199, 176, 176, 176, 176, 328, 328, 328, 328, 200, 200, 117, 117, 117, 117, 197, 197, 197, 20, 80, 20, 20, 20, 209, 287, 44, 44, 42, 42, 42, 147, 147, 147, 380, 288, 278, 278, 215, 129, 129, 259, 74, 425, 386, 386, 431, 265, 265, 265, 265, 85, 85, 85, 85, 207, 207, 207, 19, 19, 454, 454, 225, 225, 197, 80, 20, 20, 127, 45, 45, 45, 45, 325, 58, 72, 72, 110, 110, 110, 254, 254, 254, 240, 314, 314, 198, 22, 448, 448, 448, 448, 3, 14, 14, 411, 411, 188, 121, 121, 121, 121, 64, 76, 310, 161, 161, 487, 487, 469, 469, 186, 31, 238, 6, 6, 272, 272, 176, 176, 176, 328, 200, 200, 248, 76, 465, 144, 144, 27, 27, 370, 370, 370, 370, 370, 370, 370, 370, 77, 77, 342, 224, 494, 469, 469, 458, 458, 208, 208, 441, 441, 11, 11, 11, 11, 11, 11, 11, 379, 243, 243, 77, 270, 433, 390, 390, 18, 18, 112, 112, 427, 56, 56, 247, 312, 126, 292, 292, 292, 292, 292, 23, 23, 23, 23, 23, 23, 101, 101, 101, 391, 391, 20, 20, 20, 289, 289, 20, 75, 108, 377, 377, 123, 123, 123, 378, 43, 345, 345, 407, 407, 407, 407, 407, 36, 310, 107, 107, 447, 447, 97, 483, 226, 226, 226, 226, 226, 20, 20, 287, 287, 111, 111, 111, 111, 438, 438, 143, 458, 144, 27, 437, 481, 481, 481, 481, 481, 481, 293, 175, 175, 81, 255, 255, 255, 236, 36, 108, 119, 119, 351, 432, 432, 432, 330, 379, 64, 76, 310, 436, 436, 436, 60, 298, 298, 298, 275, 275, 303, 303, 303, 303, 117, 48, 48]
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
torch.Size([1, 566, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_121-127105-0000
generate
processing 11th semantic_sys file
11
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WELL IF I DON'T KNOW WHO SHE WAS IN LOVE WITH I KNOW WHO HE WAS
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
486
 19%|█▉        | 12/64 [02:36<13:44, 15.86s/it]2024-03-25 02:44:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:44:35 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
 20%|██        | 13/64 [02:43<11:17, 13.29s/it]2024-03-25 02:44:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:44:42 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
 22%|██▏       | 14/64 [02:51<09:45, 11.71s/it]2024-03-25 02:44:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:44:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
[17, 17, 296, 296, 7, 7, 364, 364, 364, 276, 276, 109, 109, 109, 443, 443, 443, 443, 443, 443, 443, 443, 443, 443, 139, 139, 139, 139, 139, 16, 16, 293, 293, 175, 175, 81, 118, 118, 118, 118, 118, 205, 205, 261, 25, 111, 111, 111, 111, 111, 111, 111, 438, 438, 438, 236, 239, 384, 371, 180, 180, 84, 84, 350, 350, 350, 350, 413, 413, 413, 457, 457, 457, 196, 309, 309, 309, 309, 309, 309, 309, 479, 479, 331, 331, 84, 84, 84, 84, 84, 84, 84, 84, 84, 16, 16, 16, 16, 16, 16, 274, 274, 274, 58, 58, 72, 72, 72, 72, 489, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 274, 274, 274, 274, 274, 186, 186, 186, 99, 338, 338, 338, 338, 338, 338, 338, 338, 338, 338, 338, 400, 400, 400, 400, 400, 400, 30, 30, 30, 30, 246, 246, 246,top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
torch.Size([1, 494, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_20_steps_16_2024-03-25_10:41:38
sys_file:gen_121-127105-0000
generate
processing 11th semantic_sys file
11
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WELL IF I DON'T KNOW WHO SHE WAS IN LOVE WITH I KNOW WHO HE WAS
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
296
[17, 17, 296, 296, 7, 7, 364, 364, 364, 276, 276, 109, 109, 443, 443, 443, 443, 443, 139, 139, 139, 293, 293, 293, 293, 293, 293, 335, 335, 440, 188, 118, 118, 118, 118, 118, 118, 205, 205, 261, 25, 111, 111, 111, 111, 111, 438, 438, 236, 239, 239, 371, 180, 84, 84, 350, 350, 350, 413, 413, 413, 457, 457, 457, 196, 309, 309, 479, 331, 84, 84, 84, 84, 16, 16, 274, 274, 58, 58, 183, 183, 489, 181, 181, 181, 374, 374, 374, 132, 132, 132, 186, 186, 99, 338, 338, 338, 400, 400, 400, 400, 30, 301, 301, 378, 43, 364, 364, 364, 276, 276, 346, 346, 141, 141, 141, 141, 141, 120, 120, 282, 282, 37, 37, 185, 185, 269, 342, 342, 97, 483, 226, 82, 188, 188, 340, 340, 340, 116, 33, 33, 250, 250, 251, 241, 241, 431, 431, 266, 266, 266, 266, 266, 266, 266, 266, 355, 355, 355, 375, 375, 375, 173, 173, 352, 352, 419, 427, 229, 82, 82, 24torch.Size([1, 203, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_70_steps_16_2024-03-25_10:41:38
sys_file:gen_121-127105-0022
generate
processing 12th semantic_sys file
12
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE OTHERS RESENTED POSTPONEMENT BUT IT WAS JUST HIS SCRUPLES THAT CHARMED ME
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
379
[17, 296, 5, 448, 448, 448, 464, 464, 180, 493, 493, 493, 493, 493, 493, 216, 216, 300, 300, 300, 334, 304, 304, 304, 304, 185, 185, 49, 269, 323, 390, 390, 390, 390, 18, 97, 97, 97, 225, 225, 225, 80, 80, 80, 80, 80, 320, 7, 147, 456, 456, 456, 186, 162, 162, 172, 115, 273, 273, 432, 432, 432, 330, 330, 64, 76, 76, 36, 449, 449, 191, 191, 191, 191, 191, 37, 24, 24, 24, 131, 131, 404, 404, 404, 404, 404, 263, 263, 263, 263, 439, 78, 78, 170, 20, 170, 170, 20, 28, 20, 28, 28, 20, 28, 20, 2, 2, 20, 20, 341, 341, 341, 369, 12, 12, 12, 260, 260, 260, 260, 391, 391, 391, 73, 73, 20, 289, 289, 320, 74, 74, 437, 437, 496, 496, 496, 496, 274, 186, 39, 54, 86, 238, 238, 6, 272, 472, 221, 336, 336, 74, 74, 437, 437, 496, 350, 350, 350, 413, 413, 413, 413, 250, 250, 250, 291, 291, 291, 291, 291, 291, 379, 243, 243, 243, 233, 75, 227, 227, 419, 419, 419, 439, 439, 439, 439, 78, 78, 20, 170, 20, 28, 20, 28, 28, 28, 28, 20, 362, 362, 20, 362, 362, 362, 20, 20, 362, 20, 362, 20, 362, 362, 20, 369, 369, 369, 21, 21, 21, 21, 326, 326, 101, 101, 149, 149, 149, 228, 289, 320, 320, 159, 159, 159, 285, 285, 111, 111, 111, 438, 438, 143, 143, 36, 108, 119, 119, 351, 213, 213, 213, 213, 246, 301, 301, 378, 345, 345, 141, 141, 141, 141, 281, 281, 453, 142, 221, 221, 310, 310, 107, 395, 395, 180, 151, 151, 151, 169, 150, 150, 54, 86, 238, 6, 272, 272, 183, 257, 257, 257, 257, 257, 31, 31, 162, 482, 482, 105, 105, 336, 336, 208, 79, 487, 487, 374, 374, 132, 215, 215, 129, 259, 74, 29, 100, 302, 302, 497, 497, 497, 497, 185, 49, 49, 269, 9, 198, 198, 127, 114, 45, 45, 45, 45, 385, 143, 129, 36, 310, 107, 107, 395, 395, 351, 499, 499, 306, 306, 306, 306, 396, 396, 396, 203, 53, 64, 64, 212, 212, 131, 131, 472, 472, 196, 196, 217, 429, 429, 429, 429, 429, 429, 19, 19, 19, 19, 454, 454, 454]
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
torch.Size([1, 377, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_70_steps_16_2024-03-25_10:41:38
sys_file:gen_121-127105-0006
generate
processing 13th semantic_sys file
13
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: SOMEONE ELSE TOLD A STORY NOT PARTICULARLY EFFECTIVE WHICH I SAW HE WAS NOT FOLLOWING
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
241
[17, 17, 296, 296, 66, 66, 172, 115, 273, 231, 231, 231, 53, 53, 250, 174, 174, 174, 348, 94, 199, 180, 139, 139, 139, 293, 293, 122, 77, 77, 86, 86, 238, 6, 272, 119, 351, 424, 424, 424, 424, 122, 122, 122, 44, 44, 38, 162, 232, 232, 482, 238, 6, 272, 106, 106, 153, 153, 153, 372, 372, 406, 467, 337, 337, 41, 41, 19, 19, 19, 454, 454, 454, 225, 225, 225, 225, 80, 20, 20, 7, 309, 479, 331, 307, 307, 307, 61, 167, 167, 457, 35, 259, 74, 190, 492, 492, 236, 129, 82, 108, 119, 278, 278, 278, 143, 192, 192, 485, 485, 134, 134, 175, 81, 81, 300, 382, 134, 134, 175, 175, 81, 166, 166, 166, 324, 464, 464, 255, 255, 349, 205, 261, 25, 470, 151, 151, 178, 178, 35, 96, 82, 272, 34, 459, 459, 173, 173, 402, 402, 345, 345, 407, 407, 407, 407, 310, 107, 395, 111, 111, 111, 111, 438, 186, 162, 232, 232, 172, 115, 273, 106, 106, 405, 405, 405, 405, 206, 206, 206, 206, 58, 183, 183, 451, 451, 30, 30, 30, 301, 378, 43, 345, 141, 141, 141, 281, 453, 9, 221, 196, 309, 479, 307, 307, 307, 307, 61, 61, 167, 167, 457, 90, 393, 234, 261, 25, 106, 481, 481, 481, 481, 175, 175, 175, 81, 134, 134, 88, 88, 176, 176, 176, 328, 328, 303, 303, 48, 48, 48, 417]
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
torch.Size([1, 239, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_70_steps_16_2024-03-25_10:41:38
sys_file:gen_121-127105-0001
generate
processing 14th semantic_sys file
14
args.target_ 27%|██▋       | 17/64 [03:25<09:01, 11.53s/it]2024-03-25 02:45:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:45:24 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
[17, 17, 296, 108, 108, 377, 377, 374, 374, 374, 374, 132, 132, 132, 132, 132, 132, 132, 216, 216, 127, 114, 114, 258, 258, 271, 271, 271, 39, 39, 390, 390, 390, 390, 390, 390, 18, 18, 112, 112, 56, 56, 56, 56, 47, 47, 47, 47, 20, 20, 47, 47, 47, 47, 20, 316, 73, 20, 20, 20, 373, 451, 257, 257, 257, 453, 9, 168, 145, 145, 145, 365, 365, 365, 330, 379, 379, 77, 77, 77, 54, 224, 300, 300, 382, 378, 345, 141, 141, 141, 281, 142, 221, 221, 259, 74, 74, 190, 488, 488, 426, 426, 53, 53, 53, 76, 76, 96, 36, 108, 449, 119, 351, 84, 84, 84, 496, 496, 274, 274, 274, 274, 274, 186, 349, 164, 164, 164, 164, 470, 470, 365, 365, 365, 200, 200, 76, 76, 192, 192, 472, 472, 221, 401, 401, 401, 82, 144, 27, 106, 91, 91, 405, 206, 206, 24, 314, 314, 196, 196, 196, 309, 309, 479, 331, 331, 84, 84, 84, 84, 16, 16, 16, 274, 98, 98, 98, 13, 13, 414, 414, 414, 414, 170, 20, 20, 28, 20, 28, 20, 28, 20, 2, 20, 2, 20, 20, 163, 163, 163, 163, 163, 20, 163, 163, 163, 163, 316, 316, 73, 20, 20, 412, 83, 55, 55, 322, 67, 212, 34, 356, 356, 281, 281, 9, 198, 22, 283, 455, 455, 42, 147, 380, 288, 443, 178, 178, 458, 192, 192, 242, 469, 314, 314, 131, 219, 2 27%|██▋       | 17/64 [03:35<09:03, 11.55s/it]2024-03-25 02:45:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:45:33 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
[17, 17, 296, 108, 108, 377, 351, 374, 374, 374, 374, 374, 374, 132, 132, 132, 132, 132, 132, 98, 98, 13, 229, 229, 247, 312, 312, 187, 187, 187, 187, 187, 12, 12, 12, 12, 12, 12, 12, 260, 260, 260, 260, 260, 260, 260, 391, 391, 228, 140, 289, 289, 140, 127, 127, 114, 258, 258, 258, 258, 31, 54, 54, 54, 183, 183, 183, 257, 257, 257, 257, 257, 368, 453, 9, 168, 168, 106, 106, 284, 284, 284, 365, 365, 365, 365, 330, 348, 379, 379, 77, 77, 77, 54, 54, 172, 224, 224, 300, 334, 334, 355, 355, 355, 355, 355, 355, 355, 452, 452, 263, 263, 13, 78, 78, 140, 140, 312, 312, 187, 187, 187, 187, 187, 187, 260, 391, 391, 391, 228, 140, 140, 320, 7, 345, 141, 141, 141, 141, 281, 281, 9, 142, 221, 221, 336, 336, 82, 74, 190, 190, 488, 488, 488, 426, 426, 426, 53, 53, 53, 53, 53, 243, 243, 233, 233, 233, 96, 227, 227, 419, 419, 419, 439, 439, 439, 439, 78, 78, 140, 140, 28, 28, 140, 28, 140, 2, 2, 140, 2, 140, 2, 2, 2, 2, 140, 366, 140, 366, 366, 366, 140, 316, 140, 316, 316, 316, 73, 73, 289, 289, 209, 209, 287, 287, 84, 496, 496, 496, 274, 274, 186, 349, 164, 164, 164, 164, 164, 164, 470, 470, 486, 365, 365, 365, 200, 200, 200, 457, 457, 457, 457, 32, 239, 144, output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_10_steps_16_2024-03-25_10:41:38
sys_file:gen_121-127105-0007
generate
processing 15th semantic_sys file
15
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: CRIED ONE OF THE WOMEN HE TOOK NO NOTICE OF HER HE LOOKED AT ME BUT AS IF INSTEAD OF ME HE SAW WHAT HE SPOKE OF
enroll_x_lens:tensor([31], dtype=torch.int32)[17, 17, 208, 208, 190, 487, 499, 499, 499, 265, 265, 265, 265, 85, 85, 85, 146, 146, 24, 131, 133, 133, 345, 276, 174, 174, 174, 174, 94, 199, 223, 223, 130, 402, 198, 22, 283, 283, 455, 43, 43, 364, 276, 109, 109, 278, 278, 278, 203, 53, 473, 136, 136, 275, 116, 94, 183, 451, 30, 30, 30, 30, 422, 143, 36, 108, 108, 295, 295, 295, 295, 295, 457, 457, 457, 196, 309, 479, 331, 231, 231, 231, 231, 274, 274, 10, 10, 10, 309, 479, 331, 84, 84, 496, 496, 496, 274, 285, 285, 459, 459, 459, 271, 31, 342, 342, 224, 168, 69, 69, 223, 223, 130, 402, 402, 156, 156, 156, 156, 59, 59, 313, 58, 183, 451, 451, 30, 30, 30, 301, 301, 251, 251, 241, 367, 367, 367, 367, 367, 96, 96, 401, 82, 384, 415, 415, 415, 415, 457, 457, 457, 217, 429, 429, 429, 429, 429, 19, 19, 19, 454, 454, 229, 82, 247, 312, 126, 126, 292, 292, 23, 23, 408, 408, 149, 228, 140, 140, 140, 320, 159, 159, 159, 285, 285, 34, 253, 253, 253, 253, 453, 453, 168, 118, 118, 118, 118, 118, 402, 29, 340, 340, 340, 33, 394, 478, 162, 232, 68, 238, 6, 272, 470, 470, 470, 443, 443, 240, 285, 34, 69, 223, 223, 130, 402, 196, 217, 217, 473, 429, 429, 429, 429, 246, 246, 3, 183, 183, 451, 451, 30, 30, 422, 422, 162, 232, 68, 68, 115, 115, 273, 106, 106, 405, 405, 405, 405, 405, 206, 206, 206, 206, 98, 98, 225, 197, 197, 197, 7, 364, 181, 181, 181, 181, 181, 285, 325, 183, 451, 451, 30, 30, 30, 422, 162, 232, 232, 105, 105, 336, 336, 354, 470, 189, 496, 496, 496, 274, 274, 35, 458, 192, 192, 223, 223, 223, 223, 223, 223, 223, 223, 173, 352, 352, 352, 419, 427, 229, 82]
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
torch.Size([1, 317, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_70_steps_16_2024-03-25_10:41:38
sys_file:gen_121-127105-0002
generate
processing 16th semantic_sys file
16
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE WAS SOMETHING INDIVIDUAL ABOUT THE GREAT FARM A MOST UNUSUAL TRIMNESS AND CARE FOR DETAIL
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
351
[17, 296, 296, 0, 0, 222, 378, 378, 345, 141, 141, 281, 162, 54, 232, 172, 172, 115, 231, 231, 231, 231, 231, 53, 76, 35, 164, 214, 214, 214, 214, 200, 200, 464, 121, 116, 33, 394, 212, 384, 371, 490, 490, 173, 4, 280, 278, 278, 278, 278, 278, 310, 310, 107, 395, 134, 134, 134, 100, 100, 100, 100, 497, 497, 497, 497, 255, 255, 255, 8, 354, 180, 113, 113, 113, 113, 113, 167, 35, 35, 198, 22, 283, 455, 416, 239, 208, 79, 79, 484, 484, 484, 484, 484, 252, 252, 143, 131, 393, 393, 234, 234, 234, 261, 261, 25, 106, 284, 284, 306, 426, 426, 426, 426, 426, 450, 203, 203, 53, 70, 65, 44, 44, 44, 44, 399, 217, 217, 70, 70, 65, 65, 496, 496, 496, 496, 274, 186, 39, 54, 54, 86, 86, 238, 6, 272, 483, 226, 226, 226, 226, 226, 226, 140, 140, 209, 287, 319, 319, 319, 319, 348, 33, 33, 219, 219, 219, 219, 219, 219, 485, 374, 374, 374, 132, 132, 368, 368, 368, 107, 395, 395, 134, 134, 134, 100, 100, 100, 100, 497, 497, 497, 122, 129, 82, 108, 161, 161, 161, 161, 487, 487, 288, 288, 278, 203, 53, 64, 64, 10, 94, 459, 459, 459, 459, 271, 271, 39, 39, 390, 390, 390, 390, 18, 112, 427, 82, 247, 126, 326, 326, 326, 326, 326, 101, 149, 149, 228, 82, 83, 83, 55, 55, 446, 446, 67, 67, 90, 76, 129, 82, 144, 445, 445, 445, 351, 351, 351, 264, 264, 264, 264, 264, 264, 264, 264, 355, 355, 355, 355, 355, 355, 452, 263, 263, 229, 82, 247, 126, 126, 23, 23, 23, 101, 101, 149, 149, 82, 373, 393, 234, 234, 234, 234, 234, 234, 234, 261, 25, 148, 148, 148, 148, 148, 148, 148, 182, 182, 182, 182, 387, 387, 387, 236, 236, 239, 239, 384, 371, 371, 213, 213, 213, 213, 422, 422, 143, 36, 108, 119, 119, 351, 351, 470, 470, 403, 171, 264, 120, 139, 139, 139, 375, 375, 375, 375, 98, 98, 98, 13, 13]
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
torch.Size([1, 349, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_70_steps_16_2024-03-25_10:41:38
sys_file:gen 31%|███▏      | 20/64 [04:04<09:21, 12.76s/it]2024-03-25 02:46:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:46:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
[17, 17, 17, 268, 268, 268, 268, 293, 215, 35, 35, 259, 354, 190, 190, 380, 380, 499, 315, 315, 315, 450, 450, 413, 348, 64, 219, 152, 152, 152, 152, 202, 402, 402, 221, 82, 144, 27, 106, 189, 405, 405, 167, 167, 457, 35, 478, 66, 68, 68, 115, 273, 273, 432, 330, 330, 379, 64, 77, 77, 54, 54, 142, 219, 152, 152, 152, 143, 458, 144, 445, 210, 210, 210, 210, 210, 210, 203, 53, 53, 58, 58, 72, 350, 350, 350, 350, 350, 350, 350, 350, 203, 203, 381, 381, 117, 404, 229, 247, 247, 126, 126, 326, 326, 326, 326, 101, 101, 101, 149, 228, 491, 491, 287, 111, 111, 438, 438, 43, 43, 345, 109, 109, 278, 99, 99, 436, 107, 395, 111, 111, 111, 111, 438, 58, 58, 72, 72, 110, 110, 110, 486, 486, 486, 460, 460, 240, 240, 24, 24, 131, 483, 483, 440, 440, 89, 89, 446, 94, 94, 199, 44, 255, 38, 349, 164, 164, 164, 164, 164, 164, 164, 25, 444, 213, 213, 213, 213, 358, 358, 233, 36, 227, 227, 472, 472, 221, 336, 491, 491, 108, 377, 377, 123, 123, 123, 399, 399, 217, 217, 217, 70, 473, 65, 65, 84, 84, 84, 84, 16, 16, 16, 16, 16, 274, 274, 274, 98, 98, 98, 225, 225, 225, 225, 225, 7, 70, 70, 46, 46, 46, 46, 46, 438, 464, 106, 106, 153, 153, 153, 387, 387, 387, 167, 457, 233, 310, 310, 107, 107, 107, 395, 395, 334, 334, 334, 355, 355, 37, 37, 24, 24, 131, 419, 439, 439]
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_[17, 17, 296, 296, 268, 268, 268, 268, 268, 268, 293, 293, 215, 8, 32, 32, 32, 354, 190, 190, 380, 380, 380, 499, 315, 315, 315, 315, 315, 450, 450, 450, 413, 348, 64, 219, 219, 219, 152, 152, 152, 152, 152, 202, 402, 402, 221, 401, 82, 144, 27, 106, 106, 405, 405, 405, 206, 167, 167, 35, 35, 478, 478, 66, 68, 68, 68, 115, 273, 273, 432, 432, 330, 379, 379, 77, 77, 77, 54, 86, 142, 219, 219, 152, 152, 152, 132, 143, 129, 129, 82, 82, 445, 445, 445, 210, 210, 210, 210, 210, 210, 210, 434, 434, 203, 53, 53, 58, 58, 72, 72, 437, 350, 350, 350, 350, 350, 350, 182, 182, 182, 413, 413, 203, 381, 381, 381, 117, 48, 13, 13, 229, 82, 82, 312, 312, 187, 187, 187, 187, 187, 187, 187, 187, 260, 391, 391, 244, 244, 244, 244, 244, 412, 287, 111, 111, 111, 111, 438, 378, 43, 43, 364, 345, 109, 109, 278, 278, 278, 99, 99, 99, 436, 107, 395, 395, 180, 111, 111, 111, 438, 438, 58, 58, 72, 110, 110, 110, 254, 254, 240, 240, 314, 314, 196, 196, 309, 309, 479, 331, 331, 145, 486, 460, 460, 169, 169, 35, 35, 164, 26, 26, 359, 359, 81, 444, 213, 213, 213, 252, 252, 143, 401, 401, 401, 82, 82, 108, 377, 377, 374, 374, 374, 132, 132, 399, 399, 70, 70, 70, 65, 65, 350, 350, 350, 274, 274, 399, 399, 70, 70, 46, 46, 46, 46, 46, 46, 438, 464, 464, 106, 106, 106, 153, 153, 387, 372, 372, 396, 396, 236, 35, 36, 310, 107, 107, 395, 395, 334, 334, 334, 59, 59, 59, 3 31%|███▏      | 20/64 [04:20<11:30, 15.70s/it]2024-03-25 02:46:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:46:19 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_10_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134493-0011
generate
processing 18th semantic_sys file
18
args.target_mode==1 or args.[17, 17, 296, 188, 475, 475, 475, 475, 475, 94, 475, 475, 475, 324, 301, 378, 43, 364, 276, 174, 174, 174, 174, 319, 348, 466, 466, 466, 114, 114, 264, 264, 264, 468, 468, 467, 467, 255, 255, 8, 8, 354, 180, 180, 113, 113, 113, 113, 450, 450, 167, 167, 77, 270, 54, 142, 397, 397, 389, 389, 389, 285, 202, 202, 202, 402, 402, 221, 82, 75, 108, 119, 119, 351, 424, 424, 424, 424, 424, 424, 497, 497, 122, 122, 24, 310, 107, 477, 477, 477, 477, 477, 477, 132, 132, 132, 98, 98, 13, 13, 229, 170, 170, 170, 28, 140, 2, 140, 2, 140, 140, 140, 2, 2, 140, 2, 140, 2, 2, 2, 140, 163, 163, 163, 140, 140, 73, 73, 289, 320, 127, 45, 45, 45, 45, 35, 35, 259, 127, 258, 258, 258, 258, 31, 54, 54, 142, 397, 397, 345, 141, 141, 141, 281, 9, 142, 397, 364, 364, 276, 276, 174, 174, 174, 174, 348, 199, 223, 223, 223, 130, 402, 198, 22, 22, 283, 455, 42, 42, 147, 147, 380, 288, 278, 278, 143, 310, 107, 107, 395, 459, 459, 271, 31, 54, 86, 238, 6, 272, 393, 393, 261, 261, 25, 106, 284, 284, 306, 306, 306, 306, 306, 306, 396, 59, 59, 203, 203, 381, 381, 471, 471, 185, 49, 323, 390, 18, 18, 18, 112, 112, 56, 56, 47, 47, 140, 47, 140, 47, 47, 47, 47, 80, 73, 73, 289, 412, 287, 125, 125, 125, 125, 466, 466, 22, 283, 455, 455, 236, 239, 384, 490, 490, 490, 490, 173, 4, 4, 280, 106, 106, 265, 265, 265, 265, 265, 265, 265, 265, 85, 85, 85, 85, 207, 207, 37, 37, 24, 131, 404, 439, 439, 78, 170, 140, 170, 28, 140, 28, 28, 140, 2, 2, 140, 2, 2, 2, 2, 2, 2, 140, 2, 163, 163, 140, 316, 316, 73, 73, 140, 320, 83, 83, 55, 55, 322, 67, 67, 212, 212, 127, 45, 45, 45, 45, 45, 167, 35, 35, 401, 198, 22, 5, 5, 455, 38, 349, 234, 234, 261, 25, 25, 499, 306, 306, 306, 306, 396, 396, 203, 203, 53, 29, 334, 334, 334, 59, 452, 452, 263, 263, 225, 225, 80, 80, 80, 320, 7, 345, 141, 141, 141, 281, 453, 9, 44, 44, 44, 44, 43, 43, 364, 364, 276, 276, 276, 174, 174, 174, 399, 53, 473, 242, 275, 116, 116, 195, 195, 195, 117, 117, 117, 48, 48, 417, 417, 417, 47, 47, 47, 47, 140, 47, 80, 80, 140, 80, 80, 209, 209, 145, 145, 145, 486, 329, 175, 175, 175, 81, 81, 469, 416, 416, 96, 96, 453, 453, 453, 168, 470, 470, 365, 365, 365, 365, 365, 330, 388, 64, 212, 161, 161, 495, 495, 467, 423, 423, 255, 8, 8, 239, 354, 380, 498, 498, 498, 498, 396, 396, 313, 416, 416, 96, 96, 270, 323, 224, 224, 275, 275, 275, 275, 303, 303, 303, 48, 48, 48]
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
torch.Size([1, 496, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_70_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134493-0017
generate
processing 19th semantic_sys file
19
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HIS WIFE NOW LIES BESIDE HIM AND THE WHITE SHAFT THAT MARKS THEIR GRAVES GLEAMS ACROSS THE WHEAT FIELDS
enroll_x_lens:tensor([29], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
360
[17, 17, 296, 451, 257, 257, 257, 281, 9, 142, 397, 364, 276, 276, 346, 346, 346, 428, 428, 428, 146, 146, 358, 349, 352, 352, 352, 402, 196, 196, 309, 479, 331, 331, 315, 315, 315, 450, 450, 293, 293, 251, 251, 251, 241, 431, 431, 265, 265, 265, 265, 85, 85, 146, 71, 368, 269, 142, 221, 221, 336, 354, 420, 420, 420, 422, 162, 162, 232, 232, 172, 115, 273, 273, 265, 265, 265, 85, 85, 146, 146, 24, 325, 183, 183, 57, 57, 57, 57, 203, 381, 381, 381, 48, 404, 13, 78, 20, 170, 20, 20, 20, 312, 312, 312, 292, 292, 292, 292, 292, 21, 21, 21, 21, 23, 23, 23, 23, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 391, 391, 20, 20, 20, 20, 412, 412, 83, 55, 55, 322, 322, 67, 466, 22, 5, 5, 455, 43, 364, 364, 276, 346, 346, 346, 428, 428, 146, 146, 252, 143, 35, 36, 310, 310, 338, 338, 338, 338, 338, 338, 338, 395, 395, 470, 470, 486, 486, 486, 460, 460, 460, 169, 169, 169, 352, 352, 352, 352, 352, 198, 198, 198, 127, 45, 45, 45, 45, 457, 457, 196, 196, 217, 70, 70, 65, 65, 306, 306, 306, 306, 396, 396, 178, 35, 458, 270, 270, 270, 323, 86, 198, 198, 198, 127, 114, 222, 222, 222, 222, 245, 245, 416, 32, 239, 208, 79, 79, 380, 288, 288, 171, 171, 171, 171, 246, 318, 173, 173, 270, 49, 269, 9, 142, 221, 221, 336, 144, 208, 425, 386, 386, 431, 444, 444, 360, 360, 434, 434, 203, 53, 471, 471, 49, 49, 9, 9, 168, 255, 255, 255, 143, 458, 208, 208, 208, 190, 190, 499, 499, 499, 405, 405, 405, 206, 169, 150, 39, 54, 54, 86, 238, 198, 22, 22, 283, 455, 455, 43, 364, 276, 109, 109, 109, 213, 213, 252, 252, 143, 36, 131, 393, 393, 234, 261, 261, 25, 485, 213, 213, 213, 213, 286, 139, 139, 139, 139, 375, 375, 375, 375, 122, 233, 233, 270, 270, 270, 270, 390, 390, 390, 390, 18, 18, 18, 112, 112, 56, 56, 1 36%|███▌      | 23/64 [04:31<06:57, 10.19s/it]2024-03-25 02:46:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:46:30 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
[17, 296, 296, 287, 111, 111, 111, 111, 438, 438, 143, 36, 108, 119, 351, 213, 213, 213, 213, 213, 246, 246, 246, 246, 246, 246, 246, 19, 19, 19, 454, 454, 229, 82, 247, 312, 187, 187, 187, 408, 391, 391, 140, 140, 140, 412, 412, 188, 356, 356, 356, 281, 162, 232, 232, 172, 115, 273, 278, 178, 143, 96, 96, 86, 238, 6, 272, 119, 351, 360, 360, 360, 360, 434, 434, 339, 339, 33, 219, 219, 219, 286, 286, 286, 286, 286, 286, 286, 286, 286, 468, 468, 59, 304, 304, 304, 185, 185, 269, 269, 390, 390, 18, 112, 427, 82, 247, 312, 187, 187, 391, 391, 140, 140, 373, 373, 66, 66, 172, 115, 273, 432, 330, 379, 379, 77, 77, 54, 142, 238, 6, 310, 107, 395, 180, 329, 329, 329, 426, 426, 426, 206, 388, 348, 33, 394, 212, 32, 354, 354, 498, 329, 329, 329, 329, 416, 96, 270, 342, 224, 224, 242, 116, 33, 394, 394, 239, 384, 371, 180, 265, 265, 265, 265, 265, 265, 85, 85, 85, 207, 207, 37, 24, 131, 404, 439, 439, 78]
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
torch.Size([1, 186, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134493-0000
generate
processing 21th semantic_sys file
21
args.target_mode==1 or args.target_ 36%|███▌      | 23/64 [04:43<06:59, 10.23s/it]2024-03-25 02:46:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:46:41 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
sys_file:gen_237-134493-0001
generate
processing 20th semantic_sys file
20
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: IT IS SIXTEEN YEARS SINCE JOHN BERGSON DIED
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2sema[17, 17, 287, 287, 284, 284, 284, 265, 265, 85, 85, 85, 146, 146, 146, 252, 252, 143, 36, 36, 449, 449, 449, 41, 41, 41, 41, 41, 246, 246, 246, 19, 19, 19, 19, 19, 454, 454, 454, 454, 454, 78, 78, 170, 20, 20, 20, 312, 187, 187, 187, 12, 12, 12, 408, 408, 408, 408, 391, 391, 20, 20, 20, 20, 412, 188, 356, 356, 356, 281, 162, 162, 232, 68, 68, 115, 115, 273, 278, 278, 278, 143, 458, 96, 96, 96, 232, 232, 86, 238, 6, 6, 272, 371, 444, 360, 360, 360, 360, 360, 434, 434, 339, 339, 33, 33, 248, 219, 219, 219, 219, 286, 286, 286, 286, 286, 286, 286, 286, 286, 286, 286, 286, 286, 355, 355, 355, 355, 355, 355, 355, 355, 355, 355, 304, 304, 304, 185, 185, 185, 185, 49, 269, 269, 433, 390, 390, 18, 18, 112, 427, 56, 56, 56, 312, 312, 312, 187, 187, 187, 12, 12, 12, 12, 12, 12, 12, 260, 408, 391, 391, 391, 20, 20, 373, 373, 66, 66, 68, 68, 68, 115, 115, 273, 278, 278, 278, 379, 379, 379, 243, 77, 77, 77, 342, 86, 86, 142, 238, 238, 336, 336, 310, 107, 395, 329, 329, 329, 329, 329, 426, 426, 426, 413, 348, 195, 195, 33, 394, 394, 32, 32, 239, 354, 354, 498, 498, 498, 498, 498, 498, 498, 178, 178, 458, 96, 96, 270, 323, 224, 224, 242, 242, 275, 116, 33, 33, 33, 394, 394, 212, 384, 384, 180, 180, 265, 265, 265, 265, 265, 265, 265, 265, 265, 265, 85, 85, 85, 85, 207, 207, 207, 207, 207, 207, 207, 37, 37, 24, 24, 131, 227, 419, 439, 439]
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
torch.Size([1, 283, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_10_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134493-0000
generate
processing 21th semantic_sys file
21
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE AIR AND THE EARTH ARE CURIOUSLY MATED AND INTERMINGLED AS IF THE ONE WERE THE BREATH OF THE OTHER
enroll_x_lens:tensor([41], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
326
[17, 17, 127, 448, 448, 448, 448, 14, 411, 411, 264, 264, 264, 264, 264, 264, 264, 264, 468, 468, 468, 467, 467, 340, 116, 116, 466, 22, 22, 448, 448, 448, 3, 14, 411, 411, 498, 498, 498, 498, 498, 498, 498, 396, 396, 169, 169, 169, 164, 164, 164, 164, 483, 440, 353, 353, 353, 353, 313, 143, 129, 259, 445, 445, 445, 485, 485, 485, 485, 485, 468, 468, 468, 337, 337, 337, 459, 459, 459, 31, 39, 342, 342, 26, 359, 166, 166, 166, 166, 301, 399, 217, 217, 473, 473, 476, 476, 476, 476, 171, 252, 252, 325, 325, 191, 191, 191, 191, 191, 37, 37, 24, 131, 404, 404, 229, 82, 247, 312, 126, 126, 292, 292, 292, 23, 23, 23, 408, 408, 408, 391, 228, 20, 20, 412, 83, 55, 55, 322, 67, 199, 199, 121, 121, 121, 121, 394, 465, 108, 119, 119, 351, 351, 308, 308, 308, 308, 308, 396, 396, 203, 53, 53, 176, 176, 176, 135, 200, 200, 248, 212, 144, 302, 302, 302, 302, 302, 375, 375, 375, 122, 122, 122, 227, 227, 419, 419, 439, 78, 56, 56, 170, 20, 20, 312, 312, 187, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 260, 260, 260, 260, 391, 391, 391, 20, 73, 20, 20, 412, 83, 83, 253, 253, 253, 253, 253, 253, 453, 453, 342, 342, 168, 118, 118, 118, 118, 118, 402, 402, 198, 198, 22, 5, 5, 455, 43, 364, 276, 276, 174, 174, 174, 174, 319, 330, 348, 33, 250, 250, 250, 345, 347, 347, 347, 313, 216, 216, 22, 283, 455, 455, 8, 259, 354, 380, 380, 288, 288, 443, 443, 443, 169, 169, 150, 164, 164, 164, 69, 69, 69, 130, 130, 198, 22, 22, 448, 448, 448, 464, 464, 180, 493, 493, 493, 493, 493, 493, 216, 300, 300, 300, 334, 334, 59, 59, 59, 59, 452, 452, 452, 263, 263, 263, 225]
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
torch.Size([1, 324, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_10_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134493-0004
generate
processing 22th semantic_sys file
22
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: INDEED HE HAD LOOKED AWAY WITH THE PURPOSE OF NOT SEEING IT
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
189
[17, 17, 296, 296, 188, 121, 121, 67, 212, 384, 371, 213, 213, 213, 213, 246, 246, 246, 246, 252, 24, 24, 404, 404, 439, 439, 78, 414, 170, 170, 20, 20, 20, 20, 187, 187, 12, 12, 12, 12, 408, 408, 408, 391, 391, 20, 73, 20, 20, 373, 451, 451, 30, 30, 30, 464, 254, 254, 254, 254, 26, 251, 251, 367, 367, 367, 367, 367, 35, 96, 96, 36, 272, 34, 255, 255, 43, 43, 276, 109, 109, 403, 403, 403, 403, 403, 207, 207, 207, 207, 3, 301, 43, 345, 333, 333, 333, 220, 35, 259, 22, 283, 455, 455, 129, 259, 74, 492, 492, 492, 492, 492, 215, 215, 35, 29, 29, 459, 459, 271, 31, 342, 342, 168, 69, 69, 223, 130, 130, 402, 196, 309, 309, 479, 331, 307, 307, 307, 307, 61, 61, 167, 167, 457, 457, 478, 66, 68, 68, 68, 115, 267, 267, 267, 267, 267, 360, 360, 135, 135, 135, 200, 200, 464, 464, 180, 111, 111, 111, 438, 438, 438, 143, 36, 36, 108, 119, 119, 351, 213, 213, 213, 213, 246, 246, 19, 19, 19, 454]
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
torch.Size([1, 187, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_10_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134493-0013
generate
processing 23th semantic_sys file
23
args.target_mode==1 or args.target_mode==2
semantic 41%|████      | 26/64 [04:55<05:17,  8.35s/it]2024-03-25 02:46:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:46:54 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
 42%|████▏     | 27/64 [05:15<07:22, 11.97s/it]top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
torch.Size([1, 326, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134493-0018
generate
processing 24th semantic_sys file
24
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT'S NOT MUCH OF A JOB FOR AN ATHLETE HERE I'VE BEEN TO TOWN AND BACK
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
196
[17, 296, 114, 92, 92, 92, 240, 77, 342, 86, 86, 196, 479, 331, 307, 307, 61, 167, 457, 457, 70, 383, 383, 383, 383, 383, 310, 107, 395, 223, 223, 130, 280, 44, 44, 236, 236, 310, 107, 395, 180, 106, 284, 405, 405, 405, 206, 206, 215, 215, 393, 393, 155, 155, 332, 332, 332, 467, 44, 44, 44, 199, 335, 14, 411, 145, 145, 145, 145, 486, 460, 460, 169, 169, 150, 164, 164, 26, 26, 359, 81, 81, 444, 213, 213, 252, 325, 131, 183, 183, 451, 286, 286, 286, 286, 286, 286, 468, 59, 59, 59, 59, 59, 59, 59, 452, 452, 452, 263, 263, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 412, 412, 287, 287, 111, 111, 438, 438, 202, 202, 402, 402, 221, 82, 354, 137, 137, 137, 137, 33, 394, 76, 465, 108, 377, 344, 344, 374, 374, 132, 236, 36, 108, 119, 119, 351, 351, 315, 315, 315, 315, 450, 450, 450, 413, 413, 94, 199, 89, 89, 446, 116, 33, 394, 32, 354, 354, 180, 376, 376, 376, 376, 376, 376, 376, 460, 178, 178, 178, 233, 82, 140, 192, 419, 419, 439]
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_tooutput_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_10_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134493-0018
generate
processing 24th semantic_sys file
24
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT'S NOT MUCH OF A JOB FOR AN ATHLETE HERE I'VE BEEN TO TOWN AND BACK
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
204
[17, 17, 296, 114, 114, 92, 92, 240, 35, 77, 342, 86, 221, 196, 479, 331, 307, 307, 307, 61, 61, 167, 457, 457, 70, 70, 383, 383, 383, 383, 383, 35, 310, 107, 107, 395, 223, 223, 130, 280, 44, 44, 44, 236, 239, 239, 310, 107, 395, 395, 180, 499, 499, 405, 405, 405, 405, 206, 206, 206, 215, 8, 8, 90, 393, 393, 155, 155, 155, 332, 332, 332, 467, 467, 44, 116, 94, 199, 145, 145, 145, 486, 486, 460, 460, 169, 169, 164, 26, 26, 26, 359, 81, 81, 41, 41, 19, 19, 19, 454, 454, 229, 20, 20, 20, 312, 3output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_updatetop_k_know_token:30
torch.Size([1, 251, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_30_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134493-0006
generate
processing 25th semantic_sys file
25
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: OH EVER SO MUCH ONLY HE SEEMS KIND OF STAID AND SCHOOL TEACHERY
enroll_x_lens:tensor([54], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
248
[17, 296, 287, 84, 84, 16, 16, 16, 16, 16, 16, 274, 274, 88, 335, 14, 411, 145, 145, 463, 463, 463, 463, 463, 280, 29, 29, 382, 382, 382, 59, 313, 313, 186, 186, 162, 232, 232, 172, 115, 344, 344, 344, 344, 344, 399, 399, 70, 383, 383, 383, 383, 383, 383, 383, 35, 310, 107, 447, 483, 14, 411, 411, 350, 350, 350, 350, 350, 350, 250, 250, 359, 81, 166, 166, 166, 324, 324, 246, 246, 3, 3, 183, 183, 183, 451, 30, 30, 30, 30, 422, 186, 162, 162, 232, 172, 115, 115, 273, 444, 444, 360, 434, 434, 339, 339, 53, 471, 71, 49, 269, 9, 142, 221, 82, 82, 144, 27, 27, 437, 480, 480, 480, 480, 480, 480, 480, 85, 85, 299, 299, 299, 299, 339, 64, 212, 131, 69, 462, 462, 462, 130, 402, 478, 162, 232, 232, 482, 238, 6, 82, 384, 470, 470, 470, 171, 171, 171, 171, 171, 171, 171, 246, 246, 246, 246, 246, 252, 24, 24, 131, 404, 404, 404, 225, 225, 225, 225, 225, 225, 225, 412, 83, 83, 89, 89, 446, 446, 446, 67, 394, 478, 478, 162, 482, 105, 105, 336, 82, 144, 208, 153, 153, 153, 153, 153, 182, 182, 182, 497, 497, 497, 122, 122, 129, 82, 108, 119, 119, 351, 351, 213, 213, 213, 213, 213, 252, 143, 36, 310, 107, 107, 161, 495, 495, 487, 41, 41, 41, 41, 41, 41, 19, 19, 19, 454, 454, 454]
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
torch.Size([1, 246, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_30_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134500-0021
generate
processing 26th semantic_sys file
26
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I CAN'T PLAY WITH YOU LIKE A LITTLE BOY ANY MORE HE SAID SLOWLY THAT'S WHAT YOU MISS MARIE
enroll_x_lens:tensor([38], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
259
[17, 17, 296, 287, 111, 111, 438, 438, 143, 458, 445, 445, 351, 351, 365, 365, 365, 365, 167, 457, 35, 401, 82, 74, 425, 386, 386, 431, 403, 403, 403, 171, 301, 378, 43, 333, 333, 333, 220, 220, 164, 219, 477, 477, 477, 477, 132, 251, 241, 266, 266, 266, 266, 178, 35, 192, 44, 44, 44, 251, 241, 431, 278, 278, 285, 302, 497, 497, 8, 32, 32, 354, 153, 153, 153, 153, 387, 387, 387, 146, 146, 3, 3, 14, 411, 411, 475, 475, 475, 475, 475, 475, 475, 475, 301, 399, 217, 70, 138, 138, 138, 138, 138, 138, 372, 372, 372, 59, 59, 59, 452, 263, 263, 229, 82, 82, 312, 312, 187, 187, 187, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 260, 260, 163, 163, 140, 163, 163, 140, 140, 316, 316, 316, 140, 140, 140, 373, 451, 451, 30, 30, 422, 162, 232, 172, 115, 273, 470, 120, 120, 240, 240, 314, 478, 478, 232, 232, 232, 172, 26, 26, 241, 431, 431, 84, 84, 496, 496, 274, 274, 359, 359, 474, 474, 474, 474, 474, 19, 19, 454, 454, 225, 225, 225, 225, 225, 80, 82, 127, 127, 114, 92, 92, 240, 240, 77, 77, 9, 397, 397, 181, 181, 181, 181, 36, 310, 107, 152, 152, 152, 152, 399, 217, 473, 473, 258, 258, 31, 54, 54, 142, 221, 196, 217, 473, 65, 329, 329, 42, 42, 42, 147, 380, 256, 256, 256, 256, 213, 246, 246, 246, 19, 19, 19, 19, 454, 454]
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
torch.Size([1, 257, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_30_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134500-0036
generate
processing 27th semantic_sys file
27
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHEN SHE USED TO TELL ME ABOUT HIM I ALWAYS WONDERED WHETHER SHE WASN'T A LITTLE IN LOVE WITH HIM
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
382
[17, 17, 296, 345, 409, 409, 409, 67, 478, 338, 338, 400, 400, 400, 30, 30, 422, 219, 219, 219, 219, 485, 485, 374, 3 45%|████▌     | 29/64 [05:35<06:30, 11.15s/it]2024-03-25 02:47:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:47:34 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
 47%|████▋     | 30/64 [05:45<05:58, 10.54s/it]2024-03-25 02:47:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:47:44 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WHEN SHE USED TO TELL ME ABOUT HIM I ALWAYS WONDERED WHETHER SHE WASN'T A LITTLE IN LOVE WITH HIM
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
246
[17, 17, 296, 409, 409, 409, 67, 478, 338, 338, 338, 400, 400, 400, 30, 30, 219, 219, 219, 219, 485, 485, 374, 374, 132, 132, 186, 39, 54, 54, 86, 238, 336, 336, 20, 20, 108, 108, 377, 344, 344, 344, 374, 374, 132, 132, 236, 36, 36, 108, 119, 119, 351, 351, 139, 139, 139, 293, 293, 399, 399, 429, 429, 429, 429, 464, 464, 255, 255, 236, 8, 354, 180, 113, 113, 113, 113, 113, 167, 285, 325, 183, 57, 57, 57, 57, 203, 381, 381, 117, 48, 229, 20, 20, 312, 312, 126, 292, 23, 23, 23, 23, 101, 149, 149, 228, 20, 412, 287, 111, 111, 111, 438, 464, 464, 106, 297, 297, 297, 297, 297, 293, 43, 345, 345, 141, 141, 281, 453, 142, 142, 133, 364, 276, 174, 174, 319, 319, 348, 64, 64, 212, 300, 382, 382, 382, 313, 24, 24, 133, 133, 364, 364, 345, 109, 109, 443, 443, 216, 216, 300, 300, 300, 313, 186, 99, 338, 338, 400, 400, 400, 400, 301, 378, 43, 345, 141, 141, 141, 281, 453, 168, 168, 242, 242, 116, 64, 212, 131, 34, 44, 44, 251, 251, 241, 431, 278, 278, 278, 285, 302, 497, 497, 497, 335, 440, 188, 340, 340, 340, 33, 33, 250, 251, 251, 241, 431, 266, 266, 266, 266, 173, 173, 402, 402, 345, 345, 333, 333, 220, 220, 164, 164, 183, 57, 57, 57, 57, 57, 57, 203, 381, 381, 381, 48, 48]
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
torch.Size([1, 244, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/ntop_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
torch.Size([1, 284, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_20_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134500-0022
generate
processing 28th semantic_sys file
28
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: BUT EMIL IF I UNDERSTAND THEN ALL OUR GOOD TIMES ARE OVER WE CAN NEVER DO NICE THINGS TOGETHER ANY MORE
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
550
[17, 296, 159, 159, 159, 159, 159, 167, 167, 457, 35, 401, 401, 401, 401, 401, 184, 184, 184, 184, 184, 184, 184, 140, 209, 209, 145, 329, 329, 329, 329, 329, 53, 53, 473, 65, 302, 302, 302, 375, 375, 375, 375, 98, 98, 98, 98, 13, 13, 414, 170, 140, 47, 140, 47, 140, 47, 47, 140, 140, 316, 73, 73, 140, 140, 412, 188, 118, 118, 118, 118, 118, 402, 402, 14, 14, 287, 111, 111, 111, 111, 111, 111, 438, 438, 464, 464, 145, 319, 319, 348, 348, 64, 212, 300, 300, 469, 469, 469, 186, 162, 54, 232, 232, 238, 6, 6, 272, 470, 470, 470, 294, 294, 294, 294, 294, 282, 282, 282, 282, 282, 388, 195, 195, 195, 212, 212, 131, 419, 439, 427, 82, 82, 312, 312, 312, 292, 292, 292, 292, 292, 292, 292, 292, 21, 21, 21, 21, 23, 23, 408, 408, 408, 149, 149, 228, 289, 289, 140, 320, 7, 127, 127, 361, 361, 361, 361, 361, 361, 361, 282, 388, 388, 195, 195, 195, 195, 195, 195, 117, 117, 117, 404, 404, 439, 439, 78, 78, 170, 47, 140, 140, 47, 47, 47, 47, 140, 316, 140, 316, 140, 73, 73, 73, 73, 140, 209, 287, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297, 297, 293, 293, 293, 293, 335, 14, 14, 411, 287, 353, 353, 353, 353, 353, 353, 396, 396, 245, 416, 416, 239, 144, 484, 484, 484, 484, 484, 240, 314, 314, 314, 32, 401, 259, 108, 119, 119, 119, 351, 103, 103, 103, 103, 103, 103, 103, 85, 299, 299, 299, 299, 203, 53, 471, 49, 49, 453, 168, 353, 353, 353, 353, 353, 353, 467, 14, 14, 14, 411, 411, 410, 410, 410, 410, 410, 410, 410, 173, 173, 280, 29, 29, 382, 382, 59, 59, 59, 245, 43, 43, 364, 345, 152, 152, 152, 152, 152, 422, 143, 458, 458, 445, 445, 351, 351, 351, 365, 365, 365, 365, 282, 282, 282, 282, 388, 195, 195, 195, 195, 195, 117, 117, 117, 48, 48, 417, 417, 170, 170, 170, 28, 28, 28, 28, 140, 2, 2, 140, 2, 2, 2, 2, 140, 2, 2, 2, 140, 366, 366, 366, 366, 366, 366, 140, 366, 366, 366, 316, 316, 316, 316, 140, 73, 73, 289, 7, 309, 309, 309, 309, 309, 309, 309, 479, 331, 463, 463, 463, 463, 463, 463, 280, 29, 29, 382, 382, 313, 313, 236, 239, 384, 371, 374, 374, 374, 374, 132, 10, 10, 479, 479, 331, 265, 428, 428, 428, 146, 146, 358, 186, 39, 39, 86, 86, 86, 238, 6, 336, 164, 214, 214, 214, 214, 214, 214, 214, 328, 200, 200, 200, 471, 471, 185, 49, 269, 433, 390, 390, 18, 112, 427, 56, 56, 247, 312, 312, 187, 292, 292, 292, 292, 23, 23, 23, 23, 23, 408, 408, 408, 391, 391, 391, 228, 289, 289, 289, 75, 108, 377, 87, 87, 87, 87, 239, 239, 445, 180, 180, 443, 443, 443, 240, 216, 216, 300, 300, 300, 382, 382, 59, 313, 335, 14, 14, 411, 411, 475, 475, 475, 475, 475, 475, 94, 475, 475, 475, 475, 301, 399, 217, 70, 138, 138, 138, 138, 138, 138, 138, 138, 372, 372, 372, 59, 59, 59, 452, 452, 452, 263, 263]
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
torch.Size([1, 548, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_20_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134500-0037
generate
processing 29th semantic_sys file
29
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: AND EMIL MOWED HIS WAY SLOWLY DOWN TOWARD THE CHERRY TREES
enroll_x_lens:tensor([34], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
251
[17, 17, 83, 55, 322, 322, 67, 212, 131, 335, 14, 411, 145, 329, 329, 329, 329, 53, 53, 65, 302, 302, 497, 497, 497, 399, 399, 70, 70, 65, 65, 84, 84, 84, 84, 496, 496, 496, 496, 274, 274, 37, 24, 131, 131, 183, 183, 183, 183, 257, 257, 257, 257, 257, 281, 453, 9, 142, 397, 133, 364, 364, 364, 276, 276, 109, 109, 403, 403, 403, 403, 403, 403, 403, 403, 207, 207, 207, 207, 207, 207, 207, 19, 3, 3, 3, 3, 3, 197, 197, 197, 197, 197, 197, 197, 197, 20, 20, 197, 66, 66, 232, 232, 232, 232, 482, 26, 26, 26, 241, 241, 431, 84, 84, 84, 496, 496, 496, 274, 274, 274, 359, 359, 359, 474, 474, 474, 474, 324, 301, 236, 239, 239, 371, 180, 180, 315, 315, 315, 315, 315, 315, 450, 450, 450, 450, 413, 413, 413, 195, 394, 394, 76, 259, 108, 377, 377, 123, 441, 441, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 387, 387, 387, 387, 387, 387, 37, 24, 24, 131, 472, 472, 198, 198, 22, 283, 455, 236, 129, 310, 310, 107, 107, 395, 351, 351, 264, 264, 264, 468, 468, 468, 468, 337, 337, 337, 324, 324, 422, 143, 259, 310, 107, 161, 161, 161, 487, 487, 487, 288, 288, 288 50%|█████     | 32/64 [06:00<04:46,  8.96s/it]2024-03-25 02:47:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:47:59 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
 52%|█████▏    | 33/64 [06:06<04:12,  8.15s/it]2024-03-25 02:48:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:48:05 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
 53%|█████▎    | 34/64 [06:15<04:07,  8.26s/it][17, 296, 296, 111, 111, 111, 438, 378, 378, 43, 345, 109, 109, 278, 278, 99, 99, 338, 447, 447, 447, 219, 152, 152, 152, 152, 378, 43, 43, 364, 276, 276, 347, 347, 347, 498, 498, 396, 396, 396, 313, 385, 457, 457, 478, 478, 66, 482, 172, 344, 344, 344, 344, 344, 344, 274, 274, 42, 42, 147, 147, 380, 288, 443, 443, 443, 169, 150, 150, 54, 86, 86, 86, 238, 6, 336, 26, 26, 359, 262, 262, 262, 262, 262, 271, 271, 271, 39, 433, 433, 433, 160, 160, 112, 427, 56, 247, 247, 126, 126, 292, 326, 326, 326, 326, 326, 101, 408, 408, 149, 228, 20, 412, 412, 83, 55, 55, 322, 67, 212, 239, 384, 371, 371, 278, 278, 278, 240, 314, 242, 242, 242, 33, 33, 90, 212, 212, 445, 180, 278, 278, 278, 240, 385, 35, 35, 478, 66, 68, 172, 344, 344, 344, 344, 274, 43, 43, 43, 364, 276, 276, 109, 109, 498, 396, 396, 178, 178, 35, 96, 96, 401, 82, 384, 371, 180, 180, 230, 230, 230, 230, 230, 215, 215, 35, 35, 35, 483, 483, 226, 20, 209, 410, 410, 410, 410, 410, 280, 29, 29, 382, 313, 313, 38, 164, 164, 164, 214, 214, 214, 214, 214, 214, 328, 328, 200, 200, 471, 471, 49, 269, 9, 338, 338, 400, 400, 400, 400, 30, 422, 422, 162, 342, 68, 115, 273, 470, 120, 120, 120, 240, 314, 314, 478, 478, 66, 68, 68, 115, 273, 273, 486, 486, 486, 486, 460, 460, 240, 240, 314, 314, 26, 359, 359, 474, 474, 474, 474, 474, 19, 19, 19, 454, 454, 454, 78, 78, 20, 421, 20]
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
torch.Size([1, 278, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134500-0033
generate
processing 31th semantic_sys file
31
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT WON'T LAST IT WILL GO AWAY AND THINGS WILL BE JUST 55%|█████▍    | 35/64 [06:16<03:20,  6.91s/it]2024-03-25 02:48:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:48:15 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
[17, 296, 127, 114, 92, 92, 92, 167, 457, 457, 364, 276, 276, 174, 350, 350, 350, 350, 413, 457, 457, 457, 457, 251, 241, 431, 431, 376, 376, 376, 376, 376, 460, 169, 150, 54, 54, 238, 6, 6, 272, 106, 106, 265, 265, 428, 85, 85, 146, 146, 358, 385, 457, 197, 197, 82, 197, 197, 197, 197, 197, 197, 80, 80, 140, 140, 140, 140, 209, 188, 213, 213, 213, 213, 213, 213, 246, 246, 246, 246, 246, 301, 378, 43, 345, 345, 389, 389, 389, 497, 122, 416, 239, 144, 180, 84, 84, 496, 88, 88, 88, 255, 255, 43, 43, 364, 276, 109, 109top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
torch.Size([1, 280, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_20_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134500-0033
generate
processing 31th semantic_sys file
31
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THAT WON'T LAST IT WILL GO AWAY AND THINGS WILL BE JUST AS THEY USED TO
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
321
[17, 17, 127, 114, 92, 92, 92, 92, 167, 167, 457, 457, 364, 364, 276, 276, 109, 350, 350, 350, 350, 350, 413, 413, 457, 457, 457, 457, 251, 251, 251, 241, 431, 431, 431, 376, 376, 376, 376, 376, 376, 376, 376, 460, 460, 169, 150, 150, 54, 54, 86, 238, 6, 272, 34, 106, 111, 111, 111, 111, 111, 111, 85, 85, 85, 85, 207, 207, 207, 207, 19, 19, 19, 454, 454, 229, 82, 247, 126, 126, 126, 292, 23, 23, 23, 408, 408, 391, 391, 140, 289, 289, 289, 140, 108, 108, 119, 119, 351, 351, 213, 213, 213, 213, 246, 301, 301, 378, 345, 345, 389, 389, 389, 497, 122, 416, 239, 239, 27, 180, 84, 84, 84, 16, 88, 88, 88, 88, 255, 255, 255, 43, 43, 364, 276, 109, 109, 109, 403, 403, 403, 403, 403, 403, 403, 207, 207, 207, 207, 207, 207, 207, 19, 19, 19, 454, 454, 454, 78, 78, 140, 140, 312, 312, 312, 292, 292, 292, 292, 292, 292, 21, 21, 21, 21, 21, 21, 21, 21, 21, 408, 408, 408, 408, 149, 149, 228, 140, 140, 412, 83, 83, 83, 55, 55, 55, 322, 322, 67, 394, 76, 465, 465, 164, 164, 214, 214, 214, 214, 214, 360, 360, 200, 200, 200, 471, 49, 49, 9, 142, 397, 345, 345, 389, 389, 389, 389, 497, 122, 8, 239, 354, 420, 420, 420, 420, 324, 422, 236, 32, 32, 239, 310, 107, 107, 395, 395, 395, 180, 151, 151, 151, 151, 151, 151, 169, 169, 150, 150, 54, 86, 238, 6, 6, 272, 34, 253, 253, 253, 253, 253, 253, 453, 9, 9, 198, 198, 114, 0, 0, 0, 0, 0, 301, 219, 219, 219, 219, 485, 485, 374, 374, 374, 132, 368, 186, 186, 54, 238, 238, 6, 82, 272, 377, 87, 87, 374, 374, 374, 374, 374, 132, 132, 132, 132, 132, 132, 98, 98, 98, 13]
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
torch.Size([1, 319, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_20_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134500-0039
generate
processing 32th semantic_sys file
32
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I'M SURE ALEXANDRA HOPES YOU WILL STAY ON HERE SHE MURMURED
enroll_x_lens:tensor([45], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
181
[17, 17, 296, 287, 287, 111, 111, 111, 111, 438, 438, 203, 53, 53, 90, 478, 162, 338, 338, 338, 338, 395, 395, 487, 498, 498, 498, 498, 468, 468, 396, 313, 335, 14, 411, 145, 145, 329, 329, 329, 175, 81, 469, 469, 416, 416, 96, 453, 342, 168, 470, 329, 365, 365, 365, 330, 64, 212, 161, 300, 382, 423, 423, 423, 58, 58, 72, 72, 437, 437, 496, 496, 496, 496, 496, 274, 215, 233, 233, 20, 20, 270, 270, 270, 390, 390, 390, 390, 390, 97, 97, 97, 219, 219, 152, 152, 152, 378, 345, 389, 389, 389, 497, 186, 162, 162, 232, 232, 238, 6, 20, 384, 470, 470, 403, 403, 403, 171, 171, 3, 3, 14, 14, 411, 287, 426, 426, 426, 426, 125, 125, 348, 33, 33, 58, 183, 183, 183, 286, 286, 286, 286, 468, 468, 468, 59, 313, 313, 186, 99, 338, 338, 338, 400, 400, 400, 30, 301, 399, 217, 70, 473, 65, 498, 498, 498, 203, 53, 53, 29, 334, 334, 334, 59, 59, 37, 37, 24, 131, 419, 439]
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
torch.Size([1, 179, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_20_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134500-0028
generate
processing 33th semantic_sys file
33
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I PRAY FOR YOU BUT THAT'S NOT THE SAME AS IF YOU PRAYED YOURSELF
enroll_x_lens:tensor([27], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
184
[17, 296, 287, 111, 111, 438, 438, 143, 129, 259, 74, 190, 190, 487, 288, 288, 171, 171, 171, 252, 349, 349, 205, 155, 332, 332, 332, 332, 219, 219, 219, 219, 477, 477, 477, 477, 477, 477, 132, 132, 132, 132, 98, 98, 98, 98, 98, 13, 13, 13, 237, 237, 237, 237, 47, 47, 140, 140, 140, 47, 140, 140, 73, 73, 73, 140, 320, 159, 159, 159, 236, 35, 259, 127, 114, 92, 92, 240, 240, 35, 77, 77, 86, 8 56%|█████▋    | 36/64 [06:30<03:45,  8.06s/it]2024-03-25 02:48:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:48:29 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
 58%|█████▊    | 37/64 [06:39<03:50,  8.54s/it]2024-03-25 02:48:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:48:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
synthesize text: I GET TIRED OF SEEING MEN AND HORSES GOING UP AND DOWN UP AND DOWN
enroll_x_lens:tensor([35], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
162
[17, 296, 296, 111, 111, 438, 416, 416, 445, 445, 278, 278, 385, 143, 401, 82, 108, 119, 119, 437, 437, 265, 428, 85, 146, 146, 468, 468, 313, 313, 325, 34, 223, 223, 130, 186, 232, 232, 172, 115, 267, 267, 267, 267, 360, 135, 135, 135, 135, 200, 248, 248, 248, 217, 217, 473, 473, 136, 136, 136, 136, 136, 330, 94, 199, 89, 89, 446, 116, 33, 90, 58, 72, 72, 72, 441, 153, 153, 153, 372, 396, 396, 186, 99, 54, 54, 224, 50, 50, 50, 50, 49, 9, 142, 221, 336, 144, 180, 84, 88, 88, 88, 176, 135, 135, 200, 464, 180, 230, 230, 230, 215, 35, 82, 29, 242, 116, 116, 394, 394, 239, 384, 371, 180, 315, 315, 315, 450, 413, 413, 199, 199, 230, 230, 215, 215, 82, 29, 242, 116, 33, 394, 394, 212, 384, 371, 180, 315, 315, 315, 315, 450, 450, 413, 413, 413, 117, 48, 13, 229, 244, 244]
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
torch.Size([1, 160, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134500-0032
generate
processing 35th semantic_sys file
35
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FRANK READ ENGLISH SLOWLY AND THE MORE HE READ ABOUT THIS DIVORCE CASE T[17, 296, 190, 380, 380, 288, 365, 365, 360, 200, 76, 76, 458, 208, 397, 397, 147, 147, 380, 288, 288, 443, 120, 120, 120, 240, 240, 325, 34, 335, 14, 411, 188, 188, 360, 360, 200, 200, 248, 248, 359, 359, 81, 81, 81, 459, 271, 271, 99, 99, 447, 447, 447, 482, 482, 482, 482, 26, 26, 26, 386, 431, 431, 84, 496, 496, 496, 274, 175, 359, 474, 474, 474, 474, 474, 474, 19, 19, 19, 454, 454, 229, 229, 170, 170, 170, 20, 20, 312, 187, 187, 187, 187, 12, 12, 12, 12, 12, 12, 163, 163, 163, 163, 163, 163, 20, 316, 316, 316, 20, 73, 20, 20, 412, 83, 83, 55, 55, 322, 67, 466, 466, 22, 5, 455, 455, 399, 70, 70, 138, 138, 138, 138, 138, 138, 138, 372, 372, 396, 396, 313, 313, 58, 183, 183, 451, 451, 30, 30, 30, 301, 301, 42, 42, 42, 147, 147, 380, 288, 443, 240, 240, 325, 34, 255, 255, 236, 8, 354, 180, 180, 113, 113, 113, 113, 113, 450, 167, 167, 167, 457, 457, 7, 198, 114, 114, 258, 258, 258, 31, 31, 54, 86, 86, 238, 6, 272, 490, 490, 490, 173, 280, 280, 280, 153, 153, 153, 153, 372, 372, 372, 396, 396, 396 59%|█████▉    | 38/64 [06:57<03:42,  8.56s/it]2024-03-25 02:48:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:48:56 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
torch.Size([1, 219, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_20_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134500-0032
generate
processing 35th semantic_sys file
35
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FRANK READ ENGLISH SLOWLY AND THE MORE HE READ ABOUT THIS DIVORCE CASE THE ANGRIER HE GREW
enroll_x_lens:tensor([39], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
296
[17, 17, 261, 380, 380, 288, 365, 365, 365, 365, 360, 200, 76, 458, 208, 133, 42, 42, 147, 147, 380, 288, 443, 443, 240, 240, 325, 34, 34, 145, 145, 365, 365, 365, 200, 200, 248, 248, 359, 81, 81, 459, 459, 271, 99, 99, 447, 447, 447, 482, 482, 482, 482, 482, 26, 26, 26, 241, 241, 431, 431, 84, 84, 496, 496, 274, 274, 274, 359, 359, 359, 474, 474, 474, 474, 474, 19, 19, 19, 19, 454, 454, 454, 78, 78, 140, 140, 140, 312, 312, 312, 187, 12, 292, 292, 292, 23, 23, 23, 23, 23, 408, 408, 408, 391, 228, 321, 321, 412, 83, 55, 55, 322, 67, 466, 22, 5, 455, 455, 399, 70, 138, 138, 138, 138, 138, 138, 372, 372, 396, 313, 58, 183, 451, 451, 30, 30, 30, 30, 301, 42, 42, 147, 147, 380, 380, 288, 443, 443, 240, 240, 285, 34, 255, 255, 8, 8, 354, 180, 180, 113, 113, 113, 113, 450, 450, 167, 35, 35, 401, 321, 127, 114, 258, 258, 258, 258, 31, 54, 86, 238, 6, 321, 384, 371, 490, 490, 490, 173, 280, 280, 280, 153, 153, 153, 153, 153, 372, 372, 372, 372, 59, 59, 59, 59, 304, 304, 304, 185, 186, 269, 323, 323, 18, 97, 97, 225, 80, 80, 140, 321, 321, 144, 445, 445, 351, 343, 343, 171, 171, 252, 186, 39, 54, 86, 238, 198, 22, 448, 448, 448, 464, 464, 145, 145, 145, 365, 365, 365, 360, 200, 248, 212, 29, 495, 382, 337, 337, 286, 286, 334, 382, 382, 313, 58, 183, 451, 30, 30, 30, 30, 301, 416, 239, 208, 79, 79, 79, 380, 288, 288, 288, 374, 374, 132, 132, 132, 132, 132, 132, 132, 98, 98, 98, 98, 13]
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
torch.Size([1, 294, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_20_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134500-0000
generate
processing 36th semantic_sys file
36
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: JUST SMELL THE WILD ROSES THEY ARE ALWAYS SO SPICY AFTER A RAIN
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
275
[17, 17, 296, 107, 395, 180, 151, 151, 151, 169, 150, 150, 86, 86, 238, 6, 6, 272, 478, 66, 66, 232, 232, 68, 68, 105, 105, 196, 217, 473, 65, 189, 189, 139, 139, 139, 293, 293, 293, 293, 122, 216, 22, 283, 455, 455, 43, 364, 276, 276, 346, 346, 346, 265, 265, 265, 265, 85, 85, 85, 139, 139, 293, 293, 122, 122, 122, 133, 133, 147, 147, 380, 380, 288, 496, 496, 496, 496, 496, 274, 274, 368, 368, 368, 453, 168, 168, 50, 50, 50, 50, 50, 50, 50, 185, 185, 269, 269, 433, 160, 160, 112, 427, 56, 56, 20, 20, 312, 312, 187, 292, 292, 292, 292, 292, 292, 21, 21, 21, 408, 408, 408, 408, 149, 228, 20, 20, 320, 127, 0, 0, 0, 0, 464, 353, 353, 353, 353, 353, 14, 14, 14, 14, 411, 297, 297, 297, 297, 297, 297, 297, 297, 297, 293, 293, 43, 345, 109, 109, 109, 403, 171, 171, 318, 318, 318, 49, 269, 342, 342, 68, 68, 68, 115, 344, 344, 344, 344, 344, 344, 274, 186, 186, 162, 232, 232, 68, 68, 68, 68, 68, 105, 105, 105, 336, 336, 20, 354, 106, 499, 428, 428, 428, 146, 146, 358, 358, 186, 186, 39, 68, 68, 224, 41, 41, 41, 41, 324, 3, 3, 464, 464, 145, 145, 145, 486, 460, 460, 460, 460, 169, 169, 402, 402, 96, 6, 272, 300, 300, 382, 495, 406, 406, 467, 467, 44, 44, 44, 42, 42, 147, 147, 380, 380, 288, 290, 290, 290, 290, 290, 290, 290, 434, 434, 434, 434, 434, 434, 434, 339, 303, 117, 117, 48, 48]
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
torch.Size([1, 273, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_20_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134500-0006
generate
processing 37th semantic_sys file
37
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I LIKE TO TALK TO CARL ABOUT NEW YORK AND WHAT A FELLOW CAN DO THERE
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
220
[17, 17, 296, 287, 111, 111, 111, 438, 438, 251, 241, 266, 266,  62%|██████▎   | 40/64 [07:11<03:54,  9.76s/it]2024-03-25 02:49:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:49:10 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
 64%|██████▍   | 41/64 [07:19<03:33,  9.28s/it]2024-03-25 02:49:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:49:18 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
torch.Size([1, 274, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134500-0024
generate
processing 38th semantic_sys file
38
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: I CAN'T PRAY TO HAVE THE THINGS I WANT HE SAID SLOWLY AND I WON'T PRAY NOT TO HAVE THEM NOT IF I'M DAMNED FOR IT
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
381
[17, 17, 296, 287, 111, 111, 438, 438, 143, 458, 445, 445, 351, 351, 365, 365, 365, 330, 457, 457, 401, 82, 74, 190, 190, 487, 288, 288, 403, 171, 171, 252, 422, 143, 36, 108, 108, 119, 351, 374, 374, 374, 132, 132, 58, 58, 110, 110, 202, 202, 202, 202, 314, 198, 198, 22, 283, 283, 455, 38, 164, 164, 164, 214, 214, 214, 214, 214, 328, 200, 200, 471, 49, 49, 453, 168, 168, 111, 111, 111, 111, 438, 378, 43, 276, 276, 174, 174, 174, 319, 319, 167, 457, 457, 183, 183, 451, 451, 30, 30, 422, 186, 162, 232, 232, 172, 115, 273, 470, 470, 120, 120, 120, 240, 314, 314, 314, 478, 478, 232, 232, 232, 232, 172, 26, 26, 26, 241, 431, 431, 84, 84, 84, 496, 496, 274, 274, 359, 359, 359, 474, 474, 474, 474, 474, 19, 19, 19, 19, 454, 454, 454, 78, 78, 140, 170, 140, 140, 312, 312, 312, 292, 292, 292, 292, 21, 21, 326, 326, 326, 326, 326, 101, 101, 149, 149, 82, 412, 83, 55, 55, 322, 322, 94, 199, 111, 111, 111, 438, 438, 378, 43, 276, 109, 109, 350, 350, 350, 350, 457, 457, 457, 401, 82, 259, 74, 190, 190, 487, 288, 288, 403, 171, 171, 252, 339, 10, 10, 309, 479, 331, 307, 307, 307, 307, 61, 61, 167, 457, 457, 401, 401, 82, 75, 108, 108, 119, 119, 351, 374, 374, 374, 374, 374, 374, 132, 132, 132, 132, 132, 132, 132, 98, 98, 58, 58, 110, 110, 110, 202, 202, 202, 202, 202, 173, 402, 198, 198, 127, 114, 114, 114, 57, 57, 57, 282, 282, 203, 203, 381, 381, 381, 117, 404, 404, 225, 439, 78, 78, 140, 140, 47, 140, 80, 140, 80, 140, 7, 7, 309, 479, 331, 307, 307, 307, 307, 61, 206, 285,[17, 17, 296, 287, 111, 111, 438, 438, 143, 458, 445, 445, 445, 351, 351, 365, 365, 365, 365, 330, 167, 167, 457, 457, 401, 401, 259, 74, 74, 190, 190, 190, 190, 190, 487, 380, 288, 288, 403, 403, 403, 403, 171, 171, 207, 246, 246, 246, 3, 422, 143, 36, 108, 108, 377, 377, 374, 374, 374, 132, 132, 58, 58, 110, 110, 202, 202, 202, 202, 202, 173, 402, 198, 198, 198, 22, 283, 283, 455, 38, 164, 164, 214, 214, 214, 214, 214, 214, 328, 200, 200, 471, 49, 453, 168, 111, 111, 438, 378, 43, 276, 276, 174, 174, 174, 319, 348, 94, 183, 451, 30, 30, 30, 422, 162, 342, 172, 273, 470, 120, 240, 314, 314, 478, 162, 232, 232, 172, 26, 26, 26, 241, 431, 84, 84, 496, 496, 274, 2enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
257
[17, 17, 296, 44, 44, 44, 8, 8, 354, 190, 380, 380, 288, 278, 278, 31, 39, 342, 86, 105, 105, 336, 208, 208, 397, 345, 109, 109, 278, 330, 116, 64, 64, 212, 131, 34, 254, 254, 254, 254, 131, 472, 221, 82, 144, 27, 27, 351, 319, 319, 319, 203, 53, 53, 65, 230, 230, 230, 230, 230, 215, 215, 233, 233, 233, 20, 20, 419, 419, 419, 427, 229, 20, 312, 312, 187, 187, 12, 12, 12, 12, 12, 408, 408, 408, 408, 149, 149, 228, 20, 412, 83, 55, 55, 322, 322, 67, 250, 250, 141, 141, 141, 141, 281, 9, 142, 221, 336, 161, 161, 79, 499, 499, 499, 265, 265, 265, 85, 85, 146, 173, 173, 280, 176, 135, 135, 200, 200, 248, 248, 76, 401, 401, 20, 74, 74, 437, 437, 437, 151, 169, 349, 205, 205, 261, 41, 41, 324, 324, 324, 324, 301, 301, 43, 364, 364, 364, 276, 276, 346, 346, 428, 428, 146, 146, 358, 457, 233, 233, 131, 472, 472, 472, 401, 401, 20, 144, 208, 208, 425, 386, 386, 431, 315, 315, 315, 315, 315, 315, 315, 450, 450, 450, 450, 413, 37, 24, 24, 270, 270, 270, 433, 342, 224, 494, 255, 255, 143, 458, 208, 208, 190, 487, 499, 499, 405, 169, 150, 39, 86, 238, 198, 22, 22, 283, 38, 38, 162, 68, 68, 105, 105, 336, 144, 180, 180, 265, 265, 265, 265, 265, 265, 265, 85, 85, 85, 207, 207, 19, 19, 454, 454, 454, 78, 78, 421, 20]
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
torch.Size([1, 255, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_70_steps_16_2024-03-25_10:41:38
sys_file:gen_237-134500-0002
generate
processing 40th semantic_sys file
40
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY REGAINED THEIR APARTMENT APPARENTLY WITHOUT DISTURBING THE HOUSEHOLD OF GAMEWELL
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
240
[17, 17, 296, 127, 0, 222, 222, 468, 406, 467, 467, 255, 255, 255, 416, 416, 239, 445, 445, 180, 290, 290, 290, 290, 290, 434, 434, 434, 434, 339, 339, 64, 212, 212, 198, 198, 127, 114, 222, 222, 468, 468, 406, 467, 255, 255, 255, 129, 259, 74, 74, 437, 437, 306, 306, 306, 306, 396, 396, 457, 457, 196, 196, 291, 291, 291, 116, 199, 255, 255, 255, 129, 82, 74, 74, 351, 351, 351, 264, 264, 468, 468, 11, 11, 11, 11, 11, 457, 457, 359, 359, 359, 474, 474, 474, 474, 474, 19, 19, 19, 19, 454, 229, 82, 247, 126, 126, 326, 101, 149, 149, 20, 20, 20, 320, 333, 333, 220, 220, 216, 114, 113, 113, 113, 113, 113, 167, 35, 35, 36, 384, 490, 490, 490, 490, 31, 54, 54, 238, 6, 272, 161, 487, 498, 498, 498, 396, 215, 8, 354, 176, 176, 135, 135, 200, 248, 248, 22, 283, 283, 455, 58, 72, 72, 72, 268, 268, 268, 268, 268, 268, 268, 268, 293, 293, 186, 39, 54, 54, 142, 142, 72, 437, 424, 424, 424, 424, 424, 424, 424, 182, 182, 182, 497, 497, 497, 122, 122, 131, 483, 483, 440, 69, 69, 69, 462, 130, 402, 402, 32, 32, 239, 445, 445, 180, 93, 290, 290, 171, 171, 434, 301, 399, 250, 250, 276, 276, 109, 109, 109, 443, 139, 139, 139, 375, 375, 375, 98, 98, 13]
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
top_k_know_token:70
torch.Size([1, 238, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_70_steps_16_2024-03-25_10:41:38
sys_file:gen_61-70970-0040
generate
processing 41th semantic_sys file
41
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: STUTELEY WAS BY HIS SIDE IN A FLASH AND THEN THEY BOTH BEGAN FEELING ABOUT THEM TO ASCERTAIN THE SHAPE AND CHARACTER OF THIS VAULT
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
458
[17, 17, 17, 296, 66, 482, 482, 238, 6, 6, 272, 371, 485, 485, 374, 374, 374, 132, 252, 143, 36, 449, 449, 134, 134, 134, 359, 359, 359, 474, 474, 474, 324, 324, 301, 378, 345, 141, 141, 141, 141, 281, 9,  67%|██████▋   | 43/64 [07:51<04:49, 13.76s/it]2024-03-25 02:49:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:49:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:49:50 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
[17, 17, 17, 66, 66, 482, 482, 482, 238, 6, 272, 371, 470, 374, 374, 374, 374, 252, 186, 449, 449, 449, 134, 134, 134, 359, 359, 474, 474, 474, 474, 324, 3, 301, 378, 43, 345, 141, 141, 141, 141, 281, 453, 142, 221, 336, 354, 354, 62, 62, 62, 62, 62, 62, 85, 146, 146, 58, 183, 183, 257, 257, 257, 257, 257, 31, 162, 232, 232, 172, 172, 115, 273, 273, 265, 265, 428, 85, 146, 146, 252, 24, 325, 335, 188, 340, 340, 340, 94, 199, 199, 44, 44, 38, 349, 234, 234, 234, 261, 425, 386, 386, 431, 486, 376, 376, 460, 169, 169, 169, 99, 99, 436, 436, 436, 447, 112, 112, 427, 56, 56, 56, 312, 312, 312, 187, 292, 292, 12, 12, 12, 12, 12, 12, 12, 12, 12, 260, [17, 17, 17, 296, 66, 66, 482, 238, 238, 336, 336, 75, 371, 485, 374, 374, 374, 374, 285, 285, 134, 134, 134, 134, 359, 359, 474, 474, 474, 474, 474, 324, 301, 301, 378, 345, 345, 141, 141, 281, 281, 453, 142, 221, 336, 354, 354, 62, 62, 62, 62, 62, 62, 146, 146, 146, 257, 257, 257, 257, 257, 31, 162, 232, 232, 232, 172, 172, 115, 273, 273, 265, 265, 265, 85, 85, 146, 146, 146, 24, 325, 34, 340, 340, 340, 94, 199, 44, 44, 38, 349, 234, 234, 261, 261, 425, 386, 386, 431, 431, 486, 376, 376, 376, 376, 376, 376, 460, 460, 169, 169, 99, 99, 436, 436, 436, 447, 18, 112, 427, 56, 247, 247, 126, 126, 292, 292, 326, 326, 326, 326, 326, 326, 101, 408, 149, 149, 228, 140, 412, 83, 83, 55, 55, 322, 322, 466, 466, 361, 361, 361, 361, 361, 348, 466, 466, 466, 114, 0, 0, 0, 0, 301, 301, 8, 8, 354, 354, 106, 496, 496, 496, 496, 496, 274, 169, 169, 164, 164, 221, 221, 401, 354, 420, 420, 420, 416, 239, 445, 445, 210, 210, 210, 210, 210, 330, 388, 33, 394, 90, 393, 234, 234, 261, 261, 25, 485, 485, 485, 286, 139, 139, 175, 175, 81, 176, 135, 135, 200, 464, 255, 255, 255, 8, 8, 354, 180, 113, 113, 113, 113, 113, 167, 167, 35, 35, 198, 114, 114, 57, 57, 57, 203, 203, 381, 381, 381, 117, 404, 13, 229, 82, 140, 247, 126, 126, 23, 23, 408, 408, 391, 140, 140, 140, 289, 289, 75, 108,[17, 17, 296, 296, 66, 66, 482, 482, 238, 6, 272, 371, 485, 485, 374, 374, 374, 252, 143, 36, 26, 26, 359, 474, 166, 166, 301, 378, 43, 345, 141, 141, 141, 281, 9, 142, 221, 336, 354, 62, 62, 62, 62, 62, 438, 58, 183, 257, 257, 257, 257, 257, 162, 162, 232, 172, 172, 115, 273, 273, 265, 265, 265, 265, 85, 85, 146, 146, 24, 325, 34, 340, 340, 340, 116, 94, 199, 44, 44, 38, 349, 234, 234, 261, 425, 425, 386, 431, 486, 486, 376, 460, 460, 169, 169, 169, 99, 436, 338, 338, 338, 18, 18, 112, 112, 439, 56, 56, 56, 170, 20, 28, 20, 28, 20, 28, 20, 20, 20, 341, 20, 341, 341, 341, 369, 369, 369, 369, 369, 369, 369, 369, 369, 369, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 260, 260, 260, 260, 260, 260, 260, 391, 391, 391, 228, 20, 20, 412, 55, 55, 322, 322, 466, 466, 361, 361, 361, 361, 361, 348, 466, 466, 114, 0, 0, 0, 0, 301, 8, 8, 354, 106, 106, 496, 496, 496, 496, 496, 169, 169, 352, 164, 164, 221, 336, 354, 354, 420, 420, 420, 416, 458, 445, 210, 210, 210, 210, 210, 210, 330, 388, 33, 394, 90, 393, 234, 261, 25, 25, 485, 485, 213, 286, 139, 139, 175, 81, 176, 135, 135, 200, 464, 255, 255, 8, 8, 354, 180, 113, 113, 113, 113, 113, 167, 167, 457, 457, 198, 127, 114, 57, 57, 57, 203, 381, 381, 381, 117, 117, 48, 48, 48, 417, 417, 237, 237, 237, 237, 20, 237, 237, 237, 237, 237, 237, 20, 2, 20, 2, 2, 20, 20, 211, 211, 163, 20, 163, 163, 20, 20, 316, 316, 20, 73, 289, 289, 289, 108, 108, 377, 351, 374, 374, 374, 132, 88, 14, 14, 411, 145, 145, 486, 460, 460, 169, 150, 54, 54, 224, 494, 494, 494, 236, 36, 108, 119, 119, 351, 351, 290[17, 17, 296, 276, 276, 153, 153, 372, 372, 372, 396, 396, 396, 242, 242, 242, 195, 195, 195, 195, 195, 195, 195, 117, 117, 117, 48, 48, 48, 417, 170, 170, 170, 170, 20, 28, 20, 28, 20, 20, 2, 20, 2, 2, 2, 20, 2, 2, 20, 2, 163, 20, 163, 163, 163, 163, 163, 163, 316, 20, 20, 316, 73, 73, 289, 373, 66, 66, 232, 232, 105, 105, 336, 336, 354, 189, 496, 496, 496, 274, 274, 35, 96, 96, 198, 127, 114, 180, 151, 151, 151, 169, 150, 150, 54, 54, 142, 397, 397, 345, 333, 333, 220, 220, 162, 232, 232, 232, 172, 115, 273, 494, 154, 416, 416, 96, 196, 196, 479, 278, 278, 278, 349, 349, 352, 469, 469, 469, 469, 416, 192, 11, 11, 11, 11, 379, 379, 379, 243, 77, 77, 433, 390, 390, 390, 390, 18, 112, 112, 427, 56, 56, 56, 312, 312, 312, 187, 187, 12, 12, 12, 12, 260, 260, 260, 260, 260, 163, 163, 163, 163, 20, 316, 20, 316, 316, 73, 7synthesize text: WARRENTON SPOKE THUS WITH SIGNIFICANCE TO SHOW ROBIN THAT HE WAS NOT TO THINK GEOFFREY'S CLAIMS TO THE ESTATE WOULD BE PASSED BY
enroll_x_lens:tensor([49], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
434
[17, 296, 296, 276, 153, 153, 372, 372, 372, 467, 467, 242, 242, 64, 76, 465, 108, 449, 242, 242, 242, 116, 33, 394, 478, 162, 482, 105, 105, 105, 336, 354, 106, 496, 496, 496, 496, 274, 274, 143, 458, 96, 96, 198, 198, 127, 114, 180, 151, 151, 151, 151, 169, 169, 150, 39, 54, 54, 142, 397, 397, 345, 333, 333, 333, 220, 220, 164, 478, 66, 232, 172, 172, 224, 494, 494, 154, 416, 416, 196, 196, 309, 479, 278, 278, 278, 278, 173, 349, 469, 469, 469, 469, 469, 458, 192, 11, 11, 11, 11, 379, 379, 471, 471, 77, 269, 54, 86, 238, 6, 336, 82, 108, 377, 377, 374, 374, 374, 374, 132, 186, 186, 99, 338, 338, 338, 338, 395, 395, 84, 84, 84, 496, 496, 274, 274, 274, 42, 42, 42, 147, 147, 380, 499, 499, 284, 405, 405, 405, 206, 206, 206, 215, 215, 8, 29, 275, 275, 275, 275, 275, 388, 303, 303, 117, 48, 48, 48, 229, 229, 82, 312, 187, 187, 187, 187, 391, 244, 392, 392, 392, 73, 392, 392, 320, 127, 45, 45, 45, 45, 325, 183, 183, 451, 30, 30, 30, 30, 301, 301, 378, 43, 345, 141, 141, 141, 141, 281, 281, 453, 9, 142, 221, 196, 309, 309, 479, 331, 307, 307, 307, 307, 307, 61, 61, 167, 167, 457, 457, 401, 82, 108, 108, 377, 377, 374, 374, 374, 374, 374, 132, 422, 143, 164, 164, 164, 214, 214, 214, 214, 360, 360, 200, 248, 76, 96, 401, 310, 107, 395, 329, 329, 329, 329, 329, 329, 329, 349, 205, 155, 29, 29, 495, 382, 313, 313, 368, 269, 9, 142, 221, 221, 336, 208, 208, 386, 386, 386, 431, 431, 290, 290, 290, 290, 434, 434, 203, 203, 53, 471, 471, 49, 49, 269, 323, 323, 18, 97, 97, 197, 197, 197, 80, 80, 80, 82, 108, 377, 377, 123, 123, 123, 216, 22, 22, 448, 448, 448, 464, 255, 255, 38, 162, 162, 232, 232, 482, 238, 6, 6, 272, 470, 470, 470, 403, 171, 171, 171, 358, 358, 358, 385, 233, 131, 419, 427, 229, 82, 247, 187, 187, 187, 187, 391, 391, 391, 228, 140, 140, 320, 7, 345, 345, 389, 389, 389, 314, 314, 239, 239, 420, 420, 420, 420, 301, 143, 129, 259, 74, 74, 311, 311, 311, 311, 311, 311, 311, 311, 460, 169, 150, 150, 54, 86, 238, 238, 6, 272, 472, 221, 82, 354, 354, 106, 265, 265, 265, 265, 265, 265, 265, 265, 85, 85, 85, 85, 207, 207, 207, 19, 454, 454, 13, 229]
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
torch.Size([1, 432, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_30_steps_16_2024-03-25_10:41:38
sys_file:gen_61-70970-0035
generate
processing 43th semantic_sys file
43
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THE HOURS PASSED WEARILY BY AND MOVEMENT COULD YET BE HEARD ABOUT THE HALL
An exception occurred: 'aɪʊɹ'
processing 44th semantic_sys file
44
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: FROM THE BLACKNESS BEHIND THE LIGHT THEY HEARD A VOICE WARRENTON'S
enroll_x_lens:tensor([60], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
230
[17, 17, 296, 165, 165, 165, 466, 466, 466, 283, 283, 455, 455, 8, 259, 425, 425, 431, 431, 376, 376, 376, 460, 460, 178, 35, 96, 96, 196, 459, 459, 459, 459, 271, 31, 342, 342, 86, 142, 221, 336, 336, 354, 420, 420, 420, 422, 58, 58, 72, 437, 480, 480, 480, 480, 480, 480, 299, 299, 299, 299, 299, 339, 339, 64, 212, 212, 131, 419, 439, 439, 78, 20, 170, 20, 47, 20, 20, 2, 2, 20, 2, 20, 163, 163, 163, 20, 316, 20, 73, 289, 289, 20, 127, 5, 5, 455, 455, 251, 251, 241, 241, 431, 428, 428, 428, 428, 146, 358, 358, 358, 358, 233, 233, 233, 75, 227, 419, 419, 419, 439, 439, 78, 20, 20, 20, 47, 47, 20, 47, 20, 47, 47, 47, 316, 316, 73, 20, 289, 289, 320, 320, 114, 0, 0, 0, 422, 422, 58, 72, 72, 498, 498, 498, 498, 498, 396, 313, 285, 285, 34, 44, 44, 44, 173, 4, 280, 280, 343, 343, 343, 343, 343, 343, 146, 358, 186, 39, 54, 54, 142, 397, 397, 336, 364, 2 75%|███████▌  | 48/64 [08:26<02:29,  9.32s/it]2024-03-25 02:50:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:50:25 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_10_steps_16_2024-03-25_10:41:38
sys_file:gen_61-70970-0029
generate
processing 45th semantic_sys file
45
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ROBIN CAREFULLY DESCENDED THE LADDER AND FOUND HIMSELF SOON UPON FIRM ROCKY GROUND
enroll_output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_61-70970-0029
generate
processing 45th semantic_sys file
45
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ROBIN CAREFULLY DESCENDED THE LADDER AND FOUND HIMSELF SOON UPON FIRM ROCKY GROUND
enroll_x_lens:tensor([47], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
263
[17, 296, 296, 147, 147, 380, 329, 329, 329, 215, 29, 29, 242, 242, 33, 90, 90, 76, 259, 144, 445, 351, 351, 351, 264, 264, 264, 264, 460, 169, 349, 205, 262, 262, 262, 359, 359, 166, 166, 166, 301, 236, 239, 490, 490, 490, 38, 162, 232, 172, 115, 273, 432, 432, 432, 330, 64, 212, 191, 191, 191, 314, 314, 198, 22, 283, 455, 455, 251, 241, 241, 431, 486, 486, 486, 460, 240, 285, 300, 334, 355, 355, 355, 452, 263, 263, 225, 225, 225, 225, 225, 225, 412, 83, 55, 55, 322, 67, 394, 90, 393, 234, 234, 261, 25, 180, 315, 315, 315, 315, 450, 450, 413, 348, 64, 131, 183, 183, 57, 57, 203, 53, 478, 478, 162, 232, 172, 172, 115, 273, 279, 279, 279, 279, 279, 279, 279, 375, 169, 352, 352, 352, 352, 352, 352, 112, 112, 439, 78, 140, 140, 47, 47, 140, 140, 140, 373, 373, 66, 66, 482, 172, 172, 115, 273, 374, 374, 374, 132, 339, 94, 199, 255, 255, 129, 259, 74, 437, 437, 125, 125, 125, 125, 348, 33, 394, 90, 393, 393, 234, 234, 261, 25, 25, 498, 498, 498, 498, 498, 498, 498, 355, 355, 203, 203, 381, 381, 381, 117, 404, 404, 225, 225, 225, 225, 225, 80, 80, 7, 7, 7, 147, 147, 380, 499, 405, 405, 405, 458, 192, 192, 192, 41, 324, 324, 324, 301, 416, 239, 208, 79, 79, 380, 380, 315, 315, 315, 315, 315, 315, 450, 450, 450, 413, 303, 303, 303, 243, 212, 131, 419, 439, 439]
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_[17, 296, 451, 451, 30, 30, 464, 121, 121, 53, 394, 465, 74, 74, 425, 425, 386, 386, 153, 153, 387, 387, 387, 71, 368, 453, 9, 142, 219, 219, 219, 477, 477, 477, 374, 374, 132, 132, 132, 132, 132, 98, 98, 13, 13, 13, 78, 170, 140, 140, 140, 312, 312, 187, 187, 12, 12, 12, 12, 260, 260, 260, 260, 391, 391, 391, 140, 140, 73, 73, 289, 140, 209, 83, 443, 443, 443, 169, 150, 39, 54, 86, 238, 6, 336, 82, 108, 108, 377, 377, 374, 374, 374, 374, 374, 132, 132, 132, 8, 259, 354, 420, 420, 420, 422, 325, 490, 490, 490, 490, 162, 232, 232, 482, 105, 105, 336, 208, 79, 79, 487, 288, 288, 213, 213, 213, 246, 358, 358, 233, 36, 227, 227, 419, 419, 427, 427, 82, 247, 312, 187, 187, 187, 187, 187, 187, 391, 391, 391, 228, 140, 140, 412, 83, 253, 253, 253, 253, 453, 198, 198, 198, 22, 283, 455, 455, 416, 239, 144, 208, 79, 79, 380, 288, 288, 403, 403, 171, 171, 171, 246, 246, 246, 246, 173, 173, 280, 280, 340, 340, 116, 466, 466, 466, 114, 258, 258, 258, 31, 31, 54, 86, 142, 221, 196, 217, 70, 65, 486, 486, 486, 460, 460, 169, 449, 449, 449, 449, 300, 355, 355, 355, 355, 355, 452, 263, 263, 13, 229, 82, 312, 312, 187, 187, 187, 187, 187, 260, 260, 260, 391, 391, 391, 140, 373, 373, 155, 155, 332, 332, 332, 406, 467, 467, 340, 340, 33, 394, [17, 17, 296, 451, 451, 30, 464, 464, 121, 121, 53, 394, 76, 74, 425, 425, 386, 386, 153, 153, 153, 153, 387, 387, 387, 368, 368, 453, 219, 219, 477, 477, 378, 88, 109, 443, 443, 443, 169, 150, 39, 86, 238, 6, 82, 108, 377, 377, 374, 374, 374, 301, 8, 354, 420, 420, 420, 301, 325, 490, 490, 490, 38, 162, 232, 482, 105, 105, 336, 79, 79, 487, 288, 213, 213, 213, 358, 358, 36, 449, 449, 253, 253, 253, 281, 453, 198, 198, 198, 22, 283, 455, 416, 82, 208, 79, 79, 380, 288, 288, 171, 171, 171, 252, 173, 280, 34, 340, 340, 116, 466, 466, 114, 258, 258, 258, 31, 342, 142, 221, 196, 217, 473, 65, 486, 486, 460, 460, 169, 36, 449, 449, 300, 334, 355, 355, 355, 355, 452, 263, 263, 13, 78, 140, 170, 140, 140, 140, 312, 312, 187, 12, 12, 12, 12, 12, 12, 12, 12, 260, 260, 260, 391, 391, 140, 140, 373, 373, 155, 155, 332, 332, 406, 467, 467, 340, 340, 33, 394, 478, 162, 232, 232, 172, 115, 273, 374, 374, 374, 374, 374, 132, 132, 216, 164, 164, 183, 257, 257, 257, 281, 453, 9, 26, 251, 241, 431, 431, 265, 428, 428, 428, 146, 358, 358, 358, 352, 352, 352, 352, 97, 483, 440, 356, 356, 356, 281, 453, 168, 168, 340, 340, 340, 116, 466, 466, 22, 283, 455, 58, 72, 72, 437, 481, 481, 481, 481, 175, 175, 81, 84, 84, 84, 84, 84, 16, 274, 274, 274, 335, 335, 440, 69, 69, 223, 130, 280, 106, 222, 222, 222, 353, 353, 206, 206, 58, 72, 72, 294, 294, 294, 294, 294, 282, 388, 379, 303, 471, 471, 471, 471, 270, 269, 433, 390, 18, 18, 112, 112, 439]
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
torch.Size([1, 298, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_30_steps_16_2024-03-25_10:41:38
sys_file:gen_61-70970-0039
generate
processing 47th semantic_sys file
47
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY THEN RENEWED THEIR JOURNEY AND UNDER THE BETTER LIGHT MADE A SAFE CROSSING OF THE STABLE ROOFS
enroll_x_lens:tensor([55], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
333
[17, 296, 127, 0, 0, 0, 0, 301, 301, 216, 127, 361, 361, 361, 361, 361, 330, 388, 33, 33, 250, 250, 147, 147, 456, 456, 456, 116, 10, 10, 309, 398, 398, 398, 374, 374, 132, 132, 132, 314, 314, 314, 198, 127, 114, 222, 222, 222, 222, 313, 313, 236, 239, 310, 107, 395, 395, 498, 498, 498, 498, 498, 498, 396, 396, 313, 94, 199, 41, 41, 41, 324, 19, 3, 464, 89, 89, 89, 446, 322, 67, 212, 131, 34, 106, 319, 319, 319, 319, 348, 64, 212, 300, 300, 300, 313, 216, 216, 22, 283, 455, 455, 8, 354, 180, 180, 443, 443, 443, 443, 285, 285, 334, 334, 334, 59, 59, 452, 452, 263, 263, 13, 78, 170, 170, 170, 140, 28, 28, 28, 28, 28, 140, 2, 2, 2, 140, 2, 2, 2, 2, 2, 2, 2, 140, 366, 366, 366, 366, 140, 316, 316, 140, 316, 316, 73, 140, 289, 289, 7, 7, 241, 241, 431, 428, 428, 428, 428, 146, 146, 252, 252, 457, 457, 196, 196, 473, 476, 476, 476, 476, 252, 325, 34, 44, 44, 44, 38, 162, 54, 172, 172, 115, 273, 470, 470, 403, 403, 403, 171, 171, 171, 358, 358, 358, 352, 352, 352, 352, 352, 352, 352, 419, 419, 439, 439, 439, 78, 78, 47, 47, 140, 47, 47, 47, 140, 80, 80, 80, 80, 289, 144, 208, 208, 190, 190, 499, 499, 499, 405, 405, 405, 405, 206, 169, 150, 150, 54, 54, 224, 176, 176, 176, 176, 328, 328, 200, 200, 200, 117, 117, 404, 404, 225, 225, 225, 78, 47, 47, 140, 80, 80, 80, 140, 412, 287, 69, 69, 223, 223, 130, 130, 198, 22, 22, 283, 283, 38, 162, 54, 238, 238, 6, 272, 470, 470, 171, 171, 171, 171, 252, 8, 8, 100, 100, 497, 497, 497, 42, 42, 42, 147, 147, 380, 380, 288, 374, 374, 374, 132, 132, 132, 358, 349, 352, 352, 352, 352, 352, 352, 352, 352, 112]
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_kno 80%|███████▉  | 51/64 [09:04<02:25, 11.21s/it]2024-03-25 02:51:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:51:03 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
[17, 17, 296, 451, 257, 257, 257, 257, 31, 54, 54, 86, 238, 6, 108, 119, 119, 351, 351, 84, 84, 84, 496, 496, 274, 274, 413, 413, 339, 195, 471, 49, 49, 142, 142, 397, 42, 42, 42, 147, 147, 380, 380, 189, 189, 189, 365, 365, 365, 365, 328, 200, 200, 248, 248, 76, 129, 82, 74, 74, 425, 425, 425, 425, 425, 386, 431, 151, 151, 151, 151, 151, 368, 453, 342, 224, 11, 11, 11, 379, 379, 243, 243, 26, 26, 26, 359, 359, 359, 474, 474, 474, 474, 474, 19, 19, 454, 454, 229, 229, 247, 312, 126, 126, 292, 292, 292, 292, 23, 23, 23, 23, 101, 101, 149, 228, 20, 412, 287, 125, 125, 125, 125, 348, 250, 250, 250, 364, 364, 364, 364, 276, 276, 276, 346, 346, 346, 372, 406, 406, 467, 467, 467, 242, 242, 116, 33, 64, 394, 76, 36, 108, 449, 449, 242, 242, 242, 116, 116, 33, 394, 368, 49, 453, 168, 168, 286, 286, 286, 286, 286, 286, 286, 286, 286, 286, 286, 286, 50, 50, 50, 185, 49, 453, 168, 89, 89, 446, 116, 33, 90, 393, 393, 234, 234, 234, 234, 261, 261, 25, 148, 148, 148, 148, 148, 148, 148, 387, 387, 387, 169, 169, 169, 164, 164, 352, 352, 352, 352, 352, 112, 427, 56, 20, 20, 312, 187, 187, 187, 12, 23, 260, 260, 391, 391, 391, 20, 20, 2 80%|███████▉  | 51/64 [09:12<02top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
torch.Size([1, 289, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_61-70970-0021
generate
processing 48th semantic_sys file
48
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HIS TONES RANG PLEASANTLY ON WARRENTON'S EARS AND FORTHWITH A GOOD FELLOWSHIP WAS HERALDED BETWEEN THEM
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
291
[17, 296, 296, 257, 257, 257, 257, 31, 54, 86, 238, 6, 336, 119, 351, 351, 84, 84, 84, 350, 350, 350, 413, 413, 413, 413, 413, 195, 195, 471, 49, 49, 142, 397, 42, 147, 147, 380, 288, 288, 365, 365, 365, 365, 282, 282, 282, 388, 195, 195, 394, 394, 465, 74, 425, 386, 386, 431, 151, 151, 151, 368, 453, 342, 168, 11, 379, 457, 359, 359, 474, 474, 474, 474, 464, 464, 125, 125, 125, 125, 125, 348, 250, 250, 364, 276, 276, 346, 346, 306, 372, 372, 467, 467, 467, 242, 116, 64, 76, 108, 449, 449, 242, 275, 275, 379, 379, 394, 77, 77, 342, 168, 483, 411, 411, 286, 286, 286, 286, 286, 286, 468, 59, 59, 59, 304, 304, 185, 185, 269, 433, 433, 160, 112, 112, 56, 56, 56, 56, 140, 140, 140, 140, 28, 140, 2, 140, 341, 341, 341, 341, 341, 341, 341, 369, 369, 369, 369, 369, 21, 408, 408, 408, 408, 149, 149, 140, 412, 83, 55, 322, 67, 90, 393, 205, 205, 25, 148, 148, 148, 148, 372, 396, 396, 169, 164, 164, 397, 397, 345, 333, 333, 220, 220, 164, 164, 22, 44, 44, 416, 416, 239, 144, 144, 484, 484, 484, 240, 314, 90, 90, 205, 205, 25, 25, 443, 443, 139, 175, 175, 81, 81, 469, 169, 99, 436, 436, 395, 395, 459, 459, 459, 215, 215, 35, 259, 345, 141, 141, 281, 453, 9, 58, 72, 110, 351, 329, 468, 406, 467, 302, 302, 302, 122, 325, 34, 191, 191, 314, 314, 239, 354, 354, 255, 236, 236, 259, 108, 119, 397, 487, 109, 360, 360, 360, 339, 339, 466, 466, 114, 57, 57, 57, 57, 57, 203, 381, 381, 48, 48, 417]
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
torch.Size([1, 289, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_61-70970-0037
generate
processing 49[17, 296, 25, 278, 278, 278, 278, 385, 457, 478, 478, 232, 232, 172, 115, 273, 374, 374, 374, 374, 374, 252, 143, 35, 270, 270, 342, 142, 58, 72, 110, 294, 294, 294, 294, 294, 294, 294, 282, 282, 388, 64, 212, 131, 472, 133, 42, 147, 147, 380, 288, 443, 151, 151, 169, 150, 86, 86, 238, 272, 272, 191, 191, 191, 325, 34, 415, 415, 415, 457, 457, 251, 251, 241, 431, 376, 376, 376, 376, 376, 376, 460, 169, 150, 39, 86, 86, 6, 6, 34, 255, 236, 129, 259, 74, 437, 125, 125, 125, 125, 125, 125, 348, 466, 466, 22, 283, 455, 236, 129, 82, 108, 119, 437, 437, 405, 405, 405, 405, 405, 206, 215, 35, 35, 35, 401, 133, 147, 147, 380, 380, 499, 499, 319, 319, 319, 319, 413, 413, 200, 200, 200, 200, 69, 69, 69, 223, 130, 130, 280, 44, 44, 44, 251, 251, 251, 241, 431, 431, 486, 376, 376, 376, 376, 460, 460, 240, 285, 300, 334, 334, 59, 59, 59, 452, 452, 263, 229, 82, 247, 126, 126, 326, 326, 408, 408, 149, 228, 140, 140, 83, 55, 55, 322, 322, 67, 478, 478, 162, 232, 232, 482, 482, 482, 26, 26, 26, 251, 241, 431, 431, 496, 496, 496, 274, 274, 359, 359, 474, 474, 474, 166, 301, 216, 216, 22, 283, 455, 236, 129, 36, 108, 161, 161, 487, 487, 487, 487, 374, 374, 374, 132, 132, 358, 358, 186, 352, 352, 352, 352, 352, 352, 352, 352, 97, 225, 225, 80, 140, 140, 80, 80, 140, 144, 445, 210, 210, 210, 210, 210, 210, 434, 339, 339, 394, 394, 76, 36, 108, 377, 123, 123, 123, 123, 123, 58, 183, 57, 57, 57, 57, 57, 57, 203, 381, 381, 381, 381, 48, 48, 48]
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
torch.Size([1, 299, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_30_steps_16_2024-03-25_10:41:38
sys_file:gen_61-70970-0026
generate
processing 50th semantic_sys file
50
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: ROBIN FITZOOTH SAW THAT HIS DOUBTS OF WARRENTON HAD BEEN UNFAIR AND HE BECAME ASHAMED OF HIMSELF FOR HARBORING THEM
enroll_x_lens:tensor([40], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
338
[17, 17, 296, 296, 7, 7, 147, 147, 380, 329, 329, 329, 329, 329, 329, 215, 29, 242, 242, 116, 33, 90, 90, 393, 205, 25, 25, 278, 278, 385, 457, 478, 478, 68, 68, 68, 115, 115, 273, 374, 374, 374, 132, 132, 358, 169, 164, 164, 164, 66, 66, 66, 68, 68, 115, 273, 106, 106, 481, 481, 481, 293, 293, 216, 45, 45, 45, 45, 325, 183, 257, 257, 257, 257, 257, 453, 9, 221, 336, 82, 384, 371, 180, 180, 315, 113, 113, 113, 450, 167, 35, 270, 342, 224, 69, 462, 462, 130, 402, 402, 364, 276, 276, 153, 372, 372, 372, 467, 467, 242, 242, 64, 76, 108, 449, 242, 275, 275, 116, 33, 58, 58, 110, 254, 254, 254, 254, 314, 314, 239, 354, 137, 137, 137, 137, 94, 335, 14, 411, 319, 319, 319, 348, 33, 394, 90, 393, 234, 234, 234, 261, 25, 470, 470, 264, 264, 264, 264, 264, 264, 468, 59, 59, 59, 452, 263, 229, 82, 247, 126, 126, 126, 292, 292, 292, 23, 23, 23, 408, 408, 408, 149, 228, 140, 412, 83, 55, 55, 322, 67, 131, 183, 451, 30, 30, 30, 301, 8, 354, 420, 420, 422, 143, 458, 445, 210, 210, 210, 210, 210, 210, 203, 53, 44, 44, 44, 38, 338, 338, 338, 395, 470, 470, 290, 290, 290, 290, 290, 434, 434, 434, 203, 53, 64, 212, 131, 69, 223, 223, 130, 402, 183, 57, 57, 203, 53, 53, 478, 162, 232, 172, 115, 273, 279, 279, 279, 279, 279, 279, 279, 375, 169, 352, 352, 352, 352, 352, 352, 112, 78, 82, 82, 312, 312, 187, 187, 187, 187, 12, 260, 260, 260, 391, 391, 140, 140, 140, 373, 393, 234, 234, 155, 155, 332, 148, 332, 372, 372, 245, 245, 58, 72, 72, 437, 306, 306, 306, 306, 396, 396, 8, 8, 29, 495, 495, 495, 406, 176, 135, 135, 135, 200, 248, 248, 114, 114, 57, 57, 57, 57, 203, 381, 381, 381, 48, 48, 48, 417]
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
torch.Size([1, 336, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_30_s 86%|████████▌ | 55/64 [09:36<01:26,  9.65s/it][17, 17, 296, 7, 217, 217, 70, 65, 65, 496, 496, 496, 496, 274, 274, 186, 39, 86, 86, 86, 6, 6, 272, 494, 223, 223, 130, 280, 280, 106, 297, 297, 297, 297, 297, 297, 293, 293, 497, 42, 42, 42, 147, 147, 380, 499, 499, 405, 405, 405, 206, 206, 215, 215, 29, 242, 242, 116, 33, 394, 394, 76, 401, 82, 82, 25, 106, 106, 405, 405, 405, 405, 206, 206, 285, 34, 223, 223, 130, 402, 183, 257, 257, 257, 257, 257, 31, 342, 86, 86, 142, 393, 205, 261, 25, 91, 91, 91, 91, 91, 91, 206, 206, 493, 216, 300, 300, 300, 382, 382, 245, 43, 43, 364, 364, 276, 276, 181, 181, 181, 181, 167, 457, 457, 364, 345, 345, 389, 389, 389, 325, 183, 183, 451, 30, 30, 30, 422, 143, 458, 82, 445, 445, 351, 351, 351, 315, 315, 315, 450, 450, 450, 413, 77, 77, 342, 342, 224, 224, 302, 302, 302, 302, 375, 375, 375, 98, 98, 13, 13, 140, 140]
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
top_k_know_token:10
torch.Size([1, 170, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts[17, 17, 296, 7, 217, 217, 217, 70, 70, 65, 65, 496, 496, 496, 496, 274, 274, 186, 39, 54, 86, 86, 238, 6, 6, 272, 494, 223, 223, 130, 280, 280, 106, 106, 297, 297, 297, 297, 297, 297, 297, 293, 497, 497, 497, 42, 42, 42, 147, 147, 380, 499, 499, 405, 405, 206, 206, 215, 8, 29, 242, 242, 242, 116, 116, 33, 394, 394, 478, 164, 164, 164, 164, 164, 25, 106, 106, 405, 405, 405, 206, 206, 285, 34, 69, 223, 223, 130, 280, 280, 257, 257, 257, 257, 257, 31, 54, 54, 142, 142, 393, 234, 234, 234, 234, 261, 25, 25, 91, 91, 91, 91, 91, 91, 91, 206, 206, 493, 216, 216, 300, 300, 334, 334, 334, 59, 59, 452, 263, 229, 82, 247, 312, 126, 126, 292, 23, 23, 23, 23, 23, 260, 260, 391, 391, 391, 140, 140, 289, 140, 140, 7, 7, 364, 364, 364, 364, 276, 276, 276, 181, 181, 181, 181, 181, 181, 167, 167, 385, 457, 233, 82, 131, 133, 133, 364, 345, 430, 430, 430, 430, 430, 325, 183, 451, 30, 30, 30, 422, 422, 143, 82, 144, 445, 445, 351, 351, 351, 315, 315, 450, 450, 413, 413, 64, 77, 77, 77, 323, 323, 224, 302, 302, 302, 302, 375, 375, 98, 98, 13, 13]
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
torch.Size([1, 219, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_20_steps_16_2024-03-25_10:4[17, 17, 296, 253, 253, 253, 253, 453, 453, 168, 180, 145, 475, 330, 94, 199, 475, 475, 324, 464, 464, 464, 340, 116, 94, 199, 335, 411, 360, 360, 360, 360, 200, 248, 248, 248, 359, 359, 81, 275, 275, 275, 275, 388, 195, 195, 64, 212, 131, 483, 483, 440, 287, 111, 111, 111, 111, 378, 43, 345, 345, 389, 389, 389, 314, 478, 478, 232, 232, 172, 115, 273, 470, 403, 403, 171, 171, 252, 422, 186, 162, 232, 172, 172, 115, 273, 470, 120, 120, 240, 314, 314, 90, 90, 239, 445, 445, 180, 290, 290, 290, 290, 290, 434, 203, 203, 381, 381, 381, 48, 48, 48, 417, 417, 417, 237, 170, 20, 28, 28, 28, 20, 20, 28, 20, 20, 362, 20, 362, 20, 362, 20, 362, 20, 20, 362, 20, 362, 20, 362, 366, 366, 20, 366, 366, 366, 366, 366, 20, 366, 366, 20, 366, 316, 316, 20, 316, 316, 316, 73, 20, 289, 320, 7, 276, 109, 109, 139, 139, 139, 293, 293, 293, 293, 122, 129, 259, 74, 190, 190, 488, 488, 499, 315, 315, 315, 450, 450, 413, 122, 26, 359, 474, 474, 474, 166, 301, 216, 216, 114, 45, 45, 45, 240, 325, 325, 34, 356, 356, 356, 356, 356, 368, 368, 453, 9, 168, 340, 340, 340, 340, 116, 33, 199, 183, 183, 257, 257, 257, 257, 257, 453, 9, 238, 6, 384, 371, 93, 93, 93, 93, 93, 93, 207, 207, 207, 19, 19, 19, 454, 454, 454]
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
torch.Size([1, 250, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_30_steps_16_2024-03-25_10:41:38
sys_file:gen_61-70970-0011
generate
processing 53th semantic_sys file
53
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WILL WHISPERED ROBIN OPENING HIS DOOR AS HE SPOKE ARE YOU READY
enroll_x_lens:tensor([54], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
178
[17, 296, 345, 345, 109, 389, 139, 139, 293, 497, 497, 43, 364, 345, 109, 109, 278, 278, 31, 54, 54, 105, 105, 336, 336, 29, 191, 191, 191, 314, 314, 131, 133, 147, 147, 380, 499, 329, 329, 329, 215, 29, 29, 242, 242, 116, 94, 199, 199, 410, 410, 410, 410, 410, 215, 129, 259, 29, 242, 242, 116, 94, 199, 176, 135, 135, 200, 200, 248, 183, 183, 257, 257, 257, 257, 453, 9, 9, 221, 82, 384, 371, 106, 153, 153, 153, 153, 153, 182, 182, 182, 182, 182, 182, 182, 375, 375, 98, 98, 98, 263, 13, 13, 78, 20, 20, 47, 20, 47, 20, 80, 20, 20, 412, 83, 253, 253, 253, 453, 9, 168, 30, 30, 30, 422, 186, 162, 232, 482, 105, 105, 336, 354, 470, 189, 189, 496, 496, 274, 274, 143, 458, 192, 192, 106, 353, 353, 353, 353, 438, 219, 219, 219, 477, 477, 477, 132, 42, 42, 147, 147, 380, 288, 288, 443, 240, 325, 325, 34, 41, 41, 19, 19, 19, 454, 454, 454, 454]
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
top_k_know_token:30
torch.Size([1, 176, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_30_steps_16_2024-03-25_10:41:38
sys_file:gen_61-70970-0020
generate
processing 54th semantic_sys file
54
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THEY MOVED THEREAFTER CAUTIOUSLY ABOUT THE HUT GROPING BEFORE AND ABOUT THEM TO FIND SOMETHING TO SHOW THAT WARRENTON HAD FULFILLED HIS MISSION
enroll_x_lens:tensor([32], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
402
[17, 17, 296, 0, 0, 0, 0, 399, 217, 473, 65, 374, 374, 374, 374, 173, 402, 198, 198, 114, 114, 222, 222, 468, 406, 467, 467, 145, 145, 460, 460, 460, 460, 402, 402, 35, 36, 272, 300, 382, 245, 245, 129, 82, 144, 27, 437, 437, 437, 405, 405, 405, 405, 206, 206, 169, 99, 436, 436, 395, 459, 459, 459, 271, 31, 54, 86, 26, 26, 359, 474, 474, 474, 474, 464, 464, 255, 255, 8, 354, 180, 113, 113, 113, 113, 113, 167, 35,  88%|████████▊ | 56/64 [10:03<01:31, 11.45s/it]2024-03-25 02:52:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:52:02 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
 89%|████████▉ | 57/64 [10:11<01:12, 10.29s/it]2024-03-25 02:52:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:52:09 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
[17, 17, 296, 0, 0, 0, 0, 399, 399, 70, 473, 65, 374, 374, 374, 374, 173, 173, 402, 402, 198, 198, 127, 114, 222, 222, 222, 406, 406, 467, 467, 467, 145, 145, 486, 486, 460, 460, 460, 460, 169, 402, 402, 6, 272, 272, 300, 334, 334, 59, 59, 59, 452, 452, 263, 263, 225, 225, 80, 20, 80, 80, 80, 20, 20, 144, 27, 27, 437, 437, 405, 405, 405, 405, 206, 169, 99, 436, 436, 395, 459, 459, 459, 31, 162, 54, 86, 86, 86, 26, 359, 474, 474, 474, 474, 474, 464, 464, 255, 255, 8, 8, 354, 180, 113, 113, 113, 113, 167, 35, 35, 198, 22, 283, 283, 455, 58, 72, 72, 72, 437, 437, 151, 151, 151, 120, 385, 385, 385, 233, 233, 197, 197, 20, 20, 47, 47, 20, 47, 20, 20, 47, 47, 20, 20, 80, 80, 80, 20, 80, 20, 320, 208, 79, 79, 380, 499, 496, 496, 215, 215, 35, 354, 176, 135, 135, 200, 248, 248, 212, 354, 420, 420, 420, 422, 349, 349, 234, 234, 261, 25, 148, 148, 148, 148, 148, 148, 148, 372, 372, 372, 372, 59, 59, 59, 452, 452, 263, 263, 13, 78, 170, 170, 170, 20, 20, 312, 312, 312, 312, 292, 292, 292, 292, 292, 292, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 408, 408, 408, 149, 149, 228, 20, 412, 83, 55, 55, 322, 322, 94, 199, 255, 255, 255, 8, 8, 354, 180, 180, 113, 113, 113, 113, 113, 167, 35, 35, 35, 127, 114, 114, 57, 57, 57, 203, 203, 381, 381, 381, 117, 404, 404, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 80, 80, 80, 20, 20, 108, 108, 119, 119, 351, 374, 374, 374, 374, 374, 132, 349, 349, 349, 234, 261, 261, 25, 106, 480, 480, 480, 480, 480, 480, 480, 85, 299, 299, 299, 299, 339, 339, 64, 212, 131, 419, 439, 225, 225, 225, 225, 80, 20, 373, 66, 66, 232, 172, 172, 115, 273, 231, 231, 231, 231, 53, 76, 76, 465, 164, 214, 214, 214, 214, 328, 200, 248, 248, 76, 401, 259, 108, 108, 377, 344, 344, 344, 374, 374, 374, 132, 132, 186, 99, 338, 338, 338, 338, 395, 395, 470, 84, 84, 84, 84, 84, 84, 16, 16, 16, 274, 274, 98, 98, 98, 13, 229, 229, 20, 312, 312, 312, 312, 187, 292, 292, 292, 292, 23, 23, 23, 23, 23, 23, 23, 101, 101, 149, 149, 228, 228, 289, 320, 320, 127, 45, 45, 45, 45, 457, 457, 43, 364, 364, 364, 276, 276, 276, 153, 153, 372, 372, 406, 406, 467, 467, 242, 330, 116, 33, 64, 76, 465, 108, 449, 242, 242, 275, 275, 275, 275, 388, 195, 195, 195, 117, 117, 117, 404, 404, 225, 225, 225, 72, 72, 110, 110, 254, 254, 254, 254, 254, 314, 90, 393, 393, 234, 234, 261, 25, 25, 494, 494, 494, 38, 349, 349, 234, 234, 234, 261, 261, 25, 470, 139, 139, 139, 139, 139, 139, 293, 497, 497, 122, 122, 131, 131, 183, 183, 183, 183, 257, 257, 257, 257, 257, 257, 453, 9, 142, 221, 196, 217, 473, 65, 278, 278, 278, 99, 99, 436, 436, 60, 60, 298, 298, 275, 275, 303, 303, 303, 48, 48, 48, 417, 417]
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20[17, 17, 29output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_61-70970-0024
generate
processing 55th semantic_sys file
55
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: HE WAS IN DEEP CONVERSE WITH THE CLERK AND ENTERED THE HALL HOLDING HIM BY THE ARM
enroll_x_lens:tensor([36], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
321
[17, 17, 296, 451, 451, 30, 30, 378, 378, 345, 141, 141, 141, 141, 281, 342, 342, 168, 340, 340, 340, 116, 33, 394, 394, 32, 239, 384, 384, 371, 371, 213, 213, 213, 213, 213, 252, 215, 35, 35, 96, 472, 221, 458, 144, 27, 27, 437, 370, 370, 370, 370, 370, 370, 370, 348, 348, 64, 90, 4, 280, 280, 498, 498, 498, 498, 498, 498, 396, 396, 271, 186, 186, 39, 54, 390, 390, 390, 390, 390, 18, 18, 112, 427, 56, 56, 247, 312, 126, 126, 292, 23, 23, 23, 101, 101, 149, 149, 228, 20, 20, 320, 345, 333, 333, 220, 220, 35, 259, 22, 283, 455, 455, 129, 458, 144, 208, 208, 208, 386, 386, 386, 431, 431, 284, 284, 284, 284, 284, 284, 284, 306, 306, 306, 59, 59, 59, 59, 178, 178, 233, 233, 82, 192, 192, 419, 419, 439, 439, 78, 78, 20, 20, 312, 312, 187, 12, 12, 12, 12, 12, 408, 408, 408, 149, 228, 20, 289, 20, 83, 55, 322, 322, 67, 335, 335, 14, 411, 145, 145, 432, 330, 330, 330, 64, 76, 449, 449, 300, 300, 382, 382, 313, 313, 314, 314, 198, 22, 283, 283, 455, 58, 58, 72, 72, 437, 437, 481, 481, 481, 481, 481, 481, 481, 481, 182, 182, 182, 375, 375, 375, 375, 98, 98, 98, 225, 225, 225, 225, 225, 225, 225, 72, 72, 72, 72, 424, 424, 424, 424, 424, 424, 424, 424, 424, 122, 122, 325, 176, 135, 135, 135, 200, 248, 248, 183, 183, 57, 57, 57, 57, 57, 57, 57, 282, 282, 282, 203, 203, 381, 381, 381, 117, 117, 48, 48, 417, 417, 225, 80, 80, 20, 80, 20, 354, 62, 62, 62, 62, 62, 216, 216, 22, 283, 283, 455, 14, 14, 14, 411, 411, 284, 284, 284, 306, 306, 306, 306, 306, 306, 306, 306, 59, 59, 59, 203, 381, 381, 48, 48, 417]
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
torch.Size([1, 319, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_61-70970-0007
generate
processing 56th semantic_sys file
56
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: NAY NAY LORDING ANSWERED WARRENTON WITH A HALF LAUGH
enroll_x_lens:tensor([42], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
172
[17, 17, 296, 7, 7, 309, 479, 331, 290, 290, 171, 171, 252, 339, 94, 199, 398, 398, 324, 324, 301, 301, 251, 251, 251, 251, 241, 241, 431, 106, 153, 153, 387, 372, 372, 396, 313, 285, 325, 176, 176, 176, 328, 328, 328, 200, 200, 200, 248, 3, 335, 14, 82, 411, 145, 145, 145, 365, 365, 365, 330, 330, 379, 77, 77, 54, 54, 224, 300, 300, 382, 382, 382, 313, 313, 24, 314, 133, 133, 364, 276, 276, 276, 153, 372, 372, 372, 406, 467, 467, 242, 242, 116, 64, 76, 465, 108, 449, 242, 242, 275, 275, 275, 116, 195, 195, 195, 117, 117, 117, 117, 117, 117, 225, 225, 225, 80, 20, 20, 20, 7, 345, 333, 333, 220, 220, 216, 22, 44, 44, 44, 58, 72, 110, 110, 110, 486, 486, 486, 460, 460, 460, 169, 349, 352, 352, 402, 26, 26, 241, 241, 431, 431, 376, 376, 376, 376, 376, 460, 460, 169, 169, 169, 352, 352, 352, 352, 352, 352, 352, 352, 112]
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
torch.Size([1, 170, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_61-70970-0034
generate
processing 57th semantic_sys file
57
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: THERE BEFELL AN ANXIOUS INTERVIEW MISTRESS FITZOOTH ARGUING FOR AND AGAINST THE SQUIRE'S PROJECT IN A BREATH
enroll_x_lens:tensor([37], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
367
[17, 17, 296, 127, 0, 222, 222, 245, 8, 354, 420, 420, 420, 422, 349, 349, 234, 234, 261, 25, 189, 189, 189, 189, 189, 139, 139, 139, 293, 293, 293, 335, 335, 440, 89, 89, 446, 116, 94, 335, 14, 411, 145, 145, 145, 365, 365, 365, 360, 200, 76, 96, 96, 99, 436, 436, 395, 459, 459, 459, 271, 31, 39, 54, 54, 224, 483, 483, 188, 188, 121, 121, 116, 76, 465, 449, 487, 487, 487, 469, 173, 173, 280, 485, 485, 485, 485, 374, 132, 132, 132, 132, 98, 98, 13, 13, 170, 20, 20, 20, 20, 312, 312, 187, 12, 12, 12, 12, 23 92%|█████████▏| 59/64 [10:40<01:01, 12.33s/it]2024-03-25 02:52:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:52:38 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
 94%|█████████▍| 60/64 [10:49<00:45, 11.47s/it]2024-03-25 02:52:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
2024-03-25 02:52:48 | WARNING | phonemizer | words count mismatch on 100.0% of the lines (1/1)
[296, 296, 127, 114, 0, 0, 264, 264, 264, 264, 468, 468, 468, 245, 245, 8, 8, 354, 420, 420, 420, 422, 349, 349, 205, 205, 261, 25, 189, 189, 189, 189, 139, 139, 175, 175, 81, 44, 44, 44, 44, 116, 94, 335, 335, 14, 411, 145, 145, 145, 365, 365, 365, 360, 200, 76, 96, 96, 99, 436, 436, 395, 459, 459, 459, 459, 271, 31, 54, 54, 9, 483, 483, 188, 188, 121, 121, 121, 64, 212, 449, 300, 487, 487, 469, 469, 173, 8, 239, 219, 219, 219, 485, 485, 485, 485, 374, 374, 132, 132, 132, 399, 217, 217, 473, 473, 258, 258, 258, 31, 54, 54, 238, 6, 161, 161, 487, 487, 459, 459, 271, 31, 31, 54, 142, 142, 393, 393, 234, 261, 261, 25, 278, 278, 278, 385, 35, 478, 478, 66, 232, 482, 482, 172, 172, 115, 115, 273, 374, 374, 374, 132, 132, 132, 358, 358, 164, 164, 164, 164, 97, 483, 483, 226, 226, 82, 82, 287, 287, 353, 306, 306, 396, 396, 313, 416, 416, 239, 445, 485, 485, 485, 374, 374, 88, 88, 176, 176, 135, 135, 200, 200, 248, 248, 90, 349, 393, 234, 234, 234, 261, 261, 25, 148, 148, 148, 148, 148, 148, 148, 148, 182, 182, 182, 372, 372, 372, 59, 59, 452, 452, 263, 263, 13, 414, 414, 414, 82, 312, 312, 187, 187, 187, 187, 12, 12, 140, 12, 12, 12, 163, 163, 140, 391, 391, 140, 140, 140, 412, 83, 55, 55, 322, 322, 67, 212, 34, 255, 255, 416, 416, 239, 445, 180, 180, 432, 432, 330, 330, 379, 77, 77, 54, 86, 238, 6, 6, 472, 472, 198, 198, 22, 283, 283, 38, 38, 162, 232, 482, 105, 105, 336, 208, 208, 441, 441, 153, 346, 346, 346, 265, 265, 85, 85, 85, 85, 264, 334, 334, 334, 304, 304, 304, 304, 185, 185, 49, 323, 323, 18, 18, 112, 427, 56, 56, 56, 56, 187, 187, 187, 187, 187, 187, 187, 187, 391, 391, 140, 73, 140, 73, 140, 74, 190, 488, 488, 488, 488, 488, 206, 206, 24, 310, 310, 395, 395, 469, 469, 178, 178, 143, 35, 36, 131, 483, 483, 226, 188, 188, 340, 340, 340, 116, 199, 199, 44, 44, 44, 8, 8, 32, 354, 354, 190, 380, 380, 288, 288, 443, 443, 120, 169, 169, 150, 352, 164, 352, 352, 352, 352, 352, 112, 112]
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_kn[17, 296, 296, 127, 0, 0, 0, 0, 378, 378, 347, 347, 347, 347, 467, 467, 255, 255, 215, 129, 74, 74, 437, 437, 125, 125, 125, 125, 125, 348, 466, 22, 283, 283, 455, 455, 173, 4, 280, 280, 498, 498, 498, 498, 498, 498, 498, 396, 396, 37, 24, 24, 310, 107, 69, 69, 69, 130, 130, 280, 44, 44, 44, 94, 199, 199, 106, 410, 410, 410, 215, [17, 17, 296, 0, 0, 0, 0, 378, 378, 347, 347, 347, 467, 467, 255, 255, 215, 35, 74, 74, 437, 125, 125, 125, 125, 125, 348, 466, 466, 283, 283, 455, 4, 4, 4, 280, 498, 498, 498, 498, 498, 498, 498, 396, 396, 313, 24, 24, 310, 107, 69, 69, 223, 130, 280, 44, 44, 44, 94, 335, 14, 411, 411, 410, 410, 410, 410, 215, 35, 29, 242, 242, 116, 33, 394, 76, 310, 161, 161, 161, 161, 487, 487, 487, 499, 486, 486, 376, 376, 460, 460, 460, 215, 35, 35, 29, 89, 340, 340, 466, 466, 22, 283, 455, 349, 205, 205, 205, 261, 25, 148, 148, 306, 306, 306, 372, 396, 396, 245, 35, 35, 208, 208, 441, 441, 153, 153, 153, 387, 387, 348, 94, 300, 382, 382, 382, 69, 130, 130, 198, 22, 283, 455, 455, 72, 72, 72, 72, 437, 437, 405, 405, 405, 405, 206, 167, 167, 35, 35, 35, 35, 440, 89, 89, 446, 116, 394, 478, 162, 232, 482, 482, 482, 482, 482, 238, 6, 336, 371, 470, 374, 374, 374, 374, 457, 457, 359, 359, 359, 474, 474, 474, 324, 19, 19, 454, 229, 82, 247, 126, 126, 126, 326, 326, 326, 326, 326, 101, 101, 149, 228, 20, 20, 110, 254, 254, 254, 254, 314, 35, 36, 310, 107, 161, 161, 487, 487, 189, 189, 189, 215, 35, 35, 35, 96, 401, 401, 401, 82, 384, 371, 180, 410, 410, 410, 410, 410, 410, 29, 29, 29, 382, 313, 216, 216, 22, 448, 448, 448, 448, 14, 14, 411, 145, 145, 443, 443, 443, 240, 240, 24, 24, 310, 107, 69, 69, 130, 130, 198, 22, 283, 455, 455, 42, 147, 456, 456, 456, 456, 173, 4, 4, 280, 498, 498, 498, 498, 498, 396, 396, 169, 186, 39, 54, 238, 6, 272, 472, 393, 393, 234, 234, 234, 261, 425, 425, 386, 386, 431, 376, 376, 376, 376, 376, 460, 460, 215, 35, 35, 35, 35, 196, 196, 70, 65, 65, 315, 315, 315, 450, 450, 450, 169, 169, 35, 35, 164, 483, 440, 69, 223, 130, 130, 198, 22, 258, 258, 31, 162, 54, 142, 105, 336, 336, 74, 74, 351, 351, 278, 278, 278, 120, 385, 385, 385, 233, 233, 414, 414, 414]
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
torch.Size([1, 378, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_61-70970-0025
generate
processing 59th semantic_sys file
59
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: WE WILL GO OUT TOGETHER TO THE BOWER THERE IS A WAY DOWN TO THE COURT FROM MY WINDOW
enroll_x_lens:tensor([43], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
304
[17, 17, 296, 345, 152, 152, 152, 378, 378, 345, 345, 389, 389, 497, 497, 122, 32, 32, 144, 27, 180, 84, 496, 496, 88, 88, 88, 106, 113, 113, 113, 113, 113, 167, 35, 35, 35, 36, 108, 377, 123, 87, 416, 416, 445, 180, 180, 443, 493, 493, 493, 216, 300, 300, 334, 382, 59, 452, 452, 263, 414, 414, 414, 414, 414, 414, 47, 47, 47, 47, 47, 47, 47, 140, 140, 316, 140, 73, 73, 73, 289, 82, 75, 108, 377, 377, 374, 374, 374, 374, 132, 132, 132, 132, 216, 216, 22, 283, 455, 455, 8, 32, 239, 354, 354, 180, 486, 486, 315, 315, 315, 450, 450, 450, 182, 372, 372, 372, 334, 59, 59, 59, 452, 263, 263, 414, 414, 414, 414, 414, 414, 414, 47, 47, 82, 47, 47, 140, 47, 140, 140, 73, 73, 73, 140, 7, 127, 114, 0, 222, 468, 468, 356, 356, 356, 281, 9, 9, 168, 44, 44, 44, 44, 43, 43, 364, 276, 276, 109, 109, 403, 403, 403, 403, 403, 207, 207, 207, 207, 3, 3, 301, 314, 239, 384, 371, 180, 315, 315, 315, 315, 450, 450, 450, 413, 348, 394, 76, 76, 259, 108, 108, 119, 351, 374, 374, 374, 374, 374, 132, 132, 132, 132, 132, 98, 98, 98, 13, 414, 414, 414, 414, 414, 414, 47, 47, 47, 47, 47, 47, 140, 140, 316, 73, 140, 73, 140, 127, 22, 283, 455, 455, 129, 259, 208, 208, 441, 441, 153, 153, 372, 372, 396, 396, 385, 35, 35, 393, 393, 155, 155, 165, 165, 165, 165, 399, 53, 70, 70, 70, 46, 46, 46, 46, 46, 438, 438, 43, 43, 364, 276, 109, 109, 278, 330, 116, 33, 64, 64, 212, 384, 180, 84, 84, 84, 496, 274, 98, 98, 98, 13, 414, 414, 414]
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
torch.Size([1, 302, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_61-70970-0016
generate
processing 60th semantic_sys file
60
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: CRIED HE WAVING THE LANTHORN BEFORE HIM TO MAKE SURE THAT THESE WERE NO GHOSTS IN FRONT OF HIM
enroll_x_lens:tensor([50], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
294
[17, 17, 296, 208, 190, 190, 487, 499, 499, 499, 265, 265, 265, 265, 85, 85, 85, 85, 146, 146, 146, 252, 24, 131, 183, 183, 451, 451, 30, 30, 30, 301, 378, 43, 345, 109, 109, 109, 171, 171, 171, 252, 173, 173, 280, 176, 135, 135, 200, 200, 248, 248, 212, 22, 283, 455, 455, 251, 251, 241, 431, 431, 294, 365, 365, 365, 330, 330, 348, 64, 76, 76, 164, 164, 164, 106, 106, 153, 153, 387, 387, 372, 372, 396, 388, 33, 64, 212, 212, 420, 420, 420, 422, 349, 205, 205, 155, 148, 148, 148, 148, 148, 372, 372, 396, 58, 58, 183, 57, 57, 57, 57, 57, 203, 53, 53, 394, 76, 76, 82, 108, 108, 119, 351, 344, 374, 374, 374, 132, 132, 399, 399, 217, 473, 473, 65, 476, 476, 476, 476, 252, 252, 143, 458, 96, 99, 338, 338, 338, 395, 395, 487, 498, 498, 498, 498, 498, 59, 59, 59, 59, 452, 452, 263, 229, 82, 82, 312, 312, 126, 292, 292, 1, 1, 1, 1, 1 98%|█████████▊| 63/64 [11:29<00:12, 12.77s/it][17, 17, 296, 208, 190, 190, 487, 499, 265, 265, 85, 146, 146, 252, 325, 183, 451, 30, 30, 30, 301, 43, 364, 276, 109, 109, 403, 171, 171, 171, 252, 173, 173, 280, 176, 135, 135, 200, 248, 248, 22, 283, 455, 455, 251, 251, 251, 241, 431, 431, 294, 294, 294, 294, 282, 388, 348, 64, 394, 76, 164, 164, 164, 106, 106, 153, 153, 387, 372, 372, 396, 388, 64, 394, 212, 354, 420, 420, 422, 349, 349, 205, 155, 148, 148, 148, 148, 372, 372, 245, 58, 58, 183, 57, 57, 57, 57, 203, 53, 53, 394, 76, 465, 82, 108, 108, 119, 119, 351, 374, 374, 374, 374, 132, 132, 132, 399, 217, 473, 473, 476, 476, 476, 476, 143, 143, 458, 96, 96, 338, 338, 338, 338, 338, 395, 487, 498, 498, 498, 498, 498, 59, 59, 59, 313, 313, 216, 216, 127, 45, 45, 45, 45, 45, 35, 35, 401, 82, 127, 127, 124, 124, 124, 124, 124, 246, 318, 318, 318, 49, 9, 142, 397, 397, 347, 347, 347, 347, 313, 10, 10, 309, 479, 331, 231, 231, 231, 231, 274, 274, 416, 32, 32, 82, 82, 144, 180, 180, 496, 496, 496, 496, 496, 496, 274, 358, 186, 39, 54, 54, 390, 390, 238, 238, 6, 82, 270, 270, 270, 390, 390, 18, 97, 483, 226, 226, 140, 140, 188, 340, 340, 340, 33, 33, 90, 393, 393, 234, 234, 261, 25, 487, 499, 319, 319, 348, 64, 76, 36, 449, 69, 223, 223, 130, 402, 402, 183, 57, 57, 57, 57, 57, 57, 203, 203, 303, 303, 48, 48, 48]
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
torch.Size([1, 268, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/conv100%|██████████| 64/64 [11:32<00:00, 11.90s/it]100%|██████████| 64/64 [11:32<00:00, 10.82s/it]
[17, 17, 296, 345, 389, 389, 389, 143, 129, 458, 144, 208, 190, 190, 487, 499, 499, 499, 265, 265, 85, 146, 146, 146, 325, 183, 451, 451, 30, 30, 422, 162, 162, 68, 68, 115, 273, 106, 405, 405,[17, 17, 296, 296, 345, 345, 389, 389, 497, 497, 143, 129, 259, 208, 208, 208, 190, 487, 499, 499, 499, 499, 265, 265, 85, 85, 146, 146, 146, 24, 131, 183, 183, 451, 451, 30, 30, 30, 30, 422, 186, 162, 162, 232, 232, 172, 115, 273, 273, 106, 405, 405, 405, 405, 206, 169, 349, 352, 352, 352, 26, 359, 359, 474, 474, 474, 474, 474, 19, 19, 19, 19, 454, 454, 454, 78, 170, 170, 170, 140, 28, 28, 28, 140, 28, 28, 140, 362, 362, 362, 362, 140, 140, 362, 140, 140, 362, 140, 362, 362, 140, 366, 366, 366, 140, 366, 366, 140, 366, 366, 140, 366, 366, 140, 316, 316, 140, 73, 73, 289, 209, 209, 83, 55, 55, 322, 67, 67, 394, 478, 478, 232, 232, 482, 482, 238, 6, 272, 371, 485, 374, 374, 374, 132, 252, 143, 36, 449, 449, 134, 134, 134, 359, 359, 474, 474, 474, 474, 474, 246, 246, 246, 246, 3, 3, 3, 183, 489, 489, 489, 489, 489, 88, 58, 58, 110, 254, 254, 254, 254, 314, 314, 129, 36, 310, 310, 107, 107, 395, 395, 351, 84, 496, 496, 496, 496, 274, 274, 368, 368, 453, 9, 168, 168, 275, 275, 275, 275, 116, 195, 195, 195, 404, 404, 404, 225, 225, 225, 225, 225, 183, 183, 257, 257, 257, 257, 257, 281, 453, 9, 142, 221, 336, 144, 445, 351, 351, 486, 486, 315, 450, 450, 450, 413, 413, 35, 35, 310, 107, 107, 395, 255, 255, 255, 143, 129, 458, 208, 208, 190, 190, 487, 499, 499, 405, 405, 405, 405, 206, 169, 150, 39, 54, 86, 238, 198, 198, 22, 22, 283, 455, 236, 236, 239, 239, 371, 106, 153, 153, 153, 153, 153, 153, 182, 372, 372, 372, 372, 59, 59, 59, 59, 452, 452, 452, 263, 263, 263, 225, 225, 225, 225, 225, 225, 80, 80, 80, 80, 209, 209, 69, 69, 223, 223, 130, 402, 402, 183, 183, 257, 257, 257, 257, 257, 368, 368, 453, 9, 142, 219, 219, 464, 180, 180, 319, 319, 319, 319, 348, 348, 248, 248, 248, 217, 70, 473, 65, 486, 486, 486, 460, 460, 169, 150, 150, 54, 86, 238, 6, 272, 300, 334, 334, 334, 304, 304, 304, 304, 304, 304, 185, 185, 185, 185, 269, 323, 323, 18, 112, 427, 56, 247, 312, 312, 187, 292, 292, 292, 292, 23, 23, 23, 23, 23, 23, 408, 408, 391, 391, 391, 140, 289, 289, 82, 75, 310, 107, 395, 351, 290, 290, 290, 290, 360, 434, 339, 53, 53, 212, 29, 334, 334, 334, 59, 59, 59, 59, 59, 59, 452, 452, 263, 263, 263, 225, 225, 225, 225, 225, 225, 225, 373, 66, 66, 482, 482, 482, 482, 105, 105, 105, 336, 336, 336, 354, 190, 189, 189, 189, 189, 189, 189, 189, 189, 189, 365, 365, 328, 328, 328, 200, 200, 200, 248, 335, 14, 14, 440, 230, 230, 230, 230, 230, 230, 215, 215, 35, 35, 483, 483, 440, 440, 415, 415, 415, 415, 415, 415, 457, 133, 364, 364, 276, 276, 174, 174, 174, 174, 319, 319, 379, 379, 379, 243, 77, 77, 77, 433, 390, 390, 390, 390, 18, 18, 18, 112, 97, 225, 225, 225, 225, 80, 80, 226, 209, 209, 188, 188, 340, 340, 340, 116, 94, 199, 335, 145, 145, 365, 365, 365, 330, 330, 379, 77, 77, 77, 323, 224, 224, 334, 334, 334, 59, 59, 59, 452, 452, 263, 263, 263]
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
torch.Size([1, 578, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_61-70970-0015
generate
processing 62th semantic_sys file
62
args.target_mode==1 or args.target_mode==2
semantic nums is 1
synthesize text: YOUNG FITZOOTH HAD BEEN COMMANDED TO HIS MOTHER'S CHAMBER SO SOON AS HE HAD COME OUT FROM HIS CONVERSE WITH THE SQUIRE
enroll_x_lens:tensor([44], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
362
[17, 17, 219, 219, 180, 180, 319, 319, 319, 348, 348, 248, 248, 90, 349, 393, 205, 261, 261, 25, 278, 278, 278, 385, 35, 77, 478, 232, 232, 172, 115, 115, 444, 374, 374, 374, 374, 132, 132, 358, 169, 164, 164, 164, 164, 164, 97, 225, 110, 254, 254, 254, 314, 314, 239, 354, 137, 137, 137, 137, 33, 90, 90, 76, 144, 27, 27, 121, 399, 217, 473, 473, 365, 365, 365, 365, 365, 365, 330, 388, 64, 212, 191, 191, 191, 314, 314, 314, 32, 82, 108, 108, 377, 119, 351, 374, 374, 374, 374, 374, 132, 132, 132, 132, 132, 132, 98, 98, 13, 229, 20, 20, 20, 312, 312, 292, 292, 23, 326, 23, 101, 408, 408, 228, 20, 20, 373, 451, 257, 257, 257, 257, 453, 9, 142, 196, 217, 70, 65, 493, 493, 493, 493, 216, 300, 300, 382, 304, 304, 186, 186, 142, 221, 221, 82, 310, 107, 395, 395, 351, 290, 290, 290, 290, 434, 339, 53, 53, 212, 29, 334, 334, 59, 59, 59, 452, 452, 186, 186, 66, 66, 482, 482, 172, 115, 344, 344, 344, 344, 344, 344, 344, 274, 274, 274, 186, 186, 162, 232, 232, 172, 172, 115, 273, 273, 374, 374, 374, 374, 132, 132, 132, 132, 413, 413, 413, 195, 199, 199, 253, 253, 253, 253, 253, 453, 9, 9, 451, 451, 30, 30, 464, 254, 254, 254, 254, 314, 90, 129, 82, 144, 27, 27, 351, 319, 319, 319, 53, 53, 65, 113, 113, 113, 113, 113, 450, 167, 167, 457, 393, 393, 155, 155, 165, 165, 165, 165, 53, 53, 257, 257, 257, 257, 9, 142, 221, 336, 144, 27, 27, 437, 370, 370, 370, 370, 370, 370, 370, 348, 64, 64, 90, 4, 280, 29, 498, 498, 498, 59, 304, 304, 271, 186, 39, 323, 390, 390, 18, 18, 112, 112, 56, 56, 56, 56, 20, 80, 20, 20, 20, 320, 345, 333, 333, 220, 220, 35, 198, 22, 283, 283, 38, 162, 162, 482, 105, 105, 105, 208, 208, 441, 153, 153, 346, 346, 346, 91, 265, 85, 85, 85, 85, 334, 334, 334, 334, 59, 59, 452, 452, 263, 263]
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
top_k_know_token:50
torch.Size([1, 360, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_50_steps_16_2024-03-25_10:41:38
sys_file:gen_61-70970-0000
generate
processing 63th semantic_sys file
63
args.target_mode==1 or args.t100%|██████████| 64/64 [11:36<00:00, 11.04s/it]100%|██████████| 64/64 [11:36<00:00, 10.88s/it]
synthesize text: THERE WAS NO CHANCE TO ALTER HIS SLEEPING ROOM TO ONE NEARER TO GAMEWELL'S CHAMBER
enroll_x_lens:tensor([48], dtype=torch.int32)
txt2semantic need not prompt
before_semantic:
after is :
412
[17, 17, 296, 127, 0, 0, 222, 245, 378, 43, 345, 141, 141, 141, 281, 281, 9, 9, 142, 196, 309, 309, 479, 331, 231, 231, 231, 231, 231, 231, 274, 274, 274, 122, 143, 36, 310, 107, 107, 395, 395, 351, 365, 365, 365, 365, 365, 365, 365, 282, 282, 282, 379, 243, 77, 77, 323, 323, 323, 323, 238, 221, 336, 82, 108, 108, 377, 377, 374, 374, 374, 374, 374, 132, 132, 132, 132, 88, 88, 106, 106, 481, 481, 481, 481, 481, 293, 122, 122, 122, 35, 35, 36, 108, 449, 300, 334, 334, 334, 334, 59, 59, 59, 59, 452, 452, 452, 263, 263, 263, 225, 225, 225, 225, 80, 80, 20, 20, 373, 183, 257, 257, 257, 257, 31, 162, 54, 232, 482, 482, 26, 26, 26, 359, 81, 444, 213, 213, 252, 215, 215, 259, 354, 176, 176, 176, 135, 328, 200, 200, 248, 248, 42, 147, 147, 380, 380, 288, 374, 374, 132, 132, 132, 203, 53, 53, 394, 90, 76, 259, 82, 108, 108, 119, 351, 374, 374, 374, 374, 374, 374, 132, 132, 132, 132, 132, 132, 132, 132, 132, 98, 98, 98, 98, 13, 13, 13, 78, 170, 20, 20, 20, 312, 312, 187, 12, 12, 12, 12, 23, 260, 260, 391, 391, 391, 20, 20, 20, 289, 320, 7, 364, 276, 174, 174, 174, 174, 174, 174, 174, 319, 388, 388, 195, 195, 195, 195, 195, 195, 117, 117, 117, 404, 404, 225, 225, 225, 225, 225, 225, 225, 225, 7, 7, 309, 398, 398, 398, 398, 398, 398, 398, 468, 468, 406, 406, 467, 382, 382, 382, 382, 59, 59, 59, 59, 59, 452, 452, 452, 263, 263, 225, 225, 225, 80, 20, 80, 80, 20, 108, 108, 377, 377, 123, 374, 374, 374, 132, 132, 416, 239, 144, 445, 180, 93, 93, 290, 290, 290, 290, 434, 434, 434, 434, 434, 203, 203, 381, 381, 381, 381, 117, 404, 404, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 7, 7, 364, 364, 276, 109, 109, 443, 443, 443, 139, 139, 139, 139, 139, 375, 375, 375, 375, 375, 375, 375, 375, 185, 185, 185, 185, 269, 269, 390, 390, 390, 18, 18, 97, 97, 97, 225, 80, 80, 80, 80, 80, 80, 20, 310, 107, 107, 395, 395, 351, 290, 290, 290, 290, 290, 434, 434, 339, 53, 53, 212, 29, 29, 334, 334, 334, 334, 59, 59, 59, 59, 452, 452, 452, 263, 263, 263]
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
top_k_know_token:20
torch.Size([1, 410, 16])
output_dir is /home/v-zhijunjia/data/tts_test_librispeech/nar_test/converted_can_del_tts/baseline/update_all_nar_mask_t_0_nar_mask_r_0.5_gp_i_mask_True_knowtoken_topk_update/base-line-no-prompt-tts-2stages_topk_stage1_2_topk_stage2_70_top_k_know_token_stage2_20_steps_16_2024-03-25_10:41:38
sys_file:gen_61-70970-0013
generate
