Current working directory: /home/v-zhijunjia/CodecGen
2024-01-20 12:31:43 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
/home/v-zhijunjia/miniconda3/envs/valle-4-23/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MiniBatchKMeans from version 0.24.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
only_antoregressive is True
add_prenet is False
only_antoregressive is True
add_prenet is False
self.ar_text_prenet : Identity()
add_prenetï¼šFalse
  0%|          | 0/50 [00:00<?, ?it/s]processing 0th semantic_sys file
0
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
135
[17, 17, 20, 296, 7, 479, 331, 331, 463, 463, 378, 378, 88, 88, 141, 141, 281, 31, 54, 172, 344, 344, 344, 344, 274, 186, 162, 54, 482, 238, 6, 336, 79, 79, 487, 288, 290, 290, 290, 290, 434, 434, 434, 339, 64, 212, 77, 97, 483, 483, 440, 44, 255, 215, 129, 82, 82, 74, 190, 488, 488, 488, 405, 206, 169, 349, 349, 155, 29, 29, 313, 313, 24, 314, 90, 221, 401, 82, 445, 445, 210, 210, 210, 210, 210, 203, 53, 70, 230, 230, 230, 230, 215, 215, 35, 96, 401, 36, 377, 123, 123, 123, 236, 239, 310, 107, 395, 395, 329, 443, 443, 240, 285, 34, 374, 374, 374, 186, 162, 54, 54, 224, 273, 494, 494, 175, 175, 81, 459, 275, 275, 303, 48, 193, 193]
after is :
135
[17, 17, 296, 331, 331, 331, 463, 331, 463, 463, 463, 29, 463, 29, 313, 313, 313, 313, 313, 186, 186, 162, 344, 344, 344, 344, 162, 344, 344, 162, 238, 238, 238, 238, 161, 161, 161, 487, 290, 487, 290, 434, 434, 434, 434, 434, 339, 64, 107, 310, 107, 310, 44, 236, 140, 140, 140, 190, 488, 405, 488, 405, 206, 206, 169, 349, 349, 29, 469, 29, 469, 469, 457, 314, 90, 140, 140, 210, 445, 210, 210, 210, 210, 210, 210, 230, 230, 230, 230, 215, 230, 230, 401, 140, 123, 123, 123, 140, 123, 236, 123, 239, 329, 329, 42, 374, 374, 374, 374, 374, 374, 380, 374, 374, 374, 186, 54, 54, 175, 54, 81, 224, 175, 81, 175, 81, 81, 81, 81, 303, 303, 117, 48, 193,tensotensor([272], device='cuda:0', dtype=torch.int32)
text_len:272
prefix_lençç¬¬0ç¬¬0ä¸ªåºåˆ—meet end_token: 1024
ç¬¬0ä¸ªåºåˆ—endï¼Œ ç»ˆæ­¢é•¿åº¦ä¸º135ï¼ˆåŒ…å«ç»ˆæ­¢ç¬¦ï¼‰
æ‰€æœ‰åºåˆ—ç»ˆæ­¢
133
torch.Size([1, 133, ooutpoutput_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_2_epoch__topk_2_2024-01-20_20:3ssys_sys_file:ASI_arctic_bgenerate
  2%|â–         | 1/50 [00:29<24:00, 29.39s/it]processing 1th semantic_sys file
1
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
185
[17, 17, 296, 296, 5, 5, 5, 5, 455, 251, 251, 251, 431, 431, 428, 428, 428, 428, 146, 146, 146, 358, 358, 358, 173, 352, 352, 352, 352, 352, 197, 197, 197, 7, 32, 239, 384, 114, 0, 264, 264, 264, 264, 264, 468, 406, 42, 43, 345, 141, 141, 141, 141, 141, 281, 54, 54, 9, 58, 72, 72, 72, 110, 110, 443, 139, 139, 139, 122, 122, 143, 36, 472, 393, 393, 155, 262, 262, 262, 262, 262, 387, 387, 175, 175, 175, 335, 440, 440, 89, 446, 446, 94, 94, 199, 335, 440, 145, 415, 415, 415, 415, 35, 35, 26, 26, 26, 241, 81, 470, 443, 313, 313, 143, 36, 449, 34, 469, 469, 178, 416, 233, 401, 82, 401, 20, 32, 354, 159, 159, 159, 159, 236, 35, 35, 401, 401, 82, 20, 20, 377, 377, 374, 374, 374, 132, 132, 422, 236, 239, 310, 107, 107, 395, 395, 374, 374, 132, 88, 88, 81, 242, 116, 10, 10, 479, 331, 331, 265, 265, 265, 85, 85, 85, 207, 207, 207, 19, 19, 19, 19, 454, 193, 193, 17]
after is :
185
[17, 17, 296, 296, 296, 7, 320, 7, 7, 5, 5, 5, 5, 455, 251, 251, 241, 251, 241, 431, 431, 428, 146, 428, 146, 358, 352, 358, 352, 352, 352, 352, 352, 352, 7, 127, 114, 114, 114, 114, 468, 468, 245, 245, 468, 141, 345, 141, 141, 141, 141, 141, 141, 281, 58, 54, 281, 142, 142, 72, 110, 72, 72, 139, 293, 293, 293, 262, 262, 262, 262, 262, 393, 262, 262, 262, 262, 262, 262, 262, 497, 497, 497, 497, 335, 335, 89, 440, 440, 89, 199, 440, 440, 440, 199, 415, 431, 251, 431, 251, 251, 251, 431, 469, 469, 431, 469, 469, 443, 469, 469, 431, 469, 143, 469, 469, 178, 469, 401, 82, 401, 159, 401, 82, 159, 401, 401, 108, 401, 401, 108, 108, 401, 108, 108, 108, 108, 82, 374, 108, 374, 374, 374, 374, 374, 374, 374, 374, 374, 374, 374, 88, 479, 479, 479, 479, 479, 331, 331, 331, 265, 331, 265, 265, 85, 265, 85, 19, 19, 19, 98, 98, 19, 19, 454, 13, 417, 439, 237, 417, 421, 128, 193, 193,tensotensor([372], device='cuda:0', dtype=torch.int32)
text_len:372
prefix_lenç¬¬0äç¬¬0ä¸ªåºåˆ—meet end_token: 1024
ç¬¬0ä¸ªåºåˆ—endï¼Œ ç»ˆæ­¢é•¿åº¦ä¸º186ï¼ˆåŒ…å«ç»ˆæ­¢ç¬¦ï¼‰
æ‰€æœ‰åºåˆ—ç»ˆæ­¢
184
torch.Size([1, 184, 16])
output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_2_epoch__topk_2_2024-01-20_20:3sys_fsys_file:ASI_arctic_bgenergenerate
  4%|â–         | 2/50 [01:16<31:51, 39.82s/it]processing 2th semantic_sys file
2
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
128
[17, 17, 296, 72, 72, 268, 268, 268, 293, 43, 43, 43, 345, 109, 109, 443, 443, 443, 240, 240, 175, 175, 219, 485, 485, 11, 11, 11, 116, 64, 212, 465, 26, 359, 359, 166, 166, 324, 324, 3, 3, 14, 259, 440, 287, 145, 111, 111, 443, 378, 378, 43, 345, 345, 109, 109, 432, 330, 330, 116, 64, 76, 82, 335, 483, 440, 145, 415, 415, 415, 415, 415, 35, 35, 34, 34, 191, 191, 191, 314, 314, 314, 32, 32, 32, 491, 384, 114, 180, 92, 92, 92, 92, 92, 240, 240, 35, 35, 96, 393, 205, 205, 261, 25, 148, 148, 498, 498, 498, 387, 271, 368, 368, 453, 54, 86, 238, 6, 82, 272, 41, 93, 93, 93, 19, 19, 193, 193]
after is :
128
[17, 17, 296, 296, 296, 184, 373, 268, 373, 268, 268, 72, 268, 268, 109, 109, 280, 106, 280, 139, 293, 293, 175, 175, 293, 139, 11, 359, 359, 11, 359, 359, 474, 359, 359, 474, 474, 359, 324, 474, 166, 474, 464, 111, 111, 438, 438, 111, 111, 111, 438, 438, 111, 438, 43, 43, 432, 109, 330, 330, 432, 432, 330, 330, 330, 330, 330, 415, 415, 415, 415, 415, 415, 415, 415, 92, 92, 92, 92, 114, 92, 92, 92, 92, 167, 167, 457, 393, 261, 261, 25, 261, 498, 498, 25, 498, 498, 186, 498, 186, 313, 238, 238, 313, 82, 93, 93, 93, 93, 93, 93, 93, 93, 93, 207, 19, 19, 439, 439, 78, 439, 439, 78, 78, 140, 193, 193, 193tetensor([258], device='cuda:0', dtype=torch.int32)
text_len:258
prefix_len:ç¬ç¬ç¬¬0ä¸ªåºåˆ—meet end_token: 1024
ç¬¬0ä¸ªåºåˆ—ç¬¬0ä¸ªåºåˆ—endï¼Œ ç»ˆæ­¢é•¿åº¦ä¸º128ï¼ˆåŒæ‰€ææ‰€æœ‰åºåˆ—ç»ˆæ­¢
125
torch.Size([1, 125, 1output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_2_epoch__topk_2_2024-01-20_20:31:39
sys_file:ASI_arctic_b0505
gegenerate
  6%|â–Œ         | 3/50 [01:43<26:44, 34.14s/it]processing 3th semantic_sys file
args.targeargs.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
189
[17, 17, 20, 20, 296, 177, 177, 177, 177, 131, 133, 389, 389, 389, 389, 58, 58, 72, 72, 110, 110, 110, 443, 139, 139, 139, 293, 240, 215, 35, 35, 35, 197, 96, 401, 82, 108, 87, 87, 87, 87, 236, 129, 259, 82, 119, 180, 499, 265, 265, 85, 146, 146, 146, 146, 146, 252, 252, 24, 24, 472, 196, 196, 217, 429, 429, 429, 429, 429, 429, 246, 246, 246, 3, 3, 197, 226, 226, 82, 440, 287, 255, 255, 255, 251, 251, 241, 431, 235, 235, 235, 235, 235, 235, 235, 413, 348, 335, 14, 14, 440, 287, 319, 319, 348, 64, 212, 212, 384, 34, 278, 139, 251, 241, 431, 443, 443, 146, 438, 416, 416, 416, 239, 144, 106, 106, 91, 91, 91, 405, 206, 206, 240, 24, 35, 35, 478, 232, 232, 232, 238, 336, 272, 470, 470, 443, 240, 240, 24, 325, 41, 324, 324, 464, 464, 89, 446, 446, 203, 394, 76, 129, 82, 74, 425, 386, 386, 431, 265, 265, 480, 85, 299, 203, 203, 53, 53, 291, 291, 291, 275, 303, 303, 303, 48, 48, 193, 193, 193]
after is :
189
[17, 17, 296, 296, 177, 177, 177, 177, 177, 177, 177, 177, 177, 389, 389, 58, 58, 58, 58, 58, 139, 139, 139, 139, 215, 215, 293, 215, 96, 96, 82, 96, 96, 87, 87, 87, 87, 87, 87, 108, 108, 265, 265, 265, 265, 265, 265, 265, 85, 265, 85, 146, 146, 217, 429, 429, 429, 429, 429, 429, 429, 429, 429, 246, 429, 429, 464, 3, 464, 440, 251, 251, 251, 319, 319, 431, 235, 431, 235, 235, 348, 235, 348, 235, 319, 319, 319, 348, 348, 348, 319, 319, 348, 319, 348, 348, 319, 319, 319, 348, 431, 431, 153, 153, 153, 431, 431, 153, 146, 146, 146, 146, 146, 146, 146, 153, 153, 146, 232, 146, 146, 232, 232, 232, 232, 232, 232, 232, 232, 470, 470, 470, 470, 470, 240, 470, 470, 470, 240, 240, 240, 41, 240, 42, 42, 41, 89, 89, 464, 446, 89, 74, 53, 74, 74, 74, 425, 386, 386, 386, 431, 386, 386, 399, 203, 203, 203, 291, 291, 291, 275, 291, 291, 291, 291, 291, 303, 303, 303, 48, 48, 439, 417, 417, 417, 417, 244, 244, 1tentensor([380], devtensor([380], device='cuda:0', dtype=torch.int32)
text_lenç¬¬ç¬¬0ä¸ªåºåˆ—meet end_token: 1024
ç¬¬0ä¸ªåºåˆ—endï¼Œ ç»ˆæ­¢é•¿åº¦ä¸º190ï¼ˆåŒ…å«ç»ˆæ­¢ç¬¦ï¼‰
æ‰€æœ‰åºåˆ—ç»ˆæ­¢
188
torch.Size([1, 188, 16])
output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_2_epoch__topk_2_2024-01-20_20:31:39
sys_file:ASI_arctic_b05generate
  8%|â–Š         | 4/50 [02:32<30:28, 39.76s/it]processing 4th semantic_sys file
4
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
133
[17, 17, 491, 296, 373, 451, 451, 451, 30, 30, 464, 464, 254, 254, 254, 254, 240, 131, 393, 393, 234, 155, 25, 25, 148, 387, 387, 313, 313, 186, 349, 205, 205, 25, 29, 189, 189, 189, 313, 240, 240, 240, 325, 34, 257, 257, 257, 257, 31, 9, 9, 221, 239, 384, 371, 485, 485, 374, 374, 374, 132, 122, 35, 82, 449, 41, 41, 41, 324, 324, 3, 3, 335, 14, 440, 440, 89, 55, 446, 446, 67, 33, 394, 76, 129, 20, 354, 354, 470, 476, 171, 171, 171, 171, 171, 252, 24, 314, 35, 401, 401, 82, 74, 190, 441, 153, 153, 153, 153, 387, 387, 387, 387, 355, 37, 175, 359, 359, 359, 474, 474, 41, 41, 19, 19, 19, 454, 305, 128, 193, 193, 193, 17]
after is :
133
[17, 17, 296, 296, 296, 140, 491, 373, 373, 451, 451, 451, 30, 58, 58, 254, 254, 254, 254, 254, 393, 393, 393, 393, 393, 25, 25, 25, 261, 25, 25, 25, 25, 25, 25, 25, 261, 261, 25, 139, 139, 139, 122, 34, 122, 24, 24, 24, 183, 9, 9, 9, 257, 86, 221, 221, 82, 82, 82, 374, 485, 374, 374, 374, 374, 374, 374, 325, 41, 41, 41, 41, 3, 41, 440, 440, 89, 440, 89, 440, 89, 33, 33, 394, 394, 76, 351, 351, 351, 476, 171, 252, 171, 171, 171, 252, 314, 314, 314, 401, 314, 82, 74, 190, 190, 74, 190, 437, 424, 424, 424, 424, 424, 424, 175, 175, 175, 81, 474, 474, 19, 19, 19, 19, 454, 454, 78, 454, 78, 128, 193,tensor([268tensor([268], device='cuda:0', dtype=torch.int32)
text_len:268
prefix_len:134
_len:268
prefixç¬¬0ä¸ªåºåˆ—meet end_token: 1024
ç¬¬0ä¸ªåºåˆ—endï¼Œ ç»ˆæ­¢é•¿åº¦ä¸º133ï¼ˆåŒ…å«ç»ˆæ­¢ç¬¦ï¼‰
æ‰€æœ‰åºåˆ—ç»ˆæ­¢
131
torch.Size([1, 131, 16])
output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_2_epoch__topk_2_2024-01-20_20:31:39
sys_file:ASI_arctic_b0509
rate
 10%|â–ˆ         | 5/50 [02:35<23:08, 30.87s/it]processing 5th semantic_sys file
5
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
115
[17, 17, 20, 20, 108, 377, 87, 87, 378, 399, 70, 70, 65, 65, 153, 481, 387, 387, 387, 240, 285, 34, 84, 302, 302, 293, 293, 14, 14, 14, 411, 287, 287, 284, 206, 206, 240, 348, 348, 196, 10, 309, 479, 331, 331, 443, 443, 178, 178, 35, 96, 96, 54, 54, 86, 6, 82, 272, 371, 93, 41, 41, 324, 324, 3, 3, 335, 14, 226, 440, 177, 177, 177, 177, 177, 35, 401, 196, 70, 70, 65, 65, 428, 428, 428, 146, 146, 252, 314, 314, 32, 239, 420, 420, 420, 420, 422, 416, 239, 144, 144, 180, 106, 106, 426, 426, 426, 426, 426, 426, 282, 282, 303, 303, 193]
after is :
115
[17, 17, 296, 108, 108, 87, 87, 399, 399, 399, 70, 65, 70, 65, 284, 284, 306, 306, 306, 306, 406, 406, 406, 406, 467, 467, 16, 16, 88, 297, 293, 293, 293, 293, 89, 89, 89, 10, 10, 10, 443, 178, 443, 178, 178, 178, 178, 178, 178, 96, 96, 86, 86, 86, 272, 6, 93, 93, 93, 93, 93, 207, 3, 3, 464, 3, 177, 177, 177, 177, 177, 177, 177, 457, 457, 65, 457, 457, 146, 252, 252, 252, 252, 301, 301, 420, 420, 420, 420, 420, 420, 180, 27, 426, 426, 426, 426, 426, 426, 426, 282, 282, 388, 282, 282, 282, 282, 303, 303, 48, 48, 48, 48, 193, 193]
tensor([232], device='cuda:0', dtype=torch.int32)
text_len:232
prefix_len:116
