Current working directory: /home/v-zhijunjia/CodecGen
2024-01-20 12:35:58 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
/home/v-zhijunjia/miniconda3/envs/valle-4-23/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MiniBatchKMeans from version 0.24.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
only_antoregressive is True
add_prenet is False
only_antoregressive is True
add_prenet is False
self.ar_text_prenet : Identity()
add_prenet：False
  0%|          | 0/50 [00:00<?, ?it/s]processing 0th semantic_sys file
0
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
135
[17, 17, 20, 296, 7, 479, 331, 331, 463, 463, 378, 378, 88, 88, 141, 141, 281, 31, 54, 172, 344, 344, 344, 344, 274, 186, 162, 54, 482, 238, 6, 336, 79, 79, 487, 288, 290, 290, 290, 290, 434, 434, 434, 339, 64, 212, 77, 97, 483, 483, 440, 44, 255, 215, 129, 82, 82, 74, 190, 488, 488, 488, 405, 206, 169, 349, 349, 155, 29, 29, 313, 313, 24, 314, 90, 221, 401, 82, 445, 445, 210, 210, 210, 210, 210, 203, 53, 70, 230, 230, 230, 230, 215, 215, 35, 96, 401, 36, 377, 123, 123, 123, 236, 239, 310, 107, 395, 395, 329, 443, 443, 240, 285, 34, 374, 374, 374, 186, 162, 54, 54, 224, 273, 494, 494, 175, 175, 81, 459, 275, 275, 303, 48, 193, 193]
after is :
135
[17, 17, 296, 296, 331, 315, 463, 463, 463, 463, 280, 313, 29, 29, 280, 186, 29, 232, 382, 231, 232, 344, 344, 38, 344, 232, 232, 344, 162, 344, 162, 482, 482, 238, 161, 238, 487, 290, 487, 290, 487, 487, 434, 434, 64, 339, 64, 339, 64, 212, 310, 107, 44, 129, 190, 140, 259, 488, 190, 190, 206, 190, 405, 206, 405, 349, 352, 29, 469, 469, 313, 498, 469, 90, 90, 90, 90, 445, 140, 210, 210, 210, 210, 252, 53, 53, 230, 230, 230, 215, 230, 230, 140, 401, 140, 96, 377, 123, 123, 123, 310, 123, 329, 42, 42, 329, 374, 498, 329, 374, 374, 374, 374, 186, 374, 374, 54, 186, 54, 302, 175, 81, 81, 275, 275, 81, 81, 81, 275, 275, 381, 48, 48, 193, 193]
tensor([272], device='cuda:0', dtype=torch.int32)
text_len:272
prefix_len:136
第0个序列meet end_token: 1024
第0个序列end， 终止长度为135（包含终止符）
所有序列终止
133
torch.Size([1, 133, 16])
output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_9_epoch__topk_9_2024-01-20_20:35:55
sys_file:ASI_arctic_b0494
generate
  2%|▏         | 1/50 [00:28<23:21, 28.59s/it]processing 1th semantic_sys file
1
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
185
[17, 17, 296, 296, 5, 5, 5, 5, 455, 251, 251, 251, 431, 431, 428, 428, 428, 428, 146, 146, 146, 358, 358, 358, 173, 352, 352, 352, 352, 352, 197, 197, 197, 7, 32, 239, 384, 114, 0, 264, 264, 264, 264, 264, 468, 406, 42, 43, 345, 141, 141, 141, 141, 141, 281, 54, 54, 9, 58, 72, 72, 72, 110, 110, 443, 139, 139, 139, 122, 122, 143, 36, 472, 393, 393, 155, 262, 262, 262, 262, 262, 387, 387, 175, 175, 175, 335, 440, 440, 89, 446, 446, 94, 94, 199, 335, 440, 145, 415, 415, 415, 415, 35, 35, 26, 26, 26, 241, 81, 470, 443, 313, 313, 143, 36, 449, 34, 469, 469, 178, 416, 233, 401, 82, 401, 20, 32, 354, 159, 159, 159, 159, 236, 35, 35, 401, 401, 82, 20, 20, 377, 377, 374, 374, 374, 132, 132, 422, 236, 239, 310, 107, 107, 395, 395, 374, 374, 132, 88, 88, 81, 242, 116, 10, 10, 479, 331, 331, 265, 265, 265, 85, 85, 85, 207, 207, 207, 19, 19, 19, 19, 454, 193, 193, 17]
after is :
185
[17, 17, 296, 7, 140, 184, 7, 7, 7, 320, 5, 5, 5, 251, 251, 251, 251, 241, 251, 241, 428, 431, 428, 428, 428, 358, 428, 358, 352, 352, 352, 358, 82, 197, 114, 114, 127, 198, 0, 114, 264, 378, 245, 264, 141, 141, 141, 141, 141, 281, 345, 141, 54, 281, 281, 142, 142, 58, 142, 142, 142, 72, 72, 293, 293, 110, 393, 82, 122, 457, 262, 393, 262, 262, 262, 262, 262, 100, 262, 262, 182, 175, 497, 440, 335, 335, 89, 335, 199, 199, 199, 34, 440, 251, 94, 251, 164, 164, 255, 251, 469, 26, 251, 431, 164, 26, 164, 431, 469, 161, 469, 469, 469, 469, 458, 401, 143, 233, 197, 401, 192, 401, 159, 401, 401, 401, 159, 401, 82, 82, 140, 108, 108, 377, 108, 108, 108, 374, 374, 310, 239, 485, 107, 485, 374, 485, 236, 88, 88, 398, 132, 88, 331, 10, 199, 10, 479, 479, 479, 479, 479, 85, 265, 265, 85, 85, 207, 85, 98, 19, 454, 375, 454, 19, 98, 439, 78, 78, 78, 140, 140, 140, 244, 244, 193]
tensor([372], device='cuda:0', dtype=torch.int32)
text_len:372
prefix_len:186
第0个序列meet end_token: 1024
第0个序列end， 终止长度为185（包含终止符）
所有序列终止
183
torch.Size([1, 183, 16])
output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_9_epoch__topk_9_2024-01-20_20:35:55
sys_file:ASI_arctic_b0504
generate
  4%|▍         | 2/50 [01:13<30:26, 38.06s/it]processing 2th semantic_sys file
2
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
128
[17, 17, 296, 72, 72, 268, 268, 268, 293, 43, 43, 43, 345, 109, 109, 443, 443, 443, 240, 240, 175, 175, 219, 485, 485, 11, 11, 11, 116, 64, 212, 465, 26, 359, 359, 166, 166, 324, 324, 3, 3, 14, 259, 440, 287, 145, 111, 111, 443, 378, 378, 43, 345, 345, 109, 109, 432, 330, 330, 116, 64, 76, 82, 335, 483, 440, 145, 415, 415, 415, 415, 415, 35, 35, 34, 34, 191, 191, 191, 314, 314, 314, 32, 32, 32, 491, 384, 114, 180, 92, 92, 92, 92, 92, 240, 240, 35, 35, 96, 393, 205, 205, 261, 25, 148, 148, 498, 498, 498, 387, 271, 368, 368, 453, 54, 86, 238, 6, 82, 272, 41, 93, 93, 93, 19, 19, 193, 193]
after is :
128
[17, 17, 296, 296, 296, 184, 491, 373, 268, 373, 268, 268, 268, 268, 280, 109, 280, 486, 106, 293, 175, 139, 139, 293, 81, 81, 324, 469, 26, 11, 379, 457, 359, 324, 474, 359, 26, 166, 474, 324, 464, 324, 3, 324, 111, 324, 111, 111, 438, 85, 111, 438, 111, 438, 109, 364, 432, 276, 330, 432, 94, 432, 330, 330, 330, 415, 330, 440, 76, 415, 415, 415, 198, 415, 415, 92, 92, 35, 167, 114, 261, 457, 114, 457, 114, 92, 92, 261, 25, 234, 25, 25, 25, 25, 86, 261, 498, 498, 54, 186, 498, 313, 238, 86, 82, 86, 384, 93, 93, 93, 93, 93, 93, 93, 93, 454, 439, 439, 417, 439, 439, 78, 78, 237, 417, 140, 193, 17]
tensor([258], device='cuda:0', dtype=torch.int32)
text_len:258
prefix_len:130
第0个序列meet end_token: 1024
第0个序列end， 终止长度为128（包含终止符）
所有序列终止
126
torch.Size([1, 126, 16])
output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_9_epoch__topk_9_2024-01-20_20:35:55
sys_file:ASI_arctic_b0505
generate
  6%|▌         | 3/50 [01:37<24:41, 31.52s/it]processing 3th semantic_sys file
3
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
189
[17, 17, 20, 20, 296, 177, 177, 177, 177, 131, 133, 389, 389, 389, 389, 58, 58, 72, 72, 110, 110, 110, 443, 139, 139, 139, 293, 240, 215, 35, 35, 35, 197, 96, 401, 82, 108, 87, 87, 87, 87, 236, 129, 259, 82, 119, 180, 499, 265, 265, 85, 146, 146, 146, 146, 146, 252, 252, 24, 24, 472, 196, 196, 217, 429, 429, 429, 429, 429, 429, 246, 246, 246, 3, 3, 197, 226, 226, 82, 440, 287, 255, 255, 255, 251, 251, 241, 431, 235, 235, 235, 235, 235, 235, 235, 413, 348, 335, 14, 14, 440, 287, 319, 319, 348, 64, 212, 212, 384, 34, 278, 139, 251, 241, 431, 443, 443, 146, 438, 416, 416, 416, 239, 144, 106, 106, 91, 91, 91, 405, 206, 206, 240, 24, 35, 35, 478, 232, 232, 232, 238, 336, 272, 470, 470, 443, 240, 240, 24, 325, 41, 324, 324, 464, 464, 89, 446, 446, 203, 394, 76, 129, 82, 74, 425, 386, 386, 431, 265, 265, 480, 85, 299, 203, 203, 53, 53, 291, 291, 291, 275, 303, 303, 303, 48, 48, 193, 193, 193]
after is :
189
[17, 17, 296, 82, 188, 184, 140, 177, 177, 177, 177, 345, 389, 389, 58, 389, 58, 139, 110, 110, 486, 110, 139, 215, 202, 82, 82, 96, 215, 215, 35, 472, 472, 87, 377, 236, 377, 87, 236, 119, 108, 437, 129, 265, 265, 265, 265, 85, 85, 499, 85, 146, 399, 196, 399, 196, 429, 196, 429, 429, 3, 464, 429, 3, 429, 454, 246, 429, 14, 14, 255, 251, 319, 319, 235, 335, 431, 235, 241, 319, 235, 319, 235, 319, 440, 319, 319, 348, 348, 335, 431, 348, 235, 319, 348, 348, 348, 251, 348, 431, 319, 416, 106, 106, 153, 153, 251, 153, 153, 146, 153, 458, 438, 146, 153, 146, 146, 405, 153, 106, 232, 314, 172, 232, 232, 232, 41, 265, 232, 41, 232, 240, 85, 470, 470, 325, 41, 325, 406, 470, 41, 325, 240, 468, 468, 464, 147, 324, 464, 121, 121, 456, 74, 425, 74, 386, 425, 425, 425, 399, 386, 480, 480, 399, 85, 203, 469, 291, 469, 399, 291, 291, 291, 379, 379, 291, 291, 291, 303, 419, 82, 227, 78, 417, 417, 193, 193, 193, 17]
tensor([380], device='cuda:0', dtype=torch.int32)
text_len:380
prefix_len:190
第0个序列meet end_token: 1024
第0个序列end， 终止长度为189（包含终止符）
所有序列终止
187
torch.Size([1, 187, 16])
output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_9_epoch__topk_9_2024-01-20_20:35:55
sys_file:ASI_arctic_b0506
generate
  8%|▊         | 4/50 [02:23<28:48, 37.57s/it]processing 4th semantic_sys file
4
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
133
[17, 17, 491, 296, 373, 451, 451, 451, 30, 30, 464, 464, 254, 254, 254, 254, 240, 131, 393, 393, 234, 155, 25, 25, 148, 387, 387, 313, 313, 186, 349, 205, 205, 25, 29, 189, 189, 189, 313, 240, 240, 240, 325, 34, 257, 257, 257, 257, 31, 9, 9, 221, 239, 384, 371, 485, 485, 374, 374, 374, 132, 122, 35, 82, 449, 41, 41, 41, 324, 324, 3, 3, 335, 14, 440, 440, 89, 55, 446, 446, 67, 33, 394, 76, 129, 20, 354, 354, 470, 476, 171, 171, 171, 171, 171, 252, 24, 314, 35, 401, 401, 82, 74, 190, 441, 153, 153, 153, 153, 387, 387, 387, 387, 355, 37, 175, 359, 359, 359, 474, 474, 41, 41, 19, 19, 19, 454, 305, 128, 193, 193, 193, 17]
after is :
133
[17, 17, 296, 296, 296, 140, 491, 373, 373, 451, 451, 58, 58, 30, 254, 254, 58, 254, 90, 393, 393, 393, 393, 393, 205, 25, 393, 25, 25, 245, 349, 25, 234, 25, 261, 261, 25, 25, 261, 122, 25, 293, 139, 34, 122, 122, 34, 24, 257, 183, 9, 281, 9, 221, 82, 221, 82, 82, 221, 336, 374, 374, 395, 374, 374, 374, 285, 374, 41, 41, 41, 41, 3, 41, 3, 440, 440, 440, 440, 89, 67, 67, 33, 55, 394, 82, 259, 74, 351, 76, 476, 171, 476, 171, 171, 252, 24, 252, 314, 401, 401, 74, 74, 74, 74, 437, 74, 437, 424, 424, 424, 424, 424, 139, 81, 175, 359, 139, 474, 19, 19, 19, 19, 454, 454, 19, 19, 19, 237, 417, 491, 193, 17]
tensor([268], device='cuda:0', dtype=torch.int32)
text_len:268
prefix_len:134
第0个序列meet end_token: 1024
第0个序列end， 终止长度为134（包含终止符）
所有序列终止
132
torch.Size([1, 132, 16])
output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_9_epoch__topk_9_2024-01-20_20:35:55
sys_file:ASI_arctic_b0509
generate
 10%|█         | 5/50 [02:50<25:07, 33.50s/it]processing 5th semantic_sys file
5
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
115
[17, 17, 20, 20, 108, 377, 87, 87, 378, 399, 70, 70, 65, 65, 153, 481, 387, 387, 387, 240, 285, 34, 84, 302, 302, 293, 293, 14, 14, 14, 411, 287, 287, 284, 206, 206, 240, 348, 348, 196, 10, 309, 479, 331, 331, 443, 443, 178, 178, 35, 96, 96, 54, 54, 86, 6, 82, 272, 371, 93, 41, 41, 324, 324, 3, 3, 335, 14, 226, 440, 177, 177, 177, 177, 177, 35, 401, 196, 70, 70, 65, 65, 428, 428, 428, 146, 146, 252, 314, 314, 32, 239, 420, 420, 420, 420, 422, 416, 239, 144, 144, 180, 106, 106, 426, 426, 426, 426, 426, 426, 282, 282, 303, 303, 193]
after is :
115
[17, 17, 296, 296, 108, 87, 399, 491, 87, 399, 87, 70, 65, 399, 284, 284, 306, 306, 467, 406, 467, 467, 372, 467, 467, 14, 335, 16, 293, 293, 297, 450, 440, 94, 89, 89, 293, 446, 10, 10, 96, 178, 331, 178, 443, 178, 96, 443, 232, 54, 232, 232, 54, 6, 272, 272, 272, 93, 93, 93, 3, 207, 207, 207, 177, 3, 177, 3, 3, 177, 177, 177, 177, 473, 476, 217, 457, 389, 457, 428, 457, 457, 301, 457, 301, 420, 420, 239, 420, 82, 144, 464, 27, 464, 106, 426, 426, 426, 426, 426, 282, 282, 282, 282, 282, 426, 282, 117, 388, 48, 78, 303, 491, 193, 193]
tensor([232], device='cuda:0', dtype=torch.int32)
text_len:232
prefix_len:116
第0个序列meet end_token: 1024
第0个序列end， 终止长度为115（包含终止符）
所有序列终止
113
torch.Size([1, 113, 16])
output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_9_epoch__topk_9_2024-01-20_20:35:55
sys_file:ASI_arctic_b0514
generate
 12%|█▏        | 6/50 [03:10<21:14, 28.97s/it]processing 6th semantic_sys file
6
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
207
[17, 20, 296, 296, 66, 68, 68, 115, 267, 267, 329, 301, 175, 175, 423, 423, 423, 486, 486, 460, 240, 240, 285, 34, 34, 177, 236, 251, 251, 241, 431, 431, 376, 376, 376, 376, 460, 146, 178, 96, 96, 39, 86, 238, 6, 272, 472, 156, 156, 156, 156, 156, 313, 186, 186, 162, 232, 172, 172, 115, 273, 106, 106, 153, 153, 153, 387, 387, 387, 372, 406, 245, 245, 399, 399, 217, 70, 70, 65, 284, 284, 284, 315, 450, 450, 450, 450, 274, 274, 122, 24, 35, 82, 227, 97, 483, 197, 197, 7, 251, 251, 241, 235, 235, 235, 235, 235, 235, 235, 235, 200, 200, 200, 464, 188, 340, 116, 94, 94, 331, 230, 230, 230, 230, 169, 402, 402, 402, 401, 82, 377, 87, 87, 87, 186, 186, 162, 482, 172, 115, 273, 273, 265, 265, 265, 85, 85, 146, 146, 58, 58, 183, 156, 156, 156, 156, 271, 31, 162, 342, 342, 115, 273, 145, 151, 240, 240, 314, 239, 469, 469, 469, 31, 9, 142, 221, 20, 261, 25, 470, 470, 486, 486, 486, 460, 460, 178, 178, 178, 96, 96, 99, 436, 436, 436, 60, 60, 298, 298, 298, 303, 303, 303, 48, 193, 193, 17]
after is :
207
[17, 17, 296, 296, 66, 66, 66, 68, 115, 115, 273, 115, 273, 444, 251, 464, 175, 423, 251, 423, 423, 423, 423, 175, 423, 81, 423, 423, 251, 423, 240, 251, 251, 241, 241, 251, 241, 241, 376, 431, 376, 376, 376, 431, 96, 178, 96, 150, 96, 272, 82, 272, 140, 140, 272, 156, 156, 156, 38, 162, 482, 38, 106, 106, 38, 172, 115, 106, 172, 70, 482, 65, 70, 70, 217, 65, 217, 306, 65, 473, 65, 65, 450, 315, 274, 450, 315, 315, 26, 251, 315, 7, 82, 251, 235, 241, 251, 431, 7, 235, 235, 235, 235, 235, 235, 235, 235, 235, 116, 235, 200, 116, 200, 199, 94, 230, 230, 169, 352, 75, 230, 87, 230, 402, 377, 82, 87, 87, 87, 87, 87, 172, 172, 232, 106, 68, 265, 273, 68, 265, 146, 146, 265, 183, 146, 58, 58, 59, 59, 58, 186, 162, 162, 162, 31, 342, 54, 31, 342, 115, 342, 240, 240, 240, 240, 240, 34, 393, 469, 261, 25, 234, 25, 470, 142, 178, 470, 460, 178, 460, 458, 178, 178, 96, 178, 436, 298, 60, 96, 60, 436, 298, 298, 436, 298, 298, 117, 117, 117, 417, 82, 417, 128, 421, 244, 193, 17]
tensor([416], device='cuda:0', dtype=torch.int32)
text_len:416
prefix_len:208
第0个序列meet end_token: 1024
第0个序列end， 终止长度为207（包含终止符）
所有序列终止
205
torch.Size([1, 205, 16])
output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_9_epoch__topk_9_2024-01-20_20:35:55
sys_file:ASI_arctic_b0516
generate
 14%|█▍        | 7/50 [04:06<27:11, 37.94s/it]processing 7th semantic_sys file
7
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
188
[17, 17, 296, 296, 114, 45, 45, 240, 285, 34, 111, 151, 151, 240, 99, 99, 436, 436, 395, 395, 242, 242, 116, 33, 250, 217, 398, 398, 398, 374, 374, 368, 368, 368, 453, 168, 469, 469, 469, 143, 143, 35, 401, 259, 354, 425, 359, 286, 286, 286, 286, 286, 464, 464, 355, 355, 355, 355, 37, 173, 197, 197, 198, 198, 22, 283, 455, 455, 143, 129, 129, 401, 82, 144, 27, 180, 284, 284, 315, 315, 315, 450, 450, 450, 450, 413, 413, 413, 64, 64, 243, 243, 36, 36, 227, 227, 227, 419, 419, 419, 439, 427, 56, 247, 312, 126, 23, 23, 23, 101, 391, 391, 491, 20, 491, 20, 320, 345, 345, 141, 141, 141, 141, 281, 281, 453, 168, 168, 44, 44, 240, 285, 335, 14, 14, 411, 411, 153, 153, 274, 8, 8, 354, 485, 213, 213, 252, 252, 24, 239, 371, 324, 324, 464, 11, 11, 11, 330, 116, 33, 394, 77, 478, 232, 232, 172, 86, 26, 26, 251, 241, 81, 444, 444, 171, 171, 246, 246, 19, 19, 19, 173, 173, 352, 352, 193, 193, 17]
after is :
188
[17, 17, 296, 296, 82, 7, 373, 7, 114, 127, 127, 127, 151, 240, 240, 5, 5, 285, 14, 169, 169, 99, 169, 436, 99, 169, 169, 99, 169, 99, 242, 330, 196, 278, 196, 99, 368, 196, 278, 94, 278, 368, 242, 278, 368, 368, 368, 368, 278, 494, 82, 278, 494, 286, 386, 485, 485, 425, 485, 431, 464, 324, 264, 59, 286, 474, 3, 468, 59, 3, 59, 216, 452, 3, 283, 198, 283, 458, 458, 458, 82, 144, 27, 82, 27, 27, 351, 351, 351, 27, 315, 315, 450, 450, 450, 450, 36, 64, 397, 419, 397, 397, 133, 397, 397, 397, 397, 141, 345, 141, 141, 141, 141, 141, 345, 44, 281, 168, 44, 255, 168, 168, 106, 168, 44, 496, 274, 8, 44, 82, 274, 496, 255, 255, 82, 213, 213, 213, 213, 324, 324, 11, 324, 324, 11, 379, 379, 324, 464, 11, 379, 478, 162, 26, 431, 241, 241, 241, 241, 241, 251, 444, 444, 251, 431, 431, 403, 358, 207, 173, 173, 173, 352, 358, 173, 352, 352, 352, 439, 439, 237, 78, 82, 78, 193, 193, 193, 193]
tensor([378], device='cuda:0', dtype=torch.int32)
text_len:378
prefix_len:190
第0个序列meet end_token: 1024
第0个序列end， 终止长度为187（包含终止符）
所有序列终止
185
torch.Size([1, 185, 16])
output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_9_epoch__topk_9_2024-01-20_20:35:55
sys_file:ASI_arctic_b0523
generate
 16%|█▌        | 8/50 [04:53<28:34, 40.82s/it]processing 8th semantic_sys file
8
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
161
[17, 17, 296, 320, 5, 5, 5, 455, 455, 280, 104, 104, 104, 443, 240, 240, 337, 337, 324, 324, 3, 335, 14, 14, 145, 145, 145, 428, 428, 146, 146, 252, 24, 325, 34, 324, 324, 464, 464, 355, 355, 355, 14, 14, 14, 14, 82, 411, 287, 405, 405, 169, 169, 349, 352, 352, 29, 29, 277, 277, 313, 385, 24, 35, 36, 131, 133, 133, 364, 345, 141, 141, 141, 141, 141, 281, 31, 54, 54, 142, 142, 142, 221, 336, 336, 197, 80, 80, 20, 491, 82, 74, 190, 487, 288, 288, 213, 324, 301, 301, 143, 129, 259, 74, 354, 153, 153, 153, 387, 387, 387, 387, 274, 186, 162, 54, 54, 86, 238, 6, 336, 272, 377, 123, 123, 374, 406, 406, 467, 459, 459, 271, 271, 31, 39, 39, 390, 390, 390, 390, 390, 390, 390, 160, 18, 18, 18, 18, 18, 112, 112, 112, 237, 237, 439, 78, 128, 491, 491, 193, 17]
after is :
161
[17, 17, 296, 296, 320, 412, 7, 127, 4, 127, 127, 127, 455, 5, 4, 4, 4, 104, 104, 280, 104, 264, 337, 468, 468, 337, 468, 3, 3, 85, 3, 411, 146, 3, 85, 239, 371, 371, 324, 239, 236, 428, 239, 14, 213, 239, 324, 371, 464, 411, 464, 145, 3, 423, 145, 14, 335, 349, 440, 352, 277, 349, 352, 277, 280, 277, 277, 469, 325, 325, 131, 131, 227, 345, 345, 345, 364, 345, 345, 345, 141, 345, 141, 345, 141, 141, 9, 82, 190, 190, 142, 74, 142, 74, 74, 488, 488, 74, 190, 74, 129, 82, 441, 74, 441, 82, 74, 74, 82, 82, 82, 437, 496, 6, 318, 6, 54, 496, 496, 82, 377, 377, 236, 123, 123, 377, 123, 123, 487, 377, 123, 108, 377, 123, 123, 123, 459, 459, 334, 487, 123, 271, 459, 459, 54, 390, 185, 271, 390, 39, 18, 439, 18, 18, 112, 237, 417, 128, 193, 244, 193]
tensor([324], device='cuda:0', dtype=torch.int32)
text_len:324
prefix_len:162
第0个序列meet end_token: 1024
第0个序列end， 终止长度为162（包含终止符）
所有序列终止
160
torch.Size([1, 160, 16])
output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_9_epoch__topk_9_2024-01-20_20:35:55
sys_file:ASI_arctic_b0527
generate
 18%|█▊        | 9/50 [05:29<26:51, 39.30s/it]processing 9th semantic_sys file
9
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
82
[17, 17, 17, 20, 108, 119, 180, 486, 486, 486, 85, 146, 146, 438, 169, 349, 349, 205, 261, 25, 148, 148, 148, 387, 387, 372, 396, 467, 277, 277, 37, 24, 239, 131, 419, 419, 439, 225, 225, 225, 225, 20, 20, 7, 7, 7, 127, 430, 430, 430, 325, 34, 114, 443, 443, 240, 240, 236, 35, 259, 108, 119, 470, 278, 278, 139, 175, 175, 219, 219, 219, 477, 477, 477, 477, 132, 132, 98, 13, 13, 193, 193]
after is :
82
[17, 17, 17, 107, 107, 107, 184, 289, 140, 320, 306, 306, 306, 106, 146, 245, 349, 464, 349, 349, 245, 155, 25, 205, 372, 25, 205, 385, 396, 457, 82, 325, 225, 457, 385, 430, 140, 430, 430, 239, 82, 314, 0, 0, 114, 216, 216, 0, 114, 127, 313, 114, 119, 293, 82, 36, 119, 443, 443, 139, 293, 139, 293, 81, 81, 477, 219, 219, 219, 477, 477, 477, 477, 132, 132, 13, 132, 98, 98, 98, 225, 193]
tensor([166], device='cuda:0', dtype=torch.int32)
text_len:166
prefix_len:84
第0个序列meet end_token: 1024
第0个序列end， 终止长度为81（包含终止符）
所有序列终止
79
torch.Size([1, 79, 16])
output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_9_epoch__topk_9_2024-01-20_20:35:55
sys_file:ASI_arctic_b0536
generate
 20%|██        | 10/50 [05:41<20:36, 30.90s/it]processing 10th semantic_sys file
10
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
200
[17, 17, 296, 140, 320, 7, 7, 7, 7, 127, 127, 114, 430, 430, 71, 71, 368, 281, 453, 9, 183, 183, 451, 30, 30, 30, 30, 422, 236, 129, 82, 108, 119, 308, 308, 308, 308, 308, 308, 308, 308, 313, 348, 64, 212, 212, 22, 283, 283, 455, 236, 236, 129, 401, 140, 384, 119, 470, 432, 432, 330, 94, 94, 94, 199, 199, 120, 120, 275, 304, 379, 379, 243, 77, 269, 54, 172, 224, 351, 89, 89, 322, 67, 394, 394, 239, 310, 107, 395, 180, 180, 284, 284, 206, 206, 240, 34, 416, 416, 416, 192, 242, 242, 116, 94, 199, 69, 462, 462, 130, 402, 402, 66, 482, 172, 115, 273, 470, 403, 171, 171, 422, 143, 458, 82, 144, 208, 106, 106, 481, 481, 481, 206, 206, 240, 175, 122, 122, 24, 310, 107, 107, 219, 219, 477, 477, 477, 477, 301, 301, 8, 32, 32, 354, 354, 180, 376, 376, 376, 376, 460, 178, 143, 458, 144, 27, 106, 125, 125, 125, 125, 348, 33, 33, 394, 217, 217, 473, 429, 429, 429, 429, 429, 429, 246, 246, 246, 19, 19, 19, 19, 19, 454, 454, 454, 78, 140, 140, 193, 17]
after is :
200
[17, 17, 296, 296, 140, 7, 7, 82, 7, 127, 7, 430, 127, 114, 430, 114, 169, 54, 342, 54, 451, 183, 451, 30, 30, 422, 422, 82, 129, 108, 82, 119, 82, 308, 308, 308, 308, 396, 308, 313, 308, 131, 388, 131, 64, 198, 22, 22, 283, 455, 351, 351, 119, 351, 351, 351, 119, 351, 330, 432, 432, 432, 388, 330, 195, 195, 195, 195, 195, 195, 195, 433, 269, 390, 54, 269, 483, 226, 394, 82, 483, 97, 83, 83, 83, 394, 107, 394, 405, 180, 180, 206, 306, 206, 416, 178, 306, 178, 306, 192, 206, 178, 192, 94, 199, 199, 69, 335, 199, 402, 402, 130, 94, 130, 280, 130, 273, 130, 143, 172, 115, 171, 232, 172, 172, 143, 273, 192, 481, 481, 481, 481, 437, 481, 437, 236, 293, 82, 206, 481, 310, 122, 107, 8, 8, 8, 354, 477, 219, 324, 301, 180, 376, 354, 376, 354, 180, 180, 376, 180, 180, 178, 354, 354, 180, 192, 192, 192, 125, 125, 206, 250, 33, 33, 473, 33, 429, 429, 473, 217, 429, 429, 429, 473, 429, 429, 429, 19, 19, 19, 19, 454, 454, 82, 454, 454, 128, 193, 244, 193]
tensor([402], device='cuda:0', dtype=torch.int32)
text_len:402
prefix_len:201
第0个序列meet end_token: 1024
第0个序列end， 终止长度为200（包含终止符）
所有序列终止
198
torch.Size([1, 198, 16])
output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_9_epoch__topk_9_2024-01-20_20:35:55
sys_file:KSP_arctic_b0492
generate
 22%|██▏       | 11/50 [06:34<24:25, 37.56s/it]processing 11th semantic_sys file
11
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
190
[17, 17, 17, 296, 412, 412, 287, 287, 111, 111, 111, 438, 438, 422, 422, 162, 232, 232, 172, 172, 115, 273, 470, 443, 120, 240, 240, 24, 314, 314, 239, 36, 335, 483, 440, 440, 287, 89, 89, 446, 446, 67, 64, 212, 212, 384, 490, 490, 490, 490, 31, 232, 54, 142, 142, 196, 196, 217, 473, 65, 278, 278, 368, 31, 54, 54, 238, 6, 82, 272, 114, 283, 255, 455, 399, 217, 70, 473, 65, 65, 486, 486, 460, 460, 240, 143, 36, 82, 449, 300, 300, 334, 355, 355, 355, 406, 335, 440, 440, 83, 253, 253, 253, 253, 253, 453, 453, 221, 196, 479, 479, 307, 307, 307, 307, 61, 167, 35, 35, 36, 133, 133, 364, 276, 181, 181, 181, 240, 285, 402, 401, 401, 401, 401, 82, 82, 108, 119, 351, 351, 360, 360, 360, 200, 76, 458, 458, 192, 176, 176, 135, 135, 200, 200, 200, 464, 255, 255, 255, 8, 8, 354, 354, 106, 113, 113, 113, 113, 113, 113, 113, 274, 413, 413, 233, 233, 233, 140, 227, 227, 419, 439, 439, 439, 78, 140, 140, 140, 193, 17]
after is :
190
[17, 17, 17, 296, 287, 296, 82, 287, 209, 111, 287, 422, 438, 438, 162, 186, 162, 422, 68, 68, 68, 68, 273, 443, 68, 273, 68, 240, 273, 240, 240, 460, 37, 483, 240, 440, 89, 335, 89, 446, 446, 89, 212, 33, 212, 212, 394, 116, 490, 258, 250, 31, 490, 490, 31, 490, 490, 258, 196, 196, 278, 473, 473, 258, 258, 258, 258, 196, 238, 217, 473, 258, 473, 217, 258, 258, 473, 217, 217, 217, 70, 217, 65, 217, 473, 65, 65, 217, 460, 460, 334, 300, 460, 285, 59, 59, 59, 59, 440, 467, 253, 253, 440, 253, 253, 253, 9, 483, 9, 479, 9, 307, 196, 281, 307, 61, 457, 307, 479, 307, 181, 364, 61, 133, 181, 402, 276, 364, 276, 181, 276, 401, 82, 181, 164, 396, 164, 164, 164, 164, 214, 360, 360, 360, 360, 76, 176, 328, 464, 328, 200, 200, 200, 200, 335, 200, 200, 255, 354, 255, 354, 8, 354, 145, 113, 180, 180, 233, 113, 113, 180, 113, 450, 413, 82, 413, 450, 419, 419, 227, 439, 82, 439, 78, 421, 417, 244, 244, 193, 193]
tensor([382], device='cuda:0', dtype=torch.int32)
text_len:382
prefix_len:191
第0个序列meet end_token: 1024
第0个序列end， 终止长度为191（包含终止符）
所有序列终止
189
torch.Size([1, 189, 16])
output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_9_epoch__topk_9_2024-01-20_20:35:55
sys_file:KSP_arctic_b0499
generate
 24%|██▍       | 12/50 [07:22<25:53, 40.88s/it]processing 12th semantic_sys file
12
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
202
[17, 17, 17, 140, 188, 177, 177, 177, 177, 177, 36, 131, 133, 133, 345, 389, 389, 389, 389, 131, 58, 58, 72, 72, 110, 110, 443, 443, 240, 252, 252, 215, 215, 401, 401, 96, 140, 140, 377, 87, 87, 87, 87, 236, 129, 82, 384, 180, 265, 265, 428, 146, 146, 146, 252, 252, 314, 314, 32, 196, 196, 429, 429, 429, 429, 429, 429, 429, 246, 246, 3, 3, 335, 440, 255, 255, 255, 255, 251, 241, 431, 431, 235, 235, 235, 235, 235, 235, 235, 235, 413, 200, 200, 303, 117, 335, 335, 440, 440, 287, 89, 55, 55, 322, 67, 64, 76, 239, 82, 384, 470, 278, 278, 139, 139, 251, 241, 431, 111, 111, 111, 438, 438, 301, 416, 416, 144, 27, 106, 106, 306, 306, 306, 396, 313, 143, 131, 162, 54, 232, 482, 238, 6, 272, 470, 470, 151, 240, 325, 325, 41, 324, 324, 324, 3, 3, 3, 3, 440, 188, 188, 121, 121, 121, 121, 53, 76, 259, 74, 425, 425, 386, 499, 265, 428, 85, 146, 146, 203, 399, 291, 291, 291, 291, 291, 291, 303, 243, 243, 243, 82, 75, 227, 419, 439, 439, 439, 237, 193, 140, 193, 17]
after is :
202
[17, 17, 140, 296, 82, 188, 209, 188, 177, 188, 177, 177, 133, 177, 345, 457, 389, 389, 389, 389, 58, 58, 110, 58, 110, 110, 486, 460, 110, 215, 215, 215, 82, 215, 96, 96, 96, 82, 82, 87, 108, 87, 265, 108, 437, 82, 108, 265, 119, 265, 85, 146, 265, 399, 399, 146, 399, 146, 429, 429, 196, 429, 429, 429, 464, 464, 429, 464, 440, 431, 251, 255, 251, 426, 235, 235, 241, 235, 200, 413, 235, 413, 235, 200, 195, 413, 413, 195, 413, 117, 117, 413, 404, 404, 440, 226, 440, 446, 83, 83, 89, 322, 55, 108, 76, 108, 139, 351, 139, 351, 139, 351, 175, 111, 111, 111, 111, 111, 111, 111, 111, 416, 111, 111, 111, 438, 422, 111, 416, 180, 438, 180, 405, 167, 405, 206, 232, 405, 405, 232, 232, 232, 6, 162, 238, 240, 238, 285, 41, 406, 467, 406, 406, 468, 337, 337, 3, 3, 3, 340, 440, 188, 121, 121, 188, 74, 394, 425, 121, 425, 425, 386, 387, 387, 65, 469, 65, 146, 291, 291, 473, 291, 291, 291, 291, 291, 379, 291, 379, 243, 243, 419, 439, 439, 439, 439, 82, 421, 128, 193, 193, 193]
tensor([406], device='cuda:0', dtype=torch.int32)
text_len:406
prefix_len:203
第0个序列meet end_token: 1024
第0个序列end， 终止长度为203（包含终止符）
所有序列终止
201
torch.Size([1, 201, 16])
output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_9_epoch__topk_9_2024-01-20_20:35:55
sys_file:KSP_arctic_b0506
generate
 26%|██▌       | 13/50 [08:17<27:45, 45.00s/it]processing 13th semantic_sys file
13
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
140
[17, 17, 17, 140, 140, 127, 87, 87, 132, 43, 399, 70, 70, 65, 65, 65, 284, 284, 481, 240, 240, 285, 406, 467, 84, 302, 302, 274, 274, 98, 335, 14, 14, 287, 287, 287, 284, 353, 206, 240, 313, 313, 236, 196, 10, 94, 331, 331, 443, 443, 178, 178, 458, 96, 96, 54, 54, 86, 86, 6, 336, 384, 384, 93, 93, 93, 93, 93, 93, 207, 207, 207, 207, 207, 188, 177, 177, 177, 177, 82, 401, 401, 196, 217, 70, 65, 65, 428, 428, 428, 428, 146, 146, 252, 143, 36, 131, 183, 183, 183, 183, 451, 451, 30, 30, 30, 324, 301, 301, 416, 416, 239, 144, 27, 106, 106, 106, 426, 426, 426, 426, 426, 426, 426, 282, 282, 388, 388, 303, 303, 303, 303, 117, 48, 48, 417, 193, 140, 140, 193]
after is :
140
[17, 17, 17, 296, 491, 184, 184, 108, 108, 377, 108, 377, 377, 399, 473, 217, 255, 65, 284, 284, 284, 306, 406, 467, 306, 306, 306, 467, 467, 84, 467, 88, 84, 274, 88, 88, 440, 274, 353, 88, 88, 313, 94, 10, 10, 309, 331, 331, 443, 443, 443, 331, 86, 342, 178, 96, 54, 86, 86, 86, 86, 238, 238, 82, 6, 6, 93, 93, 93, 93, 93, 207, 207, 207, 207, 19, 3, 188, 335, 385, 188, 188, 217, 188, 385, 457, 217, 217, 70, 217, 65, 428, 146, 65, 146, 217, 428, 146, 358, 358, 301, 183, 30, 451, 451, 30, 30, 301, 239, 144, 416, 144, 27, 27, 106, 426, 426, 426, 426, 426, 426, 426, 282, 282, 282, 282, 282, 303, 303, 117, 303, 404, 48, 417, 439, 128, 78, 140, 193, 193]
tensor([282], device='cuda:0', dtype=torch.int32)
text_len:282
prefix_len:141
第0个序列meet end_token: 1024
第0个序列end， 终止长度为141（包含终止符）
所有序列终止
139
torch.Size([1, 139, 16])
output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_9_epoch__topk_9_2024-01-20_20:35:55
sys_file:KSP_arctic_b0514
generate
 28%|██▊       | 14/50 [08:46<24:03, 40.09s/it]processing 14th semantic_sys file
14
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
130
[17, 17, 17, 296, 296, 7, 8, 159, 159, 159, 159, 313, 314, 233, 82, 131, 483, 14, 14, 287, 287, 287, 287, 287, 284, 284, 284, 206, 175, 251, 122, 212, 34, 288, 288, 288, 288, 24, 34, 166, 166, 324, 324, 324, 3, 58, 183, 183, 183, 451, 451, 30, 286, 286, 286, 264, 264, 264, 468, 468, 313, 313, 24, 90, 90, 143, 82, 140, 144, 27, 370, 370, 370, 53, 53, 394, 76, 129, 82, 74, 441, 441, 153, 153, 387, 387, 387, 368, 368, 453, 9, 238, 272, 272, 183, 183, 57, 57, 203, 53, 394, 394, 465, 162, 54, 172, 273, 279, 279, 279, 279, 279, 279, 279, 37, 358, 352, 352, 352, 352, 352, 352, 352, 112, 439, 417, 417, 193, 193, 193]
after is :
130
[17, 17, 244, 296, 296, 184, 184, 289, 159, 7, 159, 159, 335, 159, 159, 159, 167, 457, 14, 14, 411, 297, 297, 293, 42, 293, 42, 297, 288, 293, 297, 147, 288, 288, 288, 443, 288, 324, 324, 443, 325, 324, 451, 41, 324, 3, 324, 183, 183, 183, 451, 110, 254, 254, 58, 82, 254, 143, 144, 458, 27, 27, 27, 144, 121, 121, 27, 27, 27, 76, 76, 394, 76, 76, 437, 74, 496, 496, 496, 496, 496, 368, 496, 274, 238, 6, 86, 9, 272, 86, 57, 394, 232, 478, 478, 232, 68, 172, 394, 172, 273, 115, 279, 279, 279, 279, 279, 279, 279, 169, 279, 349, 352, 352, 352, 352, 352, 112, 439, 352, 82, 439, 421, 305, 78, 128, 128, 140, 193, 193]
tensor([262], device='cuda:0', dtype=torch.int32)
text_len:262
prefix_len:131
第0个序列meet end_token: 1024
第0个序列end， 终止长度为131（包含终止符）
所有序列终止
129
torch.Size([1, 129, 16])
output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_9_epoch__topk_9_2024-01-20_20:35:55
sys_file:KSP_arctic_b0515
generate
 30%|███       | 15/50 [09:11<20:47, 35.64s/it]processing 15th semantic_sys file
15
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
153
[17, 17, 20, 296, 296, 7, 7, 8, 354, 159, 159, 159, 159, 313, 313, 24, 314, 32, 32, 239, 127, 114, 0, 0, 0, 240, 285, 380, 380, 141, 141, 141, 281, 281, 453, 168, 106, 106, 297, 297, 297, 293, 293, 122, 122, 186, 478, 54, 54, 273, 494, 153, 387, 313, 313, 129, 129, 140, 384, 119, 106, 405, 405, 405, 405, 206, 178, 178, 458, 140, 192, 192, 69, 69, 223, 223, 130, 130, 402, 402, 402, 397, 133, 345, 407, 407, 407, 143, 36, 310, 107, 447, 221, 221, 458, 144, 27, 190, 487, 487, 499, 486, 486, 486, 486, 460, 460, 460, 460, 169, 352, 352, 352, 402, 96, 82, 131, 340, 340, 340, 466, 466, 22, 22, 283, 455, 455, 4, 280, 280, 278, 278, 278, 278, 175, 81, 81, 278, 120, 120, 120, 37, 37, 37, 24, 310, 310, 310, 107, 107, 18, 193, 193]
after is :
153
[17, 17, 296, 296, 296, 184, 159, 140, 159, 159, 159, 159, 159, 401, 82, 127, 127, 114, 0, 245, 0, 0, 345, 141, 245, 345, 141, 281, 141, 141, 168, 168, 297, 297, 14, 297, 106, 293, 297, 273, 172, 293, 273, 273, 273, 224, 494, 82, 494, 236, 36, 274, 274, 119, 129, 119, 108, 82, 351, 405, 82, 206, 178, 206, 82, 440, 192, 192, 440, 192, 130, 345, 458, 130, 397, 402, 345, 345, 407, 107, 221, 310, 82, 221, 144, 458, 82, 380, 190, 487, 487, 487, 380, 460, 486, 460, 499, 460, 460, 460, 352, 349, 169, 483, 82, 89, 340, 188, 483, 466, 340, 22, 466, 116, 22, 22, 283, 22, 283, 280, 455, 280, 455, 455, 278, 278, 278, 81, 278, 81, 24, 120, 81, 37, 469, 310, 107, 107, 310, 107, 24, 390, 439, 310, 112, 78, 439, 112, 237, 237, 439, 193, 193]
tensor([308], device='cuda:0', dtype=torch.int32)
text_len:308
prefix_len:154
第0个序列meet end_token: 1024
第0个序列end， 终止长度为154（包含终止符）
所有序列终止
152
torch.Size([1, 152, 16])
output_dir is /home/v-zhijunjia/zhijundata_small_v2/data_local/accent_wer/val_ac_models/converted_can_del/valle_nar_ac_9_epoch__topk_9_2024-01-20_20:35:55
sys_file:KSP_arctic_b0518
generate
 32%|███▏      | 16/50 [09:44<19:40, 34.73s/it]processing 16th semantic_sys file
16
args.target_mode==1 or args.target_mode==2
semantic nums is 1
txt2semantic need prompt
before_semantic:
107
[17, 17, 296, 140, 140, 144, 27, 106, 319, 319, 203, 203, 53, 88, 88, 106, 426, 426, 426, 426, 426, 426, 426, 282, 282, 388, 195, 303, 303, 303, 303, 303, 303, 303, 195, 195, 7, 7, 212, 239, 384, 384, 180, 443, 443, 240, 240, 251, 251, 301, 196, 217, 217, 70, 70, 65, 256, 256, 256, 256, 256, 256, 256, 240, 285, 313, 472, 143, 401, 82, 36, 310, 107, 395, 119, 351, 351, 486, 486, 486, 240, 175, 175, 81, 81, 432, 432, 290, 290, 434, 339, 339, 243, 243, 310, 310, 107, 447, 447, 238, 6, 82, 227, 227, 419, 193, 193]
after is :
107
[17, 17, 144, 296, 27, 27, 27, 437, 27, 319, 27, 351, 399, 426, 426, 203, 426, 319, 426, 426, 426, 426, 426, 282, 282, 426, 117, 303, 303, 195, 195, 225, 225, 197, 197, 384, 384, 371, 371, 293, 139, 293, 180, 180, 371, 139, 293, 139, 293, 329, 53, 293, 153, 497, 313, 36, 256, 143, 82, 236, 82, 310, 143, 107, 82, 395, 351, 351, 486, 486, 180, 107, 351, 351, 175, 175, 139, 81, 81, 175, 290, 81, 175, 81, 81, 195, 195, 195, 24, 303, 243, 310, 107, 310, 243, 447, 112, 447, 447, 439, 82, 78, 419, 128, 128, 193, 193]
tensor([216], device='cuda:0', dtype=torch.int32)
text_len:216
prefix_len:108
